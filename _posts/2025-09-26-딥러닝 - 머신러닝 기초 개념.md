---
layout: post
title: 딥러닝 - 머신러닝 기초 개념
date: 2025-09-26 22:25:23 +0900
category: 딥러닝
---
# 1.1 머신러닝 기초 개념

## A. 학습 패러다임 한눈에 보기

### A-1. 지도학습(Supervised Learning)
- **정의:** 입력 $$\mathbf{x}$$와 **정답 라벨** $$y$$ 가 쌍으로 주어질 때, $$f_\theta(\mathbf{x}) \approx y$$ 를 학습.
- **목표 함수(경험적 위험 최소화):**
  $$
  \min_{\theta} \ \mathcal{R}_{\mathrm{emp}}(\theta)
  = \frac{1}{N}\sum_{i=1}^{N} \ell\big(f_\theta(\mathbf{x}_i), y_i\big)
  $$
  여기서 $$\ell(\cdot,\cdot)$$ 은 손실함수(예: 분류는 Cross-Entropy, 회귀는 MSE).

- **예:** 고양이/개 분류, 가격 회귀, 결함 여부 판별.

### A-2. 비지도학습(Unsupervised Learning)
- **정의:** **라벨 없이** 입력만 $$\{\mathbf{x}_i\}$$ 주어질 때 구조나 분포를 파악(군집화, 차원축소, 밀도추정 등).
- **대표 과제:** K-Means, PCA, 오토인코더(AE)로 임베딩 학습, 이상치 탐지.

### A-3. 자기지도학습(Self-Supervised Learning, SSL)
- **정의:** 데이터 자체에서 **자기표현/가짜 라벨**을 만들어 학습(프리텍스트 과제). 라벨이 없이도 표현을 얻고, 다운스트림(지도) 과제에 전이.
- **대표 과제:** 마스크드 토큰 예측(BERT류), 대조학습(InfoNCE/SimCLR), 이미지 회전 예측, 패치 순서 맞추기.

---

## B. 일반화(Generalization), 과적합/과소적합, 편향–분산

### B-1. 일반화와 일반화 갭
- **일반화:** 훈련에 보지 않은 데이터에서도 낮은 오류를 보이는 성질.
- **일반화 갭:**  
  $$
  \mathrm{Gap} = \mathcal{L}_{\text{test}}(\hat\theta) - \mathcal{L}_{\text{train}}(\hat\theta)
  $$
  작을수록 좋다.

### B-2. 과소적합(Underfitting) vs 과적합(Overfitting)
- **과소적합:** 모델이 너무 단순하거나 학습이 부족 → 훈련/검증 모두 성능 낮음.
- **과적합:** 모델이 너무 복잡하거나 규제가 부족 → 훈련 성능은 좋지만 검증/테스트 성능 나쁨.

### B-3. 편향–분산 트레이드오프
- **예측 오차 분해(개념식):**
  $$
  \mathbb{E}_{\mathcal{D}}\!\big[(\hat f(\mathbf{x}) - f(\mathbf{x}))^2\big]
  = \big(\mathrm{Bias}[\hat f(\mathbf{x})]\big)^2
  + \mathrm{Var}[\hat f(\mathbf{x})]
  + \sigma^2
  $$
  - **Bias(편향):** 모델의 체계적 오차(너무 단순하면 큼)
  - **Var(분산):** 데이터 변동에 대한 민감도(너무 복잡하면 큼)
  - **\(\sigma^2\):** 데이터 고유 잡음(줄이기 어려움)

---

## C. 데이터 분리: 학습/검증/테스트

### C-1. 왜 3-way split이 필요한가
- **Train(학습):** 파라미터 업데이트에 사용
- **Validation(검증):** 하이퍼파라미터/조기 종료/모델 선택
- **Test(테스트):** **최종 성능** 보고(단 한 번, 모델 선택에 영향 주면 안 됨)

### C-2. 일반적 비율과 변형
- **일반 비율:** 8:1:1 또는 7:2:1 (데이터 크기/난이도/불균형에 따라 조정)
- **시계열:** 시간 누수 방지를 위해 과거→미래 순으로 분리
- **불균형 분류:** **계층적 분할(stratified split)** 필요

---

## D. 실전 시나리오 & 코드 (PyTorch)

> 목표: 합성 데이터로 **분류·회귀**, **과적합/일반화**, **검증 분리**, **비지도/자기지도 맛보기**를 한 번에 훑는다.  
> 실행 환경: Python 3.x, torch(필수), torchvision(SSL 예시에서 옵션), numpy(선택).  
> 주의: 예시 코드는 컨셉 전달용이며, 실제 프로젝트에서는 로깅/예외처리/모듈화 강화 권장.

### D-0. 재현성(Seed), 디바이스, 유틸

```python
# reproducibility & device helpers (PyTorch)
import os, random, math
import numpy as np
import torch

def set_seed(seed=42, deterministic=True):
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    if deterministic:
        torch.backends.cudnn.deterministic = True
        torch.backends.cudnn.benchmark = False

def get_device():
    return torch.device("cuda" if torch.cuda.is_available() else "cpu")

set_seed(42)
device = get_device()
print("Device:", device)
```

> 실무 팁: **DataLoader의 `num_workers`** 와 **CuDNN 설정**은 재현성과 성능 간 트레이드오프다. 벤치마크는 off(재현성↑), on(성능↑). 논문화/보고 목적이면 재현성 우선.

---

### D-1. 합성 분류 데이터 생성 (2D, 두 개의 클래스로 시작)

```python
# create synthetic 2D classification dataset
def make_two_moons(n=400, noise=0.2, gap=0.0):
    # 두 개의 '달' 모양 데이터
    # class 0: 상단 호, class 1: 하단 호
    angles = np.random.rand(n) * np.pi
    x0 = np.c_[np.cos(angles), np.sin(angles)]
    x1 = np.c_[1 - np.cos(angles) + gap, -np.sin(angles) - 0.5]
    X = np.vstack([x0, x1])
    y = np.array([0]*n + [1]*n)
    # 노이즈
    X += np.random.randn(*X.shape) * noise
    # to tensors
    X = torch.tensor(X, dtype=torch.float32)
    y = torch.tensor(y, dtype=torch.long)
    return X, y

X, y = make_two_moons(n=500, noise=0.15, gap=0.15)
print(X.shape, y.shape, y.float().mean())  # class balance 확인(대략 0.5)
```

#### D-1-1. 학습/검증/테스트 분리(계층적 분할)

```python
from sklearn.model_selection import train_test_split

# 계층적 분할(라벨 비율 유지)
X_train, X_temp, y_train, y_temp = train_test_split(
    X, y, test_size=0.3, stratify=y, random_state=42
)
X_val, X_test, y_val, y_test = train_test_split(
    X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42
)

print(len(X_train), len(X_val), len(X_test))
```

> **데이터 누수 방지:** 스케일링(평균·표준편차 추정), 피처 선택, PCA 등 **학습 데이터로만 fit** → val/test에는 transform **only**.

---

### D-2. 간단한 MLP 분류기 (과소/과적합 관찰)

```python
import torch.nn as nn
import torch.nn.functional as F

class MLP(nn.Module):
    def __init__(self, in_dim=2, hidden=16, out_dim=2, dropout=0.0):
        super().__init__()
        self.fc1 = nn.Linear(in_dim, hidden)
        self.fc2 = nn.Linear(hidden, hidden)
        self.fc3 = nn.Linear(hidden, out_dim)
        self.dropout = nn.Dropout(dropout)

    def forward(self, x):
        x = F.relu(self.fc1(x))
        x = self.dropout(x)
        x = F.relu(self.fc2(x))
        x = self.dropout(x)
        x = self.fc3(x)
        return x
```

#### D-2-1. 훈련 유틸(정확도/손실 로그)

```python
from torch.utils.data import TensorDataset, DataLoader

def make_loader(X, y, batch=64, shuffle=True):
    ds = TensorDataset(X, y)
    return DataLoader(ds, batch_size=batch, shuffle=shuffle)

train_loader = make_loader(X_train, y_train, batch=64, shuffle=True)
val_loader   = make_loader(X_val,   y_val,   batch=256, shuffle=False)
test_loader  = make_loader(X_test,  y_test,  batch=256, shuffle=False)

def evaluate(model, loader, device):
    model.eval()
    correct, total, loss_sum = 0, 0, 0.0
    ce = nn.CrossEntropyLoss()
    with torch.no_grad():
        for xb, yb in loader:
            xb, yb = xb.to(device), yb.to(device)
            logits = model(xb)
            loss = ce(logits, yb)
            loss_sum += loss.item() * len(xb)
            preds = logits.argmax(dim=1)
            correct += (preds == yb).sum().item()
            total += len(xb)
    return loss_sum/total, correct/total

def train(model, train_loader, val_loader, epochs=100, lr=1e-2, wd=1e-4, device="cpu", early_stop=20):
    model.to(device)
    opt = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=wd)
    ce  = nn.CrossEntropyLoss()
    best_val, best_state, patience = float("inf"), None, early_stop
    history = []
    for ep in range(1, epochs+1):
        model.train()
        for xb, yb in train_loader:
            xb, yb = xb.to(device), yb.to(device)
            opt.zero_grad()
            logits = model(xb)
            loss = ce(logits, yb)
            loss.backward()
            torch.nn.utils.clip_grad_norm_(model.parameters(), 5.0)
            opt.step()
        tr_loss, tr_acc = evaluate(model, train_loader, device)
        va_loss, va_acc = evaluate(model, val_loader, device)
        history.append((ep, tr_loss, tr_acc, va_loss, va_acc))
        if va_loss < best_val:
            best_val, best_state, patience = va_loss, {k:v.cpu().clone() for k,v in model.state_dict().items()}, early_stop
        else:
            patience -= 1
        if ep % 20 == 0 or ep == 1:
            print(f"[{ep:03d}] train loss {tr_loss:.4f} acc {tr_acc:.3f} | val loss {va_loss:.4f} acc {va_acc:.3f}")
        if patience == 0:
            print("Early stopping")
            break
    if best_state is not None:
        model.load_state_dict(best_state)
    return history
```

#### D-2-2. **과소적합** 상황(너무 작은 모델/학습 부족)

```python
set_seed(7)
model_small = MLP(hidden=4, dropout=0.0)
hist_small = train(model_small, train_loader, val_loader, epochs=40, lr=5e-3, wd=1e-4, device=device)
tr_loss, tr_acc = evaluate(model_small, train_loader, device)
va_loss, va_acc = evaluate(model_small, val_loader, device)
te_loss, te_acc = evaluate(model_small, test_loader, device)
print("SMALL model -> train/val/test acc:", tr_acc, va_acc, te_acc)
```

- 관찰 포인트: 훈련/검증 정확도 모두 애매하게 낮음 → **표현력이 부족**하거나 **학습이 부족**.

#### D-2-3. **과적합** 상황(큰 모델 + 드롭아웃/정규화 없음, 에폭 과다)

```python
set_seed(7)
model_big = MLP(hidden=128, dropout=0.0)
hist_big = train(model_big, train_loader, val_loader, epochs=400, lr=1e-3, wd=0.0, device=device, early_stop=60)
tr_loss, tr_acc = evaluate(model_big, train_loader, device)
va_loss, va_acc = evaluate(model_big, val_loader, device)
te_loss, te_acc = evaluate(model_big, test_loader, device)
print("BIG (no reg) -> train/val/test acc:", tr_acc, va_acc, te_acc)
```

- 관찰 포인트: **훈련 정확도는 매우 높지만 검증/테스트 하락** → 과적합.  
  **대응:** 드롭아웃/가중치감쇠(weight decay)/데이터 증강/조기 종료.

#### D-2-4. **규제 추가** 후 재학습 (Dropout + AdamW)

```python
set_seed(7)
model_reg = MLP(hidden=128, dropout=0.3)
hist_reg = train(model_reg, train_loader, val_loader, epochs=300, lr=1e-3, wd=1e-4, device=device, early_stop=40)
tr_loss, tr_acc = evaluate(model_reg, train_loader, device)
va_loss, va_acc = evaluate(model_reg, val_loader, device)
te_loss, te_acc = evaluate(model_reg, test_loader, device)
print("REG (dropout+wd) -> train/val/test acc:", tr_acc, va_acc, te_acc)
```

- 관찰 포인트: **일반화 갭 축소** 기대.  
- 직관: 드롭아웃은 co-adaptation을 줄이고, weight decay는 파라미터 크기 폭주를 억제.

---

### D-3. 합성 회귀 데이터(다항식)로 **편향–분산 감각 익히기**

```python
# y = sin(2πx) + noise 를 다항 회귀로 근사
def make_regression(n=256, noise=0.1):
    x = np.random.rand(n, 1)
    y = np.sin(2*np.pi*x) + np.random.randn(n, 1) * noise
    x = torch.tensor(x, dtype=torch.float32)
    y = torch.tensor(y, dtype=torch.float32)
    return x, y

x, y = make_regression(n=512, noise=0.1)
x_tr, x_te, y_tr, y_te = train_test_split(x, y, test_size=0.25, random_state=42)
```

#### D-3-1. 다항 피처 만들기(모델 복잡도 제어: 차수 \(d\))

```python
def poly_features(x, degree):
    # x: (N,1) -> [x, x^2, ..., x^d]
    feats = [x]
    for d in range(2, degree+1):
        feats.append(x**d)
    return torch.cat(feats, dim=1)

class PolyReg(nn.Module):
    def __init__(self, degree):
        super().__init__()
        self.degree = degree
        self.linear = nn.Linear(degree, 1, bias=True)
    def forward(self, x):
        pf = poly_features(x, self.degree)
        return self.linear(pf)

def train_reg(model, x_tr, y_tr, x_te, y_te, lr=1e-2, epochs=2000, wd=0.0):
    model.to(device)
    opt = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=wd)
    mse = nn.MSELoss()
    for ep in range(epochs):
        model.train()
        opt.zero_grad()
        pred = model(x_tr.to(device))
        loss = mse(pred, y_tr.to(device))
        loss.backward()
        opt.step()
    with torch.no_grad():
        tr = mse(model(x_tr.to(device)), y_tr.to(device)).item()
        te = mse(model(x_te.to(device)), y_te.to(device)).item()
    return tr, te
```

#### D-3-2. 낮은 차수(편향↑) vs 높은 차수(분산↑)

```python
for d in [1, 3, 5, 9, 15]:
    set_seed(0)
    model = PolyReg(degree=d)
    tr, te = train_reg(model, x_tr, y_tr, x_te, y_te, lr=1e-2, epochs=2000, wd=1e-4)
    print(f"degree={d:2d} -> MSE train {tr:.4f}, test {te:.4f}")
```

- 관찰 포인트:  
  - **d=1(선형)**: 훈련/테스트 모두 오차 큼 (**편향↑**).  
  - **d=15**: 훈련 오차는 매우 낮지만 테스트 오차 상승(**분산↑**, 과적합).  
  - **중간 복잡도**에서 **최적 일반화**.

---

### D-4. 비지도학습 맛보기: 간단한 K-Means (PyTorch 텐서 버전)

```python
def kmeans_torch(X, k=2, iters=50):
    # X: (N, D)
    N, D = X.shape
    # 초기 중심 랜덤 선택
    idx = torch.randperm(N)[:k]
    centers = X[idx].clone()
    for _ in range(iters):
        # 할당
        dists = torch.cdist(X, centers)  # (N, k)
        labels = dists.argmin(dim=1)
        # 새로운 중심
        new_centers = torch.stack([X[labels==j].mean(dim=0) if (labels==j).any()
                                   else centers[j] for j in range(k)], dim=0)
        if torch.allclose(new_centers, centers, atol=1e-4):
            break
        centers = new_centers
    return labels, centers

# 이진 분류 데이터 X를 라벨 없이 군집화해보기(라벨 비교는 사후)
labels_unsup, centers = kmeans_torch(X, k=2, iters=100)
# 클러스터-실제라벨 매핑은 단순 비교(정확한 평가는 Hungarian 매칭 권장)
match_accuracy = max(
    (labels_unsup == y).float().mean().item(),
    (1 - (labels_unsup == y).float()).mean().item()
)
print("Unsupervised KMeans match(rough):", round(match_accuracy, 3))
```

- 관찰 포인트: 라벨 없이도 **구조가 분리된 데이터**에서는 군집이 어느 정도 라벨을 반영.  
- 한계: **결정경계가 비선형/복잡**하면 성능 저하. 지도신호가 없다면 **평가/모델 선택**도 어렵다.

---

### D-5. 자기지도(SSL) 맛보기: **간단 대조학습**(InfoNCE 형태, 개념 코드)

> 목적: 데이터에서 **두 증강 뷰**를 만들어 임베딩이 **가깝게**(positive), 다른 샘플은 **멀게**(negative) 되도록.  
> 실전은 SimCLR/Barlow Twins/SimSiam 등 구현을 권장. 아래는 개념을 간단히 축약.

$$
\mathcal{L}_{\text{InfoNCE}}
= - \frac{1}{N} \sum_{i=1}^{N}
\log \frac{\exp(\mathrm{sim}(\mathbf{z}_i, \mathbf{z}_i^+)/\tau)}
{\sum_{j=1}^{N} \exp(\mathrm{sim}(\mathbf{z}_i, \mathbf{z}_j^+)/\tau)}
$$

```python
import torch.nn as nn
import torch.nn.functional as F

class TinyProjHead(nn.Module):
    def __init__(self, in_dim=2, hid=64, out_dim=64):
        super().__init__()
        self.net = nn.Sequential(
            nn.Linear(in_dim, hid), nn.ReLU(),
            nn.Linear(hid, out_dim)
        )
    def forward(self, x):  # x: (B,2)
        z = self.net(x)
        z = F.normalize(z, dim=1)
        return z

def random_augment(x, scale=0.1):
    # 아주 단순한 증강: 작은 이동/노이즈 (개념용)
    noise = torch.randn_like(x) * scale
    return x + noise

def info_nce_loss(z1, z2, temperature=0.2):
    # z1, z2: (B, D), 같은 샘플의 두 뷰
    B, D = z1.shape
    z = torch.cat([z1, z2], dim=0)    # (2B, D)
    sim = torch.mm(z, z.t())          # (2B, 2B)
    # 자기 자신 제외 마스크
    mask = torch.eye(2*B, device=z.device).bool()
    sim = sim / temperature

    # 긍정 쌍 인덱스: i <-> i+B, i+B <-> i
    positives = torch.cat([torch.arange(B, 2*B), torch.arange(0, B)]).to(z.device)
    logits = sim[~mask].view(2*B, 2*B-1)
    positives_sim = sim[torch.arange(2*B), positives].unsqueeze(1)
    labels = torch.zeros(2*B, dtype=torch.long, device=z.device)
    # InfoNCE: pos는 첫 칸에 오도록 concat
    logits = torch.cat([positives_sim, logits], dim=1)
    loss = F.cross_entropy(logits, labels)
    return loss

# 데이터 두 뷰 생성 -> 표현학습
proj = TinyProjHead(in_dim=2).to(device)
opt = torch.optim.Adam(proj.parameters(), lr=1e-3)

X_ssl = X_train.to(device)
for step in range(300):
    xb = X_ssl[torch.randperm(len(X_ssl))[:256]]
    x1 = random_augment(xb, 0.1)
    x2 = random_augment(xb, 0.1)
    z1 = proj(x1)
    z2 = proj(x2)
    loss = info_nce_loss(z1, z2, temperature=0.2)
    opt.zero_grad(); loss.backward(); opt.step()
    if (step+1) % 60 == 0:
        print(f"[SSL] step {step+1} loss {loss.item():.4f}")
```

- **다운스트림 평가:** 학습된 프로젝션/인코더의 **표현 고정** 후, 작은 **로지스틱 회귀(또는 얕은 MLP)** 로 라벨 예측.
- 직관: 라벨 없이도 **의미 있는 근접 구조**를 배움 → **지도 데이터가 적을 때 유용**.

---

## E. 손실 함수와 위험 최소화

### E-1. 경험적 위험(ER)과 일반화 위험(GR)
- **경험적 위험(훈련 손실 평균):**
  $$
  \mathcal{R}_{\mathrm{emp}}(\theta)
  = \frac{1}{N}\sum_{i=1}^N \ell\big(f_\theta(\mathbf{x}_i), y_i\big)
  $$
- **일반화 위험(진짜 분포 평균):**
  $$
  \mathcal{R}_{\mathrm{gen}}(\theta)
  = \mathbb{E}_{(\mathbf{x},y)\sim \mathcal{P}}
  \big[\ell\big(f_\theta(\mathbf{x}), y\big)\big]
  $$
- 목표는 실제로 **\(\mathcal{R}_{\mathrm{gen}}\)** 을 낮추는 것. 우리가 관측 가능한 것은 \(\mathcal{R}_{\mathrm{emp}}\) → **일반화 갭** 최소화 전략이 핵심.

### E-2. 대표 손실들(기본)
- **MSE (회귀):**
  $$
  \ell_{\text{MSE}}(\hat y, y) = \|\hat y - y\|_2^2
  $$
- **Cross-Entropy (다중분류):**  
  $$\mathrm{CE}(\mathbf{p}, y) = - \log p_{y}$$  
  여기서 $$\mathbf{p} = \mathrm{softmax}(\mathbf{z})$$, \(p_y\) 는 정답 클래스의 확률.
- **BCEWithLogits (이진/멀티라벨):** 시그모이드+로그우도 결합 구현으로 수치 안정성↑.

---

## F. 과적합 방지 & 일반화 향상 전략

### F-1. 데이터 측면
- **더 많은 데이터/증강:** (이미지) 랜덤 크롭/수평대칭/컬러 지터, (텍스트) 백트랜슬레이션, (표) MixUp/CutMix 대안들.
- **클린 라벨링:** 라벨 노이즈가 크면 **일반화 악화**.

### F-2. 모델/학습 측면
- **규제화:** 가중치 감쇠(AdamW의 weight_decay), 드롭아웃, 라벨 스무딩.
- **조기 종료:** 검증 손실이 상승하면 학습 중단.
- **학습률 스케줄:** 큰 학습률로 빠르게 수렴 → 후반 미세조정(코사인, OneCycle).
- **정규화 레이어:** BN/LN/GN — 배치 크기/분포 변화에 주의.
- **지식 증류/프루닝/양자화:** 경량화는 일반화에 영향을 줄 수 있어 체크 필요.

---

## G. 평가: 데이터 분리와 교차검증

### G-1. 3-way split 모식도
- Train: 파라미터 업데이트  
- Val: 하이퍼파라미터/모델 선택  
- Test: **최종 보고용**. 반복 사용 금지.

### G-2. 교차검증(K-fold)
- 데이터 적을 때 **K-fold CV**로 안정적인 성능 추정:
  $$
  \hat{\mathcal{R}}_{\mathrm{CV}}
  = \frac{1}{K}\sum_{k=1}^{K} \mathcal{L}_{\text{val}_k}(\hat\theta_k)
  $$
- **Nested CV:** 모델 선택(내부 CV) + 성능 평가(외부 CV) 분리.

### G-3. 시계열(Time Series) 분리
- 과거→미래 순서 유지. 슬라이딩 윈도우/확장 윈도우 CV 사용.

---

## H. 데이터 누수(Data Leakage)와 체크리스트

### H-1. 대표 누수 케이스
- **스케일링을 전체 데이터에 fit** → 평균/표준편차가 Test 정보를 포함.  
- **피처 선택을 전체 데이터로 수행** → 중요한 피처가 Test에 의해 선택될 수 있음.  
- **시계열에서 미래 데이터가 전처리에 스며듦.**

### H-2. 안전한 파이프라인 (fit–transform 분리)

```python
# 안전한 스케일링 예시 (학습 데이터로만 fit → val/test는 transform만)
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
Xtr = torch.tensor(scaler.fit_transform(X_train.numpy()), dtype=torch.float32)
Xva = torch.tensor(scaler.transform(X_val.numpy()), dtype=torch.float32)
Xte = torch.tensor(scaler.transform(X_test.numpy()), dtype=torch.float32)
```

> 실무 팁: 전처리/모델을 **`Pipeline`** 또는 **모듈**로 묶어서 “fit은 train만” 원칙이 강제되도록 설계.

---

## I. 분류/회귀 지표(기초)와 에러 해석

### I-1. 분류(이진/다중)
- **정확도(Accuracy):** 불균형 데이터에 취약.
- **정밀도/재현율/F1:** 클래스별/마이크로/매크로 평균 주의.
- **ROC-AUC / PR-AUC:** 임계값 독립적 평가.
- **혼동행렬:** 오류 유형 파악.

### I-2. 회귀
- **MAE/MSE/RMSE, R²**
  $$
  \mathrm{MSE} = \frac{1}{N}\sum_{i} (y_i - \hat y_i)^2,\quad
  \mathrm{MAE} = \frac{1}{N}\sum_{i} |y_i - \hat y_i|
  $$

---

## J. 종합 실습: **작은 프로젝트 시나리오**

### J-1. 상황: “고양이 vs 개”의 단순화된 2D 특징판별
- **가설:** 두 종은 (귀 길이, 꼬리 길이) 2D 피처로 어느 정도 분리 가능.
- **실험 계획:**
  1) 합성 데이터 생성(두 달 데이터)  
  2) 8:1:1 분리(계층적)  
  3) 작은 MLP로 시작 → 과소적합 확인  
  4) 큰 모델로 과적합 유도 → 일반화 갭 관찰  
  5) Dropout/weight decay/조기 종료 도입 → 갭 축소  
  6) 최종 테스트 1회 평가 및 **테스트 세트 봉인**  
  7) (선택) SSL 표현을 학습한 뒤 선형 프로브로 성능 비교

- **핵심 체크리스트:**
  - 시드 고정, 데이터 누수 금지
  - 학습 곡선(훈련/검증 손실)로 과적합 감지
  - 하이퍼파라미터는 검증으로만 의사결정
  - 최종 수치는 **테스트로 단 1회**

---

## K. 자주 묻는 질문(FAQ) — 기초편

**Q1. 검증 세트를 교차검증으로 대체해도 되나요?**  
- 데이터가 적으면 K-fold로 대체 가능. 다만 **최종 선택 후** 독립 테스트 세트 평가는 유지.

**Q2. 불균형 데이터에서 정확도는 믿을 수 없나요?**  
- 네. **PR-AUC**, **F1(특히 minority 클래스)**, **리콜** 등 병행 보고 필요.

**Q3. 라벨이 너무 적습니다.**  
- **자기지도(SSL)** 로 표현을 먼저 학습 → 소량 라벨로 파인튜닝. 데이터 증강/반지도도 고려.

**Q4. 검증 성능이 출렁입니다.**  
- 랜덤성/데이터 크기/난이도 때문일 수 있음. 시드 여러 개, K-fold 평균, 조기 종료 patience 조정.

---

## L. 핵심 요약(한 장)

1. **지도/비지도/자기지도**: 라벨 유무/전략 차이 이해.  
2. **일반화**가 본질. **과적합**은 자연스러운 현상이며 **규제/증강/조기 종료**로 제어.  
3. **Train/Val/Test** 역할 분리, **데이터 누수 금지**.  
4. **편향–분산** 균형: 중간 복잡도/적절한 데이터/규제가 최적 점을 만든다.  
5. **재현성/평가 절차**를 문서화하고, **최종 테스트는 한 번만**.

---

## M. 추가 실습 과제(추천)

- (분류) 합성 데이터의 **클래스 간 겹침** 정도를 조절(noise, gap)하며 일반화 갭 변화를 기록.  
- (회귀) 다항 차수/가중치 감쇠를 스윕하여 **편향–분산 곡선** 표로 정리.  
- (비지도) K-Means 초기화 여러 번 반복 후 최적 중심 선택의 영향 평가.  
- (SSL) 간단 대조학습 후 **선형 프로브** 성능을 지도학습 처음부터 대비.  
- (누수) 고의로 누수를 만든 파이프라인 vs 안전 파이프라인의 검증 성능 차이를 비교.

---

# 부록: 수식/개념 큐시트

- **경험적 위험 최소화(ERM):**
  $$
  \hat\theta = \arg\min_{\theta} \frac{1}{N}\sum_{i=1}^N \ell\big(f_\theta(\mathbf{x}_i), y_i\big)
  $$
- **일반화 갭:**
  $$
  \mathcal{L}_{\text{test}}(\hat\theta) - \mathcal{L}_{\text{train}}(\hat\theta)
  $$
- **편향–분산 분해(개념):**
  $$
  \mathbb{E}[(\hat f - f)^2] = \mathrm{Bias}^2 + \mathrm{Var} + \sigma^2
  $$
- **Cross-Entropy:**
  $$
  \mathrm{CE}(\mathbf{p}, y) = -\log p_y, \quad \mathbf{p}=\mathrm{softmax}(\mathbf{z})
  $$
- **MSE/MAE:**
  $$
  \mathrm{MSE} = \frac{1}{N}\sum_{i}(y_i - \hat y_i)^2, \quad
  \mathrm{MAE} = \frac{1}{N}\sum_{i}|y_i - \hat y_i|
  $$

---

## 실전 체크리스트(요약)

- [ ] 데이터 분리: **Train/Val/Test** 구분, 계층적/시간 분할 고려  
- [ ] 전처리 fit은 **Train만**, Val/Test는 **transform**  
- [ ] 시드/환경 고정(재현성)  
- [ ] 학습곡선으로 과적합 모니터링, **조기 종료**  
- [ ] **규제**(Dropout, weight decay) + **증강**  
- [ ] 지표 선정: 불균형/도메인 맥락 반영  
- [ ] 최종 보고는 **Test 1회** 평가 결과