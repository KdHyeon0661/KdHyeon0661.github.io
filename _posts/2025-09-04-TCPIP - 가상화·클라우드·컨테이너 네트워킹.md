---
layout: post
title: TCPIP - 가상화·클라우드·컨테이너 네트워킹
date: 2025-09-04 19:25:23 +0900
category: TCPIP
---
# 15. 가상화·클라우드·컨테이너 네트워킹
**(🔰 하이퍼바이저·브리지·가상 NIC, ⚙️ 클라우드 VPC·서브넷·라우팅·NAT·SG/NACL, ⚙️ 컨테이너 CNI·Pod 네트워크·Service/Ingress, 🚀 오버레이(VXLAN/GRE)·eBPF 데이터패스)**

> 이 장은 “**한 대의 물리 서버/링크 위에 수십~수천 워크로드가 공존**”하는 시대의 네트워킹을 **원리→설계→운영→디버깅** 순으로 정리합니다.  
> 코드/명령은 ```로, 간단 수식은 *MathJax*로 표기합니다. (예제는 리눅스 기준이 많지만 원리는 공통)

---

## 15.1 하이퍼바이저·브리지·가상 NIC (🔰)

### 15.1.1 하이퍼바이저 개념
- **Type-1(베어메탈)**: ESXi, Hyper-V, KVM(on baremetal). 하드웨어 위에서 직접 VM 스케줄.  
- **Type-2(호스트 기반)**: VirtualBox, VMware Workstation. 호스트 OS 위 VMM 구동.
- **역할**: **가상 스위치**(vSwitch/리눅스 브리지/OVS), **가상 NIC**(vNIC: virtio-net/e1000), **가상 TAP** 인터페이스로 VM ↔ 네트워크 중계.

### 15.1.2 가상 NIC, TAP/TUN, veth
- **TAP**: L2 프레임(이더넷) 단위로 사용자 공간과 커널 사이를 연결(주로 VM).  
- **TUN**: L3 패킷(IP) 단위(주로 VPN).  
- **veth pair**: 컨테이너/네임스페이스 간 L2 파이프(양 끝은 서로에게 케이블).
- **virtio-net**: VM 내부에서 고성능 파라버추얼 NIC 드라이버.

### 15.1.3 리눅스 브리지 vs OVS
- **linux bridge**: 단순 L2 브리지 + VLAN + hairpin + ebtables/iptables 훅.  
- **Open vSwitch(OVS)**: 플로우 기반(매치/액션), OpenFlow/OVN, Geneve/VXLAN 내장, 대규모/SDN 친화.

### 15.1.4 미니 랩: VM을 브리지에 붙이기
```bash
# 1) 브리지 생성
sudo ip link add br0 type bridge
sudo ip link set br0 up

# 2) 물리 NIC를 브리지 포트로
sudo ip link set eth0 master br0
sudo ip link set eth0 up

# 3) TAP 만들고 브리지에 붙이기(QEMU가 자동 생성하기도 함)
sudo ip tuntap add dev tap0 mode tap
sudo ip link set tap0 master br0
sudo ip link set tap0 up

# 4) VM 구동(QEMU 예)
qemu-system-x86_64 -enable-kvm -m 4096 \
  -netdev tap,id=hn0,ifname=tap0,script=no,downscript=no \
  -device virtio-net-pci,netdev=hn0 \
  disk.qcow2
```
- **흐름**: `VM(virtio-net)` ↔ `tap0` ↔ `br0` ↔ `eth0` ↔ 외부.  
- **캡처 포인트**: `tcpdump -i tap0`, `-i br0`, `-i eth0`.

### 15.1.5 Hairpin(브리지 루프백)
- 같은 브리지에 붙은 포트 간 통신에서 **NAT/포워딩 후 자기 자신으로 돌아오는 트래픽 허용** 필요. 일부 환경(가정 공유기/컨트롤러)에서 **hairpin 모드** 옵션 노출.

---

## 15.2 클라우드 VPC: 서브넷·라우팅·NAT·SG/NACL (⚙️)

> 예시는 AWS 스타일로 설명하지만 Azure VNet, GCP VPC도 **용어/오브젝트만 다르고 원리 동일**합니다.

### 15.2.1 VPC·CIDR·서브넷
- **VPC**: 논리적 L3 네트워크(예: `10.10.0.0/16`).  
- **서브넷**: AZ(가용 영역) 단위 분할(예: `10.10.1.0/24` Public, `10.10.2.0/24` Private).  
- **주소 예약(보통 5개)**: 네트워크/브로드캐스트/게이트웨이 등 클라우드가 예약.
- **설계 팁**: 초기에 **충분히 큰 CIDR**(예: /16) → 서비스 증가/피어링 대비.

### 15.2.2 라우팅 테이블
- **Public Subnet**: `0.0.0.0/0 → Internet Gateway(IGW)`  
- **Private Subnet**: `0.0.0.0/0 → NAT Gateway`  
- **VPC Peering/Transit GW**: 특정 CIDR → 피어링/TGW.

```text
# 예: 프라이빗 서브넷 라우팅
10.10.0.0/16    local         # VPC 내부 라우팅
0.0.0.0/0       nat-0abc123   # 인터넷은 NAT GW로
172.16.0.0/16   tgw-xyz       # 사내망은 Transit GW
```

### 15.2.3 NAT Gateway vs NAT 인스턴스
- **NAT GW**: 관리형·확장형·고가용(존당), **소스 NAT**로 프라이빗 서브넷 인스턴스의 **아웃바운드만** 허용. 인바운드 세션 시작 불가.  
- **NAT 인스턴스**: 직접 EC2로 구성; 유연하지만 **관리/HA 부담**.

### 15.2.4 보안 그룹(SG) vs 네트워크 ACL(NACL)
- **SG**: **상태 기반(Stateful)**, 인스턴스/NIC에 **붙는** 화이트리스트. 리턴 트래픽 자동 허용.  
- **NACL**: **무상태(Stateless)**, **서브넷 경계**. 인·아웃 모두 규칙 필요, 평가 순서가 있음.
- **베스트 프랙티스**:  
  - **SG로 대부분의 정책**(역할 단위).  
  - NACL은 **광역 차단/제한**(예: 외부에서 특정 포트 전면 차단).

### 15.2.5 인터넷/프런트엔드 패턴
- **ALB/NLB/LB**를 Public Subnet에 배치, 백엔드는 Private Subnet.  
- **SG 체이닝**: LB SG → App SG만 허용, App SG → DB SG만 허용.

### 15.2.6 프라이빗 접근: 엔드포인트/프라이빗 링크
- **Gateway Endpoint(S3/Dynamo 등)**: VPC 라우트로 사설 통신.  
- **Interface Endpoint(=PrivateLink)**: 특정 서비스(자사/타사)에 **ENI**로 사설 접속.

### 15.2.7 예제: 3-Tier VPC(요약)
```text
VPC 10.10.0.0/16
  Subnet PublicA  10.10.1.0/24  (ALB, NAT GW)
  Subnet PrivateA 10.10.2.0/24  (App)
  Subnet DB       10.10.3.0/24  (RDS)
Routes:
  PublicA:  0.0.0.0/0 -> IGW
  PrivateA: 0.0.0.0/0 -> NAT GW
  DB:       내부만(local), 외부 라우트 없음
SG:
  ALB_SG: In 80/443(세상) -> Out App_SG
  App_SG: In 8080(ALB_SG) -> Out DB_SG:5432
  DB_SG:  In 5432(App_SG) -> Out 제한
```

### 15.2.8 Terraform 스니펫(개념)
```hcl
resource "aws_vpc" "main" {
  cidr_block = "10.10.0.0/16"
}

resource "aws_subnet" "priv_a" {
  vpc_id     = aws_vpc.main.id
  cidr_block = "10.10.2.0/24"
  availability_zone = "ap-northeast-2a"
  map_public_ip_on_launch = false
}
# NAT GW, Route table, IGW 등은 생략. 모듈화 권장.
```

### 15.2.9 디버깅 포인트
- **경로**: 라우팅 테이블/대상 GW/어소시에이션 확인.  
- **SG/NACL**: 방향/포트/소스, **상태성** 차이 주의.  
- **소스/목적 체크**(EC2 ENI): **Source/Dest Check**가 NAT 역할일 땐 **off** 필요.  
- **VPC Flow Logs**: Drop 이유/필드 분석.  
- **MTU**: ENI/VPN/Transit 경로 **오버헤드**(VXLAN/GRE/IPsec) 고려.

---

## 15.3 컨테이너 네트워킹: CNI·Pod·Service·Ingress (⚙️)

### 15.3.1 CNI(컨테이너 네트워크 인터페이스)
- Kubelet/컨테이너 런타임이 **Pod Sandbox 생성 시 호출**하는 표준.  
- **Plugin**이 실제 **veth/브리지/라우팅/오버레이** 구성, IP 할당, 정책 설정.

### 15.3.2 Pod 네트워크 모델
- **각 Pod는 고유 IP(평면 주소 공간)**를 가짐. Pod 간 통신은 **NAT 없이 L3**.  
- Pod 내부: `eth0`(veth) ↔ **호스트 네임스페이스의 veth peer** ↔ (브리지/라우팅) ↔ 나머지 세상.  
- **pause/샌드박스** 컨테이너가 네임스페이스를 보유, 상위 컨테이너는 이를 공유.

```bash
# 호스트에서 Pod veth 관찰
ip netns
ip -n <pod-ns> addr
tc -s qdisc show dev <veth>
```

### 15.3.3 Service & kube-proxy
- **Service**: 여러 Pod(Endpoints)를 가리키는 **가상 IP(ClusterIP)**.  
- 구현: `kube-proxy`가 **iptables/IPVS/eBPF**로 **L4 로드밸런싱**.  
- **타입**  
  - ClusterIP(기본),  
  - **NodePort**(각 노드 특정 포트로 오픈),  
  - **LoadBalancer**(클라우드 LB 연동),  
  - **ExternalName**(DNS CNAME),  
  - Headless(`clusterIP: None`, 직접 Endpoints 질의).

```yaml
apiVersion: v1
kind: Service
metadata: {name: web}
spec:
  selector: {app: web}
  ports:
  - port: 80
    targetPort: 8080
```

### 15.3.4 Ingress & Gateway
- **Ingress**: L7(HTTP/HTTPS) **가상호스트/경로** 라우팅. 컨트롤러(Nginx/HAProxy/Envoy/Traefik)가 LB 역할.  
- **Gateway API**: Ingress 발전형(역할/정책 분리, 멀티루트).  
- 예제:
```yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata: {name: web}
spec:
  rules:
  - host: example.com
    http:
      paths:
      - path: /app
        pathType: Prefix
        backend:
          service:
            name: web
            port: {number: 80}
```

### 15.3.5 DNS/서비스 디스커버리
- **CoreDNS**가 `svc.ns.svc.cluster.local` FQDN 제공.  
- Headless + StatefulSet 조합으로 **개별 Pod A 레코드** 제공(데이터베이스 샤딩 등).

### 15.3.6 클러스터 외부로: SNAT/MASQUERADE
- Pod→외부 시 **노드 IP로 SNAT**가 기본(클러스터 CIDR이 외부 라우팅에 모름).  
- **Kube-proxy iptables**에서 `MASQUERADE` 규칙 확인 가능.

```bash
# (개념) iptables -t nat -S | grep MASQUERADE
```

---

## 15.4 CNI 구현 비교: Flannel/Calico/Cilium/Weave (⚙️)

### 15.4.1 Flannel
- **Overlay 중심**(VXLAN, UDP, host-gw 등 백엔드 선택).  
- 간단·가벼움. 다만 대규모/고성능에선 **오버헤드/MTU** 주의.

### 15.4.2 Calico
- **라우팅 기반(BGP)** 로 **NAT 없이 L3**(가능 시), 옵션으로 VXLAN/Geneve.  
- **NetworkPolicy** 강력, **eBPF 모드**로 kube-proxy 대체 가능.

### 15.4.3 Cilium
- **eBPF** 중심 데이터패스(XDP/TC/Sockmap), **kube-proxy 제거** LB, **Hubble**(가시성), **Tetragon**(보안).  
- DSR/Maglev Hash, **Host/Routing/Overlay** 여러 모드.

### 15.4.4 Weave Net
- **fastdp(OVS)** + 암호화/자동 피어링. 간편하나 초대규모에는 선택적.

### 15.4.5 MTU/오버레이 공식
\[
\text{Effective MTU} \approx \text{Underlay MTU} - \text{Encap Overhead}
\]
- VXLAN 오버헤드(대략): **IP(20/40) + UDP(8) + VXLAN(8) = 36~56 B**.  
- **1500 MTU**에서 VXLAN이면 **1440~1460** 근방으로 조정 필요(내부 TCP MSS 클램핑도 고려).

```bash
# CNI MTU 조정(예: Cilium)
cilium config set mtu 1450
```

---

## 15.5 오버레이: VXLAN/GRE/Geneve (🚀)

### 15.5.1 VXLAN 큰그림
- **VTEP**(터널 엔드포인트)이 **VNI(24bit)** 로 L2 세그먼트 가상화.  
- **UDP/4789**. BUM(Broadcast, Unknown-Unicast, Multicast) 처리는 **멀티캐스트** 혹은 **컨트롤플레인(예: EVPN, OVS/OVN)** 으로 해결.
- **해시/ECMP**: UDP니까 **언더레이 L3에서 부하분산 용이**.

### 15.5.2 GRE
- **IP-in-IP** 단순 캡슐화(프로토콜 47). L4 포트 부재로 **ECMP 해시 불리**.  
- 오버헤드 적고 구현 간단. DCI/특정 장비 상호운용에 여전히 활용.

### 15.5.3 Geneve
- VXLAN 유사 + **옵션 TLV** 확장성. OVS/OVN, NVMe/TCP overlay, 대형 클라우드에 채택.

### 15.5.4 EVPN(한 줄)
- **BGP EVPN**을 컨트롤플레인으로 사용해 **MAC/IP 학습**을 제어, **멀티테넌시**·루트가드·프록시 ARP/ND 등 고급 기능.

### 15.5.5 MTU/PMTUD 주의
- 캡슐화 경로에서 **ICMP Too Big**가 막히면 **블랙홀**.  
- **노드 NIC MTU↓ + TCP MSS 클램핑**(Pod/노드 출구)로 방어.

---

## 15.6 eBPF 데이터패스 개요 (🚀)

### 15.6.1 eBPF 훅
- **XDP**(NIC RX 직후) — 초저지연 드롭/리다이렉트.  
- **TC ingress/egress** — L2/L3 처리·NAT·LB·Policy.  
- **cgroup/socket** — Connect/Bind/Sendmsg 고리, L7 메타 기반 정책.  
- **Kprobe/Tracepoint** — 커널 이벤트 관측.

### 15.6.2 기본 연산
- **BPF Map**(Hash/Array/LRU/Trie)로 상태 저장(Conntrack/Policy/LB 테이블).  
- **bpf_redirect**, **bpf_fib_lookup**(커널 라우팅 캐시 조회), **bpf_map_update_elem**.

### 15.6.3 kube-proxy 대체
- **노드 입구에서 eBPF NAT/LB** → **DSR** 가능(리턴 경로 역주행 제거).  
- **Maglev/Consistent Hash** 기반 선택으로 **연결 스티키** 보장.

### 15.6.4 관측·보안
- **Hubble**: eBPF로 Pod↔Pod/Service/정책 로그·지표.  
- **정책**: L3/L4 + L7 헤더 분석, **DNS 정책**(FQDN 해석→IP 매핑 캐시).

```bash
# bpftool 간단 둘러보기
bpftool prog show
bpftool map show
```

---

## 15.7 Kubernetes 서비스 토폴로지 심화

### 15.7.1 externalTrafficPolicy
- **Cluster**(기본): 임의 노드로 들어온 트래픽이 **클러스터 내부**에서 다시 포워딩(NAT) → **소스 IP 손실**.  
- **Local**: **로컬 엔드포인트가 있는 노드만** 수신 → **클라이언트 소스 IP 보존**, 대신 **가용성/부하 편향** 주의.

### 15.7.2 NodePort·LoadBalancer·Ingress 상호작용
- **NodePort**는 L4. Ingress는 L7. LoadBalancer는 노드 앞의 **L4 LB**(클라우드)가 NodePort로 전달.  
- eBPF LB(DSR) + Ingress(Envoy) 조합으로 **L4/7 혼합 스택** 가능.

### 15.7.3 Headless & StatefulSet
- `clusterIP: None` → **개별 Pod DNS A레코드**. 샤딩 DB/카프카 브로커에서 **정적 ID** 지원.

---

## 15.8 네트워크 정책(NetworkPolicy)

### 15.8.1 개념
- **네임스페이스/Label** 기반 L3/L4 화이트리스트. **기본은 “허용”**(정책 없으면 모두 통신 가능).  
- 구현은 CNI 의존(Calico, Cilium, Kube-router 등) — 기능/표현력 차이 있음.

```yaml
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata: {name: allow-web-to-app, namespace: prod}
spec:
  podSelector: {matchLabels: {app: app}}
  ingress:
  - from:
    - namespaceSelector: {matchLabels: {name: prod}}
      podSelector: {matchLabels: {role: web}}
    ports:
    - protocol: TCP
      port: 8080
```

### 15.8.2 팁
- **기본거부 네임스페이스**: `deny-all` 정책부터 도입 → 예외만 허용.  
- **DNS/메트릭 허용**(CoreDNS/Prometheus 등)을 잊지 말 것.

---

## 15.9 MTU/MSS/Conntrack/헤어핀

### 15.9.1 Conntrack(상태 테이블)
- kube-proxy, NAT, LB는 **conntrack 엔트리** 소모.  
- **폭주 시** 드롭/지연↑ → `nf_conntrack_max` 상향, 적절한 **idle timeout** 조정.

```bash
sysctl -w net.netfilter.nf_conntrack_max=262144
conntrack -S
```

### 15.9.2 Hairpin NAT(NodePort/Pod→자기 서비스)
- 같은 노드에서 **Pod가 자기 Service로** 접근 시 **헤어핀** 필요.  
- 일부 CNI/브리지 옵션에서 `hairpinMode=true`/브리지 hairpin on.

### 15.9.3 MSS 클램핑(오버레이)
```bash
# 노드 출구에서 SYN의 MSS를 1360으로(예시값)
iptables -t mangle -A FORWARD -p tcp --tcp-flags SYN,RST SYN \
  -j TCPMSS --set-mss 1360
```

---

## 15.10 트러블슈팅: 상황→가설→검증

### 15.10.1 “Pod↔Pod는 되는데 외부만 안됨”
```text
가설: SNAT 누락/클라우드 라우팅 없음/SG 막힘
검증: Pod→8.8.8.8 ping, 노드 iptables MASQUERADE 규칙, VPC Route 0.0.0.0/0
조치: 노드 출구 SNAT 켜기/클라우드 NAT GW 경로 확인/SG 아웃바운드 허용
```

### 15.10.2 “일부 큰 응답만 타임아웃”
```text
가설: MTU/PMTUD 블랙홀(오버레이/Peering)
검증: DF ping, tracepath, curl --http3 실패여부
조치: CNI MTU↓, TCP MSS 클램핑, ICMP PTB 허용
```

### 15.10.3 “NodePort에서 소스 IP가 사라짐”
```text
가설: externalTrafficPolicy=Cluster
조치: Local로 변경(엔드포인트 로컬 분포 확인), 또는 L7 Ingress에서 X-Forwarded-For 활용
```

### 15.10.4 “연결 수 늘자 지연 급증”
```text
가설: conntrack 한도/큐디스크/세그먼트 부족
검증: conntrack -S, ss -s, tc -s qdisc, ethtool -S
조치: nf_conntrack_max↑, fq/fq_codel, CNI/eBPF LB 검토
```

### 15.10.5 “멀티클러스터/하이브리드 통신 불안”
```text
가설: 라우팅 비대칭/NAT/보안 장비 DPI
조치: IPsec/WireGuard 터널 일원화, BGP/EVPN, MTU 조정
```

---

## 15.11 성능·품질 수식/감각 메모

### 15.11.1 오버레이 헤더 오버헤드
\[
\text{Overhead}_{\text{VXLAN}} \approx \text{IP}_{\text{out}} + \text{UDP} + \text{VXLAN} + \text{L2}_{\text{in}}
\]
- 대략 **50B±**. 유효 페이로드 비율:
\[
\text{Goodput} \approx \frac{\text{Payload}}{\text{Payload}+\text{Overheads}} \times \text{Rate}
\]

### 15.11.2 DSR의 장점(개념)
- 리턴 패킷이 **LB를 안 거침** → LB 병목/대기열↓,  
- 단, **루팅/정책**이 **대칭**이 아니라도 성립(서버가 직접 클라이언트로 응답).

---

## 15.12 베스트 프랙티스(요약 카드)

**가상화/호스트**
- [ ] 리눅스 브리지/OVS 선택 기준 문서화, hairpin·VLAN 태깅 정책.  
- [ ] NIC 오프로드/멀티큐/RSS/IRQ 핀닝, `fq`/`fq_codel` qdisc.

**클라우드 VPC**
- [ ] CIDR 여유, Public/Private 분리, NAT GW 존당 이중화.  
- [ ] SG=상태기반(역할 중심), NACL=광역 제한.  
- [ ] VPC Endpoint/PrivateLink로 **사설 경로** 적극 활용.  
- [ ] Flow Logs·라우트 시각화·헬스 대시보드.

**Kubernetes/CNI**
- [ ] CNI MTU/오버레이 선택(VXLAN vs 라우팅), eBPF 검토.  
- [ ] kube-proxy 모드(iptables/IPVS/eBPF) 명확화, externalTrafficPolicy 고려.  
- [ ] NetworkPolicy **기본거부 네임스페이스**부터.  
- [ ] DNS/메트릭/헬스 포트 허용 누락 방지.

**오버레이/eBPF**
- [ ] PMTUD/ICMP PTB 통과, MSS 클램핑.  
- [ ] eBPF LB/Policy로 성능·가시성 향상, qlog/Hubble 등 도입.  
- [ ] DSR/Maglev로 확장성 확보(테스트/가시성 선행).

---

## 15.13 참고 템플릿/스니펫 모음

### 15.13.1 OVS로 VXLAN 브리지(개념)
```bash
ovs-vsctl add-br br-int
ovs-vsctl add-port br-int vxlan0 -- set interface vxlan0 \
  type=vxlan options:remote_ip=10.0.0.2 options:key=42 options:dst_port=4789
ovs-vsctl add-port br-int tap0
```

### 15.13.2 Calico BGP(요지)
```yaml
apiVersion: crd.projectcalico.org/v1
kind: BGPPeer
metadata: {name: rr}
spec:
  peerIP: 10.10.0.254
  asNumber: 64512
```

### 15.13.3 Cilium 값 몇 가지
```bash
cilium status
cilium config set bpf-lb-dsr-dispatch  opt
cilium hubble enable
```

### 15.13.4 Ingress + Service + Deployment (요약)
```yaml
apiVersion: apps/v1
kind: Deployment
metadata: {name: web}
spec:
  replicas: 3
  selector: {matchLabels: {app: web}}
  template:
    metadata: {labels: {app: web}}
    spec:
      containers:
      - name: app
        image: ghcr.io/example/web:1.0
        ports: [{containerPort: 8080}]

---
apiVersion: v1
kind: Service
metadata: {name: web}
spec:
  selector: {app: web}
  ports: [{port: 80, targetPort: 8080}]
---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata: {name: web}
spec:
  rules:
  - host: www.example.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service: {name: web, port: {number: 80}}
```

---

## 15.14 “한 장 요약(포스터)”
- **하이퍼바이저**는 TAP/vNIC/브리지로 VM을 세상과 연결, **OVS/OVN** 등으로 SDN화.  
- **클라우드 VPC**는 **CIDR·서브넷·라우팅·NAT·SG/NACL** 조합이 기본 문법.  
- **Kubernetes**는 **CNI**가 네트워크를 만들고, **Service/Ingress**가 L4/7 진입점을 제공.  
- **오버레이(VXLAN/Geneve)**와 **eBPF 데이터패스**로 **대규모/고성능·가시성**을 동시에.  
- **항상 MTU/PMTUD/Conntrack**을 잊지 말 것—대부분의 미묘한 장애는 여기서 출발.

---

### 부록 A — 빠른 점검 명령 모음
```bash
# 호스트/VM/컨테이너 링크
ip link; ip addr; ip route
bridge link; bridge fdb

# 캡처
tcpdump -i any -nnvv 'host <IP> and port <PORT>'

# Kubernetes
kubectl get pods -o wide
kubectl describe svc <name>
kubectl -n kube-system logs ds/kube-proxy
kubectl exec -it <pod> -- sh -c 'ip addr; ip route'

# Conntrack/iptables
conntrack -S; conntrack -L
iptables -t nat -S | grep -E 'MASQUERADE|DNAT'

# Cilium/Calico
cilium status; cilium service list
calicoctl get ippool
```

### 부록 B — 용어 스냅샷
```
TAP/TUN, veth, linux bridge, OVS/OVN,
VPC/VNet, IGW, NAT GW, SG/NACL, TGW/Peering, Endpoint/PrivateLink,
CNI, Pod CIDR, kube-proxy(iptables/IPVS/eBPF), Service/Ingress/Gateway,
VXLAN/GRE/Geneve, VNI/VTEP, EVPN, PMTUD, MSS Clamp,
eBPF(XDP/TC), BPF Map, DSR, Maglev, Hubble
```