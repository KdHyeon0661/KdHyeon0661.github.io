---
layout: post
title: 선형대수 - LU 분해
date: 2025-05-14 22:20:23 +0900
category: 선형대수
---
# LU 분해(LU Decomposition) – 선형방정식을 빠르게 푸는 방법

## 1. LU 분해란

정방행렬 $$\mathbf{A}\in\mathbb{R}^{n\times n}$$ 에 대해, 가우스 소거법을 행렬 형태로 쓰면
$$
\mathbf{A}=\mathbf{L}\mathbf{U}
$$
로 분해할 수 있습니다.

- $$\mathbf{L}$$: 단위 대각(또는 일반 대각)의 하삼각행렬(lower),  
- $$\mathbf{U}$$: 상삼각행렬(upper).

수치안정성을 위해 일반적으로 **부분 피벗팅**을 포함한
$$
\mathbf{P}\mathbf{A}=\mathbf{L}\mathbf{U}
$$
형태를 사용합니다. 여기서 $$\mathbf{P}$$ 는 행 교환을 나타내는 순열행렬입니다.

---

## 2. 선형계 $$\mathbf{A}\mathbf{x}=\mathbf{b}$$ 풀이 흐름

피벗팅이 있을 때 $$\mathbf{P}\mathbf{A}=\mathbf{L}\mathbf{U}$$ 이므로
$$
\mathbf{L}\mathbf{U}\mathbf{x}=\mathbf{P}\mathbf{b}.
$$

1) 전방 대입: $$\mathbf{L}\mathbf{y}=\mathbf{P}\mathbf{b}$$ 를 풀어 $$\mathbf{y}$$ 획득.  
2) 후방 대입: $$\mathbf{U}\mathbf{x}=\mathbf{y}$$ 를 풀어 $$\mathbf{x}$$ 획득.

분해(한 번, 약 $$\tfrac{2}{3}n^3$$ 연산) 이후, 서로 다른 $$\mathbf{b}$$ 들에 대해 재사용 시 각 해는 $$O(n^2)$$ 로 빠르게 구할 수 있습니다.

---

## 3. 수작업 예제

행렬
$$
\mathbf{A}=
\begin{bmatrix}
2 & 3\\
4 & 7
\end{bmatrix},\qquad
\mathbf{b}=
\begin{bmatrix}
8\\
18
\end{bmatrix}.
$$

피벗팅 없이 Doolittle(단위 대각 $$\mathbf{L}$$)을 따르면
$$
\mathbf{L}=
\begin{bmatrix}
1 & 0\\
2 & 1
\end{bmatrix},\quad
\mathbf{U}=
\begin{bmatrix}
2 & 3\\
0 & 1
\end{bmatrix}.
$$

검산:
$$
\mathbf{L}\mathbf{U}
=
\begin{bmatrix}
1 & 0\\
2 & 1
\end{bmatrix}
\begin{bmatrix}
2 & 3\\
0 & 1
\end{bmatrix}
=
\begin{bmatrix}
2 & 3\\
4 & 7
\end{bmatrix}
=\mathbf{A}.
$$

풀이:
1) $$\mathbf{L}\mathbf{y}=\mathbf{b} \Rightarrow \begin{bmatrix}1&0\\2&1\end{bmatrix}\begin{bmatrix}y_1\\y_2\end{bmatrix}=\begin{bmatrix}8\\18\end{bmatrix} \Rightarrow y_1=8,\ y_2=2.$$
2) $$\mathbf{U}\mathbf{x}=\mathbf{y} \Rightarrow \begin{bmatrix}2&3\\0&1\end{bmatrix}\begin{bmatrix}x_1\\x_2\end{bmatrix}=\begin{bmatrix}8\\2\end{bmatrix} \Rightarrow x_2=2,\ 2x_1+3\cdot 2=8 \Rightarrow x_1=1.$$

따라서 $$\mathbf{x}=[1,\ 2]^\top.$$

---

## 4. 알고리즘, 존재성, 수치안정성

### 4.1 Doolittle 알고리즘(단위 대각 $$\mathbf{L}$$)
- 상삼각 $$\mathbf{U}$$ 를 위에서부터, 하삼각 $$\mathbf{L}$$ 의 하부를 아래로 채웁니다.
- 피벗팅 없이 작동하려면 모든 주부 피벗이 0이 아니고 수치적으로 충분히 커야 합니다.

복잡도: 분해에 대략 $$\tfrac{2}{3}n^3$$ FLOPs, 전방/후방 대입 각 $$\sim n^2$$ FLOPs.

### 4.2 피벗팅
- **부분 피벗팅**(Partial Pivoting): 각 열에서 절댓값이 가장 큰 원소를 대각선 위치로 행 교환. 표준.
- **완전 피벗팅**(Complete Pivoting): 행과 열 모두 교환(더 안정적이나 비용 증가).
- 행 교환의 개수에 따라 $$\det(\mathbf{P})=\pm 1$$ 가 결정됩니다.

### 4.3 언제 실패하거나 나빠지는가
- 특이행렬(랭크 결핍): 어떤 단계에서 피벗이 0이 되어 실패.
- 심각한 조건수(ill-conditioned): 반올림오차 증폭. 부분 피벗팅이 보통 충분하지만 최악 사례 존재.

### 4.4 대체 분해 선택
- 대칭 양의정부호(SPD): **촐레스키**(더 빠르고 안정적).
- 최소제곱: **QR**(정사영 기반, 안정적).
- 일반적 스펙트럼/차원축소: **SVD**(가장 안정적, 가장 비쌈).

---

## 5. 행렬식, 역행렬, 다중 우변

### 5.1 행렬식
$$
\mathbf{P}\mathbf{A}=\mathbf{L}\mathbf{U}\ \Rightarrow\ 
\det(\mathbf{A})=\det(\mathbf{P})^{-1}\det(\mathbf{L})\det(\mathbf{U}).
$$
단위 대각 $$\mathbf{L}$$ 에 대해 $$\det(\mathbf{L})=1$$, 순열행렬은 $$\det(\mathbf{P})=\pm 1$$.  
따라서
$$
\det(\mathbf{A})=\operatorname{sign}(\mathbf{P})\prod_{i=1}^n u_{ii}.
$$
수치적으로는 $$\log|\det|$$ 을 합으로 누적하는 `slogdet` 류를 선호합니다.

### 5.2 역행렬
직접 $$\mathbf{A}^{-1}$$ 를 만드는 대신, 보통 **열 단위로 선형계** $$\mathbf{A}\mathbf{X}=\mathbf{I}$$ 를 풀어 $$\mathbf{X}=\mathbf{A}^{-1}$$ 를 얻습니다. 비용과 안정성을 고려하면 필요한 연산에 한해 선형계를 푸는 편이 낫습니다.

### 5.3 다중 우변
$$\mathbf{B}\in\mathbb{R}^{n\times k}$$ 에 대해
$$
\mathbf{L}\mathbf{Y}=\mathbf{P}\mathbf{B},\quad \mathbf{U}\mathbf{X}=\mathbf{Y}
$$
형태로 **열 전체를 한 번에** 전방/후방 대입하면 효율적입니다.

---

## 6. PyTorch 코드

아래 코드는 PyTorch 기준입니다(추천). 내장 함수 사용법과 학습용 직접구현을 둘 다 제공합니다.

### 6.1 내장 함수로 빠르게 쓰기

#### 6.1.1 `torch.linalg.lu` 로 $$\mathbf{P},\mathbf{L},\mathbf{U}$$ 얻기
```python
import torch
torch.set_printoptions(precision=6, sci_mode=False)
dtype = torch.float64

A = torch.tensor([[2., 3.],
                  [4., 7.]], dtype=dtype)
b = torch.tensor([8., 18.], dtype=dtype)

# PA = LU
P, L, U = torch.linalg.lu(A)

# 전방·후방 대입으로 Ax=b 풀기
Pb = P @ b
# L은 단위 하삼각으로 반환됨: unitriangular=True 지정
y  = torch.linalg.solve_triangular(L, Pb, upper=False, unitriangular=True)
x  = torch.linalg.solve_triangular(U, y,  upper=True)

print("해 x =", x)  # [1., 2.] 근사
```

#### 6.1.2 다중 우변과 행렬식
```python
# 다중 우변 (열 여러 개)
B = torch.tensor([[8., 1.],
                  [18., 0.]], dtype=dtype)  # 두 개의 우변
PB = P @ B
Y  = torch.linalg.solve_triangular(L, PB, upper=False, unitriangular=True)
X  = torch.linalg.solve_triangular(U, Y,  upper=True)
print("해 X=\n", X)  # 각 열이 대응 해

# det(A) = det(P) * prod(diag(U))  (det(P)=±1)
detP = torch.linalg.det(P)  # ±1
detU = torch.prod(torch.diag(U))
detA = detP * detU
print("det(A)≈", detA.item())

# slogdet 비교(수치적으로 권장)
s, logabs = torch.linalg.slogdet(A)
print("slogdet:", s.item(), logabs.item(), " => det≈", s.item()*torch.exp(logabs).item())
```

#### 6.1.3 역행렬을 LU로 구하기(교육용)
```python
I = torch.eye(A.shape[0], dtype=dtype)
PI = P @ I
Y  = torch.linalg.solve_triangular(L, PI, upper=False, unitriangular=True)
Ainv = torch.linalg.solve_triangular(U, Y,  upper=True)
print("A^{-1}≈\n", Ainv)
print("검증 A@A^{-1}≈I ? ", torch.allclose(A @ Ainv, I, atol=1e-12))
```

### 6.2 직접 구현(학습용, 부분 피벗팅 포함)

교육 목적으로 **Doolittle + Partial Pivoting** 을 PyTorch 연산으로 구현합니다.  
실전에서는 내장 함수를 권장합니다.

```python
def lu_partial_pivot(A, eps=1e-15):
    A = A.clone().to(torch.float64)
    n = A.shape[0]
    P = torch.eye(n, dtype=A.dtype)
    L = torch.zeros((n, n), dtype=A.dtype)
    U = A.clone()
    num_swaps = 0

    for k in range(n):
        # 피벗 선택(열 k에서 |U[i,k]| 최대)
        pivot_row = k + torch.argmax(torch.abs(U[k:, k]))
        pivot_row = int(pivot_row)

        # 행 교환
        if pivot_row != k:
            U[[k, pivot_row], :] = U[[pivot_row, k], :]
            P[[k, pivot_row], :] = P[[pivot_row, k], :]
            if k > 0:
                L[[k, pivot_row], :k] = L[[pivot_row, k], :k]
            num_swaps += 1

        pivot = U[k, k].item()
        if abs(pivot) < eps:
            raise RuntimeError("LU 실패: 거의 0 피벗(특이 또는 심각한 ill-conditioning).")

        L[k, k] = 1.0
        # 소거
        for i in range(k+1, n):
            L[i, k] = U[i, k] / U[k, k]
            U[i, k:] = U[i, k:] - L[i, k] * U[k, k:]

    return P, L, U, num_swaps

def forward_sub(L, b):
    n = L.shape[0]
    y = torch.zeros_like(b, dtype=L.dtype)
    for i in range(n):
        y[i] = b[i] - (L[i, :i] @ y[:i])
        # L의 대각이 1이라고 가정(Doolittle)
    return y

def backward_sub(U, y, eps=1e-15):
    n = U.shape[0]
    x = torch.zeros_like(y, dtype=U.dtype)
    for i in range(n-1, -1, -1):
        denom = U[i, i]
        if abs(denom) < eps:
            raise RuntimeError("후방 대입 실패: 0 피벗.")
        x[i] = (y[i] - (U[i, i+1:] @ x[i+1:])) / denom
    return x

# 테스트
A = torch.tensor([[2., 3.],
                  [4., 7.]], dtype=torch.float64)
b = torch.tensor([8., 18.], dtype=torch.float64)

P, L, U, swaps = lu_partial_pivot(A)
y = forward_sub(L, P @ b)
x = backward_sub(U, y)

print("P=\n", P, "\nL=\n", L, "\nU=\n", U, "\nx=\n", x)
```

다중 우변 버전(열 여러 개에 대해 전방/후방 대입)을 구현하면 배치로 더 효율적으로 풀 수 있습니다.

---

## 7. 실전 팁과 체크리스트

1) 기본 형태는 $$\mathbf{P}\mathbf{A}=\mathbf{L}\mathbf{U}$$ 을 사용한다.  
2) 분해는 한 번, 다중 우변은 전방·후방 대입만 반복한다.  
3) SPD면 촐레스키가 더 낫다(속도, 안정성).  
4) 최소제곱(직사각)에는 QR을 선호한다.  
5) det는 곱으로 누적하지 말고 `slogdet` 로 처리한다(언더플로/오버플로 완화).  
6) 특이 또는 ill-conditioned 감지는 피벗 절댓값, `matrix_rank`, 잔차 검사로 병행한다.  
7) 희소·밴드 구조가 있으면 해당 구조 전용 LU(스파스 LU, 밴드 LU)를 사용한다.  
8) GPU에서 큰 배치의 작은 선형계는 LU 배치 연산 또는 `solve_triangular` 배치를 활용한다.

---

## 8. 추가 예시: 피벗팅 필요성 시연

아래처럼 첫 피벗이 매우 작은 경우 피벗팅이 없으면 큰 오차가 발생할 수 있습니다.

```python
eps = 1e-12
A_bad = torch.tensor([[eps, 1.],
                      [1.,   1.]], dtype=torch.float64)
b = torch.tensor([1., 2.], dtype=torch.float64)

# 피벗팅 있는 lu
P, L, U = torch.linalg.lu(A_bad)
y  = torch.linalg.solve_triangular(L, P @ b, upper=False, unitriangular=True)
x1 = torch.linalg.solve_triangular(U, y, upper=True)

# 피벗팅 없이(학습용 직접 코드에서 pivot 비활성)라면 큰 오차/실패 가능
print("피벗팅 사용 해:", x1)
```

---

## 9. 요약

- LU는 가우스 소거를 행렬분해로 일반화한 것으로, $$\mathbf{A}=\mathbf{L}\mathbf{U}$$ 또는 피벗팅 포함 $$\mathbf{P}\mathbf{A}=\mathbf{L}\mathbf{U}$$ 로 표현합니다.  
- 분해 이후 다수의 우변에 대해 빠른 반복 풀이가 가능하며, 행렬식·역행렬 계산에도 응용됩니다.  
- 수치안정성을 위해 부분 피벗팅이 표준이며, SPD는 촐레스키, 직사각 최소제곱은 QR를 고려합니다.  
- PyTorch에서는 `torch.linalg.lu`, `torch.linalg.solve_triangular`, `torch.linalg.slogdet` 조합으로 실무 수준의 구현이 간단합니다.