---
layout: post
title: 기계학습 - 데이터 분리
date: 2025-08-19 22:25:23 +0900
category: 기계학습
---
# 데이터 분리(Train/Test Split, Cross Validation)

## 1. 왜 분리하는가: 일반화 오차를 추정하기 위해

모델이 훈련 데이터에 과도하게 적합(과적합)되는 것을 감지하고, **보지 못한 데이터에 대한 성능(일반화 성능)**을 추정하려면 **학습 데이터와 평가 데이터의 분리가 필수**다.

- **홀드아웃(Train/Test)**: 빠르고 간단. 데이터가 충분할 때 적합.
- **교차검증(CV)**: 데이터가 적거나 튜닝이 필요할 때 필수. 분할 우연성에 의한 편차를 평균으로 완화.

일반화 성능의 개념적 정의:
$$
\mathcal{E}_{gen} = \mathbb{E}_{(x,y)\sim \mathcal{D}} \big[ \ell(y, \hat f(x)) \big]
$$
여기서 \(\mathcal{D}\)는 데이터 분포, \(\ell\)은 손실 함수.

---

## 2. 기본: Train/Test Split

### 2.1 권장 비율과 지침
- 넉넉한 데이터: **Train:Test = 8:2 또는 9:1**
- 적은 데이터: **교차검증** 권장
- 분류 문제: **`stratify=y`**로 클래스 비율 유지(불균형일수록 중요)

```python
from sklearn.model_selection import train_test_split
from sklearn.datasets import load_iris

X, y = load_iris(return_X_y=True)

X_tr, X_te, y_tr, y_te = train_test_split(
    X, y, test_size=0.3, random_state=42, stratify=y
)

print(len(X_tr), len(X_te))
```

> 팁: 랜덤 시드(`random_state`)를 고정하면 재현성↑. 한 번의 스플릿에 의존하지 말고 CV나 반복 홀드아웃으로 안정화하라.

---

## 3. 교차검증(Cross Validation) — 변동성 완화와 데이터 극대 활용

### 3.1 K-Fold(기본형)
- 데이터를 \(K\)개 폴드로 나누고 **K번** 반복 학습·평가.  
- 폴드 별 점수 \(\{s_1,\dots,s_K\}\)의 평균/표준편차로 성능과 변동성을 함께 보고한다.
$$
\bar{s} = \frac{1}{K}\sum_{k=1}^K s_k,\quad
\hat{\sigma} = \sqrt{\frac{1}{K-1}\sum_{k=1}^K (s_k - \bar{s})^2}
$$

```python
from sklearn.model_selection import KFold, cross_val_score
from sklearn.linear_model import LogisticRegression
from sklearn.datasets import load_iris

X, y = load_iris(return_X_y=True)
kf = KFold(n_splits=5, shuffle=True, random_state=42)
scores = cross_val_score(LogisticRegression(max_iter=1000), X, y, cv=kf)
print("Fold scores:", scores, "Mean:", scores.mean(), "Std:", scores.std())
```

### 3.2 Stratified K-Fold(분류 권장)
- 각 폴드가 **클래스 비율을 유지**. 불균형일수록 필수.

```python
from sklearn.model_selection import StratifiedKFold
skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
```

### 3.3 Repeated K-Fold(반복 CV)
- K-Fold를 여러 번 다른 셔플로 반복 → 점수 분산을 더 잘 추정.

```python
from sklearn.model_selection import RepeatedStratifiedKFold
rskf = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=42)
```

### 3.4 LOOCV(Leave-One-Out)
- 샘플 \(n\)개면 \(n\)회 반복. 데이터가 극소일 때 유용하지만 **비용↑·분산↑**.

```python
from sklearn.model_selection import LeaveOneOut, cross_val_score
loo = LeaveOneOut()
# scores = cross_val_score(model, X, y, cv=loo)  # n번 학습
```

### 3.5 ShuffleSplit / Repeated Holdout
- 홀드아웃을 다회 반복(무작위 분할)해 평균. 빠르고 간단.

```python
from sklearn.model_selection import StratifiedShuffleSplit, cross_val_score
sss = StratifiedShuffleSplit(n_splits=10, test_size=0.2, random_state=42)
```

---

## 4. 특수 상황별 분할법 — 누수 방지의 핵심

### 4.1 그룹이 있는 데이터(Grouped CV)
- **같은 개인/세션/환자/고객**의 샘플이 **훈련과 검증에 동시에 등장**하면 누수.  
- **`GroupKFold`**로 **그룹 단위**로 분리.

```python
import numpy as np
from sklearn.model_selection import GroupKFold, cross_val_score
from sklearn.linear_model import LogisticRegression

# 예: 동일 user_id를 같은 폴드에
groups = np.array([0,0,1,1,2,2,2,3,3,4,4,4])  # 길이는 샘플 수와 동일

gkf = GroupKFold(n_splits=5)
scores = cross_val_score(LogisticRegression(max_iter=1000), X, y, cv=gkf.split(X, y, groups=groups))
print(scores.mean())
```

### 4.2 시간열(Time Series) — 미래를 절대 보지 말 것
- **시계열 누수** 방지: 과거로 학습, 미래로 평가.  
- **`TimeSeriesSplit`**은 점진적 확장(**expanding window**) 또는 롤링 창.

```python
from sklearn.model_selection import TimeSeriesSplit
tscv = TimeSeriesSplit(n_splits=5)
for tr_idx, te_idx in tscv.split(X):
    X_tr, X_te = X[tr_idx], X[te_idx]
    y_tr, y_te = y[tr_idx], y[te_idx]
```

> 고급: 금융 등 **겹침(purging)**·**휴지기(embargo)**까지 고려한 분할이 필요할 수 있다(동일 이벤트 누수 차단).

### 4.3 다중 레이블/희소 텍스트
- **다중 레이블**은 단순 stratify가 어긋난다. “iterative stratification”(외부 패키지)이 도움.  
- 텍스트/이미지: **문서 단위 그룹**(사용자/뉴스 소스/촬영 세션)으로 분리해 누수 차단.

---

## 5. 데이터 누수(Data Leakage) — 가장 흔한 실패 원인

### 5.1 전처리 누수
- 스케일러/인코더를 전체 데이터에 `fit` → 훈련/검증에 정보 공유 = 누수.
- **항상 파이프라인(Pipeline)**으로 **각 폴드 학습 데이터에만 `fit`** 하도록 한다.

```python
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import cross_val_score, StratifiedKFold

pipe = Pipeline([
    ("scaler", StandardScaler()),
    ("clf", LogisticRegression(max_iter=1000))
])

skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
scores = cross_val_score(pipe, X, y, cv=skf, scoring="roc_auc")
print(scores.mean())
```

### 5.2 타깃 누수
- 미래 정보/레이블을 유출(예: “총 매출” 포함된 피처로 월 매출 예측).
- 시계열의 **시점 일치** 확인, 집계/라벨링 창 관리(라벨보다 미래 데이터를 집계하지 않기).

---

## 6. Train/Validation/Test — 3-Way 분리와 교차검증 결합

- **Train**: 학습  
- **Validation**: 모델 선택/튜닝  
- **Test(잠금)**: 마지막에 한 번만 성능 보고

권장 워크플로:
1) Train 내부에서 **교차검증**으로 하이퍼파라미터 선택(또는 **중첩 CV**)  
2) 선택된 모델로 전체 Train 재학습  
3) **잠금 Test**에 단 한 번 평가(보고용)

비율 예:
- 6:2:2 또는 7:1.5:1.5 (데이터 규모에 따라 조정)

---

## 7. 하이퍼파라미터 튜닝 — 중첩 교차검증(Nested CV)

**동일 검증 데이터를 여러 후보 모델 테스트에 재사용**하면 성능 과대평가.  
**Nested CV**는 바깥 루프로 **일반화 성능 추정**, 안쪽 루프로 **튜닝**.

```python
import numpy as np
from sklearn.model_selection import StratifiedKFold, GridSearchCV, cross_val_score
from sklearn.svm import SVC

param_grid = {"C":[0.1,1,10], "gamma":[1e-3,1e-2,1e-1]}
inner = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)
outer = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

clf = GridSearchCV(SVC(kernel="rbf", probability=True), param_grid, cv=inner, scoring="roc_auc")
nested_scores = cross_val_score(clf, X, y, cv=outer, scoring="roc_auc")
print("Nested CV AUC: ", nested_scores.mean(), "±", nested_scores.std())
```

> 실무: 시간이 부담되면 **CV + 별도 홀드아웃 검증 + 잠금 테스트**로 근사.

---

## 8. OOF(Out-of-Fold) 예측과 스태킹

- **OOF 예측**: 각 샘플에 대해 **그 샘플이 검증이었던 폴드의 예측**을 모아 만든 벡터.  
- 메타모델(스태킹) 학습 시 **훈련 데이터에서도 과적합 없이** 상위 모델의 입력으로 사용.

```python
import numpy as np
from sklearn.model_selection import StratifiedKFold
from sklearn.linear_model import LogisticRegression

skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
oof = np.zeros(len(X))
for tr_idx, va_idx in skf.split(X, y):
    model = LogisticRegression(max_iter=1000).fit(X[tr_idx], y[tr_idx])
    oof[va_idx] = model.predict_proba(X[va_idx])[:,1]

# oof -> 메타모델의 피처로 사용(스태킹)
```

---

## 9. 성능의 불확실성: 신뢰구간과 검정

### 9.1 부트스트랩 신뢰구간(CI)
- 테스트 세트에서 **부트스트랩 리샘플링**으로 점수의 CI 추정.

```python
import numpy as np
from sklearn.metrics import roc_auc_score
rng = np.random.default_rng(42)

proba = best_model.predict_proba(X_te)[:,1]

def bootstrap_ci(y_true, y_score, n=2000, alpha=0.05):
    n_samples = len(y_true)
    stats = []
    for _ in range(n):
        idx = rng.choice(n_samples, n_samples, replace=True)
        stats.append(roc_auc_score(y_true[idx], y_score[idx]))
    lo, hi = np.percentile(stats, [100*alpha/2, 100*(1-alpha/2)])
    return np.mean(stats), lo, hi

m, lo, hi = bootstrap_ci(y_te, proba)
print(f"AUC Bootstrap mean={m:.4f}, 95% CI=({lo:.4f}, {hi:.4f})")
```

### 9.2 모델 비교 검정
- **같은 테스트셋**에서 두 분류기의 **이진 예측** 비교: **McNemar 검정**(라벨과 불일치 패턴 기반).  
- ROC-AUC 비교는 **DeLong 검정**(외부 구현 필요).  
- CV 폴드 점수의 단순 t-검정은 **독립성 가정 위배**에 주의(교차의존). 보수적으로 해석.

---

## 10. 불균형/메트릭/임계값 — 분할과 평가지표의 일치

- 불균형 데이터: **Stratified CV + PR-AUC / F1 / Recall@K** 등의 **업무 목적과 일치하는 지표**.  
- 확률 예측 모델은 **임계값 최적화**(예: 유틸리티/코스트 기반)도 검증 내에서 수행해야 누수 방지.

```python
from sklearn.metrics import precision_recall_curve, average_precision_score
p, r, t = precision_recall_curve(y_te, proba)
ap = average_precision_score(y_te, proba)
```

---

## 11. 시간열 실전 레시피 — 확장/롤링/조기중단

- **Expanding window**: 학습 창을 늘리며 앞으로 예측.  
- **Rolling window**: 고정 길이 창을 굴리며 예측(개념 변화 적응).  
- **조기중단(Early stopping)**: 예측 기간별 검증 점수로 스텝 수/학습률 조절.

```python
import numpy as np
from sklearn.model_selection import TimeSeriesSplit
from sklearn.ensemble import HistGradientBoostingRegressor
from sklearn.metrics import mean_absolute_error

tscv = TimeSeriesSplit(n_splits=5)
maes = []
for tr_idx, va_idx in tscv.split(X):
    X_tr, X_va = X[tr_idx], X[va_idx]
    y_tr, y_va = y[tr_idx], y[va_idx]
    mdl = HistGradientBoostingRegressor(
        learning_rate=0.05, max_depth=6, early_stopping=True, validation_fraction=0.2,
        random_state=42
    ).fit(X_tr, y_tr)
    pred = mdl.predict(X_va)
    maes.append(mean_absolute_error(y_va, pred))
print("TSCV MAE:", np.mean(maes))
```

---

## 12. 파이프라인 + ColumnTransformer — “전처리 누수 0” 실전

- 수치/범주형을 **각 폴드 학습 데이터로만** `fit` 하도록 파이프라인 구성.

```python
import numpy as np
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import StratifiedKFold, cross_val_score

num_idx = [0,1,2]    # 수치 컬럼 인덱스
cat_idx = [3,4]      # 범주 컬럼 인덱스

pre = ColumnTransformer([
    ("num", StandardScaler(), num_idx),
    ("cat", OneHotEncoder(handle_unknown="ignore"), cat_idx)
])

pipe = Pipeline([
    ("pre", pre),
    ("clf", LogisticRegression(max_iter=2000))
])

skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
scores = cross_val_score(pipe, X, y, cv=skf, scoring="roc_auc")
print(scores.mean(), scores.std())
```

---

## 13. 학습곡선/검증곡선 — 데이터/튜닝 민감도 보기

- **Learning Curve**: 데이터 크기에 따른 성능 → **데이터 더 모으면 좋아지는가?**
- **Validation Curve**: 하이퍼파라미터에 따른 성능 → **튜닝 감도/최적영역** 파악

```python
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import learning_curve, validation_curve
from sklearn.svm import SVC

train_sizes, train_scores, val_scores = learning_curve(
    SVC(kernel="rbf", gamma=0.01), X, y, cv=5, train_sizes=np.linspace(0.1, 1.0, 5)
)
plt.plot(train_sizes, val_scores.mean(axis=1), "-o"); plt.title("Learning Curve"); plt.show()

param_range = np.logspace(-3, 1, 5)
train_scores, val_scores = validation_curve(
    SVC(kernel="rbf"), X, y, param_name="C", param_range=param_range, cv=5
)
plt.semilogx(param_range, val_scores.mean(axis=1), "-o"); plt.title("Validation Curve(C)"); plt.show()
```

---

## 14. 체크리스트 & 베스트 프랙티스

1. **문제 구조 파악**: 독립 i.i.d.인가? **시간 의존/그룹**이 있는가? → 분할 전략 결정  
2. **누수 방지**: 파이프라인 필수, 시계열 창 관리, 그룹 분리  
3. **지표 일치**: 업무 목표(예: 리콜 우선/정밀도 우선)에 맞는 지표 선택  
4. **튜닝 절차**: (Nested) CV 또는 별도 검증세트 + 최종 잠금 테스트  
5. **불확실성 보고**: 평균±표준편차, 부트스트랩 신뢰구간  
6. **임계값/캘리브레이션**: 검증 내에서 최적화, 필요 시 Platt/Isotonic  
7. **재현성**: 시드 고정, 데이터 스냅샷, 환경/버전 기록  
8. **데이터 드리프트**: 시간열/프로덕션 환경에서 **주기적 재평가** 설계

---

## 15. 종합 예제 — 이진 분류 전체 워크플로(불균형 + 파이프라인 + Nested CV + 최종 Test)

```python
import numpy as np
from sklearn.datasets import make_classification
from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.metrics import classification_report, roc_auc_score
from sklearn.linear_model import LogisticRegression

# 1. 데이터 (가상, 불균형)
X, y = make_classification(n_samples=20000, n_features=20, n_informative=8,
                           weights=[0.85, 0.15], flip_y=0.01, random_state=7)

X_tr, X_te, y_tr, y_te = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

# 2. 전처리 파이프라인 (여기서는 전부 수치라고 가정)
pre = ColumnTransformer([("num", StandardScaler(), list(range(X.shape[1])))], remainder="drop")

pipe = Pipeline([
    ("pre", pre),
    ("clf", LogisticRegression(max_iter=5000, class_weight="balanced"))
])

# 3. 하이퍼파라미터 튜닝 (Nested CV)
param_grid = {"clf__C":[0.01, 0.1, 1, 10]}
inner = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)
outer = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

gs = GridSearchCV(pipe, param_grid, cv=inner, scoring="roc_auc", n_jobs=-1)
outer_scores = []
for tr_idx, va_idx in outer.split(X_tr, y_tr):
    gs.fit(X_tr[tr_idx], y_tr[tr_idx])
    proba = gs.predict_proba(X_tr[va_idx])[:,1]
    outer_scores.append(roc_auc_score(y_tr[va_idx], proba))

print("Nested CV AUC:", np.mean(outer_scores), "±", np.std(outer_scores))
print("Best params (last fold):", gs.best_params_)

# 4. 전체 Train 재학습 → 잠금 Test 평가
best_model = gs.best_estimator_.fit(X_tr, y_tr)
y_pred = best_model.predict(X_te)
y_proba = best_model.predict_proba(X_te)[:,1]

print("Test AUC:", roc_auc_score(y_te, y_proba))
print(classification_report(y_te, y_pred, digits=4))
```

---

## 16. 요약

- **목표**: 훈련·평가 분리로 **일반화 성능**을 추정  
- **방법**: 홀드아웃(빠름) vs. 교차검증(안정) — 데이터 구조(그룹/시간열)에 맞춘 **전용 분할기** 사용  
- **누수 방지**: **파이프라인**으로 각 폴드에서 전처리 `fit`  
- **튜닝**: **(중첩) 교차검증**으로 과대평가 차단, 최종 **잠금 테스트** 한 번만  
- **신뢰보고**: 평균±표준편차, **부트스트랩 CI**, 필요 시 **검정**  
- **실전 팁**: Stratified, GroupKFold, TimeSeriesSplit, Repeated K-Fold, OOF/스태킹, 조기중단, 목적지표 일치