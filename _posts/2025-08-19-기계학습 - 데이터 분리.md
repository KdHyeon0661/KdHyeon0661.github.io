---
layout: post
title: 기계학습 - 데이터 분리
date: 2025-08-19 22:25:23 +0900
category: 기계학습
---
# 📊 데이터 분리 (Train/Test Split, Cross Validation)

머신러닝 모델을 학습할 때, **데이터 분리**는 필수적인 과정입니다.  
모델이 단순히 훈련 데이터만 잘 외우는(과적합, Overfitting) 것이 아니라 **새로운 데이터에서도 잘 일반화(Generalization)** 할 수 있는지 확인하기 위해서입니다.  

---

## 1. Train / Test Split

### (1) 기본 개념
- 데이터를 **훈련용(Train Set)** 과 **테스트용(Test Set)** 으로 분리  
- Train Set: 모델 학습에 사용  
- Test Set: 학습된 모델 성능 평가에 사용 (일종의 "시험")  

### (2) 왜 필요한가?
- 모든 데이터를 학습에 사용하면, 모델이 성능을 평가할 수 없음  
- 훈련과 평가를 분리해야 "모르는 데이터에 대한 예측 성능"을 추정 가능  

### (3) 일반적인 분리 비율
- **훈련:테스트 = 8:2** 또는 **7:3**
- 데이터가 많으면 9:1도 가능
- 데이터가 적으면 교차 검증(Cross Validation)을 사용

### (4) 파이썬 예시
```python
from sklearn.model_selection import train_test_split
from sklearn.datasets import load_iris

X, y = load_iris(return_X_y=True)

# 70% 학습, 30% 테스트 분리
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42, stratify=y
)

print("Train size:", len(X_train))
print("Test size:", len(X_test))
```

👉 `stratify=y` 옵션은 **분류 문제에서 클래스 비율을 유지**하도록 데이터를 나눔

---

## 2. Cross Validation (교차 검증)

### (1) 기본 개념
- 데이터를 단순히 Train/Test로만 나누면, 분리 방식에 따라 성능 평가가 달라질 수 있음  
- 이를 보완하기 위해 **여러 번 데이터를 나누어 학습과 평가를 반복**하는 방법  

### (2) K-Fold Cross Validation
- 데이터를 **K개의 폴드(Fold)** 로 나눔
- 매번 1개의 폴드를 검증용(Validation)으로 사용하고, 나머지 K-1개를 학습에 사용
- 총 K번 반복하여 나온 결과를 평균내어 최종 성능 추정

#### 예시 (K=5)
1. Fold1: Test / Fold2~5: Train  
2. Fold2: Test / Fold1,3~5: Train  
3. Fold3: Test / Fold1,2,4,5: Train  
4. Fold4: Test / Fold1,2,3,5: Train  
5. Fold5: Test / Fold1~4: Train  

👉 결과를 평균하면 "데이터 분할의 편향"을 줄일 수 있음

### (3) Stratified K-Fold
- 분류 문제에서는 클래스 불균형 문제가 있으므로, **각 Fold가 클래스 비율을 유지**하도록 분리하는 방식
- 불균형 데이터셋에서 권장됨

### (4) Leave-One-Out Cross Validation (LOOCV)
- 데이터가 n개일 때, n-1개를 학습에 사용하고 1개를 검증에 사용
- n번 반복하여 평균 성능을 계산
- 데이터가 적을 때 사용하지만, 계산량이 많음

### (5) 파이썬 예시
```python
from sklearn.model_selection import KFold, cross_val_score
from sklearn.linear_model import LogisticRegression
from sklearn.datasets import load_iris

X, y = load_iris(return_X_y=True)

# 5-Fold 교차검증
kf = KFold(n_splits=5, shuffle=True, random_state=42)
model = LogisticRegression(max_iter=1000)

scores = cross_val_score(model, X, y, cv=kf)
print("각 Fold 정확도:", scores)
print("평균 정확도:", scores.mean())
```

---

## 3. Train/Validation/Test 분리

실무에서는 단순 Train/Test만으로는 부족할 수 있음.  
모델을 튜닝할 때 Test Set까지 사용하면 "데이터 누수(Data Leakage)"가 발생 → 일반화 성능 과대평가 위험.  

👉 따라서 **3-way split** 사용:
1. **Train Set**: 학습
2. **Validation Set**: 모델 선택, 하이퍼파라미터 튜닝
3. **Test Set**: 최종 성능 평가 (마지막에만 사용)

예시 비율:
- Train:Validation:Test = 6:2:2
- 데이터가 적다면 K-Fold 교차검증으로 Validation을 대체

---

## 4. Cross Validation vs. Train/Test Split

| 구분 | Train/Test Split | Cross Validation |
|------|------------------|------------------|
| 장점 | 빠르고 간단 | 데이터 활용 극대화, 성능 안정적 |
| 단점 | 분할에 따라 성능 편차 발생 | 계산 비용 큼 (반복 학습 필요) |
| 권장 상황 | 데이터 많을 때 | 데이터 적거나 모델 튜닝 필요할 때 |

---

## 📌 요약
- Train/Test Split: 간단히 데이터 나누어 훈련/평가  
- Cross Validation: 여러 번 나누어 평균 성능 평가 (편향 줄임)  
- Train/Validation/Test: 실무에서 최종 성능 검증 시 필수  

---

👉 결론:  
- **데이터 많음 → Train/Test만 나눠도 충분**  
- **데이터 적음 → Cross Validation 필수**  
- **실무 프로젝트 → Train/Validation/Test 구조 + 필요시 교차검증 활용**  