---
layout: post
title: 운영체제 - 네트워크와 분산시스템 (2)
date: 2025-11-02 22:25:23 +0900
category: 운영체제
---
# Chapter 19 — Networks and Distributed Systems (2)

## 19.4 Network and Distributed Operating Systems

### 19.4.1 용어와 스펙트럼

- **Network OS(네트워크 OS)**
  각 노드는 **자기 커널/파일시스템/프로세스 공간**을 가진다. 통신은 **원격 로그인/파일 공유/RPC** 로 연결. 예: 전통 UNIX+NFS, Windows+SMB.
  *특징:* 느슨한 결합, 관리·업그레이드가 독립.

- **Distributed OS(분산 OS)**
  **한 대의 OS처럼** 보이도록 **투명성**을 제공(이름·위치·이동·복제·오류·동시성 투명성). 예: Plan 9, Amoeba, Sprite, Chorus/MiNIX/L4 계열 실험, 최근엔 **클러스터 매니저(Kubernetes/Mesos/Borg)** 가 “분산 OS에 준하는 자원 스케줄러” 역할.
  *특징:* 강 결합, 단일 시스템 이미지(SSI)에 가까움.

> **투명성 차원(요약)**
> - 접근, 위치, 이동, 복제, 동시성, 장애, 성능, 스케일 투명성

---

### 19.4.2 분산 OS의 구성 블록

- **이름공간(Name space)**: 전역 경로/서비스(Plan 9의 9P, UNIX VFS+mount, gRPC/Service Discovery).
- **IPC**: 메시지 전달(RPC/RDMA) vs 공유 메모리(DSM/NUMA).
- **스케줄링**: 클러스터 전체 **작업/컨테이너/VM**의 배치·격리(cgroup/네임스페이스).
- **파일/저장**: 네트워크 파일시스템(NFS/AFS/SMB), 분산 FS(GFS/HDFS/CephFS).
- **메모리**: DSM(Release/Entry Consistency), 원격 페이징/스왑.
- **보안**: mTLS/커버로스/권한 모델(RBAC/능력).
- **관측성**: 트레이싱(분산 트레이스), 메트릭, 로깅.

---

### 19.4.3 사례 스케치

- **Plan 9**: “모든 것은 파일” + **9P 프로토콜**. 각 프로세스는 자신만의 이름공간을 가진다.
- **Amoeba**: 객체·능력(capability) 기반 액세스 제어, 마이크로커널 + RPC.
- **Sprite**: 네트워크-wide 프로세스 마이그레이션, 파일캐시 일관성 콜백.
- **현대**: Linux+KVM 위 **Kubernetes**(컨테이너), **Ceph**(스토리지), **Istio**(서비스 메시) 조합 → 사실상의 분산 OS.

---

### 19.4.4 미니 실습① — “원격 fork/exec”에 해당하는 RPC

> *아이디어:* Network OS에서 `rsh/ssh`·원격 exec은 기본기. 아래는 **RPC 기반 원격 실행기**의 최소골격(개념).

```python
# remote_exec_server.py — asyncio RPC: 명령을 실행하고 stdout/rc를 반환
import asyncio, json, shlex

async def handle(reader, writer):
    try:
        req = json.loads((await reader.readuntil(b"\n")).decode())
        cmd = req["cmd"]; timeout = req.get("timeout", 5)
        proc = await asyncio.create_subprocess_exec(*shlex.split(cmd),
                    stdout=asyncio.subprocess.PIPE, stderr=asyncio.subprocess.STDOUT)
        try:
            out, _ = await asyncio.wait_for(proc.communicate(), timeout=timeout)
            resp = {"rc": proc.returncode, "out": out.decode(errors="ignore")}
        except asyncio.TimeoutError:
            proc.kill(); resp = {"rc": -1, "out": "timeout"}
    except Exception as e:
        resp = {"rc": -2, "out": f"error:{e}"}
    writer.write((json.dumps(resp)+"\n").encode()); await writer.drain(); writer.close()

async def main():
    srv = await asyncio.start_server(handle, "0.0.0.0", 7777)
    async with srv: await srv.serve_forever()

asyncio.run(main())
```

```python
# remote_exec_client.py
import asyncio, json
async def run(cmd):
    r, w = await asyncio.open_connection("127.0.0.1", 7777)
    w.write((json.dumps({"cmd": cmd, "timeout": 3})+"\n").encode()); await w.drain()
    resp = json.loads((await r.readuntil(b"\n")).decode()); print(resp)
    w.close(); await w.wait_closed()
asyncio.run(run("uname -a"))
```

*포인트:* at-most-once 보장, 인증·ACL·리소스 제한(cgroup)·로그/감사가 실제 운영의 핵심.

---

### 19.4.5 미니 실습② — “가짜 DSM”으로 콜백 무효화 맛보기

> *아이디어:* **AFS-style 콜백**(서버가 “네 캐시 무효화해!”)을 **키-값**에 흉내.

```python
# dsm_like.py — 서버 콜백으로 캐시 무효화(극단 단순화)
from collections import defaultdict

class KV:
    def __init__(self):
        self.v = {}; self.subs = defaultdict(set)
    def get(self, k, who):
        self.subs[k].add(who); return self.v.get(k)
    def put(self, k, val):
        self.v[k]=val
        for who in list(self.subs[k]): who.invalidate(k)

class Client:
    def __init__(self, name, srv): self.name=name; self.srv=srv; self.cache={}
    def read(self, k):
        if k in self.cache: return self.cache[k]
        v=self.srv.get(k, self); self.cache[k]=v; return v
    def write(self,k,v): self.srv.put(k,v)
    def invalidate(self,k):
        if k in self.cache: del self.cache[k]

srv=KV(); c1=Client("c1",srv); c2=Client("c2",srv)
c1.write("a","1"); print(c2.read("a"))  # cache("1")
c1.write("a","2"); print(c2.read("a"))  # 콜백 무효화되어 최신 "2" 재조회
```

---

### 19.4.6 프로세스 마이그레이션 개념(현대식 실무 힌트)

- **체크포인트/리스토어(CRIU)** 로 프로세스(혹은 컨테이너) 상태를 덤프→다른 호스트에서 복원.
- 네트워킹(소켓), 파일 핸들, 커널 버전 차이는 제약. 보통 **서비스 레벨**에서 “재기동+세션 이전”이 현실적.

```bash
# (개념) Docker + CRIU
docker checkpoint create --leave-running myct cp1
# 대상 호스트로 이미지/레이어/체크포인트 전송 후
docker start --checkpoint cp1 myct
```

---

## 19.5 Design Issues in Distributed Systems

### 19.5.1 대원칙: 투명성·확장성·내결함성·보안의 균형

- **투명성** 높일수록 **복잡성/상태** 증가 → 장애·스케일 도전.
- **확장성**(스루/지연/상태 크기)과 **강한 일관성**은 상충(대기시간 하한은 **빛의 속도**).
- **내결함성**은 **중복**(복제/파티셔닝)을 요구하고, **정족수/합의**로 제어한다.
- **보안**(mTLS·권한·감사)은 운영 복잡도/성능에 영향.

---

### 19.5.2 이름짓기/발견(Naming & Discovery)

- **정적**(설정 파일), **동적**(Service Registry: etcd/Consul/ZooKeeper), **DNS-SD**.
- 버전·지역·헬스 기반 **선택**(traffic shaping).
- **일관 해싱**으로 파티션 배정(가상 노드로 핫스팟 완화).

---

### 19.5.3 일관성 모델(Consistency Models)

- **강한 일관성(Linearizability)**: 전역 선형 순서. 지연↑, 다중 리전에 비용 큼.
- **순차(Sequential)**: 모든 노드는 같은 순서로 본다(시간은 현실과 다를 수).
- **점진/약한(Eventual)**: 시간 지나면 수렴. CRDT/오류 내성↑.
- **원자적 읽기/쓰기(ABD)**, **세션 일관성**, **원자 브로드캐스트** 등도 실무 조합.

> **쿼럼 조건**
> $$R+W>N,\quad W>\frac{N}{2}$$
> 읽기/쓰기 각각이 “충분히 겹치도록” 하여 최신성 보장.

---

### 19.5.4 동기화·합의

- **락**: 분산 락은 *대기·결정성·장애 처리*가 관건(리스 기반).
- **2PC**: 코디네이터 장애 시 블로킹.
- **합의(Raft/Paxos)**: 로그 복제 + 리더 선출.

```python
# simple_lease_lock.py — (개념) 리스 기반 분산 락
import time
class LeaseLock:
    def __init__(self): self.owner=None; self.exp=0
    def try_acquire(self, who, ttl=5):
        now=time.time()
        if now>=self.exp or self.owner==who:
            self.owner=who; self.exp=now+ttl; return True
        return False
    def release(self, who):
        if self.owner==who: self.exp=0; self.owner=None
```

*운영 팁:* 리더·락·캐시 **모두 “시간” 의존** → **NTP**·시간 드리프트 감시가 필수.

---

### 19.5.5 장애 모델/복구

- **Crash-stop** vs **Byzantine**. 대부분은 crash+임시 네트워크 분할 가정.
- **회복력 지표**: MTBF, MTTR, 에러 예산(SLO) 설계.
- **장애 주입**(chaos)으로 가설 검증.

---

### 19.5.6 보안

- **경로 암호화**(TLS 1.3/mTLS), **권한**(JWT/OAuth/RBAC), **감사 로깅**.
- **비밀 관리**(KMS/Secret store), 키 회전·폐기 자동화.
- **멀티테넌시**: 네임스페이스/네트워크 정책/노드 격리.

---

### 19.5.7 관측성

- **분산 트레이싱**(Trace/Span), **메트릭**(RED/USE), **로그**(구조화/샘플링).
- **꼬리 지연 관리**: 슬로우 요청 복제, hedged requests(상대 비용 주의).

---

### 19.5.8 지연·대역폭 모델링

- **직렬화/암복호**/프레임/큐잉/전송/서버 처리로 지연 누적.
- **경합**: p95→p99로 튀는 원인은 **스파이크·GC·락 경합**.
- $$T_{\text{end}} \approx T_{\text{ser}} + T_{\text{queue}} + T_{\text{net}} + T_{\text{svc}}$$

---

### 19.5.9 미니 실습 — “쓰기-소유자(Primary) + 읽기 복제” 서비스

```python
# primary_backup.py — 단일 프라이머리, n개의 리드 레플리카 (쓰기 재플리케이션, 읽기 R=1)
class Primary:
    def __init__(self, replicas): self.ver=0; self.v={}; self.reps=replicas
    def put(self, k, val):
        self.ver+=1; self.v[k]=(self.ver,val)
        acks=0
        for r in self.reps:
            if r.apply(k,self.v[k]): acks+=1
        return acks==len(self.reps)
    def get(self,k): return self.v.get(k)
class Replica:
    def __init__(self): self.v={}
    def apply(self,k,verval):
        self.v[k]=verval; return True
    def get(self,k): return self.v.get(k)
reps=[Replica() for _ in range(2)]; p=Primary(reps)
p.put("x","1"); print(reps[0].get("x"))
```

*설계 포인트*: Lag 감시, **리드 리디렉션**(stale 방지), **프라이머리 페일오버** 시 **정족수 합의** 필요.

---

## 19.6 Distributed File Systems (DFS)

### 19.6.1 목표/요구사항

- **투명성**: 위치/이동/접근 동일(마운트/경로).
- **일관성**: 캐시가 있는 읽기/쓰기 동작 정의(NFS·AFS·SMB·POSIX).
- **확장성**: 메타데이터 병목, 디렉터리 핫스팟 관리.
- **내결함성**: 복제/리밸런싱, 재시작 내구성.
- **보안**: 인증(커버로스/mTLS), ACL/권한.
- **성능**: 대용량 순차 I/O vs 소파일 메타데이터 폭주.

---

### 19.6.2 아키텍처 패턴

1) **클라이언트-서버(Stateless vs Stateful)**
   - *Stateless*: NFSv3 — 서버가 상태 최소화(크래시 복구 용이), 대신 **idempotent** 요구.
   - *Stateful*: NFSv4/SMB — 락/委任(delegation)/캘백으로 캐시 일관성↑.

2) **메타데이터/데이터 분리**
   - 메타데이터 서버(MDS) + 청크 서버(데이터). 예: GFS/HDFS/CephFS.
   - **큰 파일·큰 청크**(64MiB~256MiB)로 메타데이터 비중↓, 순차 I/O 최적.

3) **오브젝트 스토리지 인터페이스**
   - 키/버킷(평평한 네임스페이스), S3 API, 결국 위에 POSIX 레이어를 붙이거나(게이트웨이) 애플리케이션이 적응.

---

### 19.6.3 캐싱 & 일관성

- **클라이언트 캐시**: 데이터/속성(attr) 캐시.
- **무효화 전략**: 시간 기반(TTL), 호출 기반(callback, AFS/NFSv4 delegation).
- **쓰기 의미**
  - **클로즈-투-오픈(consistency)**: 파일 닫고 나면 다른 노드의 open에서 최신 보장(NFS 스타일).
  - **엄격한 POSIX**: 모든 write가 즉시 보임(분산에선 비용↑).

---

### 19.6.4 NFS/AFS/SMB 빠른 비교

| 항목 | NFSv3 | NFSv4 | AFS | SMB3 |
|---|---|---|---|---|
| 상태 | Stateless | Stateful | Stateful | Stateful |
| 일관성 | close-to-open | delegation/lock | 콜백 | oplock/lease |
| 보안 | AUTH_SYS/Kerberos | Kerberos | Kerberos | NTLM/Kerberos |
| 잠금 | 별도(NLM) | 통합 | 통합 | 통합 |

---

### 19.6.5 GFS/HDFS/CephFS 설계 요점

- **GFS/HDFS**: *Master/NameNode*가 파일→청크 메타데이터 관리, *Chunk/DataNode* 가 데이터를 복제(예: 3중). **대용량 순차 쓰기**에 최적.
- **CephFS**: **CRUSH** 기반 분산 배치(메타데이터도 다수 MDS), 오브젝트 RGW, 블록 RBD까지 포괄.

> **복제 오버헤드**
> $$\text{Storage Overhead} = \frac{k+m}{k}$$
> (Reed–Solomon $$k\!+\!m$$ 부호에서 데이터 $$k$$, 패리티 $$m$$)

---

### 19.6.6 운영 명령 스니펫

```bash
# NFS 서버(예: /srv/share 읽기/쓰기)
echo "/srv/share 10.0.0.0/24(rw,sync,no_root_squash)" | sudo tee -a /etc/exports
sudo exportfs -ra

# 클라이언트 마운트
sudo mount -t nfs -o vers=4,sec=krb5 nfs-server:/srv/share /mnt

# SMB 공유
sudo smbpasswd -a user
# /etc/samba/smb.conf 에 [share] 섹션 추가 후:
sudo systemctl restart smbd
```

---

### 19.6.7 미니 DFS 실습 — “메타서버 + 청크서버” 시뮬레이터

> *학습용:* 파일을 64KiB 청크로 쪼개어 **멀티 청크서버**에 분산 저장·복제(2중). 실제 네트워크 I/O 대신 **메모리**에 저장.

```python
# mini_dfs.py — 교육용 초간단 DFS (메타데이터 + 청크 복제)
import os, math, hashlib, random
CHUNK=64*1024

class ChunkServer:
    def __init__(self, name): self.name=name; self.blobs={}
    def put(self, chunk_id, data): self.blobs[chunk_id]=data; return True
    def get(self, chunk_id): return self.blobs.get(chunk_id)

class Meta:
    def __init__(self, chunk_servers, repl=2):
        self.cs=chunk_servers; self.repl=repl; self.files={}  # name -> [chunk_id...]
        self.loc={}  # chunk_id -> [servers...]
    def put_file(self, name, data:bytes):
        chunks = [data[i:i+CHUNK] for i in range(0,len(data),CHUNK)] or [b""]
        ids=[];
        for i,c in enumerate(chunks):
            cid = hashlib.sha1(f"{name}:{i}:{len(c)}".encode()).hexdigest()
            ids.append(cid)
            targets = random.sample(self.cs, self.repl)
            for t in targets: t.put(cid, c)
            self.loc[cid]=targets
        self.files[name]=ids
    def get_file(self, name):
        out=[]
        for cid in self.files[name]:
            for s in self.loc[cid]:
                blob=s.get(cid)
                if blob is not None: out.append(blob); break
        return b"".join(out)

# 데모
cs=[ChunkServer(f"s{i}") for i in range(4)]
m=Meta(cs,repl=2)
m.put_file("hello.txt", b"A"*70000 + b"B"*100)
print(len(m.get_file("hello.txt")))
```

*확장 방향:*
- **메타 복제**(합의/스냅샷), **청크 재복제**(rebalancer), **압축/암호화**, **에러코드/리트라이**, **스트리밍 업/다운로드**.

---

### 19.6.8 FUSE로 “로컬 마운트” 느낌 내기(개념)

> 실제 구현은 길어지므로 골격만. `fusepy` 같은 라이브러리로 `read`, `readdir`, `open` 에서 **메타서버 호출→청크 병합**.

```python
# fuse_skeleton.py — FUSE 핸들러 골격(동작 예시는 생략)
class MiniDFS(Operations):
    def __init__(self, meta): self.meta=meta
    def getattr(self, path, fh=None): ...
    def readdir(self, path, fh): ...
    def open(self, path, flags): ...
    def read(self, path, size, offset, fh): ...
```

---

### 19.6.9 캐시 일관성: 콜백/리스

- **콜백 무효화**(AFS): 서버가 **변경 시** 해당 파일 핸들의 캐시를 **즉시 무효화**.
- **리스(Lease)**: 서버가 일정 시간 **독점/읽기 위임**을 부여, 만료·회수 시 동기화.

```python
# lease_cache.py — 읽기 리스(lease)로 TTL 동안 캐시 유효
import time
class LeaseCache:
    def __init__(self, ttl=2): self.ttl=ttl; self.c={}
    def get(self, k, fetch):
        v,exp = self.c.get(k, (None,0))
        if time.time()<exp: return v
        v=fetch(); self.c[k]=(v, time.time()+self.ttl); return v
```

---

### 19.6.10 데이터 무결성·복구

- **체크섬**: 청크 단위 CRC/MD5; 읽기 시 검증·자동 재시도.
- **저널/Write-ahead Log**: 메타 변경 원자성.
- **스냅샷**: point-in-time 복구(카피-온-라이트).
- **Erasure Coding**: 복제 대비 공간 절약, 작은 쓰기/복구 비용 트레이드오프.

---

### 19.6.11 보안

- **전송 암호화**(TLS/mTLS), **저장 암호화**(디스크/LUKS·TME), **키 관리(KMS/HSM)**.
- **권한 모델**: POSIX 모드/ACL, NFSv4 ACL, SMB 권한.
- **감사**: 파일 접근 로그, 무결성 검증(해시 트리).

---

### 19.6.12 성능 팁

- **큰 청크** + **prefetch/read-ahead**: 순차 성능↑.
- 작은 파일 폭주 → **packing**(bundling), 메타 서버 scale-out.
- **쓰레드/큐/파이프라인**으로 업·다운로드 동시화.

---

## 종합 요약

- **19.4**: Network OS ↔ Distributed OS 스펙트럼을 이해하고, **이름공간/IPC/스케줄링/파일/보안**을 단일 시스템처럼 보이게 결합한다. 원격 exec, 콜백 무효화, 프로세스 마이그레이션(현대=CRIU) 개념을 실습으로 체감.
- **19.5**: **투명성·확장성·내결함성·보안**의 균형. **일관성 모델**과 **정족수/합의/리스**가 핵심 설계 재료. 지연 모델링, 관측성(트레이싱·메트릭) 없이는 운영 실패.
- **19.6**: DFS는 **메타/데이터 분리**, **캐시 일관성**, **복제/EC**, **보안/관측성**이 관건. NFS/AFS/SMB/GFS/HDFS/CephFS의 장단을 이해하고, 미니 DFS로 핵심 동작을 손에 익힌다.
