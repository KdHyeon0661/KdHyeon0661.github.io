---
layout: post
title: 운영체제 - 컴퓨터 시스템의 기초 (4)
date: 2025-10-12 23:35:23 +0900
category: 운영체제
---
# 컴퓨팅 환경 & 자유/오픈소스 운영체제

이 장은 **운영체제가 놓이는 환경(Computing Environments)** 과 **자유/오픈소스 운영체제(FOSS OS)** 를 폭넓게 연결한다.
각 절마다 **실행 가능한 예제**, **측정 포인트**, **구현 스니펫**을 제공해 **개념 → 실험 → 해석**의 선순환을 노린다.

---

## 1.10 Computing Environments

운영체제는 **하드웨어 형태, 전력 제약, 네트워크 토폴로지, 대기시간 목표, 신뢰성 요구**에 따라 설계 목표가 달라진다.

- **전통적(Traditional)**: 데스크탑/워크스테이션/서버, 키보드·마우스, 로컬 디스크, 비교적 풍부한 전력
- **모바일(Mobile)**: 배터리, 무선 네트워크, 센서, 앱 샌드박스, 백그라운드 제한
- **클라이언트–서버(Client–Server)**: 중앙 서버가 상태/데이터를 관리, 클라이언트는 요청/표현
- **P2P(Peer-to-Peer)**: 노드가 대등, 자율 분산·복제, NAT 횡단 필요
- **클라우드(Cloud)**: 대규모 가상화·오케스트레이션, 탄력/다중테넌시, 자동화/관측성
- **실시간 임베디드(Real-Time Embedded)**: 정해진 시간 내 응답(Deadlines), 작은 풋프린트, 드라이버 밀접

아래 하위 절은 각 환경의 **특징·도전과제·OS 기법**을 구체화한다.

---

### 1.10.1 Traditional Computing

**데스크탑/워크스테이션/서버**는 풍부한 자원과 전원, 키보드/마우스, 모니터, 로컬 디스크를 전제로 한다.
운영체제는 **다중 사용자, 다중 프로세스**, **가상 메모리**, **파일 시스템**을 중심으로 균형을 맞춘다.

#### 핵심 메커니즘
- **프로세스/스레드**: 시분할, 우선순위, 대화형 응답성
- **가상 메모리**: 보호, 공유 라이브러리, 메모리 맵 I/O
- **파일시스템**: 저널링, 캐시(페이지캐시), ACL
- **네트워크**: TCP/IP 스택, 소켓 API, 방화벽

#### [실습] 전통 환경에서의 “대화형 응답성” 관찰
```bash
# CPU 바운드 잡과 대화형 셸 경쟁
yes > /dev/null &             # 백그라운드 바쁜 작업
pid=$!
renice +10 -p $pid            # 우선순위 낮추기(대화형 응답성 보호)
time echo ping
kill $pid
```

**관찰 포인트**: 우선순위를 조정하면 사용자의 입력 대기시간이 줄어듦.
**직관 수식**: 평균 대기시간을 $$W$$, 타임슬라이스를 $$q$$, 레디큐 길이를 $$n$$이라 하면 단순화하여
$$
W \approx (n-1)\cdot q
$$
→ 대화형 태스크의 **우선순위 상승/짧은 슬라이스**가 체감 응답성 개선에 기여.

---

### 1.10.2 Mobile Computing

**모바일 OS(Android/iOS)** 는 배터리·무선 품질·센서·앱 스토어 모델·권한 시스템에 최적화된다.

#### 특징
- **앱 샌드박스**(UID 분리, 권한 선언/승인), **포그라운드/백그라운드 제약**
- **전원 관리**: Doze/App Standby(안드로이드), 백그라운드 페칭 제한
- **네트워크 변화**: Wi-Fi↔LTE 핸드오버, 고지연/패킷 손실
- **센서/위치/카메라**: 권한 기반 접근, 프라이버시 보호

#### [실험 아이디어] 모바일 병목 모델링(데스크탑에서 가상화된 네트워크로 근사)
```bash
# netem으로 모바일 네트워크 비슷한 지연/손실 환경 만들기(루트 필요)
sudo tc qdisc add dev lo root netem delay 80ms 20ms loss 2% rate 10mbit
curl -s -w "time_total:%{time_total}\n" http://127.0.0.1:8080/asset.jpg > /dev/null
sudo tc qdisc del dev lo root
```
**관찰 포인트**: 지연/손실이 페이지 로딩 체감에 미치는 영향. 모바일 OS는 **네트워크 상태 인식 API**로 앱의 동작(동기화, 업로드)을 조정.

---

### 1.10.3 Client–Server Computing

**서버**는 상태/데이터/비즈니스 로직을 유지, **클라이언트**는 UI·입력·일부 캐시를 담당.
OS는 **동시성, I/O 다중화, 보안(인증/인가), 네트워크 스택 성능**이 핵심.

#### [예제] epoll 기반 비동기 에코 서버(리눅스)
```c
// cs_epoll_echo.c — 단일 스레드로 다수 클라이언트 처리
#define _GNU_SOURCE
#include <sys/epoll.h>
#include <sys/socket.h>
#include <netinet/in.h>
#include <fcntl.h>
#include <unistd.h>
#include <errno.h>
#include <string.h>

static int nb(int fd){ int f=fcntl(fd,F_GETFL,0); return fcntl(fd,F_SETFL,f|O_NONBLOCK); }

int main(){
    int s=socket(AF_INET,SOCK_STREAM,0), one=1;
    setsockopt(s,SOL_SOCKET,SO_REUSEADDR,&one,sizeof(one));
    struct sockaddr_in a={.sin_family=AF_INET,.sin_port=htons(7778),.sin_addr={htonl(INADDR_ANY)}};
    bind(s,(struct sockaddr*)&a,sizeof(a)); listen(s,512); nb(s);

    int ep=epoll_create1(0);
    struct epoll_event ev={.events=EPOLLIN,.data.fd=s};
    epoll_ctl(ep,EPOLL_CTL_ADD,s,&ev);

    struct epoll_event evs[256]; char buf[4096];
    for(;;){
        int n=epoll_wait(ep,evs,256,-1);
        for(int i=0;i<n;i++){
            int fd=evs[i].data.fd;
            if(fd==s){
                for(;;){
                    int c=accept4(s,NULL,NULL,SOCK_NONBLOCK);
                    if(c<0){ if(errno==EAGAIN) break; else break; }
                    struct epoll_event ce={.events=EPOLLIN|EPOLLET,.data.fd=c};
                    epoll_ctl(ep,EPOLL_CTL_ADD,c,&ce);
                }
            }else{
                for(;;){
                    ssize_t r=read(fd,buf,sizeof(buf));
                    if(r>0){ (void)write(fd,buf,r); }
                    else if(r==0){ close(fd); break; }
                    else if(errno==EAGAIN) break; else { close(fd); break; }
                }
            }
        }
    }
}
```
```bash
gcc -O2 cs_epoll_echo.c -o cs_epoll_echo && ./cs_epoll_echo
# 또 다른 터미널에서:
printf "hello\n" | nc 127.0.0.1 7778
```

**지연 모델 직관**: 서버 처리시간 $$T_s$$, 네트워크 왕복 $$T_r$$라면 단일 요청 대기 없는 평균 응답은
$$
T \approx T_s + T_r
$$
동시성(파이프라이닝/큐잉)을 도입하면 처리율은 증가하지만 대기항이 붙는다(큐잉 이론 참고).

---

### 1.10.4 Peer-to-Peer Computing

**P2P**는 중앙 서버 없이 노드들이 직접 자원/데이터를 교환한다.
과제: **발견(부트스트랩, DHT)**, **NAT 횡단(STUN/TURN)**, **신뢰/평판**, **조각화·재조립**.

#### [실험 아이디어] 간이 P2P 조각 배포(로컬 3개 노드)
1) 파일을 조각화(예: 1MB 단위),
2) 각 노드가 서로가 가진 조각 인덱스를 교환,
3) 부족한 조각만 병렬 전송.

```python
# p2p_piece.py — 매우 단순한 조각 송수신(실험용)
import socket, threading, os, sys

pieces = {}  # id -> bytes

def serve(port):
    s=socket.socket(); s.bind(("0.0.0.0",port)); s.listen(64)
    def h(c):
        with c:
            cmd=c.recv(64).decode().strip().split()
            if cmd[0]=="HAVE": # 목록 요청
                c.sendall((" ".join(map(str,pieces.keys()))+"\n").encode())
            elif cmd[0]=="GET":
                pid=int(cmd[1]); c.sendall(pieces.get(pid,b""))
    while True:
        c,_=s.accept(); threading.Thread(target=h,args=(c,),daemon=True).start()

def get(host,port,pid):
    s=socket.socket(); s.connect((host,port))
    s.sendall(("GET %d\n"%pid).encode()); data=s.recv(1<<20); s.close()
    if data: pieces[pid]=data

if __name__=="__main__":
    # 초기화: pieces 사전에 일부 조각 넣어두기(테스트용)
    for i in range(5): pieces[i]=os.urandom(100*1024)
    threading.Thread(target=serve,args=(7788,),daemon=True).start()
    # 원격 피어에게 없는 조각 받아오기
    for pid in range(10):
        if pid not in pieces:
            get("127.0.0.1", 7788, pid)
    print("have:", sorted(pieces.keys()))
```

**관찰 포인트**: 조각화가 **대역폭 병렬화**에 주는 이점, 신뢰(무결성 해시) 부재 시 문제.

---

### 1.10.5 Cloud Computing

클라우드는 **대규모 가상화**와 **오케스트레이션**으로 **탄력성, 가용성, 자동화**를 달성한다.

#### 개념 구획
- **IaaS**: VM, 블록/오브젝트 스토리지, VPC
- **PaaS**: 앱 런타임/매니지드 DB/메시지 큐
- **SaaS**: 완성된 서비스
- **CaaS/K8s**: 컨테이너 오케스트레이션(스케줄링, 오토스케일, 롤아웃)

#### [실험] 컨테이너에서 CPU/메모리 제한 체감
```bash
# Docker 예시(설치 필요)
docker run --rm -it --cpus=0.5 --memory=256m alpine sh -c '
  echo "CPU/MEM 제한 내에서 스트레스"; dd if=/dev/zero of=/dev/null &
  sleep 3
  ps
'
```
**관찰 포인트**: 제한이 걸린 컨테이너는 호스트 대비 **스로틀링**됨.
OS/런타임은 **cgroups**, **네임스페이스**, **seccomp/AppArmor**로 격리·자원제한·보호를 제공.

---

### 1.10.6 Real-Time Embedded Systems

**실시간(Real-Time)** 은 “**정확한 결과를 제때** 내는 것”이 목표. 하드/소프트 실시간 구분:
- **Hard RT**: 데드라인을 **항상** 만족해야(미달 = 실패). 항공, 제어계.
- **Soft RT**: 대부분 만족(미달 시 성능 저하). 오디오/비디오.

#### 스케줄링
- **Rate Monotonic(RM)**: 주기가 짧을수록 우선순위 ↑ (고정)
- **Earliest Deadline First(EDF)**: 가장 임박한 데드라인 우선(동적)
- **Priority Inversion**: 낮은 우선순위가 락을 쥐고 높음을 막는 현상 → **Priority Inheritance**로 완화

#### [실습] 우선순위 역전 재현(리눅스 단순 근사)
```c
// rt_pi_demo.c — pthread 우선순위와 뮤텍스로 역전 근사(PI 없는 일반 뮤텍스 시나리오)
#define _GNU_SOURCE
#include <pthread.h>
#include <sched.h>
#include <stdio.h>
#include <unistd.h>

pthread_mutex_t m = PTHREAD_MUTEX_INITIALIZER;

void* low(void* p){
    pthread_mutex_lock(&m);
    // 긴 작업(락 보유)
    for(volatile long i=0;i<900000000;i++);
    pthread_mutex_unlock(&m);
    return NULL;
}
void* high(void* p){
    usleep(10000); // L이 락 잡도록 대기
    pthread_mutex_lock(&m); // 여기서 대기(역전)
    pthread_mutex_unlock(&m);
    return NULL;
}
void* mid(void* p){
    // CPU를 계속 사용하여 high를 더 지연
    for(volatile long i=0;i<900000000;i++);
    return NULL;
}

int main(){
    pthread_t L,M,H;
    pthread_attr_t a; pthread_attr_init(&a);
    struct sched_param sp;

    pthread_create(&L,&a,low,NULL);
    pthread_create(&M,&a,mid,NULL);
    pthread_create(&H,&a,high,NULL);

    pthread_join(L,NULL); pthread_join(M,NULL); pthread_join(H,NULL);
    puts("done");
}
```
```bash
gcc -O2 -pthread rt_pi_demo.c -o rt_pi_demo && ./rt_pi_demo
```
**관찰 포인트**: H(높은 우선순위)가 L의 락 때문에 막히고, M(중간)이 CPU를 소비하면 **우선순위 역전**이 악화.
실제 RTOS/리눅스 RT 파생에서는 **priority inheritance** 뮤텍스 사용으로 완화.

---

## 1.11 Free and Open-Source Operating Systems

오픈소스 OS는 **투명성·학습성·검증 가능성** 덕분에 연구/교육/산업 모두에서 핵심적 역할을 한다.

### 1.11.1 History (요약)

- **UNIX(1970s)**: 멀티태스킹/멀티유저·파일 추상화·소켓
- **BSD 계열(1970s~)**: TCP/IP 스택의 성숙, 많은 현대 OS의 기반
- **GNU 프로젝트(1983~)**: 유틸리티/컴파일러/라이브러리(리눅스 커널과 결합)
- **Linux(1991~)**: 모놀리식 커널, 전 세계 커뮤니티 주도 진화
- **오픈화**: Net/Free/OpenBSD, OpenSolaris→illumos 등

---

### 1.11.2 Free Operating Systems (정신과 라이선스)

- **Free Software**: 사용/복제/수정/배포 자유(4대 자유)
- **GPL**: 카피레프트(파생물 공개 의무), **LGPL**: 라이브러리 완화
- **BSD/MIT**: 허용적(프로프라이어터리 결합 가능)
- **CDDL**: 파일 단위 공개(illumos 계열)

**실무 포인트**: 드라이버/내부 패치 배포 시 **라이선스 준수**(저작권 표기/소스 제공 등).

---

### 1.11.3 GNU/Linux

**리눅스 커널 + GNU 유틸리티**로 폭넓은 배포판(Debian/Ubuntu/Fedora/Arch…).
특징: **모놀리식 커널**(드라이버·네트워크·파일시스템이 커널 공간), **모듈러**, **광범위 HW 지원**.

#### [실습] 미니 커널 설정/컴파일(개념 흐름)
```bash
# 소스 트리에서:
make defconfig
make -j$(nproc)                # bzImage, 모듈 빌드
# QEMU로 부팅(커널/루트fs 준비가 필요)
# qemu-system-x86_64 -kernel arch/x86/boot/bzImage -initrd rootfs.cpio.gz -append "console=ttyS0" -nographic
```

#### [실습] eBPF로 커널 관측(간단 bpftrace 예)
```bash
# 특정 시스템콜 호출 카운트(루트 필요)
sudo bpftrace -e 'tracepoint:syscalls:sys_enter_write { @[comm] = count(); }'
# Ctrl-C 후 결과: 프로세스별 write 호출 수
```

---

### 1.11.4 BSD UNIX

**FreeBSD/NetBSD/OpenBSD** 는 전통 UNIX 철학과 **깔끔한 네트워크/파일시스템/보안 스택**으로 유명.

- **FreeBSD**: 고성능 네트워크, ZFS(포팅), jails(격리)
- **NetBSD**: 광범위한 이식성(“Of course it runs NetBSD”)
- **OpenBSD**: 보안 우선, 기본적으로 안전한 설정, LibreSSL, PF 방화벽

#### [실습] FreeBSD Jails(개념)
```bash
# /etc/jail.conf 설정 후
# service jail start myjail
# jexec myjail /bin/sh
```
**관찰 포인트**: 리눅스 컨테이너와 유사하나 **커널 기능/도구 체계**가 다름.

---

### 1.11.5 Solaris / OpenSolaris / illumos

**Solaris**(구 Sun Microsystems)는 **DTrace, ZFS, Zones** 같은 혁신으로 유명.
오픈소스 분기는 **OpenSolaris → illumos** 로 이어져 **SmartOS** 등에서 사용.

- **ZFS**: 풀/스냅샷/검증(체크섬)·자기치유
- **DTrace**: 프로덕션 실시간 트레이싱
- **Zones**: 경량 가상화(컨테이너와 유사)

#### [실험 아이디어] ZFS 스냅샷/롤백(illumos 혹은 ZFS 포팅 환경)
```bash
# zfs create pool/fs
# zfs snapshot pool/fs@S1
# 변경 후
# zfs rollback pool/fs@S1
```

---

### 1.11.6 Open-Source Systems as Learning Tools

오픈소스 OS는 **실전 소스 읽기→수정→부팅→관측**의 사이클을 학습자에게 제공한다.

#### 학습 루트 제안
1) **리눅스 커널 소스 리딩**: `kernel/sched/*`, `mm/*`, `fs/*`, `net/*`
2) **QEMU로 부팅**: 위험 없이 실험, 커널 파라미터 조정
3) **BPF/DTrace**: 실시간 관측(프로브/tracepoint/kprobe)
4) **작은 OS 만들기**: xv6, u-boot, 미니 커널 실습

#### [실습] “자기만의 시스템콜” 추가(개념 스케치)
- 커널 트리에서 **테이블에 엔트리 추가**, 간단 핸들러 구현 → 빌드 → QEMU 부팅
- 사용자 공간에서 `syscall(SYS_mycall, …)` 호출로 동작 확인

#### [실습] 사용자 공간에서 “파일시스템 원리” 체험하기(FUSE)
```bash
# 간단 FUSE(설치 필요): 파이썬 fusepy 예시를 참고해 인메모리 FS 구현
# mount 후 open/read/write/rename이 어떻게 들어오는지 로깅
```

---

## 부록 A — 통합 예제: “로컬 ↔ 모바일 ↔ 클라우드” 3계층 성능 프로파일

**목표**: 세 환경의 지연·처리량·전력 제약 차이를 정량 관찰.

1) **로컬 서버**: `cs_epoll_echo`를 7778 포트로 띄움
2) **모바일 네트워크 흉내**: `tc netem`으로 지연/손실 삽입
3) **클라우드 컨테이너**: CPU/메모리 제한으로 스로틀링
4) **클라이언트**: 1, 16, 64 동시 연결로 RTT/Throughput 측정

**간단 지표 수식**:
$$
\text{Throughput} \approx \frac{k}{T_s + T_r + W(k)}
$$
- $$k$$: 동시 연결(파이프라이닝 수준),
- $$T_s$$: 서버 처리시간, $$T_r$$: 왕복지연,
- $$W(k)$$: 큐잉 지연(부하가 커질수록 증가).

**관찰 포인트**:
- 전통 환경: $$T_r$$ 작고 CPU 넉넉 → $$T_s$$가 핵심
- 모바일: $$T_r$$, 손실 ↑ → 재전송/혼잡 제어 영향 큼
- 클라우드: 자원제한/멀티테넌시로 $$T_s$$ 변동성 ↑ (지터)

---

## 부록 B — 체크리스트 요약

- **Traditional**: 프로세스/가상메모리/파일/네트워크 균형, 대화형 응답성
- **Mobile**: 전원/권한/백그라운드 제약, 네트워크 품질 민감
- **Client–Server**: 동시성/보안/관측, I/O 다중화·스레딩 전략
- **P2P**: DHT/평판/NAT, 조각화·무결성 해시
- **Cloud**: cgroups/네임스페이스/하이퍼바이저, 오토스케일, CI/CD
- **RT Embedded**: 데드라인, RM/EDF, PI로 역전 완화
- **FOSS OS**: 라이선스 준수, 리눅스/BSD/illumos, eBPF/DTrace 학습 루프

---

## 마무리

운영체제는 **환경에 따라 목표 함수가 달라진다**: 전통 환경은 **편의/성능/안정성**, 모바일은 **전력/프라이버시**, 클라우드는 **자동화/탄력/관측**, 임베디드는 **데드라인**.
이 다양성 속에서 오픈소스 운영체제는 **소스 수준의 가시성**으로 **학습·혁신·검증**을 가속한다.
