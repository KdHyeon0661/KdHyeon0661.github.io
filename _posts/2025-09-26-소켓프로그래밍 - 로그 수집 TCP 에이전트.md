---
layout: post
title: 소켓프로그래밍 - 로그 수집 TCP 에이전트
date: 2025-09-26 19:25:23 +0900
category: 소켓프로그래밍
---
# 1) 로그 수집 **TCP 에이전트** — 다중 클라이언트 수신 + 프레이밍 + **백프레셔**

> 목표: “많은 클라이언트가 한꺼번에 로그를 밀어 넣어도 **서버 메모리가 불어나지 않도록**”  
> **프레이밍(길이-프리픽스)** 과 **백프레셔(수신 일시 정지/재개)** 를 갖춘 **TCP 로그 인제스터**를 C++23로 만든다.  
> 리눅스 기준, **epoll(ET)** 기반 1개 네트워크 스레드 + 1개 파일 라이터 스레드 구조.

---

## 설계 개요

### 전선(와이어) 프로토콜 — 길이-프리픽스
- 각 로그 레코드 = `u32(빅엔디안) length` + `length` 바이트 payload(UTF-8 권장)
- 빈 프레임(0) 허용. 최대 길이는 서버 정책으로 제한(예: 1 MiB)

### 백프레셔 전략(핵심)
1) **글로벌 싱크 큐**(bounded MPSC) 용량 초과 시:  
   - per-connection 파서가 *완성 프레임*을 더 이상 큐에 넣지 않고 **해당 연결의 EPOLLIN을 꺼서(읽기 정지)**  
     커널 RecvQ→Window가 줄어들며 **TCP 레벨 역압**(sender side block)이 전파됨.
   - **로우/하이 워터마크**로 히스테리시스 적용(떨어지면 재개).
2) **per-connection 보류 슬롯**: 큐가 꽉 찬 시점의 *막 도착한 1개 프레임*을 임시 보류.  
   그 이상은 더 **파싱하지 않고**(추가 복제/메모리 증가 방지) 다음 재개 시 flush.
3) **wakeupfd(eventfd)**: 라이터 스레드가 **큐를 비울 때마다** 네트워크 루프를 깨워 **정지된 연결 재개**를 시도.

> 백프레셔의 직관:  
> 애플리케이션 수신 버퍼가 가득 → **EPOLLIN off** → 커널 RecvQ 고갈 → **TCP 윈도 축소** → 송신자 **send()가 막힘**.  
> 메모리를 무한히 늘리지 않고 **네트워크 레벨 자연 역압**을 이용.

---

## 코드: `log_agent.cpp` (단일 파일, C++23, 리눅스)

> 빌드: `g++ -std=c++23 -O2 -pthread log_agent.cpp -o log_agent`  
> 실행: `./log_agent 0.0.0.0 9000 --dir ./logs --rotate-mb 128 --cap 1048576`

```cpp
// log_agent.cpp — 다중 클라이언트 로그 인제스터 (프레이밍 + 백프레셔)
// 빌드: g++ -std=c++23 -O2 -pthread log_agent.cpp -o log_agent
// 리눅스 전용(eventfd, epoll)

#include <arpa/inet.h>
#include <errno.h>
#include <fcntl.h>
#include <netdb.h>
#include <signal.h>
#include <sys/epoll.h>
#include <sys/eventfd.h>
#include <sys/socket.h>
#include <sys/stat.h>
#include <sys/types.h>
#include <unistd.h>

#include <atomic>
#include <chrono>
#include <condition_variable>
#include <cstdint>
#include <cstdio>
#include <cstring>
#include <deque>
#include <filesystem>
#include <map>
#include <mutex>
#include <optional>
#include <print>
#include <span>
#include <string>
#include <string_view>
#include <thread>
#include <unordered_map>
#include <vector>

// ----------------------------- 유틸/RAII -----------------------------
struct unique_fd {
  int fd{-1};
  unique_fd() = default;
  explicit unique_fd(int x) : fd(x) {}
  ~unique_fd(){ if (fd>=0) ::close(fd); }
  unique_fd(const unique_fd&) = delete;
  unique_fd& operator=(const unique_fd&) = delete;
  unique_fd(unique_fd&& o) noexcept : fd(o.fd){ o.fd=-1; }
  unique_fd& operator=(unique_fd&& o) noexcept {
    if (this!=&o){ if (fd>=0) ::close(fd); fd=o.fd; o.fd=-1; }
    return *this;
  }
  explicit operator bool() const noexcept { return fd>=0; }
  int get() const noexcept { return fd; }
  int release() noexcept { int t=fd; fd=-1; return t; }
  void reset(int x=-1){ if (fd>=0) ::close(fd); fd=x; }
};

static int set_nonblock(int fd){
  int fl = ::fcntl(fd, F_GETFL, 0);
  if (fl<0) return -1;
  return ::fcntl(fd, F_SETFL, fl|O_NONBLOCK);
}
static void set_reuseaddr(int fd){
  int v=1; ::setsockopt(fd, SOL_SOCKET, SO_REUSEADDR, &v, sizeof(v));
}
static void set_nodelay(int fd){
  int v=1; ::setsockopt(fd, IPPROTO_TCP, TCP_NODELAY, &v, sizeof(v));
}

// ----------------------------- 설정 -----------------------------
struct Options {
  std::string host="0.0.0.0";
  std::string port="9000";
  std::string out_dir="./logs";
  size_t rotate_bytes = 128ull<<20; // 128 MiB
  size_t frame_cap = 1ull<<20;      // 1 MiB
  size_t queue_capacity = 65536;    // 레코드 개수 상한
  size_t resume_low_water = 16384;  // 큐 크기가 이 이하로 내려가면 재개
} opt;

static std::atomic<bool> g_running{true};

static void on_sigint(int){ g_running.store(false); }

// ----------------------------- 싱크 큐 (bounded, lock+cv) -----------------------------
// 네트워크 스레드는 overflow 시 false를 받고 읽기를 멈춘다(EPOLLIN off).
template <class T>
class BoundedQueue {
  std::deque<T> q_;
  size_t cap_;
  std::mutex m_;
  std::condition_variable cv_;
  std::atomic<size_t> sz_{0};
public:
  explicit BoundedQueue(size_t cap): cap_(cap) {}
  bool try_push(T&& v){
    std::unique_lock lk(m_);
    if (q_.size() >= cap_) return false;
    q_.push_back(std::move(v));
    sz_.store(q_.size(), std::memory_order_relaxed);
    cv_.notify_one();
    return true;
  }
  T pop_blocking(){
    std::unique_lock lk(m_);
    cv_.wait(lk, [&]{ return !q_.empty() || !g_running.load(); });
    if (q_.empty()) return T{};
    T v = std::move(q_.front()); q_.pop_front();
    sz_.store(q_.size(), std::memory_order_relaxed);
    return v;
  }
  size_t size() const noexcept { return sz_.load(std::memory_order_relaxed); }
  size_t capacity() const noexcept { return cap_; }
};

// ----------------------------- 로그 아이템 -----------------------------
struct LogItem {
  // 이미 프레이밍을 벗긴 payload (UTF-8 한 줄일 수도, JSON일 수도)
  std::vector<char> data;
  // 메타(선택): 원본 소켓, 원격 주소 등
  int src_fd{-1};
};

// 글로벌 싱크 큐 + wakeup용 eventfd
static BoundedQueue<LogItem> g_queue(opt.queue_capacity);
static unique_fd g_wakeup;

// 큐가 비워질 때 네트워크 루프를 깨우기
static void notify_wakeup(){
  uint64_t one=1;
  ::write(g_wakeup.get(), &one, sizeof(one)); // EAGAIN 무시 가능(레벨 트리거)
}

// ----------------------------- 파일 라이터 (회전) -----------------------------
class RotatingWriter {
  std::filesystem::path dir_;
  size_t rotate_bytes_;
  unique_fd fd_;
  size_t written_{0};
  int index_{0};
  std::string now_ts() {
    using namespace std::chrono;
    auto t = system_clock::now();
    std::time_t tt = system_clock::to_time_t(t);
    char buf[64]; std::strftime(buf, sizeof(buf), "%Y%m%d_%H%M%S", std::localtime(&tt));
    return buf;
  }
  void open_new() {
    std::filesystem::create_directories(dir_);
    std::string name = "log_" + now_ts() + "_" + std::to_string(index_++) + ".log";
    std::filesystem::path p = dir_ / name;
    int f = ::open(p.c_str(), O_CREAT|O_WRONLY|O_TRUNC|O_CLOEXEC, 0644);
    if (f<0) { std::perror("open log file"); std::exit(2); }
    fd_.reset(f);
    written_=0;
    std::print("[writer] rotate -> {}\n", p.string());
  }
public:
  RotatingWriter(std::filesystem::path dir, size_t rotate_bytes)
  : dir_(std::move(dir)), rotate_bytes_(rotate_bytes) {
    open_new();
  }
  void write(const LogItem& it){
    // payload를 한 줄로 보낸다고 가정하지 않는다. 없으면 개행 추가.
    bool need_nl = it.data.empty() || it.data.back()!='\n';
    if (written_ + it.data.size() + (need_nl?1:0) > rotate_bytes_) open_new();
    ssize_t n = ::write(fd_.get(), it.data.data(), it.data.size());
    if (n<0) { std::perror("write"); /* 계속 */ }
    written_ += (size_t)std::max<ssize_t>(0, n);
    if (need_nl){
      ::write(fd_.get(), "\n", 1);
      written_ += 1;
    }
  }
};

// 파일 라이터 스레드
static void writer_thread(){
  RotatingWriter w(opt.out_dir, opt.rotate_bytes);
  while (g_running.load()){
    LogItem it = g_queue.pop_blocking();
    if (!g_running.load() && it.data.empty()) break;
    if (!it.data.empty()){
      w.write(it);
      // 큐가 널널해졌다면 네트워크 루프를 깨워 읽기 재개를 시도
      if (g_queue.size() <= opt.resume_low_water) notify_wakeup();
    }
  }
  // drain (optional): 종료시 남은 것 처리할 수 있음(생략)
}

// ----------------------------- 연결 상태/파서 -----------------------------
struct Conn {
  int fd{-1};
  bool want_read{true};   // EPOLLIN 관심 여부
  bool paused{false};     // 백프레셔로 정지됨
  // 파싱 버퍼
  std::vector<char> buf;  // 수신 누적 버퍼
  size_t off{0};          // 파싱 오프셋
  std::optional<uint32_t> need; // 현재 메시지 길이
  // 보류 프레임(큐가 차서 바로 못 넘긴 1개)
  std::vector<char> pending;
};

static std::unordered_map<int, Conn> g_conns;

// 길이-프리픽스 파싱 + 큐 주입. 큐가 꽉 찼을 때 동작:
//  - 아직 완성 프레임을 pop 못 넣었으면 pending에 저장하고 읽기 정지.
static void try_flush_pending(Conn& c){
  if (c.pending.empty()) return;
  LogItem it; it.data = std::move(c.pending); it.src_fd = c.fd;
  if (g_queue.try_push(std::move(it))){
    c.pending.clear();
    c.paused = false;
    c.want_read = true; // 재개 가능
  } else {
    c.paused = true;
    c.want_read = false;
  }
}

static void parse_and_enqueue(Conn& c){
  // 이미 pending이 있으면 우선 flush
  if (!c.pending.empty()) { try_flush_pending(c); if (!c.pending.empty()) return; }

  // 가능한 만큼 파싱(히스테리시스: 큐가 빡빡하면 한두 개만 밀고 멈출 수도)
  while (true){
    if (!c.need){
      if (c.buf.size()-c.off < 4) break;
      uint32_t be=0; std::memcpy(&be, c.buf.data()+c.off, 4);
      uint32_t n = ntohl(be);
      if (n > opt.frame_cap){
        std::print(stderr, "[{}] frame too big: {} > cap {}\n", c.fd, n, opt.frame_cap);
        g_running.store(false); // 정책상 종료하거나 해당 연결만 닫아도 된다(여기선 단순 종료)
        return;
      }
      c.need = n; c.off += 4;
    }
    if (c.need){
      uint32_t n = *c.need;
      if (c.buf.size()-c.off < n) break; // 데이터 부족
      // 완성 프레임
      std::vector<char> payload(n);
      if (n) std::memcpy(payload.data(), c.buf.data()+c.off, n);
      c.off += n; c.need.reset();
      // 큐 시도
      LogItem it; it.data = std::move(payload); it.src_fd=c.fd;
      if (!g_queue.try_push(std::move(it))){
        // 큐 풀 → pending에 저장하고 읽기 정지
        c.pending = std::move(it.data);
        c.paused  = true;
        c.want_read = false;
        break;
      }
      // compaction (메모리 보존)
      if (c.off == c.buf.size()){ c.buf.clear(); c.off=0; }
      else if (c.off > (c.buf.size()/2)){
        std::vector<char> tmp(c.buf.begin()+c.off, c.buf.end());
        c.buf.swap(tmp); c.off=0;
      }
      // 큐가 가득 찼을 수 있으니 즉시 상태 확인
      if (g_queue.size() >= g_queue.capacity()){
        c.paused = true; c.want_read=false; break;
      }
    }
  }
}

// ----------------------------- epoll 도우미 -----------------------------
static void epoll_mod(int ep, int fd, uint32_t ev){
  epoll_event e{.events=ev, .data={.fd=fd}};
  ::epoll_ctl(ep, EPOLL_CTL_MOD, fd, &e);
}
static void epoll_add(int ep, int fd, uint32_t ev){
  epoll_event e{.events=ev, .data={.fd=fd}};
  ::epoll_ctl(ep, EPOLL_CTL_ADD, fd, &e);
}
static void epoll_del(int ep, int fd){
  ::epoll_ctl(ep, EPOLL_CTL_DEL, fd, nullptr);
}

// ----------------------------- 소켓 준비 -----------------------------
static unique_fd make_listener(const char* host, const char* port){
  addrinfo hints{}, *res=nullptr;
  hints.ai_family=AF_UNSPEC; hints.ai_socktype=SOCK_STREAM; hints.ai_flags=AI_PASSIVE|AI_ADDRCONFIG|AI_NUMERICSERV;
  if (getaddrinfo(host[0]?host:nullptr, port, &hints, &res)!=0) return unique_fd{-1};

  unique_fd lfd{-1};
  for (auto* ai=res; ai; ai=ai->ai_next){
    int s = ::socket(ai->ai_family, ai->ai_socktype|SOCK_NONBLOCK|SOCK_CLOEXEC, ai->ai_protocol);
    if (s<0) continue;
    unique_fd u{s};
    set_reuseaddr(u.get());
    if (::bind(u.get(), ai->ai_addr, ai->ai_addrlen)==0 && ::listen(u.get(), 4096)==0){ lfd = std::move(u); break; }
  }
  freeaddrinfo(res);
  return lfd;
}

static void accept_loop(int ep, int lfd){
  for(;;){
    sockaddr_storage ss{}; socklen_t sl=sizeof(ss);
    int c = ::accept4(lfd, (sockaddr*)&ss, &sl, SOCK_NONBLOCK|SOCK_CLOEXEC);
    if (c<0){
      if (errno==EAGAIN || errno==EWOULDBLOCK) break;
      if (errno==EINTR) continue;
      std::perror("accept"); break;
    }
    set_nodelay(c);
    Conn co; co.fd=c; co.want_read=true;
    g_conns.emplace(c, std::move(co));
    // 엣지 트리거 + RDHUP 감시
    epoll_add(ep, c, EPOLLIN|EPOLLRDHUP|EPOLLET);
  }
}

// ----------------------------- 네트워크 루프 -----------------------------
static void net_thread(unique_fd lfd){
  int ep = ::epoll_create1(EPOLL_CLOEXEC);
  if (ep<0){ std::perror("epoll_create1"); std::exit(2); }
  unique_fd epfd{ep};

  // 리스너 & wakeup 등록
  epoll_add(epfd.get(), lfd.get(), EPOLLIN);
  g_wakeup.reset(::eventfd(0, EFD_NONBLOCK|EFD_CLOEXEC));
  if (!g_wakeup) { std::perror("eventfd"); std::exit(2); }
  epoll_add(epfd.get(), g_wakeup.get(), EPOLLIN);

  std::vector<epoll_event> evs(4096);

  while (g_running.load()){
    int n = ::epoll_wait(epfd.get(), evs.data(), (int)evs.size(), 1000);
    if (n<0){
      if (errno==EINTR) continue;
      std::perror("epoll_wait"); break;
    }
    for (int i=0;i<n;i++){
      int fd = evs[i].data.fd;
      uint32_t ev = evs[i].events;

      if (fd == lfd.get()){
        if (ev & EPOLLIN) accept_loop(epfd.get(), lfd.get());
        continue;
      }
      if (fd == g_wakeup.get()){
        // drain
        uint64_t x; while (::read(g_wakeup.get(), &x, sizeof(x))>0) {}
        // 정지된 연결들 재개 시도
        for (auto& [cfd, c] : g_conns){
          if (!c.want_read && !c.pending.empty() && g_queue.size() <= opt.resume_low_water){
            try_flush_pending(c);
            if (c.want_read){
              // 버퍼 안에 더 남은 데이터가 있을 수 있으니 즉시 파싱
              parse_and_enqueue(c);
              // 관심 재설정
              epoll_mod(epfd.get(), cfd, (c.want_read?EPOLLIN:0) | EPOLLRDHUP | EPOLLET);
            }
          }
        }
        continue;
      }

      // 일반 커넥션
      auto it = g_conns.find(fd);
      if (it==g_conns.end()) continue;
      Conn& c = it->second;

      if (ev & (EPOLLHUP|EPOLLERR|EPOLLRDHUP)){
        // peer closed 또는 에러
        epoll_del(epfd.get(), fd);
        ::close(fd);
        g_conns.erase(it);
        continue;
      }

      if ((ev & EPOLLIN) && c.want_read){
        // 소진 루프
        for(;;){
          char buf[8192];
          ssize_t m = ::recv(fd, buf, sizeof(buf), 0);
          if (m>0){
            // 누적
            size_t old=c.buf.size();
            c.buf.resize(old+m);
            std::memcpy(c.buf.data()+old, buf, m);
            parse_and_enqueue(c);
            if (!c.want_read) break; // 백프레셔로 중단
            continue;
          }
          if (m==0){
            // peer close
            epoll_del(epfd.get(), fd);
            ::close(fd);
            g_conns.erase(it);
            break;
          }
          if (errno==EAGAIN||errno==EWOULDBLOCK||errno==EINTR) break;
          std::perror("recv");
          epoll_del(epfd.get(), fd);
          ::close(fd);
          g_conns.erase(it);
          break;
        }
        // 관심 갱신(읽기 정지/재개 반영)
        epoll_mod(epfd.get(), fd, (c.want_read?EPOLLIN:0) | EPOLLRDHUP | EPOLLET);
      }
    }
  }

  // 종료: 모든 연결 정리
  for (auto& [fd, c] : g_conns){ (void)c; ::close(fd); }
  g_conns.clear();
}

// ----------------------------- 인자 파싱 -----------------------------
static void parse_args(int argc, char** argv){
  if (argc>1) opt.host = argv[1];
  if (argc>2) opt.port = argv[2];
  for (int i=3;i<argc;i++){
    std::string k = argv[i];
    auto need = [&](int i){ if (i+1>=argc){ std::print(stderr,"missing value for {}\n",k); std::exit(2);} return std::string(argv[i+1]); };
    if (k=="--dir")        opt.out_dir = need(i++);
    else if (k=="--rotate-mb") opt.rotate_bytes = (size_t)std::stoul(need(i++))<<20;
    else if (k=="--cap")   opt.frame_cap = (size_t)std::stoul(need(i++));
    else if (k=="--qcap")  { opt.queue_capacity = (size_t)std::stoul(need(i++)); g_queue = BoundedQueue<LogItem>(opt.queue_capacity); }
    else if (k=="--low")   opt.resume_low_water = (size_t)std::stoul(need(i++));
  }
}

// ----------------------------- 메인 -----------------------------
int main(int argc, char** argv){
  std::signal(SIGINT,  on_sigint);
  std::signal(SIGTERM, on_sigint);
  parse_args(argc, argv);

  unique_fd lfd = make_listener(opt.host.c_str(), opt.port.c_str());
  if (!lfd){ std::print(stderr,"listen fail on {}:{}\n", opt.host, opt.port); return 1; }
  std::print("[agent] listen {}:{}  dir={} rotate={}MB cap={}B queue={}/low={}\n",
    opt.host, opt.port, opt.out_dir, (opt.rotate_bytes>>20), opt.frame_cap,
    opt.queue_capacity, opt.resume_low_water);

  std::jthread wthr(writer_thread);
  net_thread(std::move(lfd));
  g_running.store(false);
  notify_wakeup();
  return 0;
}
```

---

## 클라이언트(부하) 예제: `log_spammer.cpp`

> 여러 프로세스/스레드에서 실행해 **백프레셔 동작**을 직접 체감해보자.

```cpp
// log_spammer.cpp — 길이-프리픽스 로그 스패머(테스트용)
// 빌드: g++ -std=c++23 -O2 -pthread log_spammer.cpp -o spammer
#include <arpa/inet.h>
#include <netdb.h>
#include <sys/socket.h>
#include <unistd.h>
#include <chrono>
#include <cstring>
#include <optional>
#include <print>
#include <random>
#include <string>
#include <thread>
#include <vector>

static int dial(const char* host, const char* port){
  addrinfo hints{}, *res=nullptr;
  hints.ai_family=AF_UNSPEC; hints.ai_socktype=SOCK_STREAM; hints.ai_flags=AI_ADDRCONFIG|AI_NUMERICSERV;
  if (getaddrinfo(host,port,&hints,&res)!=0) return -1;
  int s=-1;
  for (auto* ai=res; ai; ai=ai->ai_next){
    s=::socket(ai->ai_family, ai->ai_socktype, ai->ai_protocol);
    if (s<0) continue;
    if (::connect(s, ai->ai_addr, ai->ai_addrlen)==0){ freeaddrinfo(res); return s; }
    ::close(s); s=-1;
  }
  freeaddrinfo(res);
  return -1;
}
static void send_frame(int fd, std::string_view sv){
  uint32_t be=htonl((uint32_t)sv.size());
  ::send(fd, &be, 4, 0);
  if (!sv.empty()) ::send(fd, sv.data(), sv.size(), 0);
}

int main(int argc, char** argv){
  if (argc<5){ std::print(stderr,"usage: {} <host> <port> <threads> <pps_per_thread>\n", argv[0]); return 1; }
  const char* host=argv[1]; const char* port=argv[2];
  int th = std::stoi(argv[3]); int pps = std::stoi(argv[4]);

  std::vector<std::jthread> v;
  for (int i=0;i<th;i++){
    v.emplace_back([=]{
      int s = dial(host, port);
      if (s<0){ std::print(stderr,"dial fail\n"); return; }
      std::mt19937 rng{std::random_device{}()};
      std::uniform_int_distribution<int> dlen(64, 512);
      auto tick = std::chrono::microseconds(1'000'000 / pps);
      auto next = std::chrono::steady_clock::now();
      while (true){
        std::string msg = R"({"ts":)" + std::to_string(std::time(nullptr)) +
                          R"(,"lvl":"INFO","msg":"hello", "rnd":)" + std::to_string(rng()) + "}";
        msg.resize(dlen(rng), 'x'); // 길이 가변
        send_frame(s, msg);
        next += tick;
        std::this_thread::sleep_until(next);
      }
    });
  }
  for (auto& t:v) t.join();
}
```

---

## 실험 스크립트

```bash
# 서버
./log_agent 0.0.0.0 9000 --dir ./logs --rotate-mb 32 --cap 1048576 --qcap 20000 --low 5000

# 네트워크를 느리게(라이터 병목을 유발하려면 디스크를 느리게 하거나 netem으로 RTT/손실 가중)
# sudo tc qdisc add dev lo root netem delay 10ms 5ms

# 클라이언트 (동일 머신)
./spammer 127.0.0.1 9000 8 2000   # 스레드 8, 초당 2k 레코드/스레드
```

> 관찰 포인트
> - 큐가 가득 차면 **네트워크 루프가 EPOLLIN을 끄고** 일정 시간 후 스팸머의 `send()`가 막힌다(자연 역압).
> - `--low` 수치 이하로 내려가면 **재개**되어 다시 빠르게 수신.
> - `logs/`에 회전 파일이 쌓이며, 각 레코드는 프레이밍이 벗겨진 payload 그대로 기록된다.

---

## 백프레셔/버퍼링 설계 노트

1) **per-connection 버퍼 제한**  
   - 위 예제는 *글로벌 큐* 기준으로만 역압을 건다.  
   - 추가로 연결별 `buf.size()` 상한(예: 2 MiB)을 두어 악성 송신자를 조기 차단하라.
2) **글로벌 메모리 상한**  
   - 총 `∑conn.buf + ∑pending + queue` 바이트가 **limit**을 넘으면  
     가장 무거운 연결부터 강제 종료(403/close)하는 **회복 로직**을 둔다.
3) **라이터 스레드가 병목**  
   - 디스크 sync/압축/전송 등으로 쓰기 속도가 느릴 수 있다.  
   - **N개 라이터**(shard), **압축 배치**, **`O_DIRECT`/`io_uring`**, **전용 파티션** 등으로 확장.
4) **정확히-한번(Exactly-Once) vs 적어도-한번**  
   - TCP 자체는 at-least-once 전송 의미만 갖는다. 중복 방지는 상위 레이어 ID/오프셋 설계에 의존.

---

## 오류/장애 대응 팁

- **프레임 크기 초과**: 즉시 연결 종료 + 계량(메트릭) → 경보.  
- **파싱 불일치(프로토콜 위반)**: 해당 클라이언트 격리/블랙리스트(짧은 TTL).
- **디스크 ENOSPC**: 임시로 **수신 중지** 후 알람(또는 가장 오래된 세그먼트 제거 전략).
- **큐가 항상 만원**: `--qcap`/`--low` 튜닝, 라이터 스레드 증설, 로그 집계/압축 비율 조정.

---

## 모니터링 지표(권장)

- **수신 RPS**, **큐 길이**, **paused 연결 수**, **드롭/차단 수**, **라이터 MB/s**
- 소켓 상태: `ss -ti 'sport = :9000'` → `rtt`, `send-q/recv-q`, 재전송률
- 파일 시스템: free space, fsync 시간, IO 대기

---

## 계산 메모 — 역압과 버퍼

- 커널 RecvBuf 크기를 \(B_r\), 애플리케이션 큐 상한을 \(B_a\), 송신자 속도를 \(S\)라 하면,  
  애플리케이션이 **읽기를 멈추면** 대략 \(B_r\) 만큼만 추가로 흡수한 뒤 송신자는 **RTT 후** 막히는 경향.  
- 대역폭–지연곱(BDP):
  $$
  \text{BDP} = \text{Bandwidth} \times \text{RTT}
  $$
  **BDP \(\gg B_r\)** 이면 송신자의 `send()`가 **RTT 다수** 동안 통과될 수 있으므로,  
  상위 제한 \(B_a\) 를 너무 작게 잡으면 **스파이크**에 취약. 경험적으로 \(B_a \approx 2\sim4 \times BDP\) 수준으로 시작.

---

## 확장 아이디어

- **TLS**(14장): 리스너에 TLS 래퍼(OpenSSL) 얹어 전송 보호.  
- **프로토콜 검사**: payload가 JSON일 때 **스키마 밸리데이션** 추가.  
- **멀티 라이터 샤딩**: 해시(key) 기준 파일 분할 기록으로 write 경합 감소.  
- **인덱스 파일**: 오프셋/파일ID를 별도 기록 → 빠른 재처리.  
- **io_uring**: 네트워크/디스크 모두 커널 큐 기반으로 일원화.

---

### 마무리

이 에이전트는 “**프레이밍 + 역압**”의 최소 패턴을 명확히 보여준다.  
핵심은 **무한 버퍼링을 하지 않는 것**. 읽기를 멈추고 **TCP 윈도**를 줄여 **송신자에게 압력**을 전달하라.  
그 위에 운영 지표와 튜닝(큐 크기/워터마크/라이터 성능)을 더하면, **신뢰할 수 있는 로그 수집**의 토대가 된다.