---
layout: post
title: 컴퓨터시스템 - 메모리 계층 구조
date: 2025-08-06 19:20:23 +0900
category: 컴퓨터시스템
---
# 메모리 계층 구조 — 원리·구성·성능 모델·최적화·검증까지

> 목표: **메모리 계층 구조(memory hierarchy)** 가 왜 필요한지, 어떻게 구성되는지,  
> 각 층이 **성능(지연/대역/용량)** 에 어떤 영향을 미치는지, 그리고 코드를 어떻게 바꿔 성능을 끌어올릴지까지 한 번에 잡는다.  
> 수식은 MathJax, 코드는 C/셸로 예시한다.

---

## 1) 큰 그림: 왜 ‘계층’인가?

CPU는 나노초 단위로 계산하지만, 모든 데이터를 그 속도로 공급할 수는 없다.  
따라서 **작고 빠른 저장소 → 크고 느린 저장소** 순으로 층을 쌓아 **자주 쓰는 데이터는 가까이, 드물게 쓰는 데이터는 멀리** 두는 설계를 한다.

```
레지스터
  ↓
L1I/L1D 캐시 (코어 전용)
  ↓
L2 캐시 (코어 전용 또는 반공유)
  ↓
L3/LLC (소켓 내 코어들 간 공유)
  ↓
DRAM (메인 메모리)
  ↓
보조저장장치(SSD/HDD) / 스왑
```

핵심 가정은 **지역성(Locality)**:
- **시간 지역성**: 최근 사용한 것은 곧 다시 사용될 확률 ↑
- **공간 지역성**: 한 주소를 썼다면 근처 주소도 곧 쓸 확률 ↑

---

## 2) 성능 축 세 가지: 지연·대역·용량

대략적 경향(플랫폼마다 다르지만 **서열**은 유사)

| 계층 | 용량 | 지연(대략) | 대역 | 비고 |
|---|---:|---:|---:|---|
| 레지스터 | 수십 KB | 수 사이클 | 매우 큼 | 컴파일러/파이프라인이 관리 |
| L1 | 수십 KB/코어 | ~수~10여 사이클 | 매우 큼 | I/D 분리, 라인 크기 보통 64B |
| L2 | 수백 KB~수MB | 수십 사이클 | 큼 | 코어 가까움 |
| L3(LLC) | 수MB~수십MB | 수십~수백 사이클 | 중간 | 소켓 공유 |
| DRAM | 수GB~수TB | 수백 ns | 중간 | 채널/뱅크 병렬성 |
| SSD/HDD | TB↑ | μs~ms | 낮음~중간 | OS 캐시/프리패치에 의존 |

> **교훈**: 상위 캐시에 맞춘 **접근 패턴**이 전체 성능을 좌우한다.

---

## 3) 캐시 기본기: 라인·매핑·교체·쓰기 정책

### 3.1 캐시 라인(Cache line)
- 캐시는 **라인(블록)** 단위(보통 64B)로 데이터를 가져온다 → **공간 지역성**을 활용.
- 한 요소만 필요해도 같은 라인의 나머지 바이트가 함께 온다(오염 가능).

### 3.2 매핑 방식
- **직접 매핑**: 각 라인이 딱 한 세트에만 위치 → 빠르지만 충돌 미스↑
- **집합 연관(Set-associative)**: 각 세트에 N개의 way → 충돌 완화(일반적)
- **완전 연관**: 어느 곳에나 저장 가능(비용 큼)

### 3.3 교체 정책
- LRU 근사(PLRU 등). **충돌 미스**를 줄이기 위해 **데이터 배치/패딩**이 도움.

### 3.4 쓰기 정책
- **Write-back + Write-allocate**(보편): 쓰기 시 라인을 캐시에 두고 더티 비트, 나중에 메모리 반영.
- **Write-through**: 매 쓰기 시 메모리에도 즉시 반영(단순/신뢰 ↑, 대역 소모 ↑).
- **No-write-allocate**: 미스에서 라인을 끌어오지 않고 바로 메모리에 씀(스트리밍에 유리할 수 있음).
- **비휘발(non-temporal) 저장**: 한 번 쓰고 다시 안 쓸 큰 덩어리를 **캐시 오염 없이** 내보내는 힌트.

### 3.5 포용성(Inclusivity)
- **Inclusive**: L3 ⊇ L2 ⊇ L1 (디버그/일관성 관리 용이)
- **Exclusive/Non-inclusive**: 용량 효율/정책 유연성. 플랫폼마다 다름.

---

## 4) 주소 변환과 TLB: 가상 메모리의 비용

- CPU는 **가상 주소**를 쓰고, 실제 접근은 **물리 주소**다.  
- **TLB**(Translation Lookaside Buffer)는 “가상→물리” 변환 캐시.
- **TLB reach** = (엔트리 수 × 페이지 크기). 워킹셋이 reach보다 크면 **TLB 미스**↑ → 페이지 워크 비용↑.
- **Huge Page**(2MB/1GB 등)로 reach 확대 가능. 단, 단편화·관리 주의.
- L1D 캐시는 보통 **VIVT/VIPT/VIPT-PT**(변종)로 구현: **인덱싱은 가상, 태깅은 물리**(동의어/동일성 문제 관리).

---

## 5) DRAM 구조와 지연의 정체

DRAM은 **채널→랭크→뱅크→행(row)→열(col)** 로 구성되고, 각 뱅크는 **행 버퍼(row buffer)** 를 갖는다.

- **Row hit**: 같은 행을 연속 접근하면 빠름(행 버퍼 히트).  
- **Row miss**: 다른 행이면 **precharge/activate** 순서가 필요 → 지연↑.  
- 스케줄러는 보통 **FR-FCFS**(행 히트 우선)로 처리 → **행 지역성**이 있으면 이득.

> **메시지**: DRAM에서도 **지역성**(특히 행/뱅크)과 **병렬성**(채널/뱅크 분산)이 성능을 좌우한다.

---

## 6) NUMA(Non-Uniform Memory Access)

- 멀티 소켓/칩렛 시스템에서는 메모리가 **노드**에 나뉘어 있다.  
- **로컬 노드** 접근이 빠르고, **원격 노드**는 지연/대역 페널티.  
- **First-touch** 정책: 최초로 페이지를 “쓰는” 스레드의 노드에 할당.  
- 해결책: **스레드 바인딩 + 데이터 초기화의 병렬화**(first-touch), **노드별 샤딩**.

```c
// OpenMP로 first-touch: 각 스레드가 자기 파티션을 초기화
#pragma omp parallel for
for (long i=0; i<n; i++) a[i] = 0;
```

---

## 7) 성능 모델: AMAT와 CPI 분해

### 7.1 AMAT(평균 메모리 접근 시간)
\[
\text{AMAT} = T_{L1} + m_1\Big(T_{L2} + m_2\big(T_{L3} + m_3 T_\text{Mem}\big)\Big)
\]
- \(m_k\): 각 레벨 미스율, \(T\): 해당 레벨 히트/페널티 시간.

### 7.2 CPI 근사(메모리 스톨 포함)
\[
\text{CPI} \approx \text{CPI}_\text{base} \;+\; \frac{\text{MemAccesses}}{\text{Instr}}
\times \frac{\text{Misses}}{\text{Access}}\times \frac{\text{MissPenalty}}{\text{MLP}}
\]
- **MLP**(Memory-Level Parallelism): 동시에 outstanding 가능한 미스 수.  
  포인터 추적처럼 직렬 의존이 크면 MLP≈1 → 스톨이 그대로 드러난다.

---

## 8) 지역성 & 3C 미스(+1C)

- **Compulsory**: 처음 보는 데이터라서 미스.  
- **Capacity**: 캐시 용량이 모자라서 교체.  
- **Conflict**: 같은 세트로 몰려 충돌.  
- **Coherence**(멀티코어): 타 코어 쓰기로 무효화 → 폴스 셰어링 발생.

---

## 9) 프리패칭과 MLP

- **하드웨어 프리패처**: 순차/스트라이드/근접 패턴을 학습해 선제 로드.  
- **소프트웨어 프리패치**: 접근이 예측 가능하면 거리(d) 조절.

```c
void sum_prefetch(const float *a, int n){
  float s=0;
  for (int i=0; i<n; i+=16){
    __builtin_prefetch(&a[i+64], 0, 1); // 읽기, 약한 지역성
    for (int k=0; k<16 && i+k<n; ++k) s += a[i+k];
  }
  (void)s;
}
```

---

## 10) 캐시 친화적 코드 패턴

### 10.1 행 우선 vs 열 우선
```c
// 행 우선(좋음)
for (int i=0;i<N;i++)
  for (int j=0;j<N;j++)
    s += A[i][j];

// 열 우선(스트라이드 큼 → 미스↑ 가능)
for (int j=0;j<N;j++)
  for (int i=0;i<N;i++)
    s += A[i][j];
```

### 10.2 타일링(블로킹)
```c
void mm_block(int n, float *A, float *B, float *C, int Bsz){
  for (int ii=0; ii<n; ii+=Bsz)
    for (int jj=0; jj<n; jj+=Bsz)
      for (int kk=0; kk<n; kk+=Bsz){
        int im = (ii+Bsz<n)? ii+Bsz : n;
        int jm = (jj+Bsz<n)? jj+Bsz : n;
        int km = (kk+Bsz<n)? kk+Bsz : n;
        for (int i=ii;i<im;i++)
          for (int j=jj;j<jm;j++){
            float acc = C[i*n+j];     // 레지스터 누적
            for (int k=kk;k<km;k++)
              acc += A[i*n+k]*B[k*n+j];
            C[i*n+j] = acc;           // 라인 재사용 극대화
          }
      }
}
```

### 10.3 SoA(Structure of Arrays)로 변환
```c
typedef struct { float *x, *y, *z; } vec3_soa;

void norm_soa(vec3_soa v, int n){
  #pragma omp simd
  for (int i=0;i<n;i++){
    float dx=v.x[i], dy=v.y[i], dz=v.z[i];
    v.x[i] = dx*dx + dy*dy + dz*dz; // 열 단위 연산: 벡터화/대역 효율↑
  }
}
```

### 10.4 불필요한 메모리 참조 제거(스칼라 치환)
```c
for(int i=0;i<n;i++){
  float xi=x[i], yi=y[i];     // 같은 원소 두 번 읽지 않기
  y[i] = yi + a*xi;
}
```

### 10.5 비휘발 저장(스트리밍 결과)
- “한 번 쓰고 다시 안 보는” 큰 결과 버퍼는 **non-temporal store**(컴파일러/플랫폼 힌트)로 캐시 오염을 줄일 수 있다.

---

## 11) 멀티코어에서의 일관성과 폴스 셰어링

- **코히어런시(MESI/MOESI)**: 같은 라인에 여러 코어가 접근 시 상태 전이가 발생.  
- **폴스 셰어링**: 다른 변수가 **같은 캐시 라인**에 있어도, 서로의 쓰기가 라인 무효화를 일으켜 성능 저하.

```c
typedef struct { _Alignas(64) long v; } padded_long;
padded_long counters[64]; // 각 스레드 전용 카운터(라인 패딩)
```

---

## 12) 측정과 진단: 도구·카운터

### 12.1 하드웨어 카운터(리눅스 예)
```bash
perf stat -e cycles,instructions,IPC,\
L1-dcache-loads,L1-dcache-load-misses,\
LLC-loads,LLC-load-misses,\
dTLB-load-misses,branch-misses \
./app
```
- **IPC**: 1보다 낮고 LLC 미스↑ → 메모리 바운드 가능성.  
- **dTLB-load-misses**: TLB 병목/워크셋 크기 문제.  
- **branch-misses**: 분기 패턴/예측 이슈.

### 12.2 캐시 시뮬/프로파일
- `valgrind --tool=cachegrind`(패턴 비교),  
- Intel VTune/Advisor(캐시/메모리/벡터화 분석).

---

## 13) 흔한 병목과 처방 매핑

증상 | 지표/징후 | 1차 처방 | 2차 처방
---|---|---|---
IPC<1, LLC miss↑ | backend bound | **타일링, 연속 접근, SoA** | 프리패치, 알고리즘/데이터 재구성
dTLB miss↑ | 페이지 워크↑ | Huge Page | 페이지 컬러링/레아이웃 조정
Row miss↑ | DRAM bank 활동 | 행 지역성↑(블록 순회) | 데이터 배치(채널/뱅크 분산)
폴스 셰어링 | 코히어런시 트래픽↑ | 패딩/샤딩 | 데이터 구조 재설계
스래싱 | 특정 세트 충돌↑ | 패딩/오프셋 조정 | 해시/인덱스 재설계

---

## 14) 실험 템플릿(마이크로벤치)

```c
#include <time.h>
#include <stdio.h>
#include <stdlib.h>

double now_sec(){
  struct timespec t;
  clock_gettime(CLOCK_MONOTONIC, &t);
  return t.tv_sec + t.tv_nsec*1e-9;
}

long long sum_row_major(int **a, int n){
  long long s=0;
  for(int i=0;i<n;i++)
    for(int j=0;j<n;j++)
      s += a[i][j];
  return s;
}

long long sum_col_major(int **a, int n){
  long long s=0;
  for(int j=0;j<n;j++)
    for(int i=0;i<n;i++)
      s += a[i][j];
  return s;
}

int main(int argc, char**argv){
  int n = (argc>1)? atoi(argv[1]) : 4096;
  int **a = malloc(sizeof(*a)*n);
  a[0] = aligned_alloc(64, sizeof(**a)*n*n);
  for(int i=1;i<n;i++) a[i] = a[0] + i*n;
  for(int i=0;i<n*n;i++) a[0][i] = i&1;

  double t0 = now_sec(); volatile long long s1 = sum_row_major(a, n);
  double t1 = now_sec(); volatile long long s2 = sum_col_major(a, n);
  double t2 = now_sec();
  printf("row-major=%.3f s, col-major=%.3f s, diff=%lld\n",
         t1-t0, t2-t1, (long long)(s1-s2));
  free(a[0]); free(a);
}
```

- 같은 연산이라도 **접근 순서**만 바꿔 큰 시간 차이를 체감할 수 있다.

---

## 15) 체크리스트(바로 적용)

- [ ] **행(스트라이드 1)** 순회인가? (언어의 레이아웃과 일치?)  
- [ ] **타일링/블로킹**으로 L1/L2에 붙여두는가?  
- [ ] **SoA/정렬/패딩**으로 벡터화·충돌을 돕는가?  
- [ ] **스칼라 치환/루프 불변 호이스팅**으로 중복 로드를 줄였는가?  
- [ ] **프리패치**가 유효한 패턴인가? 거리 튜닝 했는가?  
- [ ] **Huge Page/NUMA first-touch** 적용했는가?  
- [ ] **폴스 셰어링** 없는가(라인 패딩/샤딩)?  
- [ ] `perf`/프로파일로 **IPC/미스율/대역**을 숫자로 확인했는가?

---

## 16) 맺음말

메모리 계층 구조는 **지연·대역·용량**의 상충을 **지역성**으로 극복하려는 거대한 타협안이다.  
실전 성능의 80%는 **데이터가 어떻게 배치되고, 어떤 순서로 접근되는가**에서 갈린다.  
따라서 코드는 항상 **캐시를 의식**해 작성하고, **측정→개선→재측정**의 루프를 통해  
자신의 워크로드에 맞는 **타일 크기, 레이아웃, 프리패치 거리, NUMA 배치**를 찾아야 한다.