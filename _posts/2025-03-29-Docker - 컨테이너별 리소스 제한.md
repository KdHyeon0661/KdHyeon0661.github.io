---
layout: post
title: Docker - 컨테이너별 리소스 제한
date: 2025-03-29 19:20:23 +0900
category: Docker
---
# Docker 컨테이너별 리소스 제한 (CPU · Memory · 블록 IO)

## 서론: 컨테이너 리소스 제한의 필요성

컨테이너 환경에서 리소스 제한 설정은 단순한 성능 최적화를 넘어 시스템 안정성과 예측 가능한 동작을 보장하는 필수 요소입니다. 멀티 테넌시 환경에서 한 컨테이너의 비정상적인 리소스 소비가 전체 호스트 시스템에 영향을 미치는 "시끄러운 이웃(noisy neighbor)" 문제를 방지하기 위해 체계적인 리소스 관리가 필요합니다.

### 주요 리소스 위험과 제한의 효과

**CPU 과점유 문제**
한 컨테이너가 모든 CPU 코어를 독점하면 다른 컨테이너들의 응답 시간이 급격히 증가하고 서비스 타임아웃이 발생할 수 있습니다. CPU 제한을 통해 공정한 분배와 절대적인 상한선을 설정할 수 있습니다.

**메모리 폭주 문제**
제한 없이 메모리를 소비하는 컨테이너는 Linux 커널의 OOM(Out Of Memory) Killer를 트리거하여 무작위로 프로세스를 종료시킬 수 있습니다. 이는 시스템 불안정과 데이터 손실로 이어집니다. 메모리 제한은 이러한 상황을 방지하고 스왑 사용 정책을 조율할 수 있게 합니다.

**디스크 I/O 경합**
디스크 I/O를 과도하게 사용하는 컨테이너는 디스크 큐 지연을 증가시켜 다른 컨테이너들의 I/O 성능을 저하시킵니다. 블록 I/O 제한을 통해 공정한 자원 배분과 절대적인 속도 제한을 설정할 수 있습니다.

**멀티 테넌시 환경의 SLA 보장**
여러 팀이나 서비스가 동일한 인프라를 공유하는 환경에서 각 서비스의 서비스 수준 계약(SLA)을 보장하려면 리소스 격리가 필수적입니다.

리소스 제한의 핵심 목표는 **"고장 격리(fault isolation)"** 와 **"예측 가능성(predictability)"** 을 확보하는 것입니다.

---

## CPU 리소스 제한

### 다양한 CPU 제한 방식 이해하기

Docker는 여러 수준의 CPU 제한 메커니즘을 제공하여 다양한 요구사항에 대응할 수 있습니다.

**절대적인 CPU 상한 (`--cpus`)**
가장 직관적인 방법으로, 컨테이너가 사용할 수 있는 최대 CPU 코어 수를 지정합니다. 내부적으로는 CPU 할당량(quota)과 주기(period)를 계산하여 설정합니다.

**상대적 CPU 가중치 (`--cpu-shares`)**
CPU 자원이 경쟁하는 상황에서 각 컨테이너의 상대적 우선순위를 결정합니다. 기본값은 1024이며, 높은 값일수록 더 많은 CPU 시간을 할당받습니다.

**CPU 코어 고정 (`--cpuset-cpus`)**
특정 CPU 코어에 컨테이너를 고정시켜 NUMA 아키텍처나 CPU 캐시 친화성을 활용할 수 있습니다. 지연 시간에 민감한 애플리케이션에 유리합니다.

**고급 CPU 제어 (`--cpu-quota`, `--cpu-period`)**
CPU 할당량과 주기를 직접 지정하여 정밀한 제어가 가능합니다. 일반적인 경우보다 더 세밀한 제어가 필요한 특수 상황에서 사용합니다.

### 실전 CPU 제한 옵션 비교

| 목적 | 권장 옵션 | 설명 및 사용 시나리오 |
|------|-----------|----------------------|
| 최대 1.5개 코어 제한 | `--cpus=1.5` | CPU 사용량을 절대적으로 제한할 때 사용. 내부적으로 quota/period를 자동 계산합니다. |
| 상대적 낮은 우선순위 | `--cpu-shares=512` | 다른 컨테이너보다 CPU 경쟁 시 낮은 우선순위를 부여할 때 사용. 기본값 1024의 절반 수준입니다. |
| 특정 코어에 고정 | `--cpuset-cpus="0,1"` | 지연 시간에 민감한 애플리케이션이나 CPU 캐시 효율성을 높일 때 사용. |
| 정밀한 CPU 할당 | `--cpu-period=100000 --cpu-quota=150000` | 고급 제어가 필요한 경우. 실수 가능성이 높으므로 주의가 필요합니다. |

### CPU 제한의 수학적 이해

Docker의 CPU 제한은 Linux 커널의 Cgroups 기능을 기반으로 합니다. `--cpus` 옵션은 내부적으로 다음 공식으로 변환됩니다:

```
가상 CPU 코어 수 = CPU 할당량(quota) / CPU 주기(period)
```

기본 주기(period)는 100,000 마이크로초(100ms)입니다. 따라서 `--cpus=1.5`는 다음과 같이 설정됩니다:
```
CPU 할당량 = 1.5 × 100,000 = 150,000 마이크로초
```

CPU shares는 절대적인 제한이 아니라 상대적 우선순위를 나타냅니다. 두 컨테이너 A(1024 shares)와 B(512 shares)가 CPU를 경쟁할 때, A는 B보다 2배 많은 CPU 시간을 받습니다. 단, 유휴 CPU가 있는 경우 두 컨테이너 모두 제한 없이 CPU를 사용할 수 있습니다.

### 실전 CPU 제한 예제

```bash
# 절대 상한: 최대 1.5개 vCPU 사용 제한
docker run --name web --cpus="1.5" myorg/web:latest

# 상대 가중치: CPU 경쟁 시 낮은 우선순위 부여
docker run --name batch --cpu-shares=256 myorg/batch:latest

# 코어 고정: 0번과 1번 코어에만 실행 제한
docker run --name realtime --cpuset-cpus="0,1" myorg/realtime:latest

# 고급 제어: 주기와 할당량 직접 지정 (2개 vCPU에 해당)
docker run --cpu-period=100000 --cpu-quota=200000 myorg/worker:latest
```

### CPU 제한 검증 방법

```bash
# Docker 기본 모니터링 도구 사용
docker stats

# Cgroup v2에서 실제 CPU 제한 확인
cat /sys/fs/cgroup/docker/<컨테이너_ID>/cpu.max

# Cgroup v2에서 CPU 가중치 확인 (1-10000 범위)
cat /sys/fs/cgroup/docker/<컨테이너_ID>/cpu.weight
```

**참고사항**: 최신 Linux 배포판(우분투 22.04+, RHEL 9+)은 기본적으로 Cgroup v2를 사용합니다. Cgroup v2에서는 CPU shares(1024 스케일)가 `cpu.weight`(1-10000 스케일)로 매핑됩니다.

---

## 메모리 리소스 제한

### 메모리 제한 옵션 이해하기

Docker는 다양한 수준의 메모리 제한 옵션을 제공하여 애플리케이션의 메모리 사용 패턴에 맞춰 최적화할 수 있습니다.

| 옵션 | 의미 | 권장 설정 가이드 |
|------|------|-----------------|
| `--memory` | 물리적 RAM 상한 | 애플리케이션의 평균 사용량 + 20-30% 여유 공간 |
| `--memory-swap` | RAM + 스왑 총량 | 일반적으로 RAM의 1.25-1.5배 또는 스왑 사용 금지 |
| `--oom-kill-disable` | OOM 시 종료 방지 | **권장하지 않음** (호스트 시스템 위험) |
| `--kernel-memory` | 커널 메모리 제한 | Cgroup v1에서만 의미 있음, v2에서는 제거됨 |

### 스왑 메모리 전략

**스왑 사용 금지 (엄격한 제한)**
```bash
docker run --memory="512m" --memory-swap="512m" myapp:latest
```
이 설정은 컨테이너가 스왑 메모리를 전혀 사용하지 못하게 합니다. 메모리 사용량이 제한을 초과하면 즉시 OOM이 발생합니다.

**부분적 스왑 허용**
```bash
docker run --memory="1g" --memory-swap="1.5g" myapp:latest
```
이 설정은 컨테이너가 1GB의 물리적 RAM과 추가로 0.5GB의 스왑 메모리를 사용할 수 있게 합니다.

**무제한 스왑 허용 (위험)**
```bash
docker run --memory="1g" --memory-swap="-1" myapp:latest
```
이 설정은 스왑 사용에 제한을 두지 않아 심각한 성능 저하를 초래할 수 있으므로 권장하지 않습니다.

### 메모리 제한 실전 예제

```bash
# 512MB 메모리 제한, 스왑 사용 금지
docker run --memory="512m" --memory-swap="512m" myorg/api:latest

# 1GB 메모리 제한, 총 1.5GB까지 스왑 허용
docker run --memory="1g" --memory-swap="1.5g" myorg/etl:latest
```

### 메모리 사용 모니터링 및 디버깅

```bash
# Docker 기본 모니터링
docker stats

# Cgroup v2에서 메모리 제한 확인
cat /sys/fs/cgroup/docker/<컨테이너_ID>/memory.max

# 현재 메모리 사용량 확인
cat /sys/fs/cgroup/docker/<컨테이너_ID>/memory.current

# OOM 이벤트 기록 확인
cat /sys/fs/cgroup/docker/<컨테이너_ID>/memory.events
```

**중요 참고사항**: Linux OOM Killer는 메모리 제한을 초과하는 컨테이너 내부의 프로세스를 종료시킵니다. 애플리케이션이 fork 폭주나 과도한 캐시 사용으로 메모리 소비가 많다면, 최대 Resident Set Size를 줄이고 메모리 재활용 로직을 구현해야 합니다. `--oom-kill-disable` 옵션은 컨테이너가 메모리를 과도하게 사용하더라도 종료되지 않게 하지만, 이는 호스트 시스템의 안정성을 해칠 수 있으므로 사용을 권장하지 않습니다.

---

## 디스크 I/O 제한

### 두 가지 수준의 I/O 제한 이해

Docker는 블록 I/O 제한을 위해 두 가지 접근 방식을 제공합니다:

1. **상대적 I/O 가중치 (`--blkio-weight`)**: 디스크 I/O가 경쟁하는 상황에서 각 컨테이너의 상대적 우선순위를 결정합니다. 값 범위는 10-1000이며 기본값은 500입니다.

2. **절대적 I/O 스로틀링**: 특정 디스크 장치에 대해 읽기/쓰기 속도를 절대적인 값으로 제한합니다.

### I/O 제한 실전 예제

```bash
# I/O 경쟁 시 낮은 우선순위 부여
docker run --blkio-weight=300 myorg/report:latest

# 장치별 읽기/쓰기 대역폭 제한
docker run \
  --device-read-bps /dev/sda:2mb \
  --device-write-bps /dev/sda:1mb \
  myorg/archiver:latest
```

**중요 주의사항**: I/O 제한은 컨테이너의 파일 시스템 경로가 아닌 **실제 물리적 디스크 장치**에 적용됩니다. 예를 들어 Docker 데이터가 `/dev/nvme0n1p2` 파티션에 저장되어 있다면 해당 장치에 스로틀을 적용해야 합니다. `lsblk`와 `findmnt /var/lib/docker` 명령으로 실제 디스크 장치를 확인할 수 있습니다.

### Cgroup v2의 I/O 인터페이스

최신 Cgroup v2에서는 I/O 제한이 `io.weight`와 `io.max` 파일을 통해 관리됩니다. Docker는 내부적으로 이러한 설정을 매핑하므로 일반 사용자는 CLI 옵션만으로도 충분합니다. 하지만 문제 해결 시 참고할 수 있습니다:

```bash
# I/O 제한 설정 확인
cat /sys/fs/cgroup/docker/<컨테이너_ID>/io.max

# I/O 가중치 확인
cat /sys/fs/cgroup/docker/<컨테이개_ID>/io.weight
```

---

## 종합적인 리소스 제한 템플릿

다음은 프로덕션 환경에서 권장되는 안전한 기본값을 포함한 종합적인 리소스 제한 템플릿입니다:

```bash
docker run -d --name app1 \
  --cpus="1.0" \
  --cpu-shares=512 \
  --cpuset-cpus="0,1" \
  --memory="1g" \
  --memory-swap="1.25g" \
  --blkio-weight=300 \
  --device-read-bps /dev/nvme0n1p2:2mb \
  --device-write-bps /dev/nvme0n1p2:1mb \
  --pids-limit=512 \
  --ulimit nofile=65535:65535 \
  --log-driver=json-file \
  --log-opt max-size=10m \
  --log-opt max-file=5 \
  myorg/app:stable
```

추가로 고려할 수 있는 보안 및 성능 옵션:
- `--read-only --tmpfs /tmp`: 파일 시스템 보안 강화 및 성능 최적화
- `--cap-drop=ALL`: 불필요한 Linux Capabilities 제거
- `--health-*`: 컨테이너 건강 상태 모니터링 설정

---

## Docker Compose를 통한 선언적 리소스 관리

### Docker Compose v2 (비-Swarm 모드)에서의 리소스 제한

Docker Compose v2에서는 서비스 수준의 리소스 제한 키를 사용합니다. `deploy.resources.limits`는 Swarm 모드에서만 완전히 지원되며, 단일 호스트 Compose 환경에서는 대부분 무시됩니다.

```yaml
version: "3.9"
services:
  api:
    image: myorg/api:2.1.0
    cpus: "1.5"
    cpuset: "0-2"
    mem_limit: "1g"
    pids_limit: 512
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "5"
    # 블록 I/O 스로틀링은 Compose 표준 키로 지원되지 않음
    # Swarm 모드에서만 device_* 옵션 사용 가능
```

### Docker Swarm 모드에서의 리소스 제한

Swarm 모드에서는 `deploy.resources` 섹션을 사용하여 더 정교한 리소스 관리가 가능합니다:

```yaml
services:
  api:
    image: myorg/api:2.1.0
    deploy:
      resources:
        limits:
          cpus: "1.5"
          memory: 1G
        reservations:
          cpus: "0.5"
          memory: 512M
```

**중요 참고**: `reservations`는 스케줄링 힌트로 사용되며, 실행 중인 컨테이너의 강제적 제한은 `limits`에 의해 결정됩니다.

---

## 리소스 제한 검증과 벤치마킹

### CPU 및 메모리 부하 테스트

```bash
# CPU 부하 테스트: 2개 워커로 60초 동안 스트레스 테스트
docker run --rm --cpus=1.5 progrium/stress --cpu 2 --timeout 60

# 메모리 부하 테스트: 600MB 메모리 할당 후 60초 동안 유지
docker run --rm --memory=512m polinux/stress \
  --vm 1 --vm-bytes 600M --timeout 60
```

### 디스크 I/O 성능 테스트

```bash
# 호스트 시스템에 fio 설치 후 Docker 볼륨 경로에서 테스트 수행
fio --name=randread \
    --filename=/var/lib/docker/volumes/테스트볼륨/_data/testfile \
    --bs=4k \
    --iodepth=16 \
    --rw=randread \
    --runtime=60
```

### 리소스 사용량 모니터링

```bash
# Docker 기본 모니터링
docker stats

# 특정 컨테이너의 Cgroup 설정 확인
CONTAINER_ID=$(docker ps -q --filter "name=myapp")
sudo cat /sys/fs/cgroup/docker/$CONTAINER_ID/cpu.max
sudo cat /sys/fs/cgroup/docker/$CONTAINER_ID/memory.events
```

---

## 특수 워크로드를 위한 고급 리소스 관리 전략

### NUMA 아키텍처 최적화
NUMA(Non-Uniform Memory Access) 시스템에서는 `--cpuset-cpus`를 사용하여 연속적인 CPU 코어를 컨테이너에 할당하면 L3 캐시 공유를 극대화할 수 있습니다. 이는 메모리 집약적 애플리케이션의 성능을 크게 향상시킬 수 있습니다.

### 실시간(Real-time) 워크로드
지연 시간에 민감한 실시간 애플리케이션의 경우, 컨테이너 내부에서 실시간 스케줄링이 필요할 수 있습니다. 이 경우 Linux 커널 설정과 적절한 Linux Capabilities 확인이 필요합니다. 일반적인 웹 애플리케이션이나 배치 작업에는 실시간 스케줄링이 필요하지 않습니다.

### JVM 기반 애플리케이션
Java 가상 머신은 컨테이너 환경의 메모리 제한을 인식하지 못할 수 있습니다. 다음과 같은 JVM 옵션을 사용하여 메모리 사용을 최적화하세요:
```bash
# 컨테이너 메모리 제한에 맞는 힙 크기 설정
-XX:MaxRAMPercentage=75.0
-XX:InitialRAMPercentage=50.0
```

### .NET 애플리케이션
.NET 런타임도 컨테이너 메모리 제한을 인식하도록 설정할 수 있습니다:
```bash
# 환경 변수를 통한 .NET GC 힙 제한
DOTNET_GCHeapHardLimit=1073741824  # 1GB로 제한
DOTNET_GCHeapHardLimitPercent=50   # 사용 가능 메모리의 50%로 제한
```

### Python 머신러닝 워크로드
NumPy, TensorFlow, PyTorch 등의 대형 머신러닝 라이브러리를 사용하는 Python 애플리케이션은 공유 메모리(`/dev/shm`)를 많이 사용합니다. `--shm-size` 옵션으로 공유 메모리 크기를 적절히 조정하고 메모리 상한을 함께 설정하세요.

---

## 시스템 운영 관점의 검토 체크리스트

### CPU 관리
- [ ] 절대적 CPU 상한 설정: `--cpus` 옵션 사용
- [ ] 상대적 CPU 우선순위 설정: `--cpu-shares`로 워크로드별 차등 적용
- [ ] CPU 코어 고정: 지연 시간 민감도나 캐시 효율성이 중요한 경우 `--cpuset-cpus` 사용
- [ ] 설정 검증: `docker stats`와 Cgroup 파일을 통한 실제 제한 확인

### 메모리 관리
- [ ] 물리적 메모리 상한 설정: `--memory` 옵션 사용
- [ ] 스왑 메모리 정책 결정: `--memory-swap`으로 과도한 스왑 사용 방지
- [ ] 공유 메모리 크기 조정: 브라우저, 머신러닝, 빌드 시스템을 위한 `--shm-size` 설정
- [ ] OOM 이벤트 모니터링: `memory.events` 파일을 통한 OOM 발생 추적

### 디스크 I/O 관리
- [ ] 상대적 I/O 가중치 설정: `--blkio-weight`로 I/O 경합 관리
- [ ] 절대적 I/O 스로틀링: `--device-*-bps`로 장치별 대역폭 제한
- [ ] 실제 디스크 장치 확인: `lsblk`, `findmnt` 명령으로 실제 스토리지 장치 식별

### 보안 및 안정성
- [ ] 프로세스 수 제한: `--pids-limit`으로 fork 폭주 방지
- [ ] 파일 디스크립터 제한: `--ulimit nofile`로 시스템 리소스 보호
- [ ] 로그 회전 설정: `--log-opt max-size/max-file`으로 디스크 공간 보호

---

## 일반적인 문제 해결 가이드

### 문제 1: CPU 가중치가 효과가 없는 것 같음
**원인**: CPU 가중치(`--cpu-shares`)는 CPU 자원이 경쟁하는 상황에서만 의미가 있습니다. 시스템에 유휴 CPU가 충분하면 모든 컨테이너가 제한 없이 CPU를 사용할 수 있습니다.

**해결**: 실제 부하 상황에서 CPU 사용률을 모니터링하거나 인위적으로 CPU 부하를 생성하여 테스트하세요.

### 문제 2: 디스크 I/O 제한이 적용되지 않음
**원인**: I/O 스로틀링이 잘못된 디스크 장치에 적용되었을 수 있습니다. Docker가 실제로 사용하는 디스크 장치를 확인해야 합니다.

**해결**: `lsblk` 명령으로 시스템의 디스크 구성과 `findmnt /var/lib/docker` 명령으로 Docker 데이터 디렉토리가 마운트된 장치를 확인한 후, 올바른 장치에 스로틀링을 적용하세요.

### 문제 3: 메모리 제한이 설정되었는데도 OOM이 빈번하게 발생
**원인**: 페이지 캐시, 네이티브 확장 라이브러리, 자식 프로세스 등이 메모리를 추가로 사용할 수 있습니다. 또한 애플리케이션 내부의 메모리 누수도 가능한 원인입니다.

**해결**: 메모리 상한을 적절히 상향 조정하고, 애플리케이션 코드에서 캐시 크기를 제한하며, `--pids-limit`을 함께 사용하여 자식 프로세스 수를 제한하세요.

### 문제 4: 스왑 사용으로 인한 성능 저하
**원인**: `--memory-swap=-1` 설정으로 인해 스왑 사용에 제한이 없거나, 스왑 총량이 너무 커서 빈번한 스왑 인/아웃이 발생하고 있습니다.

**해결**: 스왑 총량을 제한하거나 완전히 비활성화하세요. 스왑 사용이 필수적인 경우 SSD 기반 스왑을 고려하세요.

### 문제 5: Docker Compose에서 리소스 제한이 무시됨
**원인**: Compose 파일에서 Swarm 전용 필드(`deploy.resources`)를 사용했거나, Compose 버전 호환성 문제가 있을 수 있습니다.

**해결**: 단일 호스트 Compose 환경에서는 `mem_limit`, `cpus`, `cpuset` 등 서비스 수준 키를 사용하세요.

---

## Cgroup v1과 v2의 매핑 이해

최신 Linux 배포판은 점차 Cgroup v2로 전환되고 있습니다. 다음은 두 버전 간의 주요 매핑 관계입니다:

| 리소스 유형 | Cgroup v1 인터페이스 | Cgroup v2 인터페이스 |
|-------------|---------------------|---------------------|
| CPU 상한 | `cpu.cfs_quota_us` / `cpu.cfs_period_us` | `cpu.max` |
| CPU 가중치 | `cpu.shares` | `cpu.weight` |
| 메모리 제한 | `memory.limit_in_bytes` | `memory.max` |
| I/O 스로틀링 | `blkio.throttle.*` | `io.max` |
| I/O 가중치 | `blkio.weight` | `io.weight` |

대부분의 최신 Linux 배포판(우분투 22.04+, RHEL 9+ 등)은 기본적으로 Cgroup v2를 사용합니다. Docker는 내부적으로 이러한 변환을 처리하므로 일반 사용자는 CLI 옵션만 올바르게 사용하면 됩니다.

---

## 결론

Docker 컨테이너의 리소스 제한은 현대적인 컨테이너 운영에서 필수적인 관행입니다. 효과적인 리소스 관리를 통해 다음과 같은 이점을 얻을 수 있습니다:

1. **시스템 안정성 확보**: 한 컨테이너의 비정상적인 리소스 소비가 전체 호스트에 영향을 미치는 것을 방지합니다.

2. **예측 가능한 성능**: 리소스 제한을 통해 애플리케이션의 성능을 일관되게 유지할 수 있습니다.

3. **공정한 자원 배분**: 멀티 테넌시 환경에서 모든 워크로드에 공정한 자원 접근 기회를 제공합니다.

4. **비용 최적화**: 과도한 리소스 프로비저닝을 방지하여 인프라 비용을 절감합니다.

### 실천적 권고사항

- **시작점 설정**: 웹 API 서비스에는 `cpus=1-2`, `memory=512m-1g`, `pids-limit=256-512`를 시작점으로 설정하세요.
- **워크로드 특성 반영**: 배치/ETL 작업에는 더 많은 CPU(`cpus=2-4`)를 할당하고 I/O 스로틀링을 적극적으로 사용하세요.
- **실험적 접근**: 모든 설정 변경은 측정-조정-검증의 순환 과정을 통해 접근하세요.
- **모니터링 강화**: `docker stats`, Cgroup 파일, 시스템 메트릭을 결합한 종합적인 모니터링 체계를 구축하세요.

이 가이드에서 제시한 템플릿과 원칙을 시작점으로 삼아, 조직의 특정 워크로드 패턴과 성능 요구사항에 맞춰 세부적인 튜닝을 진행하시기 바랍니다. 리소스 제한은 한 번에 완성되는 것이 아닌, 지속적인 관찰과 조정을 통해 최적화되는 과정임을 기억하세요.