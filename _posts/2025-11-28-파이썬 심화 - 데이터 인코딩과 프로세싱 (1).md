---
layout: post
title: 파이썬 심화 - 데이터 인코딩과 프로세싱 (1)
date: 2025-11-28 21:25:23 +0900
category: 파이썬 심화
---
# 데이터 인코딩과 프로세싱 (1)

## CSV 데이터 읽고 쓰기

### 다양한 CSV 처리 기법
```python
import csv
import pandas as pd
from collections import defaultdict
import json

# 기본 CSV 파일 생성
def create_basic_csv():
    """기본적인 CSV 파일 생성 예제"""
    data = [
        ['이름', '나이', '직업', '도시'],
        ['김철수', '30', '개발자', '서울'],
        ['이영희', '25', '디자이너', '부산'],
        ['박민수', '35', '매니저', '대구'],
        ['최지우', '28', '분석가', '인천']
    ]
    
    with open('employees.csv', 'w', encoding='utf-8-sig', newline='') as f:
        writer = csv.writer(f)
        writer.writerows(data)
    
    print("기본 CSV 파일 생성 완료: employees.csv")

create_basic_csv()

# CSV 파일 읽기 (여러 방식)
def read_csv_multiple_ways():
    """CSV 파일을 다양한 방식으로 읽기"""
    
    print("\n1. 기본 csv.reader 사용:")
    with open('employees.csv', 'r', encoding='utf-8-sig') as f:
        reader = csv.reader(f)
        for row in reader:
            print(f"  {row}")
    
    print("\n2. DictReader 사용 (딕셔너리 형태):")
    with open('employees.csv', 'r', encoding='utf-8-sig') as f:
        reader = csv.DictReader(f)
        for row in reader:
            print(f"  이름: {row['이름']}, 직업: {row['직업']}, 도시: {row['도시']}")
    
    print("\n3. pandas로 읽기 (데이터프레임):")
    try:
        df = pd.read_csv('employees.csv', encoding='utf-8-sig')
        print(f"  데이터프레임 크기: {df.shape}")
        print(f"  컬럼: {list(df.columns)}")
        print(f"  데이터:\n{df.to_string()}")
    except ImportError:
        print("  pandas가 설치되지 않았습니다.")

read_csv_multiple_ways()

# 다양한 구분자와 옵션 처리
def advanced_csv_operations():
    """고급 CSV 처리 작업"""
    
    # 다양한 구분자 지원
    data = [
        ['제품명', '가격', '수량', '카테고리'],
        ['노트북', '1200000', '5', '전자제품'],
        ['의자', '150000', '20', '가구'],
        ['책상', '300000', '10', '가구'],
        ['모니터', '500000', '8', '전자제품']
    ]
    
    # 탭 구분 파일 (TSV)
    with open('products.tsv', 'w', encoding='utf-8', newline='') as f:
        writer = csv.writer(f, delimiter='\t')
        writer.writerows(data)
    
    # 세미콜론 구분 파일
    with open('products_semicolon.csv', 'w', encoding='utf-8', newline='') as f:
        writer = csv.writer(f, delimiter=';')
        writer.writerows(data)
    
    # 인용부호 처리
    tricky_data = [
        ['이름', '설명', '가격'],
        ['김철수', '이 사람은 "특별한" 직원입니다', '50000'],
        ['이영희', '설명에, 쉼표가 포함된 경우', '60000'],
        ['박민수', '줄바꿈이\n포함된\n설명', '70000']
    ]
    
    with open('tricky_data.csv', 'w', encoding='utf-8', newline='') as f:
        writer = csv.writer(f, quoting=csv.QUOTE_ALL)  # 모든 필드를 인용부호로 감싸기
        writer.writerows(tricky_data)
    
    print("\n고급 CSV 파일 생성 완료:")
    print("  - products.tsv (탭 구분)")
    print("  - products_semicolon.csv (세미콜론 구분)")
    print("  - tricky_data.csv (특수 문자 포함)")

advanced_csv_operations()

# 대용량 CSV 파일 스트리밍 처리
def process_large_csv_streaming(input_file, output_file, chunk_size=1000):
    """대용량 CSV 파일을 청크 단위로 처리"""
    
    print(f"\n대용량 CSV 처리 시작: {input_file} -> {output_file}")
    
    # 샘플 대용량 CSV 생성
    with open(input_file, 'w', encoding='utf-8-sig', newline='') as f:
        writer = csv.writer(f)
        writer.writerow(['ID', '이름', '점수', '등급'])
        
        for i in range(10000):
            writer.writerow([
                f'ID{i:06d}',
                f'사용자{i}',
                f'{i % 100}',
                chr(65 + (i % 5))  # A-E 등급
            ])
    
    # 스트리밍 방식으로 처리
    processed_count = 0
    with open(input_file, 'r', encoding='utf-8-sig') as f_in, \
         open(output_file, 'w', encoding='utf-8-sig', newline='') as f_out:
        
        reader = csv.DictReader(f_in)
        writer = csv.DictWriter(f_out, fieldnames=['ID', '이름', '점수', '등급', '평가'])
        
        writer.writeheader()
        
        for row in reader:
            # 데이터 처리 (예: 점수에 따른 평가 추가)
            score = int(row['점수'])
            if score >= 90:
                row['평가'] = '우수'
            elif score >= 70:
                row['평가'] = '보통'
            else:
                row['평가'] = '향상필요'
            
            writer.writerow(row)
            processed_count += 1
            
            # 진행 상황 표시
            if processed_count % chunk_size == 0:
                print(f"  처리 중... {processed_count}개 레코드")
    
    print(f"대용량 CSV 처리 완료: {processed_count}개 레코드")

process_large_csv_streaming('large_data.csv', 'processed_data.csv')

# CSV 데이터 분석 및 통계
def analyze_csv_data(filename):
    """CSV 데이터 분석"""
    
    print(f"\nCSV 데이터 분석: {filename}")
    
    with open(filename, 'r', encoding='utf-8-sig') as f:
        reader = csv.DictReader(f)
        
        # 통계 정보 수집
        stats = defaultdict(list)
        total_records = 0
        
        for row in reader:
            total_records += 1
            for key, value in row.items():
                if value.isdigit():  # 숫자인 경우만
                    stats[key].append(int(value))
        
        # 통계 계산
        print(f"  총 레코드 수: {total_records}")
        print(f"  필드별 통계:")
        
        for field, values in stats.items():
            if values:
                print(f"    {field}:")
                print(f"      개수: {len(values)}")
                print(f"      평균: {sum(values)/len(values):.2f}")
                print(f"      최소: {min(values)}")
                print(f"      최대: {max(values)}")

analyze_csv_data('processed_data.csv')
```

## JSON 데이터 읽고 쓰기

### 다양한 JSON 처리 패턴
```python
import json
from datetime import datetime, date
from decimal import Decimal

# 기본 JSON 쓰기/읽기
def basic_json_operations():
    """기본 JSON 파일 작업"""
    
    # 파이썬 객체 생성
    data = {
        '회사': '테크노컴퍼니',
        '설립연도': 2010,
        '직원수': 150,
        '위치': '서울',
        '부서': ['개발', '디자인', '마케팅', '영업'],
        '수익': True,
        '세부정보': {
            'CEO': '김대표',
            'CTO': '이기술',
            '매출': 5000000000  # 50억
        }
    }
    
    # JSON 파일로 저장
    with open('company_data.json', 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    
    print("JSON 파일 저장 완료: company_data.json")
    
    # JSON 파일 읽기
    with open('company_data.json', 'r', encoding='utf-8') as f:
        loaded_data = json.load(f)
    
    print("\n읽어온 데이터 구조:")
    print(f"  회사명: {loaded_data['회사']}")
    print(f"  부서 수: {len(loaded_data['부서'])}")
    print(f"  CEO: {loaded_data['세부정보']['CEO']}")

basic_json_operations()

# 커스텀 객체 직렬화
class Employee:
    """직원 클래스"""
    
    def __init__(self, name, age, position, salary):
        self.name = name
        self.age = age
        self.position = position
        self.salary = salary
        self.hire_date = date.today()
    
    def to_dict(self):
        """딕셔너리로 변환"""
        return {
            'name': self.name,
            'age': self.age,
            'position': self.position,
            'salary': self.salary,
            'hire_date': self.hire_date.isoformat()
        }
    
    @classmethod
    def from_dict(cls, data):
        """딕셔너리에서 객체 생성"""
        emp = cls(
            name=data['name'],
            age=data['age'],
            position=data['position'],
            salary=data['salary']
        )
        emp.hire_date = date.fromisoformat(data['hire_date'])
        return emp

class CustomJSONEncoder(json.JSONEncoder):
    """커스텀 JSON 인코더"""
    
    def default(self, obj):
        if isinstance(obj, (datetime, date)):
            return obj.isoformat()
        elif isinstance(obj, Decimal):
            return str(obj)
        elif isinstance(obj, Employee):
            return obj.to_dict()
        elif hasattr(obj, 'to_json'):
            return obj.to_json()
        return super().default(obj)

class CustomJSONDecoder(json.JSONDecoder):
    """커스텀 JSON 디코더"""
    
    def __init__(self, *args, **kwargs):
        super().__init__(object_hook=self.object_hook, *args, **kwargs)
    
    def object_hook(self, dct):
        # 특정 키를 기반으로 객체 복원
        if 'name' in dct and 'position' in dct and 'salary' in dct:
            return Employee.from_dict(dct)
        return dct

# 커스텀 객체 JSON 처리
def custom_object_json():
    """커스텀 객체를 포함한 JSON 처리"""
    
    employees = [
        Employee('김철수', 30, '개발자', 5000000),
        Employee('이영희', 25, '디자이너', 4000000),
        Employee('박민수', 35, '매니저', 6000000)
    ]
    
    # 커스텀 인코더로 저장
    with open('employees.json', 'w', encoding='utf-8') as f:
        json.dump({
            'company': '테크노컴퍼니',
            'employees': employees,
            'created_at': datetime.now(),
            'budget': Decimal('100000000.50')
        }, f, cls=CustomJSONEncoder, ensure_ascii=False, indent=2)
    
    print("\n커스텀 객체 JSON 저장 완료: employees.json")
    
    # 커스텀 디코더로 읽기
    with open('employees.json', 'r', encoding='utf-8') as f:
        data = json.load(f, cls=CustomJSONDecoder)
    
    print("\n복원된 데이터:")
    print(f"  회사: {data['company']}")
    print(f"  직원 수: {len(data['employees'])}")
    
    for emp in data['employees']:
        if isinstance(emp, Employee):
            print(f"  - {emp.name}: {emp.position} ({emp.salary:,}원)")

custom_object_json()

# 대용량 JSON 라인 분리 형식
def large_json_handling():
    """대용량 JSON 처리 (JSON Lines 형식)"""
    
    # JSON Lines 형식: 각 줄이 독립된 JSON 객체
    print("\nJSON Lines 형식 처리:")
    
    # 대용량 데이터 생성 (JSON Lines)
    with open('big_data.jsonl', 'w', encoding='utf-8') as f:
        for i in range(1000):
            record = {
                'id': i,
                'name': f'사용자{i}',
                'value': i * 100,
                'timestamp': datetime.now().isoformat()
            }
            f.write(json.dumps(record, ensure_ascii=False) + '\n')
    
    print("  JSON Lines 파일 생성 완료: big_data.jsonl")
    
    # 스트리밍 방식으로 읽기
    print("  스트리밍 방식으로 읽기:")
    with open('big_data.jsonl', 'r', encoding='utf-8') as f:
        for i, line in enumerate(f):
            if i >= 3:  # 처음 3개만 표시
                print("    ... (생략)")
                break
            data = json.loads(line.strip())
            print(f"    레코드 {i}: {data['name']}")
    
    # pandas로 읽기 (메모리 충분 시)
    try:
        import pandas as pd
        df = pd.read_json('big_data.jsonl', lines=True)
        print(f"  pandas로 읽은 데이터 크기: {len(df)}행 x {len(df.columns)}열")
    except ImportError:
        print("  pandas가 설치되지 않았습니다.")

large_json_handling()

# JSON 데이터 검증 및 스키마
import jsonschema
from jsonschema import validate

def validate_json_with_schema():
    """JSON 스키마 검증"""
    
    # JSON 스키마 정의
    user_schema = {
        "$schema": "http://json-schema.org/draft-07/schema#",
        "type": "object",
        "required": ["id", "name", "email", "age"],
        "properties": {
            "id": {
                "type": "integer",
                "minimum": 1
            },
            "name": {
                "type": "string",
                "minLength": 2,
                "maxLength": 50
            },
            "email": {
                "type": "string",
                "format": "email"
            },
            "age": {
                "type": "integer",
                "minimum": 18,
                "maximum": 100
            },
            "address": {
                "type": "object",
                "properties": {
                    "street": {"type": "string"},
                    "city": {"type": "string"},
                    "zipcode": {"type": "string"}
                }
            }
        }
    }
    
    # 검증할 데이터
    valid_user = {
        "id": 1,
        "name": "김철수",
        "email": "kim@example.com",
        "age": 30,
        "address": {
            "street": "테헤란로",
            "city": "서울",
            "zipcode": "06141"
        }
    }
    
    invalid_user = {
        "id": -1,  # 음수 ID
        "name": "A",  # 너무 짧은 이름
        "email": "invalid-email",  # 잘못된 이메일 형식
        "age": 15  # 너무 어린 나이
    }
    
    # 검증 수행
    print("\nJSON 스키마 검증:")
    
    try:
        validate(instance=valid_user, schema=user_schema)
        print("  유효한 사용자 데이터: 검증 통과")
    except jsonschema.exceptions.ValidationError as e:
        print(f"  유효한 사용자 데이터: 검증 실패 - {e}")
    
    try:
        validate(instance=invalid_user, schema=user_schema)
        print("  잘못된 사용자 데이터: 검증 통과")
    except jsonschema.exceptions.ValidationError as e:
        print(f"  잘못된 사용자 데이터: 검증 실패 - {e}")

validate_json_with_schema()
```

## 단순한 XML 데이터 파싱

### XML 기본 파싱
```python
import xml.etree.ElementTree as ET
from xml.dom import minidom
import html

# 기본 XML 생성 및 파싱
def basic_xml_parsing():
    """기본 XML 파싱"""
    
    # XML 문자열
    xml_string = '''<?xml version="1.0" encoding="UTF-8"?>
<bookstore>
    <book category="소설">
        <title lang="ko">홍길동전</title>
        <author>허균</author>
        <year>1612</year>
        <price>15000</price>
    </book>
    <book category="프로그래밍">
        <title lang="en">Python Programming</title>
        <author>Guido van Rossum</author>
        <year>2020</year>
        <price>35000</price>
    </book>
    <book category="과학">
        <title lang="ko">코스모스</title>
        <author>칼 세이건</author>
        <year>1980</year>
        <price>28000</price>
    </book>
</bookstore>'''
    
    # 파일로 저장
    with open('bookstore.xml', 'w', encoding='utf-8') as f:
        f.write(xml_string)
    
    # ElementTree로 파싱
    tree = ET.parse('bookstore.xml')
    root = tree.getroot()
    
    print("XML 파싱 결과:")
    print(f"루트 요소: {root.tag}")
    
    # 모든 책 정보 출력
    print("\n책 목록:")
    for book in root.findall('book'):
        category = book.get('category')
        title = book.find('title').text
        author = book.find('author').text
        price = book.find('price').text
        
        print(f"  카테고리: {category}")
        print(f"    제목: {title}")
        print(f"    저자: {author}")
        print(f"    가격: {price}원")
        print()
    
    # 특정 조건 검색
    print("특정 조건 검색 (카테고리가 '소설'인 책):")
    novels = root.findall("book[@category='소설']")
    for novel in novels:
        title = novel.find('title').text
        print(f"  - {title}")

basic_xml_parsing()

# XML 생성 및 수정
def create_and_modify_xml():
    """XML 생성 및 수정"""
    
    # 새로운 XML 트리 생성
    root = ET.Element("company")
    
    # 부서 요소 추가
    dept1 = ET.SubElement(root, "department")
    dept1.set("name", "개발팀")
    dept1.set("location", "3층")
    
    # 개발팀 직원 추가
    emp1 = ET.SubElement(dept1, "employee")
    ET.SubElement(emp1, "name").text = "김철수"
    ET.SubElement(emp1, "position").text = "수석개발자"
    ET.SubElement(emp1, "salary").text = "7000000"
    
    emp2 = ET.SubElement(dept1, "employee")
    ET.SubElement(emp2, "name").text = "이영희"
    ET.SubElement(emp2, "position").text = "개발자"
    ET.SubElement(emp2, "salary").text = "5000000"
    
    # 디자인팀 추가
    dept2 = ET.SubElement(root, "department")
    dept2.set("name", "디자인팀")
    dept2.set("location", "2층")
    
    emp3 = ET.SubElement(dept2, "employee")
    ET.SubElement(emp3, "name").text = "박민수"
    ET.SubElement(emp3, "position").text = "디자이너"
    ET.SubElement(emp3, "salary").text = "4500000"
    
    # XML 파일로 저장 (정렬 포함)
    tree = ET.ElementTree(root)
    
    # 보기 좋게 포맷팅
    xml_str = ET.tostring(root, encoding='utf-8', method='xml')
    parsed = minidom.parseString(xml_str)
    pretty_xml = parsed.toprettyxml(indent="  ", encoding='utf-8')
    
    with open('company.xml', 'wb') as f:
        f.write(pretty_xml)
    
    print("XML 파일 생성 완료: company.xml")
    
    # XML 수정
    print("\nXML 수정 작업:")
    tree = ET.parse('company.xml')
    root = tree.getroot()
    
    # 새로운 직원 추가
    for dept in root.findall("department"):
        if dept.get("name") == "개발팀":
            new_emp = ET.SubElement(dept, "employee")
            ET.SubElement(new_emp, "name").text = "최신입"
            ET.SubElement(new_emp, "position").text = "주니어개발자"
            ET.SubElement(new_emp, "salary").text = "3500000"
            print("  개발팀에 새로운 직원 추가")
            break
    
    # 급여 인상
    for emp in root.findall(".//employee"):
        name = emp.find("name").text
        salary_elem = emp.find("salary")
        current_salary = int(salary_elem.text)
        new_salary = int(current_salary * 1.1)  # 10% 인상
        salary_elem.text = str(new_salary)
        print(f"  {name} 급여 인상: {current_salary:,} -> {new_salary:,}")
    
    # 수정된 XML 저장
    tree.write('company_updated.xml', encoding='utf-8', xml_declaration=True)
    print("수정된 XML 저장 완료: company_updated.xml")

create_and_modify_xml()
```

## 매우 큰 XML 파일 증분 파싱하기

### SAX 파서를 이용한 스트리밍 XML 처리
```python
import xml.sax
import xml.sax.handler
from xml.sax.xmlreader import AttributesImpl

class LargeXMLHandler(xml.sax.handler.ContentHandler):
    """대용량 XML 파일을 처리하는 SAX 핸들러"""
    
    def __init__(self, target_element, max_items=None):
        self.target_element = target_element
        self.max_items = max_items
        self.current_element = None
        self.current_data = ""
        self.item_count = 0
        self.items = []
    
    def startElement(self, name, attrs):
        self.current_element = name
        self.current_data = ""
        
        if name == self.target_element:
            # 새 아이템 시작
            self.current_item = {'attributes': dict(attrs)}
    
    def characters(self, content):
        if self.current_element:
            self.current_data += content
    
    def endElement(self, name):
        if name == self.target_element:
            # 아이템 완료
            self.item_count += 1
            self.items.append(self.current_item)
            
            if self.max_items and self.item_count >= self.max_items:
                # 최대 아이템 수 도달 시 파싱 중단
                raise xml.sax.SAXException(f"{self.max_items}개 아이템 처리 완료")
        elif self.current_element == name and hasattr(self, 'current_item'):
            # 하위 요소 데이터 저장
            self.current_item[name] = self.current_data.strip()
        
        self.current_element = None
        self.current_data = ""
    
    def get_results(self):
        return self.items, self.item_count

def incremental_xml_parsing():
    """증분 XML 파싱 (SAX 방식)"""
    
    print("대용량 XML 증분 파싱")
    
    # 대용량 XML 파일 생성 (간단한 예제)
    large_xml = '''<?xml version="1.0" encoding="UTF-8"?>
<products>
    <product id="1001">
        <name>스마트폰 A</name>
        <price>1200000</price>
        <category>전자제품</category>
        <stock>50</stock>
    </product>
    <product id="1002">
        <name>노트북 B</name>
        <price>2500000</price>
        <category>전자제품</category>
        <stock>30</stock>
    </product>
</products>'''
    
    # 더 많은 데이터를 추가하여 대용량 파일 시뮬레이션
    with open('large_products.xml', 'w', encoding='utf-8') as f:
        f.write('<?xml version="1.0" encoding="UTF-8"?>\n')
        f.write('<products>\n')
        
        for i in range(1000):  # 1000개 제품 생성
            f.write(f'''    <product id="{1000 + i}">
        <name>제품{i:04d}</name>
        <price>{100000 + (i * 10000)}</price>
        <category>카테고리{i % 10}</category>
        <stock>{i % 100}</stock>
    </product>
''')
        
        f.write('</products>\n')
    
    print(f"테스트 XML 파일 생성 완료: large_products.xml")
    
    # SAX 파서로 증분 처리
    handler = LargeXMLHandler('product', max_items=10)  # 처음 10개만 처리
    
    parser = xml.sax.make_parser()
    parser.setContentHandler(handler)
    
    try:
        parser.parse('large_products.xml')
    except xml.sax.SAXException as e:
        print(f"파싱 중단: {e}")
    
    items, count = handler.get_results()
    
    print(f"\n처리된 제품 수: {count}")
    print("처음 3개 제품 정보:")
    
    for i, item in enumerate(items[:3]):
        print(f"\n  제품 {i+1}:")
        print(f"    ID: {item['attributes']['id']}")
        print(f"    이름: {item.get('name', 'N/A')}")
        print(f"    가격: {item.get('price', 'N/A')}")
        print(f"    카테고리: {item.get('category', 'N/A')}")

incremental_xml_parsing()

# 이터레이터를 이용한 증분 파싱
import itertools

class XMLStreamParser:
    """스트리밍 방식 XML 파서"""
    
    def __init__(self, filename, target_tag):
        self.filename = filename
        self.target_tag = target_tag
    
    def parse(self):
        """제너레이터로 요소를 하나씩 반환"""
        context = ET.iterparse(self.filename, events=('start', 'end'))
        
        # 이터레이터로 변환
        context = iter(context)
        event, root = next(context)  # 루트 요소 가져오기
        
        for event, elem in context:
            if event == 'end' and elem.tag == self.target_tag:
                # 요소 파싱 완료
                yield self._parse_element(elem)
                
                # 메모리 정리 (부모 요소에서 제거)
                elem.clear()
                if elem.getprevious() is not None:
                    try:
                        del elem.getparent()[0]
                    except TypeError:
                        pass
        
        root.clear()
    
    def _parse_element(self, elem):
        """개별 요소 파싱"""
        result = {}
        result['tag'] = elem.tag
        result['attrib'] = elem.attrib
        
        # 하위 요소들 처리
        for child in elem:
            if len(child) == 0:  # 텍스트만 있는 요소
                result[child.tag] = child.text
            else:  # 중첩된 구조
                if child.tag not in result:
                    result[child.tag] = []
                result[child.tag].append(self._parse_element(child))
        
        return result

def streaming_xml_parsing():
    """스트리밍 방식 XML 파싱"""
    
    print("\n스트리밍 XML 파싱:")
    
    parser = XMLStreamParser('large_products.xml', 'product')
    
    # 처음 5개 요소만 처리
    for i, product in enumerate(itertools.islice(parser.parse(), 5)):
        print(f"\n  제품 {i+1}:")
        print(f"    ID: {product['attrib']['id']}")
        print(f"    이름: {product.get('name', 'N/A')}")
        print(f"    가격: {product.get('price', 'N/A')}원")
    
    print(f"\n  ... 나머지 제품들은 메모리에 로드되지 않음")

streaming_xml_parsing()
```

## 딕셔너리를 XML로 변환하기

### 데이터 구조를 XML로 변환
```python
def dict_to_xml(tag, d, pretty=True):
    """딕셔너리를 XML로 변환"""
    
    def _to_xml(element, data):
        """재귀적으로 딕셔너리를 XML로 변환"""
        if isinstance(data, dict):
            for key, value in data.items():
                # 키가 속성인지 확인 (@로 시작)
                if key.startswith('@'):
                    element.set(key[1:], str(value))
                # 키가 텍스트 노드인지 확인 (#로 시작)
                elif key == '#text':
                    element.text = str(value)
                # 일반 요소인 경우
                else:
                    child = ET.SubElement(element, key)
                    _to_xml(child, value)
        elif isinstance(data, list):
            for item in data:
                child = ET.SubElement(element, 'item')
                _to_xml(child, item)
        else:
            element.text = str(data)
    
    # 루트 요소 생성
    root = ET.Element(tag)
    _to_xml(root, d)
    
    # 포맷팅 옵션
    if pretty:
        xml_str = ET.tostring(root, encoding='utf-8')
        parsed = minidom.parseString(xml_str)
        return parsed.toprettyxml(indent="  ")
    else:
        return ET.tostring(root, encoding='utf-8').decode('utf-8')

def complex_dict_to_xml():
    """복잡한 딕셔너리를 XML로 변환"""
    
    # 복잡한 데이터 구조
    company_data = {
        '@name': '테크노컴퍼니',
        '@founded': '2010',
        'department': [
            {
                '@id': 'dept1',
                '@location': '3층',
                'name': '개발팀',
                'employee': [
                    {
                        '@emp_id': 'E001',
                        'name': '김철수',
                        'position': '수석개발자',
                        'salary': {'@currency': 'KRW', '#text': '7000000'},
                        'skills': {
                            'skill': ['Python', 'JavaScript', 'Django']
                        }
                    },
                    {
                        '@emp_id': 'E002',
                        'name': '이영희',
                        'position': '개발자',
                        'salary': {'@currency': 'KRW', '#text': '5000000'},
                        'skills': {
                            'skill': ['Java', 'Spring', 'MySQL']
                        }
                    }
                ]
            },
            {
                '@id': 'dept2',
                '@location': '2층',
                'name': '디자인팀',
                'employee': {
                    '@emp_id': 'E003',
                    'name': '박민수',
                    'position': '디자이너',
                    'salary': {'@currency': 'KRW', '#text': '4500000'},
                    'tools': {
                        'tool': ['Photoshop', 'Illustrator', 'Figma']
                    }
                }
            }
        ],
        'projects': {
            'project': [
                {
                    '@status': 'ongoing',
                    'name': 'AI 플랫폼 개발',
                    'budget': '100000000',
                    'deadline': '2024-12-31'
                },
                {
                    '@status': 'completed',
                    'name': '웹사이트 리뉴얼',
                    'budget': '50000000',
                    'deadline': '2024-06-30'
                }
            ]
        }
    }
    
    # XML로 변환
    xml_output = dict_to_xml('company', company_data)
    
    # 파일로 저장
    with open('company_from_dict.xml', 'w', encoding='utf-8') as f:
        f.write(xml_output)
    
    print("딕셔너리 -> XML 변환 완료: company_from_dict.xml")
    
    # 생성된 XML 확인
    print("\n생성된 XML 구조 (일부):")
    lines = xml_output.split('\n')
    for i in range(min(20, len(lines))):
        print(f"  {lines[i]}")
    
    print("  ...")

complex_dict_to_xml()

# XML을 딕셔너리로 변환
def xml_to_dict(element):
    """XML 요소를 딕셔너리로 변환"""
    
    result = {}
    
    # 속성 처리
    if element.attrib:
        for key, value in element.attrib.items():
            result[f'@{key}'] = value
    
    # 자식 요소 처리
    children = list(element)
    if children:
        # 중복 태그 카운트
        tag_count = {}
        for child in children:
            tag = child.tag
            if tag not in tag_count:
                tag_count[tag] = 0
            tag_count[tag] += 1
        
        for child in children:
            tag = child.tag
            child_dict = xml_to_dict(child)
            
            # 같은 태그가 여러 개인 경우 리스트로 저장
            if tag_count[tag] > 1:
                if tag not in result:
                    result[tag] = []
                result[tag].append(child_dict)
            else:
                result[tag] = child_dict
    else:
        # 텍스트 내용
        if element.text and element.text.strip():
            result['#text'] = element.text.strip()
    
    return result

def test_xml_dict_conversion():
    """XML ↔ 딕셔너리 변환 테스트"""
    
    # XML 파일 읽기
    tree = ET.parse('company_from_dict.xml')
    root = tree.getroot()
    
    # XML -> 딕셔너리
    company_dict = xml_to_dict(root)
    
    print("\nXML -> 딕셔너리 변환 결과 (요약):")
    print(f"  회사명: {company_dict.get('@name')}")
    print(f"  설립연도: {company_dict.get('@founded')}")
    
    departments = company_dict.get('department', [])
    if isinstance(departments, list):
        print(f"  부서 수: {len(departments)}")
        for i, dept in enumerate(departments[:2]):  # 처음 2개만 출력
            print(f"  부서 {i+1}: {dept.get('name')}")
    
    # 딕셔너리 -> XML (다시 변환)
    new_xml = dict_to_xml('company', company_dict)
    
    # 파일로 저장
    with open('company_roundtrip.xml', 'w', encoding='utf-8') as f:
        f.write(new_xml)
    
    print("\nXML ↔ 딕셔너리 왕복 변환 완료: company_roundtrip.xml")

test_xml_dict_conversion()
```

## XML 파싱, 수정, 저장

### XML 문서 조작
```python
def advanced_xml_manipulation():
    """XML 문서의 고급 조작"""
    
    print("XML 문서 고급 조작")
    
    # XML 문서 로드
    xml_content = '''<?xml version="1.0" encoding="UTF-8"?>
<library>
    <section name="소설">
        <book id="B001">
            <title>홍길동전</title>
            <author>허균</author>
            <year>1612</year>
            <available>true</available>
            <copies>5</copies>
        </book>
        <book id="B002">
            <title>토지</title>
            <author>박경리</author>
            <year>1969</year>
            <available>false</available>
            <copies>3</copies>
        </book>
    </section>
    <section name="과학">
        <book id="B003">
            <title>코스모스</title>
            <author>칼 세이건</author>
            <year>1980</year>
            <available>true</available>
            <copies>7</copies>
        </book>
    </section>
</library>'''
    
    with open('library.xml', 'w', encoding='utf-8') as f:
        f.write(xml_content)
    
    # XML 파싱
    tree = ET.parse('library.xml')
    root = tree.getroot()
    
    print("\n1. 도서 검색 및 필터링:")
    
    # 모든 도서 검색
    all_books = root.findall('.//book')
    print(f"  총 도서 수: {len(all_books)}")
    
    # 대출 가능한 도서
    available_books = root.findall(".//book[available='true']")
    print(f"  대출 가능 도서: {len(available_books)}")
    
    for book in available_books[:2]:  # 처음 2개만 출력
        title = book.find('title').text
        author = book.find('author').text
        print(f"    - {title} ({author})")
    
    # 2. 도서 정보 수정
    print("\n2. 도서 정보 수정:")
    
    # 특정 도서 찾기
    book_to_update = root.find(".//book[@id='B002']")
    if book_to_update:
        # 대출 상태 변경
        available_elem = book_to_update.find('available')
        if available_elem.text == 'false':
            available_elem.text = 'true'
            print(f"  도서 ID B002 대출 상태 변경: false -> true")
        
        # 복사본 수 증가
        copies_elem = book_to_update.find('copies')
        current_copies = int(copies_elem.text)
        copies_elem.text = str(current_copies + 2)
        print(f"  도서 ID B002 복사본 수 변경: {current_copies} -> {copies_elem.text}")
    
    # 3. 새로운 도서 추가
    print("\n3. 새로운 도서 추가:")
    
    # 프로그래밍 섹션 찾기 또는 생성
    programming_section = root.find(".//section[@name='프로그래밍']")
    if programming_section is None:
        programming_section = ET.SubElement(root, 'section')
        programming_section.set('name', '프로그래밍')
        print("  프로그래밍 섹션 생성")
    
    # 새로운 도서 추가
    new_book = ET.SubElement(programming_section, 'book')
    new_book.set('id', 'B004')
    
    ET.SubElement(new_book, 'title').text = '파이썬 완벽 가이드'
    ET.SubElement(new_book, 'author').text = '마크 럼버그'
    ET.SubElement(new_book, 'year').text = '2023'
    ET.SubElement(new_book, 'available').text = 'true'
    ET.SubElement(new_book, 'copies').text = '10'
    
    print("  새로운 도서 '파이썬 완벽 가이드' 추가")
    
    # 4. 도서 삭제
    print("\n4. 도서 삭제:")
    
    # 복사본이 적은 도서 찾기
    for book in root.findall('.//book'):
        copies = int(book.find('copies').text)
        if copies < 3:
            title = book.find('title').text
            section = book.getparent()
            section.remove(book)
            print(f"  도서 삭제: {title} (복사본: {copies}개)")
            break
    
    # 5. XML 저장 (포맷팅 포함)
    print("\n5. 수정된 XML 저장:")
    
    # ElementTree로 저장
    tree.write('library_updated.xml', 
               encoding='utf-8', 
               xml_declaration=True,
               method='xml')
    
    # 보기 좋게 포맷팅하여 다시 저장
    with open('library_updated.xml', 'r', encoding='utf-8') as f:
        xml_content = f.read()
    
    parsed = minidom.parseString(xml_content)
    pretty_xml = parsed.toprettyxml(indent="  ", encoding='utf-8')
    
    with open('library_pretty.xml', 'wb') as f:
        f.write(pretty_xml)
    
    print("  저장 완료: library_pretty.xml")
    
    # 6. 통계 생성
    print("\n6. 도서관 통계:")
    
    stats = {
        'total_books': 0,
        'available_books': 0,
        'sections': {},
        'books_by_year': {}
    }
    
    for section in root.findall('section'):
        section_name = section.get('name')
        book_count = len(section.findall('book'))
        stats['sections'][section_name] = book_count
        
        for book in section.findall('book'):
            stats['total_books'] += 1
            
            if book.find('available').text == 'true':
                stats['available_books'] += 1
            
            year = book.find('year').text
            if year not in stats['books_by_year']:
                stats['books_by_year'][year] = 0
            stats['books_by_year'][year] += 1
    
    print(f"  총 도서 수: {stats['total_books']}")
    print(f"  대출 가능 도서: {stats['available_books']}")
    print(f"  섹션별 도서 수:")
    for section, count in stats['sections'].items():
        print(f"    {section}: {count}권")
    
    # 통계를 XML로 저장
    stats_xml = ET.Element('library_stats')
    ET.SubElement(stats_xml, 'total_books').text = str(stats['total_books'])
    ET.SubElement(stats_xml, 'available_books').text = str(stats['available_books'])
    
    sections_elem = ET.SubElement(stats_xml, 'sections')
    for section, count in stats['sections'].items():
        section_elem = ET.SubElement(sections_elem, 'section')
        section_elem.set('name', section)
        section_elem.text = str(count)
    
    # 보기 좋게 포맷팅하여 저장
    stats_tree = ET.ElementTree(stats_xml)
    xml_str = ET.tostring(stats_xml, encoding='utf-8')
    parsed_stats = minidom.parseString(xml_str)
    pretty_stats = parsed_stats.toprettyxml(indent="  ", encoding='utf-8')
    
    with open('library_stats.xml', 'wb') as f:
        f.write(pretty_stats)
    
    print("  통계 저장 완료: library_stats.xml")

advanced_xml_manipulation()
```

## 네임스페이스로 XML 문서 파싱하기

### XML 네임스페이스 처리
```python
def xml_with_namespaces():
    """네임스페이스가 포함된 XML 처리"""
    
    print("XML 네임스페이스 처리")
    
    # 네임스페이스가 포함된 XML
    namespaced_xml = '''<?xml version="1.0" encoding="UTF-8"?>
<soap:Envelope 
    xmlns:soap="http://schemas.xmlsoap.org/soap/envelope/"
    xmlns:xsd="http://www.w3.org/2001/XMLSchema"
    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">
    <soap:Header>
        <auth:Authentication xmlns:auth="http://example.com/auth">
            <auth:Username>admin</auth:Username>
            <auth:Password>secret123</auth:Password>
        </auth:Authentication>
    </soap:Header>
    <soap:Body>
        <prod:ProductRequest xmlns:prod="http://example.com/products">
            <prod:Product>
                <prod:ID>P1001</prod:ID>
                <prod:Name>스마트폰 X</prod:Name>
                <prod:Category>전자제품</prod:Category>
                <prod:Price currency="USD">999.99</prod:Price>
                <prod:Specifications>
                    <spec:Display xmlns:spec="http://example.com/specs">
                        <spec:Size>6.5인치</spec:Size>
                        <spec:Resolution>1080x2400</spec:Resolution>
                    </spec:Display>
                    <spec:Camera xmlns:spec="http://example.com/specs">
                        <spec:Main>48MP</spec:Main>
                        <spec:Front>16MP</spec:Front>
                    </spec:Camera>
                </prod:Specifications>
            </prod:Product>
        </prod:ProductRequest>
    </soap:Body>
</soap:Envelope>'''
    
    with open('soap_message.xml', 'w', encoding='utf-8') as f:
        f.write(namespaced_xml)
    
    # 네임스페이스 맵 정의
    namespaces = {
        'soap': 'http://schemas.xmlsoap.org/soap/envelope/',
        'auth': 'http://example.com/auth',
        'prod': 'http://example.com/products',
        'spec': 'http://example.com/specs'
    }
    
    # ElementTree로 파싱
    tree = ET.parse('soap_message.xml')
    root = tree.getroot()
    
    print("\n1. 네임스페이스로 요소 찾기:")
    
    # 네임스페이스 접두사를 사용한 검색
    for ns_prefix, ns_uri in namespaces.items():
        # 네임스페이스 등록
        ET.register_namespace(ns_prefix, ns_uri)
    
    # 네임스페이스를 포함한 요소 찾기
    auth_elem = root.find('.//{http://example.com/auth}Authentication')
    if auth_elem:
        username = auth_elem.find('{http://example.com/auth}Username').text
        password = auth_elem.find('{http://example.com/auth}Password').text
        print(f"  인증 정보: {username} / {password}")
    
    # 2. 네임스페이스 맵을 사용한 검색
    print("\n2. 네임스페이스 맵 사용:")
    
    # find() 메서드에 네임스페이스 맵 전달
    product_request = root.find('.//prod:ProductRequest', namespaces)
    if product_request:
        product = product_request.find('prod:Product', namespaces)
        if product:
            product_id = product.find('prod:ID', namespaces).text
            product_name = product.find('prod:Name', namespaces).text
            print(f"  제품 정보: {product_name} (ID: {product_id})")
            
            # 가격 정보
            price_elem = product.find('prod:Price', namespaces)
            price = price_elem.text
            currency = price_elem.get('currency')
            print(f"  가격: {price} {currency}")
    
    # 3. 모든 네임스페이스 요소 찾기
    print("\n3. 모든 네임스페이스 요소:")
    
    # 네임스페이스 URI로 모든 요소 찾기
    prod_ns = namespaces['prod']
    product_elements = root.findall(f'.//{{{prod_ns}}}*')
    print(f"  '{prod_ns}' 네임스페이스 요소 수: {len(product_elements)}")
    
    for elem in product_elements[:3]:  # 처음 3개만 출력
        print(f"    - {elem.tag}: {elem.text or ''}")
    
    # 4. XPath와 네임스페이스
    print("\n4. XPath와 네임스페이스:")
    
    # lxml이 설치된 경우 XPath 사용
    try:
        from lxml import etree
        
        # lxml로 파싱
        lxml_tree = etree.parse('soap_message.xml')
        
        # 네임스페이스 맵 정의
        nsmap = {
            'soap': 'http://schemas.xmlsoap.org/soap/envelope/',
            'auth': 'http://example.com/auth',
            'prod': 'http://example.com/products',
            'spec': 'http://example.com/specs'
        }
        
        # XPath로 요소 찾기
        display_size = lxml_tree.xpath('//spec:Display/spec:Size', namespaces=nsmap)
        if display_size:
            print(f"  디스플레이 크기: {display_size[0].text}")
        
        camera_specs = lxml_tree.xpath('//spec:Camera/*', namespaces=nsmap)
        print(f"  카메라 사양 ({len(camera_specs)}개):")
        for spec in camera_specs:
            print(f"    - {spec.tag.split('}')[1]}: {spec.text}")
            
    except ImportError:
        print("  lxml이 설치되지 않았습니다. 고급 XPath 기능을 사용할 수 없습니다.")
    
    # 5. 네임스페이스가 포함된 XML 생성
    print("\n5. 네임스페이스 XML 생성:")
    
    # 루트 요소에 네임스페이스 선언
    root_ns = ET.Element('{http://example.com/data}DataPackage')
    root_ns.set('xmlns:xsi', 'http://www.w3.org/2001/XMLSchema-instance')
    root_ns.set('xmlns:xsd', 'http://www.w3.org/2001/XMLSchema')
    
    # 네임스페이스를 사용한 하위 요소
    header = ET.SubElement(root_ns, '{http://example.com/data}Header')
    ET.SubElement(header, '{http://example.com/data}Version').text = '1.0'
    ET.SubElement(header, '{http://example.com/data}Created').text = '2024-01-15'
    
    content = ET.SubElement(root_ns, '{http://example.com/data}Content')
    item = ET.SubElement(content, '{http://example.com/data}Item')
    item.set('{http://example.com/data}ID', 'I001')
    ET.SubElement(item, '{http://example.com/data}Name').text = '테스트 아이템'
    
    # XML로 저장
    tree_ns = ET.ElementTree(root_ns)
    
    # 네임스페이스 등록
    ET.register_namespace('data', 'http://example.com/data')
    ET.register_namespace('xsi', 'http://www.w3.org/2001/XMLSchema-instance')
    ET.register_namespace('xsd', 'http://www.w3.org/2001/XMLSchema')
    
    tree_ns.write('namespaced_output.xml', 
                  encoding='utf-8', 
                  xml_declaration=True,
                  method='xml')
    
    print("  네임스페이스 XML 생성 완료: namespaced_output.xml")
    
    # 6. 네임스페이스 변환
    print("\n6. 네임스페이스 변환:")
    
    # QName 객체 사용
    from xml.etree.ElementTree import QName
    
    # QName으로 정규화된 이름 생성
    auth_ns = 'http://example.com/auth'
    qname_username = QName(auth_ns, 'Username')
    qname_password = QName(auth_ns, 'Password')
    
    print(f"  QName 예제:")
    print(f"    Username: {qname_username}")
    print(f"    Password: {qname_password}")
    
    # 네임스페이스 제거 (간단한 처리 시)
    def strip_namespace(tag):
        """태그에서 네임스페이스 제거"""
        if '}' in tag:
            return tag.split('}', 1)[1]
        return tag
    
    # 네임스페이스 제거 예제
    for elem in root.iter():
        simple_tag = strip_namespace(elem.tag)
        if simple_tag != elem.tag:
            print(f"    {elem.tag} -> {simple_tag}")

xml_with_namespaces()
```

## 결론

Python은 다양한 데이터 포맷을 효과적으로 처리할 수 있는 풍부한 도구들을 제공합니다. CSV 처리는 `csv` 모듈을 통해 간단한 구조화된 데이터를 다루기에 적합하며, `pandas`를 함께 사용하면 더욱 강력한 데이터 분석이 가능합니다. 특히 대용량 CSV 파일을 다룰 때는 스트리밍 방식의 처리와 적절한 청크 사이즈 설정이 중요합니다.

JSON 데이터는 `json` 모듈을 통해 직렬화와 역직렬화가 용이하며, 커스텀 인코더/디코더를 구현하면 복잡한 객체도 쉽게 저장하고 복원할 수 있습니다. JSON Lines 형식은 대용량 데이터를 효율적으로 처리하는 데 적합하며, JSON 스키마를 이용한 데이터 검증은 데이터 무결성을 보장하는 중요한 도구입니다.

XML 처리는 `xml.etree.ElementTree` 모듈이 기본적인 작업에 적합하며, 대용량 파일의 경우 `xml.sax`를 통한 스트리밍 처리가 메모리 효율적입니다. 네임스페이스를 포함한 복잡한 XML 문서는 적절한 네임스페이스 맵을 정의하여 처리해야 합니다. `lxml` 라이브러리는 더 풍부한 XPath 기능과 성능 향상을 제공합니다.

딕셔너리와 XML 간의 변환은 데이터 교환과 저장에 유용하며, 재귀적인 함수 구조를 통해 복잡한 중첩 데이터도 처리할 수 있습니다. XML 문서의 조작(생성, 수정, 삭제)은 ElementTree API를 통해 직관적으로 수행할 수 있습니다.

각 데이터 포맷은 고유한 장단점과 적절한 사용 사례를 가지고 있습니다. CSV는 단순성과 보편성, JSON은 가독성과 웹 친화성, XML은 구조화와 검증 기능에 강점이 있습니다. 프로젝트의 요구사항과 데이터 특성에 맞는 적절한 포맷과 처리 방식을 선택하는 것이 중요합니다.

실제 애플리케이션에서는 이러한 포맷들을 혼합하여 사용하는 경우가 많으며, 데이터 파이프라인을 구성할 때는 각 단계에서 적절한 포맷 변환과 처리 로직을 구현해야 합니다. 성능이 중요한 경우 메모리 사용량, 처리 속도, 디스크 I/O를 고려한 최적화가 필요합니다.