---
layout: post
title: DB 심화 - 대기 이벤트별 발생 원인
date: 2025-10-24 19:25:23 +0900
category: DB 심화
---
# Oracle 대기 이벤트별 발생 원인과 실행 계획 분석

## 실습 환경 구축: 샘플 스키마와 데이터 준비

성능 문제 분석을 위한 실제적인 실습 환경을 먼저 구성해 보겠습니다.

```sql
-- 기존 테이블 정리
DROP TABLE orders CASCADE CONSTRAINTS PURGE;
DROP TABLE customers CASCADE CONSTRAINTS PURGE;

-- 고객 테이블 생성
CREATE TABLE customers (
    id      NUMBER        PRIMARY KEY,
    region  VARCHAR2(10)  NOT NULL,
    grade   NUMBER        NOT NULL,
    name    VARCHAR2(100) NOT NULL,
    email   VARCHAR2(150),
    created_date DATE     DEFAULT SYSDATE
);

-- 주문 테이블 생성  
CREATE TABLE orders (
    order_id     NUMBER        PRIMARY KEY,
    customer_id  NUMBER        NOT NULL,
    order_date   DATE          NOT NULL,
    amount       NUMBER(10,2)  NOT NULL,
    status       VARCHAR2(20)  DEFAULT 'PENDING',
    priority     NUMBER(1)     DEFAULT 3,
    CONSTRAINT fk_orders_customer FOREIGN KEY (customer_id) REFERENCES customers(id)
);

-- 인덱스 생성
CREATE INDEX ix_orders_cust_date ON orders(customer_id, order_date);
CREATE INDEX ix_orders_date ON orders(order_date);
CREATE INDEX ix_orders_status ON orders(status);
CREATE INDEX ix_customers_region_grade ON customers(region, grade);
CREATE INDEX ix_customers_region ON customers(region);

-- 샘플 데이터 생성 (실제적 데이터 분포를 모방)
DECLARE
    v_batch_size CONSTANT NUMBER := 5000;
BEGIN
    -- 고객 데이터: 100,000건
    FOR i IN 1..100000 LOOP
        INSERT INTO customers (id, region, grade, name, email) VALUES (
            i,
            CASE 
                WHEN i <= 30000 THEN 'APAC'
                WHEN i <= 60000 THEN 'EMEA'
                WHEN i <= 90000 THEN 'AMER'
                ELSE 'OTHER'
            END,
            MOD(i, 5) + 1,  -- 1-5 등급
            'Customer_' || i,
            'customer' || i || '@example.com'
        );
        
        -- 배치 커밋
        IF MOD(i, v_batch_size) = 0 THEN
            COMMIT;
            DBMS_OUTPUT.PUT_LINE('Inserted ' || i || ' customers');
        END IF;
    END LOOP;
    COMMIT;
    
    -- 주문 데이터: 2,000,000건 (2023-2024년 데이터)
    FOR i IN 1..2000000 LOOP
        INSERT INTO orders (order_id, customer_id, order_date, amount, status, priority) VALUES (
            i,
            MOD(i, 100000) + 1,  -- 고객 ID 분포
            DATE '2023-01-01' + MOD(i, 730),  -- 2년치 데이터
            ROUND(DBMS_RANDOM.VALUE(10, 5000), 2),
            CASE MOD(i, 10)
                WHEN 0 THEN 'CANCELLED'
                WHEN 1 THEN 'COMPLETED'
                WHEN 2 THEN 'PENDING'
                WHEN 3 THEN 'PROCESSING'
                ELSE 'SHIPPED'
            END,
            MOD(i, 3) + 1  -- 1-3 우선순위
        );
        
        -- 배치 커밋
        IF MOD(i, v_batch_size) = 0 THEN
            COMMIT;
            IF MOD(i, 100000) = 0 THEN
                DBMS_OUTPUT.PUT_LINE('Inserted ' || i || ' orders');
            END IF;
        END IF;
    END LOOP;
    COMMIT;
END;
/

-- 통계 수집 (중요: 실제 환경과 유사한 통계 생성)
BEGIN
    DBMS_STATS.GATHER_TABLE_STATS(
        ownname     => USER,
        tabname     => 'CUSTOMERS',
        estimate_percent => DBMS_STATS.AUTO_SAMPLE_SIZE,
        method_opt  => 'FOR ALL COLUMNS SIZE SKEWONLY',
        cascade     => TRUE,
        degree      => DBMS_STATS.AUTO_DEGREE
    );
    
    DBMS_STATS.GATHER_TABLE_STATS(
        ownname     => USER,
        tabname     => 'ORDERS',
        estimate_percent => DBMS_STATS.AUTO_SAMPLE_SIZE,
        method_opt  => 'FOR ALL COLUMNS SIZE SKEWONLY FOR COLUMNS SIZE 254 order_date status',
        cascade     => TRUE,
        degree      => DBMS_STATS.AUTO_DEGREE
    );
    
    DBMS_OUTPUT.PUT_LINE('통계 수집 완료');
END;
/

-- 데이터 분포 확인
SELECT '고객 테이블' AS table_name, COUNT(*) AS row_count FROM customers
UNION ALL
SELECT '주문 테이블' AS table_name, COUNT(*) AS row_count FROM orders;

SELECT region, COUNT(*) AS customer_count, 
       ROUND(COUNT(*) * 100.0 / SUM(COUNT(*)) OVER (), 2) AS percentage
FROM customers
GROUP BY region
ORDER BY customer_count DESC;

SELECT status, COUNT(*) AS order_count,
       ROUND(COUNT(*) * 100.0 / SUM(COUNT(*)) OVER (), 2) AS percentage
FROM orders
GROUP BY status
ORDER BY order_count DESC;
```

## 대기 이벤트와 실행 계획 분석의 기본 프레임워크

성능 문제 분석은 체계적인 접근이 필요합니다. 다음은 실전에서 검증된 분석 프레임워크입니다:

```sql
-- 1단계: 문제 시간대 설정 및 ASH 데이터 수집 준비
-- 보통 10-15분 구간으로 문제 발생 시간대를 설정합니다
VARIABLE analysis_start TIMESTAMP;
VARIABLE analysis_end TIMESTAMP;

BEGIN
    :analysis_start := SYSTIMESTAMP - INTERVAL '15' MINUTE;
    :analysis_end := SYSTIMESTAMP;
    DBMS_OUTPUT.PUT_LINE('분석 시간대: ' || :analysis_start || ' ~ ' || :analysis_end);
END;
/

-- 2단계: 상위 대기 이벤트 식별
WITH wait_analysis AS (
    SELECT 
        wait_class,
        event,
        COUNT(*) AS sample_count,
        ROUND(COUNT(*) * 100.0 / SUM(COUNT(*)) OVER (), 2) AS percentage,
        ROUND(AVG(time_waited) / 1000, 2) AS avg_wait_ms
    FROM v$active_session_history
    WHERE sample_time BETWEEN :analysis_start AND :analysis_end
      AND session_type = 'FOREGROUND'
      AND wait_class != 'Idle'
    GROUP BY wait_class, event
)
SELECT wait_class, event, sample_count, percentage, avg_wait_ms
FROM wait_analysis
WHERE sample_count > 10  -- 의미 있는 샘플 수만
ORDER BY sample_count DESC
FETCH FIRST 10 ROWS ONLY;

-- 3단계: 문제 이벤트와 연관된 SQL 식별
WITH sql_wait_correlation AS (
    SELECT 
        ash.sql_id,
        ash.event,
        COUNT(*) AS wait_samples,
        MIN(s.sql_text) AS sql_text_preview,
        SUM(CASE WHEN ash.session_state = 'ON CPU' THEN 1 ELSE 0 END) AS cpu_samples
    FROM v$active_session_history ash
    LEFT JOIN v$sql s ON ash.sql_id = s.sql_id
    WHERE ash.sample_time BETWEEN :analysis_start AND :analysis_end
      AND ash.session_type = 'FOREGROUND'
      AND ash.wait_class != 'Idle'
      AND ash.sql_id IS NOT NULL
    GROUP BY ash.sql_id, ash.event
    HAVING COUNT(*) > 5  -- 충분한 샘플이 있는 SQL만
)
SELECT 
    sql_id,
    event,
    wait_samples,
    cpu_samples,
    ROUND(wait_samples * 100.0 / (wait_samples + cpu_samples), 2) AS wait_ratio,
    SUBSTR(sql_text_preview, 1, 100) || '...' AS sql_preview
FROM sql_wait_correlation
ORDER BY wait_samples DESC
FETCH FIRST 15 ROWS ONLY;

-- 4단계: 선택된 SQL의 실행 계획 분석
-- SQL_ID를 기반으로 실제 실행 통계가 포함된 실행 계획 확인
SELECT * FROM TABLE(DBMS_XPLAN.DISPLAY_CURSOR(
    sql_id        => '&target_sql_id',  -- 위에서 찾은 SQL_ID 입력
    cursor_child_no => NULL,
    format        => 'ALLSTATS LAST ADVANCED +PEEKED_BINDS +PREDICATE +PROJECTION'
));

-- 5단계: 실행 계획 라인별 ASH 샘플 매핑
-- 특정 SQL의 어떤 실행 계획 라인에서 대기가 발생했는지 확인
SELECT 
    ash.sql_plan_line_id,
    ash.sql_plan_operation,
    ash.sql_plan_options,
    ash.event,
    COUNT(*) AS wait_samples,
    ROUND(AVG(ash.time_waited) / 1000, 2) AS avg_wait_ms_per_sample
FROM v$active_session_history ash
WHERE ash.sql_id = '&target_sql_id'
  AND ash.sample_time BETWEEN :analysis_start AND :analysis_end
  AND ash.session_state = 'WAITING'
  AND ash.sql_plan_line_id IS NOT NULL
GROUP BY ash.sql_plan_line_id, ash.sql_plan_operation, ash.sql_plan_options, ash.event
ORDER BY wait_samples DESC;
```

---

## 주요 대기 이벤트별 심층 분석 패턴

### 1. `db file sequential read` (인덱스 기반 랜덤 액세스)

이 대기 이벤트는 주로 인덱스를 통해 특정 행을 찾은 후, 해당 ROWID로 테이블 블록을 접근할 때 발생합니다.

**실전 시나리오: 고객별 최근 주문 조회가 느린 경우**
```sql
-- 문제가 될 수 있는 쿼리 예시
SELECT /*+ MONITOR */ 
       c.id AS customer_id,
       c.name,
       c.region,
       o.order_id,
       o.order_date,
       o.amount,
       o.status
FROM   customers c
JOIN   orders o ON o.customer_id = c.id
WHERE  c.region = 'APAC'
  AND  c.grade = 1
  AND  o.order_date >= DATE '2024-01-01'
ORDER BY o.order_date DESC;

-- 실행 계획 분석
SELECT * FROM TABLE(DBMS_XPLAN.DISPLAY_CURSOR(NULL, NULL, 'ALLSTATS LAST'));

-- 문제 진단:
-- 1. ix_customers_region_grade 인덱스로 APAC, grade=1 고객 필터링
-- 2. 각 고객에 대해 ix_orders_cust_date 인덱스로 주문 검색
-- 3. ROWID로 orders 테이블 접근 (여기서 순차적 읽기 발생)
-- 4. 만약 APAC 지역 grade=1 고객이 10,000명이고, 각자 평균 20건 주문이 있다면
--    최대 200,000번의 db file sequential read 발생 가능

-- 개선 방안 1: 커버링 인덱스 활용
CREATE INDEX ix_orders_cust_date_status_amt ON orders(customer_id, order_date, status, amount);

-- 개선 방안 2: 배치 처리로 랜덤 액세스 최소화
-- PL/SQL 루프에서 고객 ID를 배치로 수집한 후, WHERE customer_id IN (...) 방식으로 처리
```

**고급 분석: 클러스터링 팩터 확인**
```sql
-- 인덱스의 클러스터링 팩터 분석
SELECT 
    index_name,
    clustering_factor,
    leaf_blocks,
    num_rows,
    ROUND(clustering_factor * 100.0 / NULLIF(num_rows, 0), 2) AS cf_ratio
FROM user_indexes
WHERE table_name = 'ORDERS'
ORDER BY clustering_factor DESC;

-- 클러스터링 팩터가 나쁜 인덱스에 대한 대응:
-- 1. 테이블 재구성 (같은 순서로 정렬하여 데이터 재배치)
-- 2. 인덱스 온리 스캔 가능하도록 컬럼 추가
-- 3. 파티셔닝 도입
```

### 2. `direct path read temp` / `direct path write temp` (정렬/해시 작업의 TEMP 사용)

대용량 정렬이나 해시 조인 작업이 PGA 메모리를 초과할 때 발생합니다.

**실전 시나리오: 지역별 월간 매출 집계가 느린 경우**
```sql
-- 문제 쿼리
SELECT /*+ MONITOR GATHER_PLAN_STATISTICS */
       c.region,
       TO_CHAR(o.order_date, 'YYYY-MM') AS month,
       COUNT(*) AS order_count,
       SUM(o.amount) AS total_amount,
       AVG(o.amount) AS avg_amount
FROM   customers c
JOIN   orders o ON o.customer_id = c.id
WHERE  o.order_date BETWEEN DATE '2024-01-01' AND DATE '2024-06-30'
  AND  o.status = 'COMPLETED'
GROUP BY c.region, TO_CHAR(o.order_date, 'YYYY-MM')
ORDER BY c.region, month;

-- 실행 계획 분석
SELECT * FROM TABLE(DBMS_XPLAN.DISPLAY_CURSOR(NULL, NULL, 'ALLSTATS LAST +MEMSTATS'));

-- 문제 진단:
-- 1. 6개월 동안의 완료된 주문은 약 100,000건 (전체의 5%)
-- 2. 고객 테이블과 해시 조인 수행
-- 3. 지역, 월별로 GROUP BY 정렬 수행
-- 4. 만약 work_area_size_policy=auto이고 PGA_AGGREGATE_TARGET가 부족하면
--    디스크 TEMP 영역으로 스필 발생

-- 개선 방안 1: 사전 집계 테이블 도입
CREATE TABLE monthly_sales_summary (
    region      VARCHAR2(10),
    sale_month  VARCHAR2(7),
    order_count NUMBER,
    total_amount NUMBER(15,2),
    avg_amount  NUMBER(10,2),
    last_updated DATE,
    PRIMARY KEY (region, sale_month)
);

-- 배치 작업으로 요약 테이블 유지
BEGIN
    MERGE INTO monthly_sales_summary t
    USING (
        SELECT c.region,
               TO_CHAR(o.order_date, 'YYYY-MM') AS sale_month,
               COUNT(*) AS order_count,
               SUM(o.amount) AS total_amount,
               AVG(o.amount) AS avg_amount
        FROM   customers c
        JOIN   orders o ON o.customer_id = c.id
        WHERE  o.order_date >= TRUNC(SYSDATE, 'MM') - INTERVAL '3' MONTH
          AND  o.status = 'COMPLETED'
        GROUP BY c.region, TO_CHAR(o.order_date, 'YYYY-MM')
    ) s
    ON (t.region = s.region AND t.sale_month = s.sale_month)
    WHEN MATCHED THEN UPDATE SET
        t.order_count = s.order_count,
        t.total_amount = s.total_amount,
        t.avg_amount = s.avg_amount,
        t.last_updated = SYSDATE
    WHEN NOT MATCHED THEN INSERT 
        (region, sale_month, order_count, total_amount, avg_amount, last_updated)
    VALUES
        (s.region, s.sale_month, s.order_count, s.total_amount, s.avg_amount, SYSDATE);
    COMMIT;
END;
/

-- 개선 방안 2: 쿼리 최적화
SELECT /*+ LEADING(c) USE_HASH(c) NO_USE_MERGE(c) */
       c.region,
       TO_CHAR(o.order_date, 'YYYY-MM') AS month,
       COUNT(*) AS order_count,
       SUM(o.amount) AS total_amount
FROM   customers c
JOIN   orders o ON o.customer_id = c.id
WHERE  o.order_date >= DATE '2024-01-01'
  AND  o.order_date < DATE '2024-07-01'
  AND  o.status = 'COMPLETED'
  AND  c.region IN ('APAC', 'EMEA', 'AMER')  -- 불필요한 지역 제외
GROUP BY c.region, TO_CHAR(o.order_date, 'YYYY-MM')
HAVING COUNT(*) > 10  -- 의미 없는 소량 데이터 제외
ORDER BY c.region, month;
```

### 3. `enq: TX - row lock contention` (행 잠금 경합)

동시에 같은 데이터를 수정하려는 트랜잭션 간 충돌에서 발생합니다.

**실전 시나리오: 재고 동시 업데이트 경합**
```sql
-- 문제 시나리오 재현을 위한 테이블 추가
CREATE TABLE product_inventory (
    product_id    NUMBER PRIMARY KEY,
    product_name  VARCHAR2(100),
    quantity      NUMBER NOT NULL,
    last_updated  DATE
);

INSERT INTO product_inventory 
SELECT LEVEL, 'Product_' || LEVEL, 1000, SYSDATE
FROM dual CONNECT BY LEVEL <= 1000;
COMMIT;

-- 경합을 유발하는 프로시저 (여러 세션에서 동시 실행)
CREATE OR REPLACE PROCEDURE update_inventory_concurrent IS
    v_product_id NUMBER;
    v_quantity   NUMBER;
    v_retry_count NUMBER := 0;
BEGIN
    -- 랜덤한 제품 선택
    SELECT product_id INTO v_product_id
    FROM (SELECT product_id FROM product_inventory ORDER BY DBMS_RANDOM.VALUE)
    WHERE ROWNUM = 1;
    
    LOOP
        BEGIN
            -- 배타적 잠금 시도
            SELECT quantity INTO v_quantity
            FROM product_inventory
            WHERE product_id = v_product_id
            FOR UPDATE NOWAIT;
            
            -- 재고 업데이트
            UPDATE product_inventory
            SET quantity = quantity - 1,
                last_updated = SYSDATE
            WHERE product_id = v_product_id;
            
            COMMIT;
            EXIT;  -- 성공 시 루프 종료
            
        EXCEPTION
            WHEN OTHERS THEN
                v_retry_count := v_retry_count + 1;
                IF v_retry_count > 5 THEN
                    RAISE;
                END IF;
                DBMS_LOCK.SLEEP(0.1 * v_retry_count);  -- 지수 백오프
        END;
    END LOOP;
END update_inventory_concurrent;
/

-- 경합 모니터링
SELECT 
    s.sid,
    s.serial#,
    s.username,
    s.event,
    s.wait_time,
    s.seconds_in_wait,
    s.blocking_session,
    s.sql_id,
    SUBSTR(s.program, 1, 30) AS program
FROM v$session s
WHERE s.event LIKE 'enq: TX%'
  AND s.status = 'ACTIVE'
ORDER BY s.seconds_in_wait DESC;

-- 해결책 1: 큐 테이블을 통한 순차적 처리
CREATE TABLE inventory_update_queue (
    queue_id      NUMBER PRIMARY KEY,
    product_id    NUMBER NOT NULL,
    quantity_delta NUMBER NOT NULL,
    status        VARCHAR2(20) DEFAULT 'PENDING',
    created_date  DATE DEFAULT SYSDATE,
    processed_date DATE
);

CREATE SEQUENCE inv_queue_seq;

-- 배치 프로세서
CREATE OR REPLACE PROCEDURE process_inventory_updates IS
    CURSOR c_pending IS
        SELECT queue_id, product_id, quantity_delta
        FROM inventory_update_queue
        WHERE status = 'PENDING'
        ORDER BY created_date
        FOR UPDATE SKIP LOCKED;  -- 교착 상태 방지
BEGIN
    FOR rec IN c_pending LOOP
        BEGIN
            UPDATE product_inventory
            SET quantity = quantity + rec.quantity_delta,
                last_updated = SYSDATE
            WHERE product_id = rec.product_id;
            
            UPDATE inventory_update_queue
            SET status = 'PROCESSED',
                processed_date = SYSDATE
            WHERE queue_id = rec.queue_id;
            
            COMMIT;
            
        EXCEPTION
            WHEN OTHERS THEN
                UPDATE inventory_update_queue
                SET status = 'ERROR'
                WHERE queue_id = rec.queue_id;
                COMMIT;
                RAISE;
        END;
    END LOOP;
END process_inventory_updates;
/

-- 해결책 2: 낙관적 동시성 제어
ALTER TABLE product_inventory ADD (
    version_number NUMBER DEFAULT 0 NOT NULL
);

CREATE OR REPLACE PROCEDURE update_inventory_optimistic (
    p_product_id  NUMBER,
    p_quantity_delta NUMBER
) IS
    l_old_version NUMBER;
    l_old_quantity NUMBER;
    l_updated_rows NUMBER;
    l_retry_count NUMBER := 0;
BEGIN
    LOOP
        -- 현재 값과 버전 읽기
        SELECT quantity, version_number 
        INTO l_old_quantity, l_old_version
        FROM product_inventory
        WHERE product_id = p_product_id;
        
        -- 버전 검증과 함께 업데이트
        UPDATE product_inventory
        SET quantity = l_old_quantity + p_quantity_delta,
            version_number = version_number + 1,
            last_updated = SYSDATE
        WHERE product_id = p_product_id
          AND version_number = l_old_version;
        
        l_updated_rows := SQL%ROWCOUNT;
        
        IF l_updated_rows = 1 THEN
            COMMIT;
            RETURN;  -- 성공
        ELSE
            l_retry_count := l_retry_count + 1;
            IF l_retry_count > 3 THEN
                RAISE_APPLICATION_ERROR(-20001, 
                    '재시도 횟수 초과: 다른 트랜잭션이 동시에 수정 중입니다.');
            END IF;
            DBMS_LOCK.SLEEP(0.05 * POWER(2, l_retry_count));  -- 지수 백오프
        END IF;
    END LOOP;
END update_inventory_optimistic;
/
```

### 4. `log file sync` (커밋 대기 지연)

트랜잭션 커밋 시 LGWR 프로세스가 리두 로그를 디스크에 기록하기를 기다리는 대기입니다.

**진단 및 최적화 방법:**
```sql
-- log file sync 대기 분석
SELECT 
    event,
    total_waits,
    time_waited_micro / 1000000 AS time_waited_seconds,
    ROUND(time_waited_micro / NULLIF(total_waits, 0) / 1000, 2) AS avg_wait_ms,
    wait_class
FROM v$system_event
WHERE event = 'log file sync'
   OR event = 'log file parallel write';

-- 세션별 커밋 패턴 분석
SELECT 
    s.sid,
    s.serial#,
    s.username,
    s.program,
    st1.value AS commits,
    st2.value AS rollbacks,
    ROUND(st1.value / NULLIF(st1.value + st2.value, 0) * 100, 2) AS commit_ratio
FROM v$session s
JOIN v$sesstat st1 ON s.sid = st1.sid AND st1.statistic# = 
    (SELECT statistic# FROM v$statname WHERE name = 'user commits')
JOIN v$sesstat st2 ON s.sid = st2.sid AND st2.statistic# = 
    (SELECT statistic# FROM v$statname WHERE name = 'user rollbacks')
WHERE s.type = 'USER'
  AND s.status = 'ACTIVE'
  AND (st1.value + st2.value) > 10  -- 활동이 있는 세션만
ORDER BY st1.value DESC;

-- 배치 커밋 최적화 예제
CREATE OR REPLACE PROCEDURE process_orders_batch (
    p_batch_size NUMBER DEFAULT 1000
) IS
    TYPE order_id_tab IS TABLE OF orders.order_id%TYPE;
    l_order_ids order_id_tab;
    l_processed NUMBER := 0;
    l_total_processed NUMBER := 0;
BEGIN
    -- 처리 대상 주문 ID 수집
    SELECT order_id
    BULK COLLECT INTO l_order_ids
    FROM orders
    WHERE status = 'PENDING'
      AND order_date < SYSDATE - 1
    ORDER BY priority, order_date;
    
    -- 배치 처리
    FOR i IN 1..l_order_ids.COUNT LOOP
        -- 개별 주문 처리
        UPDATE orders
        SET status = 'PROCESSING',
            last_updated = SYSDATE
        WHERE order_id = l_order_ids(i);
        
        l_processed := l_processed + 1;
        l_total_processed := l_total_processed + 1;
        
        -- 배치 크기에 도달하면 커밋
        IF l_processed >= p_batch_size OR i = l_order_ids.COUNT THEN
            COMMIT;
            l_processed := 0;
            
            -- 진행 상황 로깅
            IF MOD(l_total_processed, 10000) = 0 THEN
                DBMS_APPLICATION_INFO.SET_MODULE(
                    module_name => 'ORDER_PROCESSING',
                    action_name => 'Processed ' || l_total_processed || ' orders'
                );
            END IF;
        END IF;
    END LOOP;
    
    DBMS_OUTPUT.PUT_LINE('Total orders processed: ' || l_total_processed);
    
EXCEPTION
    WHEN OTHERS THEN
        ROLLBACK;
        RAISE;
END process_orders_batch;
/

-- 리두 로그 I/O 성능 최적화 체크리스트
BEGIN
    DBMS_OUTPUT.PUT_LINE('=== Redo Log Configuration Check ===');
    
    -- 로그 버퍼 크기
    FOR r IN (SELECT name, value FROM v$parameter WHERE name = 'log_buffer')
    LOOP
        DBMS_OUTPUT.PUT_LINE('log_buffer: ' || r.value || ' bytes');
        DBMS_OUTPUT.PUT_LINE('Recommended: 적어도 8MB 이상, 트랜잭션 볼륨에 따라 조정');
    END LOOP;
    
    -- 로그 파일 크기 및 그룹
    FOR r IN (
        SELECT group#, bytes/1024/1024 AS size_mb, members, status
        FROM v$log
        ORDER BY group#
    )
    LOOP
        DBMS_OUTPUT.PUT_LINE('Log Group ' || r.group# || 
                            ': ' || r.size_mb || 'MB, ' || 
                            r.members || ' members, Status: ' || r.status);
    END LOOP;
    
    -- 로그 스위치 빈도 확인
    FOR r IN (
        SELECT TO_CHAR(first_time, 'HH24') AS hour,
               COUNT(*) AS switches_per_hour
        FROM v$log_history
        WHERE first_time > SYSDATE - 1
        GROUP BY TO_CHAR(first_time, 'HH24')
        ORDER BY hour
    )
    LOOP
        DBMS_OUTPUT.PUT_LINE('Hour ' || r.hour || ': ' || 
                            r.switches_per_hour || ' log switches');
        IF r.switches_per_hour > 20 THEN
            DBMS_OUTPUT.PUT_LINE('  Warning: Too frequent log switches - consider increasing log file size');
        END IF;
    END LOOP;
END;
/
```

### 5. `gc buffer busy` / `gc cr block busy` (RAC 글로벌 캐시 경합)

RAC 환경에서 인스턴스 간 데이터 블록 공유 시 발생하는 경합입니다.

```sql
-- RAC 글로벌 캐시 대기 분석
SELECT 
    inst_id,
    event,
    total_waits,
    time_waited_micro / 1000000 AS time_waited_seconds,
    ROUND(time_waited_micro / NULLIF(total_waits, 0) / 1000, 2) AS avg_wait_ms
FROM gv$system_event
WHERE event LIKE 'gc%'
   AND wait_class != 'Idle'
ORDER BY time_waited_micro DESC;

-- 핫 오브젝트 식별 (RAC 전체)
SELECT 
    obj.owner,
    obj.object_name,
    obj.object_type,
    bh.inst_id,
    COUNT(*) AS gc_wait_samples,
    MIN(ash.sample_time) AS first_sample,
    MAX(ash.sample_time) AS last_sample
FROM gv$active_session_history ash
JOIN dba_objects obj ON ash.current_obj# = obj.object_id
JOIN gv$buffer_header bh ON ash.current_file# = bh.file#
                       AND ash.current_block# = bh.block#
                       AND ash.inst_id = bh.inst_id
WHERE ash.event LIKE 'gc%'
  AND ash.sample_time > SYSDATE - INTERVAL '30' MINUTE
  AND ash.session_type = 'FOREGROUND'
GROUP BY obj.owner, obj.object_name, obj.object_type, bh.inst_id
HAVING COUNT(*) > 10
ORDER BY gc_wait_samples DESC;

-- RAC 최적화 전략 구현
-- 1. 서비스 기반 데이터 분리
BEGIN
    -- APAC 관련 작업은 인스턴스 1로 라우팅
    DBMS_SERVICE.CREATE_SERVICE(
        service_name => 'APAC_SERVICE',
        network_name => 'apac_svc'
    );
    
    DBMS_SERVICE.START_SERVICE('APAC_SERVICE', 'inst1');
    
    -- EMEA 관련 작업은 인스턴스 2로 라우팅
    DBMS_SERVICE.CREATE_SERVICE(
        service_name => 'EMEA_SERVICE',
        network_name => 'emea_svc'
    );
    
    DBMS_SERVICE.START_SERVICE('EMEA_SERVICE', 'inst2');
END;
/

-- 2. 시퀀스 최적화
CREATE SEQUENCE order_id_seq
    START WITH 1000000
    INCREMENT BY 1
    CACHE 1000
    NOORDER;  -- RAC 환경에서는 NOORDER 권장

-- 3. 애플리케이션 파티셔닝
CREATE TABLE orders_apac
PARTITION BY RANGE (order_date) (
    PARTITION p_2023_q1 VALUES LESS THAN (DATE '2023-04-01'),
    PARTITION p_2023_q2 VALUES LESS THAN (DATE '2023-07-01'),
    PARTITION p_2023_q3 VALUES LESS THAN (DATE '2023-10-01'),
    PARTITION p_2023_q4 VALUES LESS THAN (DATE '2024-01-01'),
    PARTITION p_2024_q1 VALUES LESS THAN (DATE '2024-04-01')
)
AS SELECT * FROM orders o
WHERE EXISTS (
    SELECT 1 FROM customers c
    WHERE c.id = o.customer_id
      AND c.region = 'APAC'
);

-- 4. 인스턴스 어피니티 설정
CREATE OR REPLACE PACKAGE instance_affinity AS
    FUNCTION get_preferred_instance (
        p_customer_id NUMBER
    ) RETURN NUMBER;
    
    PROCEDURE route_to_preferred_instance (
        p_customer_id NUMBER
    );
END instance_affinity;
/

CREATE OR REPLACE PACKAGE BODY instance_affinity AS
    
    FUNCTION get_preferred_instance (
        p_customer_id NUMBER
    ) RETURN NUMBER IS
        l_region VARCHAR2(10);
        l_instance NUMBER;
    BEGIN
        -- 고객 지역에 기반한 인스턴스 매핑
        SELECT region INTO l_region
        FROM customers
        WHERE id = p_customer_id;
        
        CASE l_region
            WHEN 'APAC' THEN l_instance := 1;
            WHEN 'EMEA' THEN l_instance := 2;
            WHEN 'AMER' THEN l_instance := 3;
            ELSE l_instance := 1;  -- 기본값
        END CASE;
        
        RETURN l_instance;
    END get_preferred_instance;
    
    PROCEDURE route_to_preferred_instance (
        p_customer_id NUMBER
    ) IS
        l_instance NUMBER;
        l_service_name VARCHAR2(50);
    BEGIN
        l_instance := get_preferred_instance(p_customer_id);
        
        CASE l_instance
            WHEN 1 THEN l_service_name := 'APAC_SERVICE';
            WHEN 2 THEN l_service_name := 'EMEA_SERVICE';
            WHEN 3 THEN l_service_name := 'AMER_SERVICE';
            ELSE l_service_name := 'DEFAULT_SERVICE';
        END CASE;
        
        -- 세션 서비스 변경 (실제 구현은 연결 풀 수준에서)
        DBMS_APPLICATION_INFO.SET_MODULE(
            module_name => 'ROUTED_TO_' || l_service_name,
            action_name => 'Customer_' || p_customer_id
        );
        
        DBMS_OUTPUT.PUT_LINE('Routed customer ' || p_customer_id || 
                            ' to instance ' || l_instance || 
                            ' via service ' || l_service_name);
    END route_to_preferred_instance;
    
END instance_affinity;
/
```

## 통합 성능 모니터링 대시보드

실시간으로 대기 이벤트와 실행 계획을 연계 분석할 수 있는 통합 대시보드를 구축합니다:

```sql
CREATE OR REPLACE VIEW performance_dashboard AS
WITH current_issues AS (
    SELECT 
        ash.sample_time,
        ash.sql_id,
        ash.event,
        ash.wait_class,
        ash.sql_plan_line_id,
        ash.sql_plan_operation,
        ash.sql_plan_options,
        COUNT(*) OVER (PARTITION BY ash.sql_id, ash.event) AS total_samples,
        ROW_NUMBER() OVER (
            PARTITION BY ash.sql_id 
            ORDER BY COUNT(*) OVER (PARTITION BY ash.sql_id, ash.event) DESC
        ) AS rnk
    FROM v$active_session_history ash
    WHERE ash.sample_time > SYSDATE - INTERVAL '10' MINUTE
      AND ash.session_type = 'FOREGROUND'
      AND ash.wait_class != 'Idle'
      AND ash.sql_id IS NOT NULL
),
sql_details AS (
    SELECT 
        ci.sql_id,
        ci.event,
        ci.wait_class,
        ci.sql_plan_line_id,
        ci.sql_plan_operation,
        ci.sql_plan_options,
        ci.total_samples,
        s.sql_text,
        s.executions,
        s.elapsed_time / 1000000 AS total_elapsed_sec,
        ROUND(s.elapsed_time / NULLIF(s.executions, 0) / 1000000, 3) AS avg_elapsed_sec,
        s.buffer_gets,
        s.disk_reads,
        s.rows_processed
    FROM current_issues ci
    JOIN v$sql s ON ci.sql_id = s.sql_id
    WHERE ci.rnk = 1  -- 각 SQL의 주요 대기 이벤트만
      AND ci.total_samples > 5  -- 의미 있는 샘플만
),
plan_analysis AS (
    SELECT 
        sd.*,
        pl.plan_line_id,
        pl.operation,
        pl.options,
        pl.object_name,
        pl.cost,
        pl.cardinality,
        pl.bytes
    FROM sql_details sd
    LEFT JOIN (
        SELECT 
            sql_id,
            id AS plan_line_id,
            operation,
            options,
            object_name,
            cost,
            cardinality,
            bytes
        FROM v$sql_plan
        WHERE depth = 0  -- 최상위 실행 계획만
    ) pl ON sd.sql_id = pl.sql_id
        AND sd.sql_plan_line_id = pl.plan_line_id
)
SELECT 
    sql_id,
    event,
    wait_class,
    total_samples,
    SUBSTR(sql_text, 1, 100) AS sql_preview,
    executions,
    avg_elapsed_sec,
    buffer_gets,
    disk_reads,
    rows_processed,
    sql_plan_operation || ' ' || sql_plan_options AS plan_operation,
    object_name,
    cost,
    cardinality,
    bytes,
    CASE 
        WHEN wait_class = 'User I/O' AND disk_reads > 1000 THEN 'I/O 집중 - 인덱스/접근 경로 검토 필요'
        WHEN wait_class = 'Concurrency' AND total_samples > 50 THEN '동시성 경합 - 락/트랜잭션 패턴 검토 필요'
        WHEN wait_class = 'Application' AND event LIKE 'enq: TX%' THEN '행 잠금 경합 - FK 인덱스/트랜잭션 길이 검토'
        WHEN wait_class = 'Commit' AND avg_elapsed_sec > 0.1 THEN '커밋 지연 - 배치 처리/로그 설정 검토'
        WHEN wait_class = 'Cluster' THEN 'RAC 경합 - 서비스 로컬리티/데이터 분산 검토'
        ELSE '일반 모니터링 대상'
    END AS recommendation
FROM plan_analysis
ORDER BY total_samples DESC, avg_elapsed_sec DESC;

-- 대시보드 사용 예시
SELECT * FROM performance_dashboard
WHERE total_samples > 10
  AND sample_time > SYSTIMESTAMP - INTERVAL '15' MINUTE
ORDER BY total_samples DESC
FETCH FIRST 20 ROWS ONLY;
```

## 성능 문제 해결 워크플로우 체크리스트

1. **증상 확인**
   - 응답 시간 측정 (p50, p95, p99)
   - 리소스 사용률 확인 (CPU, 메모리, I/O, 네트워크)
   - 사용자/애플리케이션 영향 범위 파악

2. **데이터 수집**
   - 문제 시간대 ASH 데이터 수집
   - AWR 리포트 생성 (문제 전/후 비교)
   - SQL Trace 활성화 (필요시)

3. **분석 수행**
   - 상위 대기 이벤트 식별
   - 문제 SQL 및 실행 계획 분석
   - 실행 계획 라인별 통계 확인
   - 데이터 분포 및 통계 검증

4. **근본 원인 도출**
   - 인덱스 설계 문제
   - 통계 부정확성
   - 애플리케이션 패턴 문제
   - 시스템 구성 문제
   - 데이터 모델 문제

5. **해결책 구현**
   - 즉시 적용 가능한 조치 (힌트, 통계 재생성)
   - 중기적 개선 (인덱스 추가/수정)
   - 장기적 개선 (애플리케이션/아키텍처 변경)

6. **검증 및 모니터링**
   - 변경 전후 성능 비교
   - 모니터링 지표 설정
   - 재발 방지 체계 구축

## 결론: 체계적 접근의 중요성

성능 문제 해결은 단순한 기술적 해법이 아니라 **체계적인 분석 과정**입니다. 대기 이벤트는 문제의 '증상'에 불과하며, 진정한 해결은 실행 계획 분석을 통해 근본 원인을 찾아내는 데 있습니다.

**성공적인 성능 튜닝을 위한 핵심 원칙:**

1. **증거 기반 접근**: 감이 아닌 데이터에 기반한 결정
2. **체계적 분석**: 대기 이벤트 → SQL → 실행 계획 → 데이터 분포 순차적 분석
3. **점진적 개선**: 작은 변경부터 시작하여 효과 검증
4. **예방적 모니터링**: 문제 발생 전 조기 발견 시스템 구축
5. **지속적 학습**: 각 사례에서 얻은 인사이트 문서화 및 공유

성능 문제는 종종 여러 요인이 복합적으로 작용합니다. 단순한 해법보다는 **종합적인 관점**에서 문제를 바라보고, 데이터베이스, 애플리케이션, 인프라를 아우르는 **통합적 접근**이 필요합니다. 이 가이드에서 제시한 방법론과 도구들을 활용하여, 단순한 문제 해결을 넘어 시스템의 지속적인 건강 상태를 관리하는 역량을 키워나가시기 바랍니다.