---
layout: post
title: 디지털신호처리 - 음성의 선형 예측 부호화
date: 2025-11-22 20:25:23 +0900
category: 디지털신호처리
---
# 음성의 선형 예측 부호화(LPC, Linear Predictive Coding)

## 0) 왜 “음성에 LPC가 통하는가?”

LPC는 음성을 다음과 같은 **“소스–필터(Source–Filter) 모델”**로 본다.

- **소스(source)**: 성대 진동(유성, voiced) 또는 난류 잡음(무성, unvoiced)
- **필터(filter)**: 성도(vocal tract)의 공명 특성(포만트, formant)

즉,

$$
s[n] = e[n] * h[n]
$$

- \(e[n]\): 여기(excitation, 소스)
- \(h[n]\): 성도의 임펄스 응답(필터)
- \(s[n]\): 관측된 음성

**음성의 대부분 정보는 성도 필터(포만트)와 여기의 형태(피치·에너지·유/무성)로 설명 가능**하다는 경험적 사실이 LPC의 출발점이다.
이를 잘 이용하면 “파형 전체를 그대로 보내는 PCM”보다 훨씬 적은 비트로도 **가청 품질을 유지**할 수 있다.

---

## 1) 음성 생성 모델: 소스–필터와 올폴(all-pole) 성도 모델

### 소스–필터 모델의 블록도

```text
  e[n] (성대/난류 소스)
          │
          ▼
  H(z) (성도 공명 필터)
          │
          ▼
        s[n] (음성 출력)
```

성도는 **주로 공명(포만트)을 만드는 시스템**이라, 주파수 응답이 **피크들(극점들)**로 설명되는 경향이 강하다. 그래서 LPC에서는 성도를

$$
H(z)=\frac{G}{A(z)}=\frac{G}{1-\sum_{k=1}^{p} a_k z^{-k}}
$$

처럼 **all-pole(올폴) IIR**로 근사한다.
- \(a_k\): LPC 계수(성도 특성)
- \(p\): 예측 차수(order)
- \(G\): 프레임 에너지(이득)

이 모델이 음성에 특히 잘 맞는 이유는,
- 모음(유성 구간)의 스펙트럼이 **좁은 대역 피크(포만트) 중심**이기 때문,
- 성도는 물리적으로 **관성·공명 기반 구조**라 올폴 근사가 실용적으로 충분하기 때문이다.

---

## 2) 선형 예측의 기본식과 최소자승(MSE) 목적

### 선형 예측 가정

현재 샘플을 과거 샘플의 선형 결합으로 예측:

$$
\hat{s}[n]=\sum_{k=1}^{p} a_k s[n-k]
$$

예측 오차(잔차):

$$
e[n]=s[n]-\hat{s}[n]=s[n]-\sum_{k=1}^{p} a_k s[n-k]
$$

여기서 \(e[n]\)는 **성도 필터를 제거한 “여기(residual)”**로 해석할 수 있다.

### 최소화 문제

평균제곱오차를 최소화:

$$
J=\mathbb{E}[e[n]^2]
$$

\(\partial J/\partial a_k = 0\)을 풀면 **정규방정식(노멀 방정식)**이 나오고,

$$
\sum_{k=1}^{p} a_k R[|i-k|]=R[i], \qquad i=1,\dots,p
$$

- \(R[m]\): 자기상관(autocorrelation)

이 **Toeplitz 구조** 덕분에 **Levinson–Durbin 재귀**로 \(O(p^2)\)에 빠르게 풀 수 있다.

---

## 3) LPC 분석 파이프라인(Encoder)

실제 음성은 **준정상(quasi-stationary)**이므로, 짧은 구간(프레임)마다 모델을 갱신한다.

### 전체 흐름

```text
음성 s[n]
  │
  ├─ (1) 프리엠퍼시스(pre-emphasis)
  │
  ├─ (2) 프레이밍(framing)
  │
  ├─ (3) 창함수(windowing)
  │
  ├─ (4) 자기상관 계산
  │
  ├─ (5) Levinson–Durbin → a_k, G
  │
  ├─ (6) 여기 파라미터 추정(피치, 유/무성, 잔차 특징)
  │
  └─ (7) 파라미터 양자화·부호화
```

각 단계가 왜 필요한지 하나씩 보자.

---

### (1) 프리엠퍼시스

음성은 저주파 에너지가 큰 편이라, 고주파를 살짝 올려
- 포만트 추정 안정성↑
- 양자화 SNR 균형↑

보통 1차 FIR:

$$
s_p[n]=s[n]-\alpha s[n-1],\qquad 0.9\le\alpha\le0.97
$$

---

### (2) 프레이밍

- 샘플링 \(8\text{ kHz}\) 음성에서 흔히 **20 ms 프레임** 사용
  \(\Rightarrow N=0.02\cdot 8000=160\) 샘플
- 프레임 간 **50% 오버랩(10 ms shift)**이 일반적
  (스펙트럼 안정 + 합성 시 블로킹 감소)

---

### (3) 창함수(Windowing)

프레임 경계의 불연속으로 생기는 스펙트럼 누설을 줄이기 위해

$$
s_w[n]=s_p[n]\cdot w[n]
$$

예: Hamming 창

$$
w[n]=0.54-0.46\cos\frac{2\pi n}{N-1}
$$

---

### (4) 자기상관(Autocorrelation)

프레임마다

$$
R[m]=\sum_{n=0}^{N-1-m} s_w[n]\, s_w[n+m]
$$

\(m=0,\dots,p\).
자기상관법은 **항상 안정적인 all-pole 필터를 보장**하는 장점이 있다.

---

### (5) Levinson–Durbin으로 LPC 계수/이득 계산

재귀적으로 반사계수(=PARCOR)와 \(a_k\)를 얻는다.

- 반사계수의 크기 \(|k_m|<1\)이면 올폴 필터는 안정
- 이게 전 편의 **격자(lattice) 구조**와 바로 연결된다.

---

### (6) 여기(Excitation) 파라미터 추정

LPC는 **성도(필터)**를 뽑았으니, 이제 **소스**를 요약해 보내야 한다.

프레임마다 보통 아래를 추정:

1. **유/무성(Voiced/Unvoiced) 판정**
   - 제로크로싱율(ZCR), 에너지, LPC 잔차의 특성 등으로 판정
2. **피치(Pitch, 기본주기 \(T_0\)) 추정**
   - 자기상관 피크 탐색이 대표적
3. **여기 형태**
   - 고전 LPC Vocoder: “유성=임펄스열, 무성=백색잡음”
   - RELP/ CELP 계열: 잔차를 더 정교하게 모델링/코드북 검색

---

### (7) 파라미터 양자화·부호화

보내는 대표 파라미터:

- LPC 계수 \(a_1,\dots,a_p\)
- 이득 \(G\)
- 피치 \(T_0\)
- 유/무성 플래그
- (고급) 잔차/코드북 인덱스

**계수는 직접 양자화하지 않고 LSF(=LSP)나 PARCOR로 변환 후 양자화**하는 것이 안정/민감도 면에서 유리하다.
- LSF는 극이 단위원 밖으로 나가는 것을 자연스럽게 억제해 **안정성 유지가 쉬움**.

---

## 4) 복원(Decoder) 파이프라인

수신측은 파라미터를 복원하고, 소스를 합성해 필터에 넣는다.

```text
수신 파라미터 (a_k, G, pitch, V/UV, ...)
  │
  ├─ (1) 여기 생성 e[n]
  │
  ├─ (2) 올폴 필터 H(z)=G/A(z)
  │
  └─ (3) 합성 음성 ŝ[n]
```

수식식으로는

$$
\hat{s}[n]=\sum_{k=1}^{p} a_k \hat{s}[n-k] + G\, e[n]
$$

즉 **IIR 합성 필터**에 **여기**를 통과시켜 음성을 만드는 구조다.

---

## 5) LPC 기반 음성 부호화기 발전 계열

### 고전 LPC Vocoder (LPC-10)

- 파라미터(포만트·피치·이득·유/무성)만 보내는 **매우 저비트율(수 kbps)** 방식
- 단점:
  - 잡음·비음(코막힘)·자음에서 품질 저하
  - “로봇 음성” 느낌

### RELP(Residual-Excited LP)

- 잔차 \(e[n]\)를 일정 대역/샘플링으로 보내 품질 향상
- CELP의 조상(1970s)

### CELP / ACELP / VSELP 등 (Analysis-by-Synthesis)

- 잔차를 **코드북에서 찾고(벡터 양자화)**,
  합성 후 오류가 최소가 되도록 선택하는 “분석-합성 최적화”
- 4–16 kbps에서도 PCM에 준하는 품질을 달성하는 대표 하이브리드 기법
- 예: 2G 이동통신의 VSELP는 20 ms 프레임을 159비트로 표현해 약 8 kbps 수준

핵심은 **LPC(성도) + 코드북 여기(잔차)**의 결합이다.

---

## 6) GNU Octave로 “미니 LPC 보코더” 만들기

여기서는 교육용으로 **고전 LPC Vocoder 수준**의 단순 버전을 구현한다.

> 전제
> - Octave에서 `signal` 패키지 사용
> - 입력은 8 kHz 모노 WAV
> - 프레임 20 ms(160 샘플), 10 ms shift
> - LPC 차수 \(p=10\) (8 kHz 음성에서 전형적인 값)
> - 유성/무성: 단순 에너지+ZCR 판정
> - 유성 여기: 피치 주기의 임펄스열
> - 무성 여기: 백색잡음

### 유틸: 프레이밍/오버랩

```octave
function frames = enframe(x, N, H)
  % x: 1-D signal
  % N: frame length
  % H: hop size
  L = length(x);
  num = floor((L - N)/H) + 1;
  frames = zeros(num, N);
  for i = 1:num
    idx = (i-1)*H + (1:N);
    frames(i,:) = x(idx);
  end
end
```

---

### 프리엠퍼시스 + 창

```octave
function xp = preemphasis(x, alpha)
  xp = filter([1 -alpha], 1, x);
end

function w = hamming_win(N)
  n = 0:N-1;
  w = 0.54 - 0.46*cos(2*pi*n/(N-1));
end
```

---

### 자기상관 + Levinson–Durbin

```octave
function R = autocorr_frame(x, p)
  % autocorrelation R[0..p]
  N = length(x);
  R = zeros(1, p+1);
  for m=0:p
    R(m+1) = sum(x(1:N-m).*x(1+m:N));
  end
end

function [a, G, k] = lpc_levinson(R, p)
  % R: autocorr R[0..p]
  a = zeros(1, p);
  E = R(1);
  k = zeros(1, p);

  for m=1:p
    if m==1
      lambda = -R(2)/E;
    else
      acc = R(m+1);
      for i=1:m-1
        acc = acc + a(i)*R(m-i+1);
      end
      lambda = -acc/E;
    end

    k(m) = lambda;  % reflection (PARCOR)

    a_new = a;
    a_new(m) = lambda;
    for i=1:m-1
      a_new(i) = a(i) + lambda*a(m-i);
    end
    a = a_new;

    E = E*(1 - lambda^2);
    if E <= 0, E = 1e-12; end
  end

  G = sqrt(E);  % residual gain
end
```

- \(|k(m)|<1\)이면 안정적인 올폴 합성필터가 보장된다.

---

### 유성/무성 판정 + 피치 추정(간단 버전)

```octave
function zcr = zero_cross_rate(x)
  zcr = sum(abs(diff(sign(x))))/(2*length(x));
end

function [is_voiced, T0] = voiced_pitch(x, Fs)
  % 매우 단순한 판정/피치 추정
  E = mean(x.^2);
  z = zero_cross_rate(x);

  is_voiced = (E > 1e-4) && (z < 0.15);

  if !is_voiced
    T0 = 0;
    return;
  end

  % pitch via autocorrelation peak search
  N = length(x);
  r = xcorr(x);
  r = r(N:end); % non-negative lags

  % human pitch band: 60~300 Hz
  lag_min = floor(Fs/300);
  lag_max = floor(Fs/60);

  [~, idx] = max(r(lag_min:lag_max));
  T0 = lag_min + idx - 1; % samples
end
```

> 이건 “설명용”이라 매우 거칠다.
> 실무는 AMDF/cepstrum/DP-pitch 등과 더 강한 V/UV 판정을 쓴다.

---

### 여기 생성

```octave
function e = excitation_gen(is_voiced, T0, N)
  if is_voiced
    e = zeros(1, N);
    pos = 1;
    while pos <= N
      e(pos) = 1;
      pos = pos + T0;
    end
  else
    e = randn(1, N);
  end
end
```

---

### 합성(올폴 IIR)

```octave
function y = synth_from_lpc(a, G, e)
  % H(z)=G/(1 - sum a_k z^-k)
  A = [1, -a];
  y = filter(G, A, e);
end
```

---

### 전체 LPC 분석→합성 데모

```octave
clear; close all; clc; pkg load signal

% 1) 입력 로드
[x, Fs] = audioread("speech_8k.wav");  % 8kHz mono
x = x(:,1)';  % row vector

% 2) 파라미터
alpha = 0.97;
Nf = round(0.02*Fs);    % 20 ms
H  = round(0.01*Fs);    % 10 ms hop
p  = 10;                % LPC order

% 3) pre-emphasis
xp = preemphasis(x, alpha);

% 4) framing + windowing
frames = enframe(xp, Nf, H);
w = hamming_win(Nf);

numF = size(frames,1);
y_frames = zeros(numF, Nf);

for i=1:numF
  f = frames(i,:) .* w;

  % LPC
  R = autocorr_frame(f, p);
  [a, G, k] = lpc_levinson(R, p);

  % voiced/unvoiced + pitch
  [vuv, T0] = voiced_pitch(f, Fs);

  % excitation
  e = excitation_gen(vuv, T0, Nf);

  % synthesis
  y_frames(i,:) = synth_from_lpc(a, G, e);
end

% 5) overlap-add
y = zeros(1, (numF-1)*H + Nf);
for i=1:numF
  idx = (i-1)*H + (1:Nf);
  y(idx) += y_frames(i,:);
end

% 6) de-emphasis(대략 역필터)
y = filter(1, [1 -alpha], y);

sound(y, Fs);  % 재생
audiowrite("lpc_synth.wav", y', Fs);
disp("done: lpc_synth.wav saved");
```

실행 후 결과를 들어보면:
- 모음 구간은 꽤 그럴듯하지만
- 자음/마찰음/잡음 구간이 “쉬-익” 혹은 “로봇”처럼 들릴 수 있다.

이게 **고전 LPC vocoder의 한계**이고,
CELP 계열이 잔차를 더 정교하게 모델링해서 품질을 끌어올린 이유다.

---

## 7) LPC 차수 선택과 포만트 해석

### 경험적 차수

일반적인 휴대전화 대역(8 kHz)에서,
- \(p \approx 8\sim12\)가 자주 쓰인다.
- 샘플링이 16 kHz로 올라가면 \(p\approx 16\sim20\) 정도로 확장하는 경우가 많다.

차수가 너무 낮으면 포만트가 뭉개지고,
너무 높으면 **양자화 민감도/불안정**과 비트 낭비가 생긴다.

### 포만트와 LPC 폴

LPC 올폴 필터의 극점들 \(p_i\)는 포만트 주파수/대역폭과 연결된다.

극점이

$$
p_i = r_i e^{j\omega_i}
$$

이면
- 포만트 주파수 \(F_i \approx \omega_i \frac{Fs}{2\pi}\)
- 대역폭 \(B_i \approx -\frac{Fs}{\pi}\ln r_i\)

즉 \(r_i\to 1\)일수록 더 날카로운 공명이다.

---

## 8) LPC 계수의 표현과 양자화(안정성 관점)

### 왜 \(a_k\)를 직접 양자화하면 위험한가?

올폴 필터는 분모

$$
A(z)=1-\sum_{k=1}^{p} a_k z^{-k}
$$

이 조금만 흔들려도
- 극점이 단위원 밖으로 나가 불안정
- 포만트 피크가 크게 이동

할 수 있다. 그래서 실무는

1. \(a_k\) → **PARCOR(반사계수)** 또는 **LSF/LSF**로 변환
2. 그 공간에서 양자화
3. 디코더에서 역변환

을 자주 쓴다.
PARCOR는 \(|k_m|<1\)만 유지하면 자동 안정이어서 격자 구조/적응 필터에 특히 강하다.

---

## 9) 정리

- **LPC(선형 예측 부호화)**는 음성을 소스–필터로 보고
  성도를 **all-pole IIR**로 근사해 파라미터만 전송하는 음성 부호화.
- 인코더는 프리엠퍼시스 → 프레이밍/창 → 자기상관 → Levinson–Durbin으로
  LPC 계수·이득·반사계수를 얻고,
  추가로 피치·유/무성·잔차 특징을 추정해 양자화한다.
- 디코더는 여기 신호를 만들고
  합성 올폴 필터에 통과시켜 음성을 재구성한다.
- 고전 LPC vocoder는 매우 저비트율이지만 자음/잡음에서 품질이 약했고,
  RELP, CELP 계열이 잔차를 더 정교하게 부호화해 **4–16 kbps 수준에서도 고품질**을 달성했다.
- GNU Octave 실험으로 **분석→합성**을 직접 돌려 보면
  LPC의 장점과 한계가 귀로 바로 확인된다.

---

## 10) 연습문제(실험 포함)

1. **LPC 차수 영향**
   위 Octave 코드에서 \(p=6,10,14\)로 바꿔 합성 음질과 포만트 해상도를 비교하라.
   - 힌트: 차수가 올라가면 모음은 선명해지지만 잡음/자음에서 불안정이 커질 수 있다.

2. **LSF 양자화 실험(개념)**
   LPC 계수 \(a_k\)를 직접 12-bit 균일 양자화했을 때와,
   PARCOR(\(k_m\))로 변환 후 동일 정밀도로 양자화한 뒤 역변환했을 때
   합성 필터의 안정성과 스펙트럼 변형을 비교하라.

3. **유성/무성 판정 개선**
   현재는 에너지+ZCR만 쓰는데,
   LPC 잔차의 에너지 분포(예: 무성은 잔차가 더 백색에 가까움)를 특징으로 추가해
   V/UV 오분류율을 줄여보라.

4. **피치 검출 알고리즘 비교**
   자기상관 기반 피치와 AMDF 기반 피치 검출을 각각 구현해서
   남/여/잡음 환경에서 오차(Hz)를 비교하라.
