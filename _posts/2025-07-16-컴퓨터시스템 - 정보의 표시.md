---
layout: post
title: 컴퓨터시스템 - 정보의 표시
date: 2025-07-16 21:20:23 +0900
category: 컴퓨터시스템
---
# 정보의 표시: 비트는 어떻게 의미를 갖는가?

## 0. 서론 — “비트는 스스로 아무 말도 하지 않는다”

우리가 다루는 것은 언제나 **비트의 패턴**이다.  
하지만 인간이 이해하는 것은 **숫자, 문자, 색, 포인터, 논리값, 구조체** 같은 “의미 있는 것들”이다.

핵심 문장:

> 비트는 그 자체로 **무의미한 패턴**이다.  
> 의미는 **해석 규칙**(표현 형식, 부호 규약, 스케일, 문자집합, 엔디안, 타입 시스템 등)을 합성할 때 생성된다.

이 글은 아래의 8가지 표현 층위를 통해 **“비트 → 의미”**를 추적한다.

1. **정수(부호 없음)**: 자리값·범위·오버플로(모듈러 산술)
2. **부호 있는 정수(2의 보수)**: 범위·부호 확장·오버플로·다른 부호 표현과 비교
3. **부동소수점(IEEE 754)**: 정규/서브노멀/±0/∞/NaN/반올림/ULP·수치적 함정
4. **고정소수점(Q 형식)**: 정밀도·스케일·포화·실수 근사
5. **문자·문자열(ASCII/Unicode/UTF-8/UTF-16)**: 코드 포인트·그래프 클러스터·인코딩
6. **불리언**: 0/비0 컨벤션, 메모리 배치, 비트 연산과의 연결
7. **열거형·비트 플래그**: 기호 ↔ 정수 매핑, 플래그 조합
8. **포인터/주소**: “숫자처럼 보이지만, 수학적 덧셈과는 다른 의미론을 가진 값”

마지막으로 **“같은 4바이트를 여러 방식으로 해석”**하는 실험으로  
표현 형식이 바뀔 때 의미가 어떻게 달라지는지 눈으로 확인한다.

---

## 1. 자리값과 모듈러 산술 — 부호 없는 정수

### 1.1 자리값 표현과 범위

n비트 부호 없는 정수의 해석은 다음과 같다.

$$
\text{Value} = \sum_{i=0}^{n-1} b_i \cdot 2^i
$$

여기서 \(b_i \in \{0,1\}\) 는 i번째 비트다.  
따라서 범위는

$$
\text{범위} = [0, 2^n - 1]
$$

- 8비트 → $$[0, 2^8-1] = [0, 255]$$  
- 32비트 → $$[0, 2^{32}-1] = [0, 4{,}294{,}967{,}295]$$

#### 예: 8비트 부호 없는 수

| 비트 패턴 | 값(10진) | 설명 |
|----------:|---------:|------|
| `0000 0000₂` | 0 | 모든 비트 0 |
| `0000 0001₂` | 1 | LSB만 1 |
| `0000 1010₂` | 10 | \(2^3 + 2^1\) |
| `1111 1111₂` | 255 | 최대값, \(2^8-1\) |

### 1.2 오버플로 = 모듈러 래핑

하드웨어에서는 덧셈·뺄셈 결과가 비트 폭을 넘어갈 때, **하위 n비트만 남기고 버린다**.  
이것은 수학적으로 다음과 같은 **모듈러 연산**에 해당한다.

$$
(x + y) \bmod 2^n,\quad (x - y) \bmod 2^n
$$

- CPU는 상위로 넘친 비트(캐리/보로우)를 **플래그 레지스터**에만 남긴다.
- 저장되는 값 자체는 “랩(lap)” 돌듯이 **0으로 되돌아가서 다시 증가**한다.

#### C에서 부호 없는 정수 오버플로

C/C++ 표준은 **부호 없는 정수의 오버플로를 의도적으로 “정의된 동작”**으로 두고 있다.  
즉, n비트 부호 없는에서의 연산은 항상 $$2^n$$에 대한 모듈러 산술이다.

```c
#include <stdint.h>
#include <stdio.h>

int main(void) {
    uint8_t a = 250, b = 20;
    uint8_t c = a + b;    // 250 + 20 = 270 → 270 mod 256 = 14

    printf("a=%u, b=%u, a+b=%u\n", a, b, c);  // 250, 20, 14
    return 0;
}
```

- 내부에서는 270이 계산되지만, **하위 8비트만 남아서 14**가 된다.
- 많은 암호·해시·체크섬 코드가 **이 모듈러 특성**을 적극 활용한다.

### 1.3 비트 연산과 마스크

부호 없는 정수는 자연스럽게 **비트 집합**으로 해석할 수 있다.  

- 특정 비트 추출: `x & (1u<<k)`
- 특정 비트 세트: `x |= (1u<<k)`
- 특정 비트 클리어: `x &= ~(1u<<k)`
- 특정 비트 토글: `x ^= (1u<<k)`

```c
#include <stdint.h>
#include <stdio.h>

static void print_bits(uint8_t x) {
    for (int i = 7; i >= 0; --i) {
        putchar((x & (1u<<i)) ? '1' : '0');
    }
}

int main(void) {
    uint8_t flags = 0;
    flags |= (1u<<0); // bit0 세트
    flags |= (1u<<3); // bit3 세트
    print_bits(flags); // 00001001
    putchar('\n');

    // bit3 토글 → 00000001
    flags ^= (1u<<3);
    print_bits(flags);
    putchar('\n');

    return 0;
}
```

- 여기서 `flags`는 “비트 플래그 집합”으로 동작한다.  
- 이 개념은 뒤에서 설명할 **열거형·비트 플래그**와 직결된다.

---

## 2. 부호 있는 정수 — 2의 보수 표현

### 2.1 정의와 범위

n비트 2의 보수에서 값은 다음과 같이 해석된다.

$$
\text{Value} = -b_{n-1}\cdot 2^{n-1} + \sum_{i=0}^{n-2} b_i \cdot 2^i
$$

따라서 범위는

$$
[-2^{n-1}, 2^{n-1}-1]
$$

예:

- 8비트 2의 보수 → $$[-128, 127]$$  
- 16비트 2의 보수 → $$[-32768, 32767]$$  

### 2.2 음수 생성: 비트 반전 + 1

양수의 2의 보수 표현을 이용해 음수를 만드는 방법은 간단하다.

1. 비트 반전(1↔0)
2. 1을 더한다

#### 예: 8비트에서 −5

- +5: `0000 0101₂`
- 반전: `1111 1010₂`
- +1: `1111 1011₂` ← −5

| 십진 | 8비트 2의 보수 |
|-----:|:---------------|
| +5   | `0000 0101`    |
| −5   | `1111 1011`    |

이 패턴 덕분에, **정수 덧셈기 하나로 +와 −를 동시에 처리**할 수 있다.  
`a - b`를 `a + (~b + 1)`로 바꾸면 되기 때문이다.

### 2.3 부호 확장(Sign Extension)

좁은 폭에서 넓은 폭으로 캐스팅할 때, 음수는 **부호 비트(MSB)를 복제**하여 확장한다.

비형식적인 설명:

- MSB가 0이면: 상위 비트에 0을 채운다.
- MSB가 1이면: 상위 비트에 1을 채운다.

수식으로 쓰면 다음과 같은 효과를 갖는다.

$$
\text{sx}_{n \to m}(x) =
\begin{cases}
x, & \text{if } x \text{ 양수 또는 0} \\
x + 2^m - 2^n, & \text{if } x \text{ 음수}
\end{cases}
$$

#### C 예제

```c
#include <stdint.h>
#include <stdio.h>

int main(void) {
    int8_t  s8  = -1;            // 0xFF
    int32_t s32 = (int32_t)s8;   // 0xFFFFFFFF == -1 (부호 확장)
    printf("s8 = %d, s32 = %d\n", s8, s32);
    return 0;
}
```

- `-1`의 8비트 표현: `1111 1111₂`  
- 32비트로 올릴 때, 상위 24비트를 모두 1로 채워 `0xFFFFFFFF`가 되어야 한다.

### 2.4 부호 있는 정수 오버플로 = 정의되지 않은 동작

C/C++에서 **부호 있는 정수의 오버플로는 “정의되지 않은 동작(UB)”** 이다.

```c
int add(int a, int b){
    return a + b; // a,b가 충분히 커서 범위를 넘으면 UB
}
```

- 컴파일러는 “a+b가 오버플로하지 않는다”는 가정을 바탕으로 최적화를 해버릴 수 있다.
- 이 때문에 **보안 취약점(수치 오버플로 기반 버그)** 로 이어지기도 한다.

보다 안전하게 하려면:

1. 부호 없는 타입에서 모듈러로 계산한 후 범위를 점검하거나,
2. 컴파일러 제공 “체크된 덧셈” 내장 함수(예: `_addcarry_u64` 등)를 사용하거나,
3. 언어 차원에서 정의하는 **포화 산술** 또는 **예외**를 활용하는 언어를 사용한다.

---

## 3. 정수 연산과 모듈러 산술 — 언어별 비교

### 3.1 언어별 오버플로 처리 비교(개념)

| 언어 | 부호 없는 오버플로 | 부호 있는 오버플로 |
|------|--------------------|--------------------|
| C/C++ | 모듈러(정의됨) | UB(정의되지 않음) |
| Java | 모듈러(정의됨, 2의 보수) | 모듈러(정의됨) |
| C#   | 기본: 모듈러(`unchecked`) | `checked` 블록에서 예외 발생 가능 |
| Rust | 디버그: 패닉, 릴리스: 모듈러(기본) | `checked_add` 등 별도로 제공 |

정수 표현 자체는 비슷하지만, **언어 설계가 “오버플로를 어떻게 다루는가”**에 따라  
안전성·성능·예측 가능성이 크게 달라진다.

### 3.2 예: C와 Java 비교

```c
// C: 부호 있는 오버플로는 UB
#include <limits.h>
#include <stdio.h>

int main(void) {
    int x = INT_MAX;
    int y = x + 1;   // UB
    printf("%d\n", y);
}
```

```java
// Java: 2의 보수 모듈러
public class IntOverflow {
    public static void main(String[] args) {
        int x = Integer.MAX_VALUE;     //  2147483647
        int y = x + 1;                 // -2147483648
        System.out.println(y);
    }
}
```

- 같은 하드웨어 위에서도 언어마다 **“표현 + 의미 계약”**이 다르기 때문에  
  같은 연산이 **다른 의미**를 갖는다.

---

## 4. 부동소수점(IEEE 754) — 실수의 이진 근사

### 4.1 형식과 해석: binary32 / binary64

IEEE 754에서 널리 쓰이는 이진 부동소수점 형식:

| 형식 | 부호 비트 s | 지수 비트 e (바이어스) | 가수 비트 f | 총 비트 수 |
|------|-------------|------------------------|-------------|------------|
| binary32 (float)  | 1 | 8 (bias=127)  | 23 | 32 |
| binary64 (double) | 1 | 11 (bias=1023)| 52 | 64 |

일반적인 **정규화 수(normal)** 는 다음과 같이 해석된다.

$$
(-1)^s \cdot (1.f)_2 \cdot 2^{E - \text{bias}}
$$

- \(s\) : 부호 비트 (0=양수, 1=음수)  
- \(E\) : 지수 필드의 정수 값  
- \(f\) : 가수 비트들을 이진 소수로 해석한 값

#### 서브노멀(subnormal) 수

지수 필드가 0일 때, 정규화된 1.x가 아닌 **0.x 형태**로 해석된다.

$$
(-1)^s \cdot (0.f)_2 \cdot 2^{1 - \text{bias}}
$$

이 영역은 0 근처의 **아주 작은 값들을 촘촘히 표현**하기 위한 구역이다.

#### 특수 값

- `E = all 1, f = 0` → `±∞`
- `E = all 1, f ≠ 0` → `NaN` (Not a Number)

### 4.2 ±0, ±∞, NaN

부동소수점에는 **0도 부호가 있고**, 무한대도 부호가 있다.

- `+0.0` / `-0.0` : 비트 패턴만 다르며, 일부 연산에서 결과가 달라질 수 있다.
- `+∞` / `-∞` : 오버플로·나누기 0 등에서 등장.
- `NaN` : “정의되지 않은 실수 결과” (0/0, ∞−∞, sqrt(음수, 실수 영역에서) 등)

예:

$$
\frac{1}{+0.0} = +\infty,\quad
\frac{1}{-0.0} = -\infty
$$

### 4.3 반올림과 비결합성

기본 반올림 모드(대부분 환경의 기본값):

- **Round to nearest, ties to even**
  - 가장 가까운 표현 가능한 수로 반올림하되,
  - 정확히 중간이면 **끝 자리가 짝수**가 되도록 선택한다.

이로 인해, 부동소수점 연산은 일반적으로 **결합법칙이 깨진다**.

$$
(a + b) + c \neq a + (b + c)
$$

#### 예시: 파이썬으로 확인

```python
xs = [1e-10] * 1_000_000 + [1.0]

s1 = sum(xs)                     # (많은 작은 것)→큰 것
s2 = 1.0 + sum([1e-10]*1_000_000)

print(s1, s2)                    # 보통 서로 약간 다름
```

- 반올림이 **어느 시점에, 어떤 순서로** 적용되느냐에 따라 결과가 달라진다.
- 수치 해석에서는 이러한 오차를 줄이기 위해 **Kahan summation** 같은 기법을 사용한다.

### 4.4 ULP와 머신 엡실론

- **ULP(Unit in Last Place)**: 인접한 두 표현 가능한 실수 사이의 거리.
  - 어떤 값 x에서, “다음 representable 값”과의 차이가 그 지점의 ULP.
- **머신 엡실론 ε**: \(1.0 + \epsilon \neq 1.0\)이 되는 **가장 작은 양수**.

$$
\text{machine epsilon} = \min \{ \epsilon > 0 \mid 1.0 + \epsilon \neq 1.0 \}
$$

- double(64비트)에서 ε는 대략 \(2^{-52} \approx 2.22\times10^{-16}\).
- float(32비트)에서 ε는 \(2^{-23} \approx 1.19\times10^{-7}\).

이 값은 “실수 계산에서 기대할 수 있는 상대 오차 하한” 정도로 이해할 수 있다.

### 4.5 C에서 비트 패턴 관찰

```c
#include <stdint.h>
#include <stdio.h>
#include <string.h>

typedef union {
    float    f;
    uint32_t u;
} U32;

static void print_bits32(uint32_t x) {
    for (int i = 31; i >= 0; --i)
        putchar((x & (1u<<i)) ? '1' : '0');
}

int main(void) {
    U32 x;
    x.f = 0.1f;   // 0.1은 이진에서 유한 표현 불가 → 근사치

    printf("0.1f = %.9f\n", x.f);
    printf("bits = 0x%08X\n", x.u);
    print_bits32(x.u);
    putchar('\n');

    return 0;
}
```

- 0.1은 이진 분수로 **유한 표현이 불가능**하므로, 가장 가까운 근사 값이 저장된다.
- 수치 오류의 원천을 확인할 수 있는 좋은 예이다.

---

## 5. 고정소수점(Q 형식) — “실수의 정수화”

### 5.1 Q 형식(Qm.n)의 정의

고정소수점은 “**정수 하나를 실수 하나처럼 해석**”하는 아이디어다.

- Q\(m.n\): 총 \(m+n\)비트 중 **정수부 m비트**, **소수부 n비트**
- 저장값 \(X\)를 실제값으로 해석:

$$
\text{Real} = \frac{X}{2^n}
$$

예: Q1.15 (16비트, 부호 있는 형식)

- 저장 범위: $$[-2^{15}, 2^{15}-1] = [-32768, 32767]$$
- 실제값 범위: \([-1.0, 1.0-2^{-15}]\)

### 5.2 곱셈 결과 스케일

Q 형식에서 곱셈을 하면 **소수부 비트가 2배**로 늘어난다.

$$
X_a = a \cdot 2^n,\quad X_b = b \cdot 2^n
$$
$$
X_a X_b = (a \cdot b) \cdot 2^{2n}
$$

따라서 다시 Q\(m.n\)로 맞추려면

$$
\text{저장값} = \frac{X_a X_b}{2^n} = (a b) \cdot 2^n
$$

이 과정을 코드로 표현하면 다음과 같다.

```c
#include <stdint.h>

static inline int16_t q15_mul(int16_t a, int16_t b){
    int32_t t = (int32_t)a * (int32_t)b; // 32b, Q1.15 * Q1.15 → Q2.30
    t += 1 << 14;                        // 반올림 (0.5 ULP)
    t >>= 15;                            // 다시 Q1.15로 스케일 다운

    // 포화(saturation)
    if (t >  32767) t =  32767;
    if (t < -32768) t = -32768;
    return (int16_t)t;
}
```

- DSP·임베디드 시스템에서 널리 쓰이는 패턴이다.
- 부동소수점 없이도 **결정적이고 빠른 실수 연산**을 구현할 수 있다.

### 5.3 장단점 요약

| 항목 | 고정소수점 | 부동소수점 |
|------|------------|------------|
| 표현 범위 | 비교적 좁음(설계된 스케일 안) | 매우 넓음(지수 덕분) |
| 정밀도 | 균등(스케일 내에서) | 값 크기에 따라 변화 |
| 연산 비용 | 정수 연산, 보통 빠름 | HW FPU가 없으면 소프트웨어 에뮬레이션 필요 |
| 구현 난이도 | 스케일·포화·오버플로 관리 필요 | 반올림·NaN/∞ 처리 필요 |

---

## 6. 문자·문자열 — 코드 포인트와 그래프 클러스터

### 6.1 코드 포인트와 그래프

**문자셋(character set)** 과 **인코딩(encoding)** 을 구분해야 한다.

- **코드 포인트(code point)**:
  - “문자”에 할당된 추상적인 번호. (예: Unicode에서 U+0041 = 'A')
- **그래프(grapheme)**:
  - 사람이 보기에는 “하나의 문자”처럼 보이는 화면상의 단위.
  - 하나의 그래프가 **여러 코드 포인트의 조합**일 수 있다.

예:

- 문자 `é`는
  - U+00E9(단일 코드 포인트) 이거나
  - U+0065('e') + U+0301(결합 악센트) 로 표현될 수 있다.

### 6.2 ASCII와 UTF-8, UTF-16

#### ASCII (American Standard Code for Information Interchange)

- 7비트 인코딩 (보통 8비트 바이트에 저장)
- 영문자, 숫자, 일부 기호, 제어 문자(줄바꿈, 탭 등)만 포함
- 현대 시스템에서는 **UTF-8의 하위 집합** 역할을 한다.

#### UTF-8

UTF-8은 **1~4바이트 가변 길이** 인코딩으로, 오늘날 웹·네트워크 표준이다.

UTF-8 바이트 패턴(요약):

| 코드 포인트 범위 | 바이트 수 | 패턴(2진) |
|------------------|----------:|-----------|
| U+0000..007F     | 1         | `0xxxxxxx` |
| U+0080..07FF     | 2         | `110xxxxx 10xxxxxx` |
| U+0800..FFFF     | 3         | `1110xxxx 10xxxxxx 10xxxxxx` |
| U+10000..10FFFF  | 4         | `11110xxx 10xxxxxx 10xxxxxx 10xxxxxx` |

#### UTF-16

- 2바이트 단위(16비트)를 기본으로 하는 인코딩.
- BMP(Basic Multilingual Plane) 내 코드 포인트(U+0000..FFFF)는 2바이트 1개로 표현.
- U+10000 이상은 **서러게이트 쌍(surrogate pair)** 를 사용해 4바이트로 표현.

### 6.3 “문자 길이 ≠ 바이트 길이” ≠ “사용자가 느끼는 글자 수”

```python
s = "A가á"  # 'A', '가', 'a' + 결합 악센트 U+0301
print("codepoints:", len(s))                 # 코드 포인트 수
print("utf8 bytes:", len(s.encode("utf-8"))) # 바이트 수
```

- `len(s)`는 코드 포인트 수를 반환한다.
- `len(s.encode("utf-8"))`는 UTF-8 인코딩 후 바이트 수다.
- 사용자가 느끼는 “글자 수”는 **그래프 클러스터 수**에 더 가깝다.  
  (이를 계산하려면 별도의 라이브러리가 필요하다.)

### 6.4 인코딩 혼선과 버그

자주 발생하는 문제:

1. **문자 인덱스를 바이트 인덱스로 착각**
   - UTF-8에서 바이트 오프셋으로 슬라이스하면 **중간 바이트**를 자를 수 있어 invalid 시퀀스 발생.
2. **UTF-16 코드 유닛을 코드 포인트로 착각**
   - 서러게이트 쌍을 무시하고 2바이트 단위로 인덱싱하면,  
     이모지·확장 코드 영역에서 깨짐.
3. **정규화(NFC/NFD) 무시**
   - `é`를 U+00E9와 U+0065+U+0301로 모두 허용하면서  
     문자열 비교/검색을 정확히 하려면 **정규화**가 필요하다.

---

## 7. 불리언 — 저장은 1비트, 정렬은 보통 1바이트 이상

### 7.1 논리값과 메모리 표현

논리적으로 **불리언(boolean)** 은 참/거짓 두 값만 필요하므로 1비트면 충분하다.  
하지만 실제 메모리에서는 **정렬(alignment)과 접근 단위** 때문에  
보통 **1바이트 이상**으로 할당된다.

C에서:

```c
#include <stdbool.h>
#include <stdio.h>

int main(void) {
    bool ok = 5;        // 비0 → true
    printf("%d\n", ok); // 1
    return 0;
}
```

- 많은 언어/라이브러리에서 “0은 false, 비0은 true” 컨벤션을 사용한다.
- 하지만 그 반대는 항상 참이 아니다. (true가 꼭 1일 필요는 없지만, 보통은 1로 구현한다.)

### 7.2 비트필드와 패킹

불리언을 많이 저장해야 할 때(예: 100만 개의 플래그) 실제로 1비트 단위로 패킹하기도 한다.

```c
struct Flags {
    unsigned a:1;
    unsigned b:1;
    unsigned c:1;
    unsigned :5; // 패딩
};
```

- 컴파일러가 비트 단위로 묶어서 저장한다.
- 하지만 비트필드의 레이아웃은 컴파일러·ABI마다 다를 수 있으므로,  
  **직렬화 포맷으로 쓰기에는 부적합**하다.

---

## 8. 열거형·비트 플래그 — 기호적 정수와 조합

### 8.1 열거형(Enum)

열거형은 “**심벌 이름 ↔ 정수 값**” 매핑이다.

```c
enum Color { RED=0, GREEN=1, BLUE=2 };

int main(void) {
    enum Color c = GREEN;
    printf("%d\n", c); // 내부적으로는 정수(1)
}
```

- 내부 표현은 보통 `int`이지만, C/C++ 표준에서 구체적인 비트 패턴은 구현에 따라 다를 수 있다.
- C++11 이후에는 `enum class`와 기저 타입 지정으로 표현을 더 엄격히 통제할 수 있다.

### 8.2 비트 플래그 — 집합 표현

비트 플래그는 하나의 정수에 여러 상태를 **집합처럼** 표현한다.

```c
enum Perm {
    PERM_R = 1 << 0,
    PERM_W = 1 << 1,
    PERM_X = 1 << 2
};

int main(void) {
    unsigned p = PERM_R | PERM_W;   // {R, W}
    int can_x = (p & PERM_X) != 0;  // X 권한 여부
    p &= ~PERM_W;                   // W 해제
}
```

비트 연산으로:

- 추가: `p |= FLAG`
- 제거: `p &= ~FLAG`
- 토글: `p ^= FLAG`
- 검사: `(p & FLAG) != 0`

운영체제 권한, 파일 모드, 네트워크 옵션, CPU 기능 플래그 등 수많은 곳에서 사용된다.

---

## 9. 포인터/주소 — “숫자처럼 보이지만 수학과는 다른 값”

### 9.1 주소와 포인터

포인터는 “메모리 상의 위치”를 가리키는 값이다.

- 32비트 시스템: 보통 4바이트
- 64비트 시스템: 보통 8바이트

```c
#include <stdint.h>
#include <stdio.h>

int main(void) {
    int x = 42;
    int *p = &x;

    uintptr_t addr = (uintptr_t)p;   // 정수 타입으로 캐스팅
    printf("x=%d, addr=0x%zx\n", x, (size_t)addr);

    return 0;
}
```

- `uintptr_t`는 “정수형 포인터 표현”을 위한 표준 타입이다.
- 하지만 정수와 포인터는 **의미론이 다르다**.

### 9.2 포인터 산술과 정렬

포인터 덧셈은 바이트 단위가 아니라 **타입 크기 단위**로 움직인다.

```c
int arr[4] = {10, 20, 30, 40};
int *p = arr;

int *q = p + 2;  // 실제 주소는 p + 2*sizeof(int)
printf("%d\n", *q); // 30
```

- 포인터 산술은 **타입을 알고 있기 때문에** 가능한 것.
- 단순히 정수 주소에 1을 더하는 것과는 의미가 다르다.

또한 하드웨어는 특정 타입을 특정 정렬 기준에 맞춘 주소에서만 접근해야 할 수도 있다.

- 예: 4바이트 정수는 주소가 4의 배수인 위치에만 존재해야 하는 아키텍처
- 부적절한 정렬에서 접근하면 성능 저하 또는 예외가 발생할 수 있다.

---

## 10. 엔디안과 재해석 — “같은 4바이트, 다른 해석”

### 10.1 엔디안(Endianness)

같은 멀티바이트 값이라도 **메모리에 저장되는 순서**가 달라질 수 있다.

- **Little-endian**:
  - 하위 바이트를 먼저 저장
  - x86, x86-64 등에서 사용
- **Big-endian**:
  - 상위 바이트를 먼저 저장
  - 일부 네트워크 프로토콜, 특정 아키텍처에서 사용

예: 32비트 값 `0x12345678`

- little-endian: `78 56 34 12`
- big-endian:     `12 34 56 78`

네트워크 바이트 순서는 전통적으로 **big-endian**을 사용한다.

### 10.2 같은 4바이트를 다른 타입으로 해석

#### 예: C에서 안전한 재해석(memcpy)

```c
#include <stdint.h>
#include <stdio.h>
#include <string.h>

static void bits32(uint32_t u){
    for(int i=31;i>=0;i--) putchar((u>>i)&1 ? '1':'0');
}

int main(void){
    uint32_t u = 0x3F800000u;  // IEEE 754 float 1.0
    float f;
    memcpy(&f, &u, sizeof f);  // 유니온 별칭 대신 memcpy 사용

    printf("as uint = %u\n", u);      // 1065353216 (환경에 따라 달라 보일 수 있음)
    printf("as float = %f\n", f);     // 1.000000
    printf("bits: "); bits32(u); puts("");

    return 0;
}
```

- `0x3F800000`는 float로 해석하면 `1.0`이지만,
- 부호 없는 32비트 정수로 해석하면 커다란 정수다.
- 같은 비트열이 **표현 형식에 따라 완전히 다른 의미**를 갖는다.

### 10.3 파이썬 struct를 이용한 재해석

```python
import struct

raw = bytes.fromhex("3F800000")   # big-endian에서 1.0f
u = struct.unpack(">I", raw)[0]   # 32b 부호 없는 정수
f = struct.unpack(">f", raw)[0]   # float

print("u =", u)
print("f =", f)
```

- `">I"`: big-endian 32비트 부호 없는 정수
- `">f"`: big-endian 32비트 float

엔디안 기호만 바꾸면 **같은 4바이트를 전혀 다르게 해석**하게 된다.

---

## 11. 숫자 표현의 대안들 — 역사적 선택과 오늘의 표준

### 11.1 부호/크기(Sign-Magnitude)

- 가장 단순한 아이디어: **MSB를 부호, 나머지를 절대값**으로 해석
- 예: 8비트에서
  - `0 0000101` → +5
  - `1 0000101` → −5

단점:

- **+0과 −0 두 가지 0**이 존재
- 덧셈/뺄셈 회로가 복잡해짐(부호에 따라 절대값 연산을 달리해야 함)

### 11.2 1의 보수(One’s Complement)

- 음수 = 양수 비트 패턴 반전
- 예: 8비트에서 +5 = `0000 0101`, −5 = `1111 1010`

단점:

- 여전히 +0 (`0000 0000`)과 −0 (`1111 1111`)이 존재
- 덧셈 후 캐리를 다시 더하는 **end-around carry** 같은 보정 필요

### 11.3 2의 보수(Two’s Complement)가 표준이 된 이유

- 1의 보수에 비해 구현이 단순(보정 규칙이 깔끔)
- +0과 −0이 **하나의 0**으로 통합
- 모듈러 산술과 자연스럽게 연결되는 성질

오늘날 대부분의 범용 CPU는 **2의 보수**를 사용한다.

---

## 12. 실험: “표시”를 바꾸면 결과가 달라진다

### 12.1 같은 바이트, 서로 다른 타입들 (파이썬)

```python
import struct

raw = bytes.fromhex("BF800000")   # 흔히 -1.0f에 사용되는 패턴

u = struct.unpack(">I", raw)[0]   # 32비트 부호 없는 정수
s = struct.unpack(">i", raw)[0]   # 32비트 부호 있는 정수
f = struct.unpack(">f", raw)[0]   # float

print("raw bytes:", raw.hex())
print("as unsigned:", u)
print("as signed:", s)
print("as float:", f)
```

- 이 바이트열은
  - unsigned → 큰 양수
  - signed → 음수
  - float → `-1.0`
- 실제 의미는 **우리가 어떤 타입으로 해석하겠다고 합의했는지**에 달렸다.

### 12.2 부동소수점의 비결합성 (다시 한 번)

```python
xs = [1e-10] * 1_000_000
s1 = sum(xs)        # 작은 값을 많이 더함
s2 = 0.0
for x in xs:
    s2 += x

print("s1:", s1)
print("s2:", s2)
print("diff:", s1 - s2)
```

- 동일한 연산을 해도 구현·순서에 따라 값이 조금씩 달라질 수 있다.
- “실수 = R 위의 이상적인 연산”이라는 생각 대신,  
  **유한 정밀도 기계 실수**라는 점을 항상 염두에 둬야 한다.

---

## 13. 디버깅 체크리스트 — 표시·해석 관련 버그를 막는 법

1. **비트 폭과 범위 명시**
   - 문서·코멘트에 타입의 비트 폭과 범위를 적어두자.
   - 예: “이 필드는 16비트 부호 없는, 0~65535 범위”

2. **부호 있는 오버플로 금지**
   - C/C++에서는 부호 있는 오버플로가 UB라는 점을 기억하고,
   - 필요하면 부호 없는로 계산 후 범위 검사·포화 처리.

3. **엔디안 명확히 표기**
   - 파일 포맷·네트워크 메시지 정의에서 **반드시 “big/little-endian”** 명시.
   - 혼용 시에는 변환 함수를 중앙에서 관리.

4. **정렬/패딩 고려**
   - 구조체를 그대로 네트워크나 파일에 덤프하는 습관은 매우 위험하다.
   - `#pragma pack` 남용 대신, **수동 직렬화 코드**를 쓰자.

5. **부동소수점 비교 시 허용 오차 사용**
   - `a == b` 대신 $$|a-b| \le \epsilon$$ 또는 ULP 기반 비교 함수 사용.
   - 누적 연산 순서에 따른 오차도 고려.

6. **문자열은 UTF-8 기준으로**
   - 내부 표현을 UTF-8로 통일하면, 입출력·웹·네트워크에서 편해진다.
   - “문자” 슬라이스는 바이트 단위가 아니라 **코드 포인트/그래프** 단위 라이브러리를 사용.

7. **재해석은 `memcpy`와 공식 API로**
   - 유니온 별칭이나 캐스팅으로 타입 재해석을 하는 대신,
   - `memcpy`, `std::bit_cast(C++20)` 등 **표준이 허용하는 방법**을 쓴다.

8. **포인터 수치화·비표준 연산 자제**
   - 포인터를 정수로 바꿔 임의 연산 후 다시 포인터로 캐스팅하는 코드는  
     이식성과 정의된 동작 측면에서 위험하다.

---

## 14. 표·도해 모음 (요약 정리)

### 14.1 8비트 정수 표현 범위

| 형식             | 최소   | 최대   |
|------------------|-------:|-------:|
| 부호 없음        | 0      | 255    |
| 2의 보수 (signed)| −128   | 127    |

### 14.2 IEEE 754 binary32 레이아웃

```
s eeeeeeee fffffffffffffffffffffff
0 1......8 9.....................31  (총 32비트)
```

값은 다음과 같이 해석된다.

$$
(-1)^s \times
\begin{cases}
(1.f)_2 \cdot 2^{E-127}, & 0 < E < 255 \quad (\text{정규})\\[4pt]
(0.f)_2 \cdot 2^{-126},  & E = 0 \quad (\text{서브노멀})\\[4pt]
\infty \text{ 또는 NaN}, & E = 255
\end{cases}
$$

### 14.3 UTF-8 인코딩 패턴

| 코드 포인트 범위 | 바이트 수 | 패턴 |
|------------------|----------:|------|
| U+0000..007F     | 1         | `0xxxxxxx` |
| U+0080..07FF     | 2         | `110xxxxx 10xxxxxx` |
| U+0800..FFFF     | 3         | `1110xxxx 10xxxxxx 10xxxxxx` |
| U+10000..10FFFF  | 4         | `11110xxx 10xxxxxx 10xxxxxx 10xxxxxx` |

---

## 15. 연습 문제 (자가 점검용)

1. 16비트 2의 보수에서 `1000 0000 0000 0000₂`의 값은 무엇인가?
   - 힌트: MSB가 1인 경우 음수이며, 값은 $$-2^{15}$$ 이다.

2. 8비트 부호 없는에서 `250 + 20`의 결과와 이유를 설명하라.
   - 힌트: $$270 \bmod 256$$ 을 계산해 보라.

3. `0xBF800000`을  
   1) 부호 없는 32비트 정수,  
   2) 부호 있는 32비트 정수,  
   3) float (IEEE 754) 로 각각 해석했을 때의 값을 구하라.

4. UTF-8에서 U+AC00(“가”)의 바이트열을 쓰고, 길이를 구하라.

5. Q1.15 형식에서 0.5×0.5를 계산할 때,
   1) 저장값(정수),
   2) 실제값(실수)을 구하고,  
   반올림·포화 과정에서 어떤 일이 일어나는지 서술하라.

6. `+0.0`과 `-0.0`의 차이를 판별하는 방법을 C 또는 파이썬 코드로 작성하라.
   - 힌트: `1.0 / x` 혹은 비트 패턴을 사용하라.

---

## 16. 부록 — 비트 시각화/재해석 유틸

### 16.1 C: 부동소수점 비트 구조 출력

```c
// C: 안전한 재해석(memcpy) + 부동소수점의 부호/지수/가수 출력
#include <stdio.h>
#include <stdint.h>
#include <string.h>

static void bits32(uint32_t u){
    for(int i=31;i>=0;i--) putchar((u>>i)&1 ? '1':'0');
}

int main(void){
    float f = -1.0f;
    uint32_t u;
    memcpy(&u, &f, sizeof f);

    printf("f = %f\n", f);
    printf("u = 0x%08X\n", u);
    printf("bits: ");
    bits32(u);
    puts("");

    unsigned s = (u >> 31) & 1u;
    unsigned E = (u >> 23) & 0xFFu;
    unsigned F =  u        & 0x7FFFFFu;

    printf("s=%u, E=%u, F=0x%06X\n", s, E, F);
    return 0;
}
```

### 16.2 파이썬: 바이트열 다중 해석

```python
import struct
import math

raw = bytes.fromhex("80000000")   # -0.0f (IEEE 754, big-endian이라고 가정)

u = struct.unpack(">I", raw)[0]
f = struct.unpack(">f", raw)[0]

print("raw =", raw.hex())
print("as uint32 =", u)
print("as float  =", f)

# +0.0과 -0.0 판별
pos_zero = 0.0
neg_zero = -0.0
print("1/+0.0 =", 1.0 / pos_zero)
print("1/-0.0 =", 1.0 / neg_zero)
print("is neg_zero negative?",
      math.copysign(1.0, neg_zero) < 0.0)
```

---

## 17. 마무리 — “표시는 계약이다”

- 비트는 그 자체로 아무 의미가 없다.
- 의미는 **표현 규약**(정수/실수/문자/포인터/플래그)과  
  **언어·플랫폼이 약속한 의미론** 위에서만 정해진다.
- 같은 비트열도
  - 2의 보수 정수로 보면 어떤 값,
  - IEEE 754 float로 보면 다른 값,
  - UTF-8 문자열로 보면 또 다른 의미를 갖는다.

안전하고 예측 가능한 시스템을 만들기 위해서는

1. **어떤 규약을 쓰는지 분명히 문서화**하고,
2. 그 규약이 코드·테스트·도구에 **일관되게 반영**되어야 한다.

비트는 언어가 아니다.  
하지만 우리가 정의한 **“표시 규약”과 “해석 규칙”**을 만나는 순간,  
비트는 숫자·문자·주소·플래그라는 **언어**가 된다.  
이 글의 목표는 그 변환 과정을 **끝까지 의식적으로 보는 눈**을 기르는 데 있다.