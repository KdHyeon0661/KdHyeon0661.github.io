---
layout: post
title: 파이썬 - 외장함수
date: 2024-08-16 19:20:23 +0900
category: Python
---
# 파이썬 외장 모듈 정리 – 표준 라이브러리 핵심 요약

파이썬의 강력한 기능 중 하나는 풍부한 표준 라이브러리입니다. 이번 글에서는 실무에서 자주 사용되는 핵심 외장 모듈들을 체계적으로 살펴보겠습니다. 각 모듈의 주요 기능과 실전 활용법을 중심으로 설명하겠습니다.

## functools - 고차 함수와 데코레이터

`functools` 모듈은 함수를 다루는 고급 도구들을 제공합니다. 메모이제이션, 부분 적용, 데코레이터 작성을 위한 유틸리티 등 함수형 프로그래밍에 유용한 기능들이 포함되어 있습니다.

### 주요 기능과 활용

```python
from functools import lru_cache, partial, wraps, reduce, singledispatch
import time

# 1. lru_cache - 메모이제이션 데코레이터
@lru_cache(maxsize=128)
def fibonacci(n: int) -> int:
    """재귀적으로 피보나치 수 계산 (성능 향상)"""
    if n < 2:
        return n
    return fibonacci(n-1) + fibonacci(n-2)

# 캐시 효과 확인
start = time.time()
result = fibonacci(35)
print(f"fibonacci(35) = {result}, 시간: {time.time() - start:.4f}초")

# 2. partial - 함수 부분 적용
def power(base, exponent):
    return base ** exponent

# 2의 거듭제곱 함수 생성
power_of_two = partial(power, 2)
print(f"2^3 = {power_of_two(3)}")  # 8
print(f"2^5 = {power_of_two(5)}")  # 32

# 3. wraps - 데코레이터 메타데이터 보존
def timing_decorator(func):
    """함수 실행 시간 측정 데코레이터"""
    @wraps(func)  # 원본 함수의 메타데이터 보존
    def wrapper(*args, **kwargs):
        start = time.perf_counter()
        result = func(*args, **kwargs)
        elapsed = time.perf_counter() - start
        print(f"{func.__name__} 실행 시간: {elapsed:.6f}초")
        return result
    return wrapper

@timing_decorator
def slow_function():
    """느린 작업 시뮬레이션"""
    time.sleep(0.1)
    return "완료"

print(slow_function.__name__)  # wraps 덕분에 'slow_function'이 유지됨
slow_function()

# 4. singledispatch - 함수 오버로딩
@singledispatch
def process(data):
    """기본 처리 함수"""
    print(f"기본 처리: {type(data)}")

@process.register(str)
def _(data: str):
    """문자열 처리"""
    print(f"문자열 길이: {len(data)}")

@process.register(list)
def _(data: list):
    """리스트 처리"""
    print(f"리스트 항목 수: {len(data)}")

# 타입에 따른 동적 처리
process("hello")      # 문자열 길이: 5
process([1, 2, 3])    # 리스트 항목 수: 3
process(3.14)         # 기본 처리: <class 'float'>

# 5. reduce - 누적 연산
from functools import reduce
from operator import mul

numbers = [1, 2, 3, 4, 5]
product = reduce(mul, numbers)
print(f"1~5의 곱: {product}")  # 120
```

### 실무 활용 팁

1. **`lru_cache` 주의사항**: 인자가 해시 가능해야 하며, 함수가 순수 함수(부작용 없음)일 때만 사용하세요.
2. **`partial`의 활용**: 콜백 함수에 기본 인자를 제공하거나, 함수 팩토리 패턴에서 유용하게 사용할 수 있습니다.
3. **`singledispatch` 활용**: 타입에 따라 다른 동작이 필요한 유틸리티 함수 작성에 적합합니다.

---

## itertools - 반복 처리를 위한 강력한 도구

`itertools` 모듈은 반복 가능한 객체를 처리하기 위한 효율적인 도구들을 제공합니다. 메모리 효율성이 뛰어나며 대용량 데이터 처리에 특히 유용합니다.

### 주요 이터레이터와 활용

```python
import itertools
import operator
from collections import Counter

# 1. 무한 시퀀스 생성
# count: 시작값부터 무한히 증가
counter = itertools.count(start=10, step=2)
first_five = list(itertools.islice(counter, 5))
print(f"count 결과: {first_five}")  # [10, 12, 14, 16, 18]

# cycle: 시퀀스를 무한 반복
colors = ['red', 'green', 'blue']
color_cycle = itertools.cycle(colors)
first_six_colors = list(itertools.islice(color_cycle, 6))
print(f"cycle 결과: {first_six_colors}")  # ['red', 'green', 'blue', 'red', 'green', 'blue']

# 2. 조합과 순열
items = ['A', 'B', 'C']

# 순열 (순서 중요)
permutations = list(itertools.permutations(items, 2))
print(f"순열(2개): {permutations}")  # [('A', 'B'), ('A', 'C'), ('B', 'A'), ('B', 'C'), ('C', 'A'), ('C', 'B')]

# 조합 (순서 무관)
combinations = list(itertools.combinations(items, 2))
print(f"조합(2개): {combinations}")  # [('A', 'B'), ('A', 'C'), ('B', 'C')]

# 중복 조합
combinations_with_replacement = list(itertools.combinations_with_replacement(items, 2))
print(f"중복조합: {combinations_with_replacement}")  # [('A', 'A'), ('A', 'B'), ('A', 'C'), ('B', 'B'), ('B', 'C'), ('C', 'C')]

# 3. 그룹화와 필터링
# groupby: 연속된 동일한 요소 그룹화
data = [1, 1, 2, 3, 3, 3, 4, 4, 5]
grouped = [(key, list(group)) for key, group in itertools.groupby(data)]
print(f"groupby 결과: {grouped}")  # [(1, [1, 1]), (2, [2]), (3, [3, 3, 3]), (4, [4, 4]), (5, [5])]

# filterfalse: 조건이 False인 요소만 필터링
numbers = range(10)
odd_numbers = list(itertools.filterfalse(lambda x: x % 2 == 0, numbers))
print(f"홀수만: {odd_numbers}")  # [1, 3, 5, 7, 9]

# 4. 누적 연산과 체이닝
# accumulate: 누적 계산
cumulative_sum = list(itertools.accumulate([1, 2, 3, 4, 5]))
print(f"누적합: {cumulative_sum}")  # [1, 3, 6, 10, 15]

cumulative_max = list(itertools.accumulate([3, 1, 4, 1, 5], max))
print(f"누적 최대값: {cumulative_max}")  # [3, 3, 4, 4, 5]

# chain: 여러 시퀀스 연결
combined = list(itertools.chain('ABC', 'DEF', [1, 2, 3]))
print(f"체인 결과: {combined}")  # ['A', 'B', 'C', 'D', 'E', 'F', 1, 2, 3]

# 5. 실전 예제: 슬라이딩 윈도우
def sliding_window(sequence, window_size):
    """슬라이딩 윈도우 생성"""
    iters = itertools.tee(sequence, window_size)
    for i, it in enumerate(iters):
        next(itertools.islice(it, i, i), None)  # 각 이터레이터를 i만큼 이동
    return zip(*iters)

data_stream = [10, 20, 30, 40, 50, 60]
windows = list(sliding_window(data_stream, 3))
print(f"슬라이딩 윈도우(크기 3): {windows}")  # [(10, 20, 30), (20, 30, 40), (30, 40, 50), (40, 50, 60)]

# 이동 평균 계산
for window in windows:
    avg = sum(window) / len(window)
    print(f"윈도우 {window}의 평균: {avg:.2f}")
```

### 성능 최적화 팁

1. **메모리 효율성**: `itertools` 함수들은 제너레이터를 반환하므로 큰 데이터셋을 처리할 때 메모리를 효율적으로 사용할 수 있습니다.
2. **필요할 때만 변환**: `list()`로 변환하기 전에 제너레이터 상태로 가능한 한 오래 유지하세요.
3. **체인 활용**: `itertools.chain()`은 큰 데이터셋을 연결할 때 특히 유용합니다.

---

## os와 pathlib - 파일 시스템 작업

파일 시스템 작업을 위한 두 가지 주요 모듈로, `os`는 전통적인 방식, `pathlib`은 객체지향적인 방식으로 경로를 다룹니다.

### os 모듈 활용

```python
import os
import shutil

# 1. 디렉토리 작업
current_dir = os.getcwd()
print(f"현재 작업 디렉토리: {current_dir}")

# 디렉토리 생성
os.makedirs("test_folder/subfolder", exist_ok=True)

# 파일 목록 확인
files = os.listdir(".")
print(f"현재 디렉토리 파일들: {files[:5]}")  # 처음 5개만 출력

# 2. 경로 조작
file_path = os.path.join("test_folder", "data.txt")
print(f"생성된 경로: {file_path}")

# 경로 분해
dirname, filename = os.path.split(file_path)
print(f"디렉토리: {dirname}, 파일명: {filename}")

# 파일 확장자 분리
name, ext = os.path.splitext(filename)
print(f"파일명: {name}, 확장자: {ext}")

# 3. 파일 작업
# 파일 존재 확인
if not os.path.exists(file_path):
    with open(file_path, 'w', encoding='utf-8') as f:
        f.write("테스트 데이터\n")
    print("파일 생성 완료")

# 파일 정보 확인
if os.path.exists(file_path):
    file_size = os.path.getsize(file_path)
    mod_time = os.path.getmtime(file_path)
    print(f"파일 크기: {file_size}바이트, 수정시간: {mod_time}")

# 4. 재귀적 파일 탐색
def find_files_by_extension(directory, extension):
    """특정 확장자를 가진 모든 파일 찾기"""
    found_files = []
    for root, dirs, files in os.walk(directory):
        for file in files:
            if file.endswith(extension):
                found_files.append(os.path.join(root, file))
    return found_files

# 5. 파일 복사 및 이동
shutil.copy(file_path, "test_folder/data_backup.txt")
print("파일 복사 완료")
```

### pathlib 모듈 활용 (현대적 접근)

```python
from pathlib import Path
import datetime

# 1. 경로 객체 생성
current_dir = Path.cwd()
home_dir = Path.home()
file_path = Path("test_folder") / "data.txt"  # / 연산자로 경로 결합

print(f"현재 디렉토리: {current_dir}")
print(f"홈 디렉토리: {home_dir}")
print(f"파일 경로: {file_path}")

# 2. 디렉토리 생성과 파일 작업
file_path.parent.mkdir(parents=True, exist_ok=True)  # 부모 디렉토리 생성

# 파일 쓰기 (간편한 API)
file_path.write_text("Pathlib으로 작성된 데이터\n", encoding='utf-8')

# 파일 읽기
content = file_path.read_text(encoding='utf-8')
print(f"파일 내용: {content}")

# 3. 경로 정보 확인
print(f"파일명: {file_path.name}")
print(f"확장자: {file_path.suffix}")
print(f"상위 디렉토리: {file_path.parent}")
print(f"절대 경로: {file_path.resolve()}")

# 4. 파일 검색
py_files = list(Path(".").glob("*.py"))  # 현재 디렉토리의 모든 .py 파일
print(f"Python 파일들: {[p.name for p in py_files[:3]]}")

# 재귀적 검색
all_py_files = list(Path(".").rglob("*.py"))  # 하위 디렉토리 포함
print(f"모든 Python 파일 수: {len(all_py_files)}")

# 5. 파일 메타데이터
if file_path.exists():
    stat_info = file_path.stat()
    print(f"파일 크기: {stat_info.st_size} 바이트")
    print(f"생성 시간: {datetime.datetime.fromtimestamp(stat_info.st_ctime)}")
    print(f"수정 시간: {datetime.datetime.fromtimestamp(stat_info.st_mtime)}")

# 6. 실전 예제: 프로젝트 파일 정리
def organize_files_by_type(source_dir: Path):
    """파일을 확장자별로 정리"""
    for file_path in source_dir.iterdir():
        if file_path.is_file():
            ext = file_path.suffix.lower()
            if ext:  # 확장자가 있는 경우
                target_dir = source_dir / ext[1:]  # 확장자명으로 디렉토리 생성 (예: .txt -> txt/)
                target_dir.mkdir(exist_ok=True)
                new_path = target_dir / file_path.name
                file_path.rename(new_path)
                print(f"{file_path.name} -> {new_path}")
```

### 선택 가이드

- **새로운 프로젝트**: `pathlib` 사용을 권장합니다. 객체지향 API가 더 직관적이고 안전합니다.
- **레거시 코드**: `os.path` 모듈과의 호환성이 필요할 수 있습니다.
- **복잡한 파일 작업**: 두 모듈을 조합하여 사용할 수 있습니다.

---

## collections - 고급 자료구조

`collections` 모듈은 파이썬의 기본 자료구조를 보완하는 고급 컨테이너 데이터 타입들을 제공합니다.

### 주요 컨테이너 타입

```python
from collections import Counter, defaultdict, deque, namedtuple, OrderedDict
from typing import List, Dict
import heapq

# 1. Counter - 요소 개수 세기
def analyze_text(text: str) -> Dict[str, int]:
    """텍스트 분석: 단어 빈도 계산"""
    words = text.lower().split()
    word_counts = Counter(words)
    return dict(word_counts.most_common(5))  # 상위 5개 단어

sample_text = "apple banana apple orange banana apple mango apple"
result = analyze_text(sample_text)
print(f"단어 빈도 분석: {result}")  # {'apple': 4, 'banana': 2, 'orange': 1, 'mango': 1}

# 2. defaultdict - 기본값이 있는 딕셔너리
def group_by_category(items: List[tuple]) -> Dict[str, List[str]]:
    """항목들을 카테고리별로 그룹화"""
    grouped = defaultdict(list)
    for category, item in items:
        grouped[category].append(item)
    return dict(grouped)

items = [("fruit", "apple"), ("fruit", "banana"), 
         ("vegetable", "carrot"), ("fruit", "orange")]
print(f"그룹화 결과: {group_by_category(items)}")

# 3. deque - 양방향 큐
class RecentItems:
    """최근 항목 관리 (슬라이딩 윈도우)"""
    def __init__(self, maxlen: int = 5):
        self.items = deque(maxlen=maxlen)
    
    def add(self, item):
        """새 항목 추가 (오래된 항목 자동 제거)"""
        self.items.append(item)
    
    def get_recent(self) -> List:
        """최근 항목 반환 (최신 순)"""
        return list(self.items)
    
    def get_oldest(self):
        """가장 오래된 항목 반환"""
        return self.items[0] if self.items else None

recent = RecentItems(3)
for i in range(5):
    recent.add(f"item_{i}")
print(f"최근 항목: {recent.get_recent()}")  # ['item_2', 'item_3', 'item_4']

# 4. namedtuple - 명명된 튜플
# 기본 사용
Point = namedtuple('Point', ['x', 'y'])
p = Point(10, 20)
print(f"점: ({p.x}, {p.y})")  # 점: (10, 20)

# 실전 예제: 데이터 레코드
Employee = namedtuple('Employee', ['id', 'name', 'position', 'salary'])

def process_employees(employees: List[tuple]) -> List[Employee]:
    """튜플 리스트를 Employee 객체로 변환"""
    return [Employee(*emp) for emp in employees]

emp_data = [
    (101, "김철수", "개발자", 5000),
    (102, "이영희", "디자이너", 4500),
    (103, "박민수", "관리자", 6000)
]

employees = process_employees(emp_data)
for emp in employees:
    print(f"{emp.name} ({emp.position}): ${emp.salary}")

# 5. OrderedDict - 순서가 보존되는 딕셔너리
def create_ordered_config() -> OrderedDict:
    """설정값을 순서대로 저장"""
    config = OrderedDict()
    config['database'] = 'postgresql'
    config['host'] = 'localhost'
    config['port'] = 5432
    config['timeout'] = 30
    return config

config = create_ordered_config()
print("설정 항목 (순서 보존):")
for key, value in config.items():
    print(f"  {key}: {value}")

# 6. ChainMap - 여러 딕셔너리 연결
from collections import ChainMap

def merge_configs(*configs: Dict) -> ChainMap:
    """여러 설정 딕셔너리 병합 (첫 번째 우선)"""
    return ChainMap(*configs)

default_config = {'theme': 'light', 'language': 'en'}
user_config = {'language': 'ko', 'font_size': 14}
session_config = {'theme': 'dark'}

merged = merge_configs(session_config, user_config, default_config)
print(f"병합된 설정: theme={merged['theme']}, language={merged['language']}")
```

### 실전 활용 패턴

1. **데이터 분석**: `Counter`를 사용한 빈도 분석
2. **그룹화 작업**: `defaultdict`를 사용한 효율적인 그룹핑
3. **최근 항목 관리**: `deque`를 사용한 슬라이딩 윈도우
4. **구조화된 데이터**: `namedtuple`을 사용한 간단한 데이터 클래스 대체

---

## datetime - 날짜와 시간 처리

`datetime` 모듈은 날짜와 시간을 다루기 위한 포괄적인 기능을 제공합니다.

### 기본 사용법과 실전 예제

```python
from datetime import datetime, date, time, timedelta
from zoneinfo import ZoneInfo  # Python 3.9+
import time as time_module

# 1. 현재 시간 얻기
now = datetime.now()
print(f"현재 시간: {now}")
print(f"형식화: {now.strftime('%Y-%m-%d %H:%M:%S')}")

# UTC 시간
utc_now = datetime.utcnow()
print(f"UTC 시간: {utc_now}")

# 타임스탬프
timestamp = datetime.timestamp(now)
print(f"타임스탬프: {timestamp}")

# 2. 날짜와 시간 생성
specific_date = date(2024, 8, 16)
specific_time = time(14, 30, 45)
specific_datetime = datetime(2024, 8, 16, 14, 30, 45)

print(f"특정 날짜: {specific_date}")
print(f"특정 시간: {specific_time}")
print(f"특정 날짜시간: {specific_datetime}")

# 3. 시간 덧셈과 뺄셈
one_day = timedelta(days=1)
three_hours = timedelta(hours=3)

tomorrow = now + one_day
yesterday = now - one_day
in_three_hours = now + three_hours

print(f"내일: {tomorrow.date()}")
print(f"어제: {yesterday.date()}")
print(f"3시간 후: {in_three_hours.time()}")

# 4. 시간 차이 계산
start_time = datetime(2024, 8, 16, 9, 0, 0)
end_time = datetime(2024, 8, 16, 17, 30, 0)

work_duration = end_time - start_time
print(f"근무 시간: {work_duration}")
print(f"총 시간: {work_duration.total_seconds() / 3600:.1f}시간")

# 5. 날짜 비교
date1 = date(2024, 8, 16)
date2 = date(2024, 8, 20)

print(f"date1 < date2: {date1 < date2}")
print(f"date1 == date2: {date1 == date2}")

# 6. 시간대 처리 (Python 3.9+)
try:
    # 서울과 뉴욕 시간대
    seoul_tz = ZoneInfo("Asia/Seoul")
    ny_tz = ZoneInfo("America/New_York")
    
    # 시간대 인식 datetime 생성
    meeting_seoul = datetime(2024, 8, 16, 15, 0, 0, tzinfo=seoul_tz)
    meeting_ny = meeting_seoul.astimezone(ny_tz)
    
    print(f"서울 회의 시간: {meeting_seoul}")
    print(f"뉴욕 회의 시간: {meeting_ny}")
except ImportError:
    print("zoneinfo 모듈을 사용할 수 없습니다 (Python 3.9+ 필요)")

# 7. 실전 예제: 로그 분석기
class LogAnalyzer:
    """로그 파일 시간 분석"""
    
    @staticmethod
    def parse_log_timestamp(log_line: str) -> datetime:
        """로그 라인에서 타임스탬프 파싱"""
        # 예: "[2024-08-16 14:30:45] ERROR: Something went wrong"
        try:
            timestamp_str = log_line[1:20]  # 대괄호 안의 타임스탬프 추출
            return datetime.strptime(timestamp_str, "%Y-%m-%d %H:%M:%S")
        except (ValueError, IndexError):
            return None
    
    @staticmethod
    def analyze_log_frequency(log_lines: List[str], interval_minutes: int = 5) -> Dict[datetime, int]:
        """로그 빈도 분석 (시간 간격별)"""
        frequency = defaultdict(int)
        
        for line in log_lines:
            timestamp = LogAnalyzer.parse_log_timestamp(line)
            if timestamp:
                # 시간 간격으로 그룹화 (예: 5분 간격)
                interval_start = timestamp.replace(
                    minute=(timestamp.minute // interval_minutes) * interval_minutes,
                    second=0,
                    microsecond=0
                )
                frequency[interval_start] += 1
        
        return dict(sorted(frequency.items()))

# 8. 성능 측정 데코레이터
def timing_decorator(func):
    """함수 실행 시간 측정"""
    def wrapper(*args, **kwargs):
        start_time = time_module.perf_counter()
        result = func(*args, **kwargs)
        end_time = time_module.perf_counter()
        elapsed = end_time - start_time
        
        print(f"{func.__name__} 실행 시간: {elapsed:.6f}초")
        return result
    return wrapper

@timing_decorator
def slow_operation():
    """느린 작업 시뮬레이션"""
    time_module.sleep(0.5)
    return "완료"

slow_operation()
```

### 시간 처리 모범 사례

1. **일관된 시간대 사용**: 내부 저장은 UTC를 사용하고, 표시할 때만 현지 시간대로 변환하세요.
2. **`datetime` vs `date` vs `time`**: 필요에 맞는 클래스를 선택하세요.
3. **문자열 변환**: `strftime`과 `strptime`을 사용한 일관된 형식 유지
4. **시간 덧셈**: `timedelta`를 사용하여 직접 계산하지 마세요.

---

## hashlib - 해시 함수

`hashlib` 모듈은 보안 해시 함수와 메시지 다이제스트 알고리즘을 제공합니다.

### 기본 사용법과 실전 응용

```python
import hashlib
import os
from typing import Union, BinaryIO

class FileIntegrityChecker:
    """파일 무결성 검사기"""
    
    SUPPORTED_ALGORITHMS = {
        'md5': hashlib.md5,
        'sha1': hashlib.sha1,
        'sha256': hashlib.sha256,
        'sha512': hashlib.sha512
    }
    
    @staticmethod
    def calculate_file_hash(filepath: str, algorithm: str = 'sha256', 
                          chunk_size: int = 8192) -> str:
        """
        대용량 파일의 해시값 계산 (청크 단위 처리)
        
        Args:
            filepath: 파일 경로
            algorithm: 해시 알고리즘 (md5, sha1, sha256, sha512)
            chunk_size: 한 번에 읽을 청크 크기
            
        Returns:
            파일의 해시값 (16진수 문자열)
        """
        if algorithm not in FileIntegrityChecker.SUPPORTED_ALGORITHMS:
            raise ValueError(f"지원하지 않는 알고리즘: {algorithm}")
        
        hash_func = FileIntegrityChecker.SUPPORTED_ALGORITHMS[algorithm]()
        
        try:
            with open(filepath, 'rb') as f:
                # 청크 단위로 읽어 해시 업데이트
                while chunk := f.read(chunk_size):
                    hash_func.update(chunk)
        except FileNotFoundError:
            raise FileNotFoundError(f"파일을 찾을 수 없습니다: {filepath}")
        except IOError as e:
            raise IOError(f"파일 읽기 오류: {e}")
        
        return hash_func.hexdigest()
    
    @staticmethod
    def verify_file_integrity(filepath: str, expected_hash: str, 
                            algorithm: str = 'sha256') -> bool:
        """파일 무결성 검증"""
        try:
            actual_hash = FileIntegrityChecker.calculate_file_hash(filepath, algorithm)
            return actual_hash == expected_hash.lower()
        except Exception as e:
            print(f"검증 실패: {e}")
            return False
    
    @staticmethod
    def create_checksum_file(directory: str, output_file: str = 'checksums.txt'):
        """디렉토리 내 모든 파일의 체크섬 생성"""
        with open(output_file, 'w', encoding='utf-8') as f_out:
            for root, dirs, files in os.walk(directory):
                for filename in files:
                    filepath = os.path.join(root, filename)
                    try:
                        # 상대 경로 계산
                        rel_path = os.path.relpath(filepath, directory)
                        file_hash = FileIntegrityChecker.calculate_file_hash(filepath)
                        f_out.write(f"{file_hash}  {rel_path}\n")
                        print(f"처리 완료: {rel_path}")
                    except Exception as e:
                        print(f"처리 실패 {filepath}: {e}")

# 사용 예제
if __name__ == "__main__":
    # 테스트 파일 생성
    test_file = "test_data.txt"
    with open(test_file, 'w', encoding='utf-8') as f:
        f.write("테스트 데이터입니다.\n" * 1000)
    
    # 파일 해시 계산
    checker = FileIntegrityChecker()
    
    print("=== 다양한 알고리즘으로 해시 계산 ===")
    for algo in ['md5', 'sha1', 'sha256', 'sha512']:
        try:
            file_hash = checker.calculate_file_hash(test_file, algo)
            print(f"{algo.upper()}: {file_hash[:32]}...")
        except Exception as e:
            print(f"{algo} 계산 실패: {e}")
    
    print("\n=== 파일 무결성 검증 ===")
    # 올바른 해시값 (SHA-256)
    correct_hash = checker.calculate_file_hash(test_file, 'sha256')
    
    # 검증 테스트
    is_valid = checker.verify_file_integrity(test_file, correct_hash, 'sha256')
    print(f"올바른 해시 검증: {'성공' if is_valid else '실패'}")
    
    # 잘못된 해시값으로 검증
    is_valid_fake = checker.verify_file_integrity(test_file, '0' * 64, 'sha256')
    print(f"잘못된 해시 검증: {'성공' if is_valid_fake else '실패'}")
    
    print("\n=== 문자열 해시 ===")
    # 문자열 해시 계산
    password = "my_secret_password"
    salt = os.urandom(16)  # 솔트 생성
    
    # 안전한 비밀번호 해시 (솔트 추가)
    password_hash = hashlib.pbkdf2_hmac(
        'sha256',
        password.encode('utf-8'),
        salt,
        100000  # 반복 횟수
    )
    
    print(f"비밀번호 해시 (솔트 포함): {password_hash.hex()}")
    print(f"솔트: {salt.hex()}")
    
    # 클래스 예제: 체크섬 파일 생성
    print("\n=== 체크섬 파일 생성 ===")
    test_dir = "test_directory"
    os.makedirs(test_dir, exist_ok=True)
    
    # 테스트 파일들 생성
    for i in range(3):
        with open(os.path.join(test_dir, f"file_{i}.txt"), 'w') as f:
            f.write(f"내용 {i}\n" * 100)
    
    checker.create_checksum_file(test_dir, "test_checksums.txt")
    
    print("\n생성된 체크섬 파일 내용:")
    with open("test_checksums.txt", 'r', encoding='utf-8') as f:
        print(f.read())
    
    # 정리
    os.remove(test_file)
    for i in range(3):
        os.remove(os.path.join(test_dir, f"file_{i}.txt"))
    os.rmdir(test_dir)
    os.remove("test_checksums.txt")
```

### 보안 주의사항

1. **비밀번호 저장**: 단순 해시만으로는 충분하지 않습니다. `pbkdf2_hmac`, `scrypt`, `argon2` 같은 키 유도 함수(KDF)를 사용하세요.
2. **솔트 사용**: 항상 고유한 솔트를 사용하여 레인보우 테이블 공격을 방지하세요.
3. **알고리즘 선택**: `md5`와 `sha1`은 보안 목적으로 사용하지 마세요. `sha256` 이상을 사용하세요.
4. **파일 무결성**: 대용량 파일은 청크 단위로 처리하여 메모리 효율성을 높이세요.

---

## sys 모듈 - 시스템 관련 기능

`sys` 모듈은 인터프리터와 런타임 환경에 대한 접근을 제공합니다.

### 주요 기능과 활용

```python
import sys
import os

# 1. 명령줄 인자 처리
def process_command_line_args():
    """명령줄 인자 처리"""
    print(f"스크립트 이름: {sys.argv[0]}")
    
    if len(sys.argv) > 1:
        print(f"전달된 인자들: {sys.argv[1:]}")
        
        # 간단한 옵션 처리
        if '--help' in sys.argv or '-h' in sys.argv:
            print("사용법: python script.py [옵션]")
            print("옵션:")
            print("  --help, -h    도움말 표시")
            print("  --version     버전 정보")
            sys.exit(0)
        
        if '--version' in sys.argv:
            print(f"Python 버전: {sys.version}")
            sys.exit(0)
    else:
        print("인자가 없습니다. --help를 참조하세요.")

# 2. Python 실행 환경 정보
def show_system_info():
    """시스템 정보 표시"""
    print(f"Python 버전: {sys.version}")
    print(f"버전 정보: {sys.version_info}")
    print(f"플랫폼: {sys.platform}")
    print(f"실행 파일 경로: {sys.executable}")
    print(f"기본 인코딩: {sys.getdefaultencoding()}")
    print(f"파일 시스템 인코딩: {sys.getfilesystemencoding()}")

# 3. 모듈 검색 경로
def manage_python_path():
    """Python 모듈 검색 경로 관리"""
    print(f"현재 모듈 검색 경로:")
    for i, path in enumerate(sys.path[:5], 1):  # 처음 5개만 출력
        print(f"  {i}. {path}")
    
    # 현재 디렉토리 추가 (일시적)
    current_dir = os.getcwd()
    if current_dir not in sys.path:
        sys.path.insert(0, current_dir)
        print(f"\n현재 디렉토리를 경로에 추가함: {current_dir}")

# 4. 표준 입출력
def custom_input_output():
    """사용자 정의 입출력 예제"""
    
    # 표준 출력 리다이렉션
    original_stdout = sys.stdout
    
    try:
        # 파일로 출력 리다이렉션
        with open('output.log', 'w', encoding='utf-8') as f:
            sys.stdout = f
            print("이 메시지는 파일에 기록됩니다.")
            print("표준 출력이 리다이렉션되었습니다.")
    finally:
        sys.stdout = original_stdout  #