---
layout: post
title: 운영체제 - 프로세스 (1)
date: 2025-10-15 20:25:23 +0900
category: 운영체제
---
# Chapter 3 — Processes  
*(3.1 Process Concept • 3.2 Process Scheduling • 3.3 Operations on Processes — with runnable examples)*

운영체제의 핵심 단위는 **프로세스(Process)**다. 본 장에서는 **프로세스의 개념(3.1)**, **스케줄링(3.2)**, **프로세스 연산(3.3)**을 **구체 예제 코드**와 함께 정리한다.  
실습은 리눅스/유닉스 계열을 기준으로 하며, 일부는 관리자 권한이 필요할 수 있다.

---

## 3.1 Process Concept

### 3.1.1 정의와 주소 공간

- **프로세스**는 “실행 중인 프로그램”의 인스턴스. 코드(텍스트), 데이터/힙, 스택, **열린 파일**, **레지스터 컨텍스트** 등으로 구성.
- **주소 공간(Address Space)**: 각 프로세스는 고유의 가상 주소 공간을 가진다. 일반적으로
  - **텍스트(text)**: 실행 코드(보통 읽기+실행)
  - **데이터(data/bss)**: 전역/정적 변수
  - **힙(heap)**: 동적 할당(`malloc/new`)
  - **스택(stack)**: 지역 변수/호출 프레임

### 3.1.2 PCB와 상태

- **PCB(Process Control Block)**: PID, 상태, 레지스터 값, 프로그램 카운터, 스케줄링 정보, 메모리 매핑, 파일 디스크립터 등.
- **상태 전이**: `New → Ready → Running → (Blocked ↔ Ready) → Terminated`

### 3.1.3 컨텍스트 스위치

- CPU가 한 프로세스에서 다른 프로세스로 전환할 때, 커널은 **레지스터/PC/스택 포인터/메모리 맵**을 저장·복원한다.
- 비용은 하드웨어/커널 구현에 따라 다르며, 캐시/TLB 효과도 중요.

### 3.1.4 프로세스 vs 스레드

- **프로세스**는 주소 공간이 분리되어 **격리**가 강함.
- **스레드(경량 프로세스)**는 같은 프로세스 내에서 **주소 공간을 공유**. 컨텍스트 스위치 비용이 더 낮고 공유 메모리를 통한 통신이 빠르지만 **동기화 오류** 위험이 있다.

### 3.1.5 예제: 현재 프로세스의 메모리 레이아웃 관찰
```c
// mem_layout.c
#include <stdio.h>
#include <stdlib.h>
int g = 42;              // data
int main(){
    static int s = 7;    // data/bss
    int local = 1;       // stack
    void* heap = malloc(16); // heap
    printf("text(main): %p\n", (void*)&main);
    printf("data(g):    %p\n", (void*)&g);
    printf("data(s):    %p\n", (void*)&s);
    printf("stack:      %p\n", (void*)&local);
    printf("heap:       %p\n", heap);
    getchar(); // /proc/<pid>/maps를 열어보자
    return 0;
}
```
```bash
gcc -O2 mem_layout.c -o mem_layout && ./mem_layout &
cat /proc/$!/maps | head
kill %1
```

### 3.1.6 예제: 프로세스 상태 전이(입출력 대기)
```c
// io_block.c — I/O 대기와 상태
#include <stdio.h>
#include <unistd.h>
#include <fcntl.h>
int main(){
    int fd = open("/dev/zero", O_RDONLY);
    char buf[1<<20];
    read(fd, buf, sizeof(buf)); // 빠른 블록 I/O
    printf("now sleeping...\n");
    sleep(5);                   // Blocked(타이머 대기) → Ready → Running
}
```

---

## 3.2 Process Scheduling

스케줄러는 **Ready** 큐의 프로세스들 중 **누가 다음에 CPU를 쓸지**를 결정한다.

### 3.2.1 목표와 지표

- **응답시간(Response time)**: 인터랙티브 시스템에서 중요 (작을수록 좋음)
- **대기시간(Waiting time)**: Ready 큐에서 기다린 시간 총합(작을수록 좋음)
- **처리량(Throughput)**: 단위 시간당 완료 작업 수(클수록 좋음)
- **CPU 이용률(Utilization)**: 바쁠수록 좋음(하지만 발열/전력 고려)

**간단 수식(평균 대기시간)**  
작업 $$i$$의 도착/서비스 시간이 주어질 때, 스케줄 정책에 따라 **평균 대기시간** $$\bar{W}$$는
$$
\bar{W}=\frac{1}{n}\sum_{i=1}^{n}W_i,\qquad W_i=T_i-S_i
$$
여기서 $$T_i$$는 총 소요시간(완료시각−도착시각), $$S_i$$는 서비스 시간.

### 3.2.2 대표 스케줄링 알고리즘

- **FCFS (First-Come, First-Served)**: 비선점·간단하지만 **콘보이 효과** 가능.
- **SJF/SRTF (Shortest Job First / Shortest Remaining Time First)**: 평균 대기시간 최소화(이론) — 실행시간 예측 필요, **기아(Starvation)** 위험.
- **RR (Round Robin)**: 시분할. 타임 슬라이스 $$q$$가 핵심. 너무 작으면 오버헤드↑, 너무 크면 FCFS에 가까워짐.
- **우선순위 스케줄링**: 정적/동적 우선순위. **에이징(Aging)**으로 기아 완화.
- **다단계 큐/피드백(MLQ/MLFQ)**: 반응성+처리량 절충. MLFQ는 CPU를 많이 쓰면 하위 큐로 **강등**, I/O 바운드 작업은 상위 큐 유지.
- **CFS (Completely Fair Scheduler, Linux)**: **가상 런타임(vruntime)** 기반 — 각 태스크가 “공정”한 CPU 점유를 받도록 **RB-tree**에서 가장 vruntime이 작은 태스크 선택.

### 3.2.3 스케줄러 시뮬레이터(FCFS/SJF/RR/MLFQ)

```python
# sched_sim.py — 간단 스케줄러 비교
from collections import deque
def fcfs(jobs):
    t=0; wait=[]
    for a,s in jobs:
        t=max(t,a); wait.append(t-a); t+=s
    return sum(wait)/len(jobs)

def sjf(jobs):
    t=0; wait=[]; pool=[]; i=0; jobs=sorted(jobs)
    while i<len(jobs) or pool:
        while i<len(jobs) and jobs[i][0]<=t:
            pool.append(jobs[i]); i+=1
        if not pool: t=jobs[i][0]; continue
        # 가장 짧은 서비스 시간 선택
        pool.sort(key=lambda x:x[1]); a,s = pool.pop(0)
        wait.append(t-a); t+=s
    return sum(wait)/len(jobs)

def rr(jobs, q=2):
    t=0; wait={}; ready=deque(); i=0; jobs=sorted(jobs)
    last_seen={}
    def enq(job):
        ready.append([job[0],job[1],job[2]]) # (a, remaining, id)
    jid=0; jobs=[(a,s,j) for (a,s),j in zip(jobs,range(len(jobs)))]
    while i<len(jobs) or ready:
        while i<len(jobs) and jobs[i][0]<=t:
            enq(list(jobs[i])); last_seen[jobs[i][2]]=t; i+=1
        if not ready: t=jobs[i][0]; continue
        a,rem,ident = ready.popleft()
        # 대기시간 누적
        if ident in last_seen: wait[ident]=wait.get(ident,0)+ (t-last_seen[ident])
        run=min(q,rem); t+=run; rem-=run
        while i<len(jobs) and jobs[i][0]<=t:
            enq(list(jobs[i])); last_seen[jobs[i][2]]=t; i+=1
        if rem>0:
            ready.append([a,rem,ident]); last_seen[ident]=t
    return sum(wait.values())/len(jobs)

def mlfq(jobs, qs=(1,2,4), aging=None):
    # 매우 단순화된 MLFQ: 상위 큐일수록 q 작음, 타임 슬라이스 소진 시 강등
    t=0; levels=[deque() for _ in qs]; i=0; jobs=sorted(jobs)
    info={}
    def enq(j):
        info[j[2]]={"lvl":0,"rem":j[1],"last":t,"arr":j[0]}
        levels[0].append(j[2])
    jid=0; jobs=[(a,s,j) for (a,s),j in zip(jobs,range(len(jobs)))]
    while i<len(jobs) or any(levels):
        while i<len(jobs) and jobs[i][0]<=t:
            enq(jobs[i]); i+=1
        lvl = next((li for li,q in enumerate(qs) if levels[li]), None)
        if lvl is None: t=jobs[i][0]; continue
        pid = levels[lvl].popleft(); q=qs[lvl]
        rem=info[pid]["rem"]; run=min(q,rem)
        t+=run; info[pid]["rem"]-=run
        while i<len(jobs) and jobs[i][0]<=t:
            enq(jobs[i]); i+=1
        if info[pid]["rem"]>0:
            info[pid]["lvl"]=min(info[pid]["lvl"]+1, len(qs)-1)
            levels[info[pid]["lvl"]].append(pid)
    waits=[0]*len(jobs)
    # rough: 완료까지의 대기 추정(정밀 구현 생략)
    # 학습 목적으로는 RR와 경향 비교만 사용
    return "trend only"
# 사용 예
jobs=[(0,5),(1,3),(2,8),(3,6)]
print("FCFS avg wait:", fcfs(jobs))
print("SJF  avg wait:", sjf(jobs))
print("RR(q=2) wait:", rr(jobs,2))
```

**해석 팁**  
- **SJF**가 평균 대기시간에 유리하지만 예측이 필요.  
- **RR**은 응답성이 좋아 인터랙티브 워크로드에 적합.  
- **MLFQ**는 자동으로 “짧고 자주 깨지는(I/O 바운드) 작업”을 상위 큐에 유지시켜 반응성을 높인다.

### 3.2.4 선점 vs 비선점, 디스패처 지연

- **선점(Preemptive)**: 타이머 인터럽트로 타임 슬라이스 만료 시 강제 회수.
- **비선점(Non-preemptive)**: 태스크가 CPU를 자발적으로 내놓을 때까지 유지.
- **디스패처 지연**: 컨텍스트 스위치/캐시/TLB 손실 비용 → 슬라이스가 너무 작으면 오히려 손해.

---

## 3.3 Operations on Processes

### 3.3.1 생성과 종료

- **생성**: `fork()`로 부모의 주소 공간을 **복제(Copy-on-Write)**, `execve()`로 새 프로그램 적재.
- **종료**: `exit()` → 커널이 자원 회수. 부모가 `wait()`/`waitpid()`로 종료 상태 수거.
- **좀비(Zombie)**: 종료했지만 부모가 아직 `wait()`하지 않아 **PID 엔트리**가 남아있는 상태.
- **고아(Orphan)**: 부모가 먼저 죽은 경우. **init/systemd**가 입양하여 수거.

#### 예제: `fork+exec` 파이프라인 (ls | sort | uniq -c | head)
```c
// pipe_chain.c
#define _GNU_SOURCE
#include <unistd.h>
#include <sys/wait.h>
#include <stdlib.h>
#include <stdio.h>
void spawn(const char* cmd, char* const argv[], int in, int out){
    if(fork()==0){
        if(in!=0){ dup2(in,0); close(in); }
        if(out!=1){ dup2(out,1); close(out); }
        execvp(cmd, argv);
        perror("exec"); _exit(127);
    }
}
int main(){
    int p1[2],p2[2],p3[2]; pipe(p1); pipe(p2); pipe(p3);
    char* a1[]={"ls","-1",NULL};
    char* a2[]={"sort",NULL};
    char* a3[]={"uniq","-c",NULL};
    char* a4[]={"head","-n","10",NULL};

    spawn("ls", a1, 0, p1[1]); close(p1[1]);
    spawn("sort", a2, p1[0], p2[1]); close(p1[0]); close(p2[1]);
    spawn("uniq", a3, p2[0], p3[1]); close(p2[0]); close(p3[1]);
    spawn("head", a4, p3[0], 1);    close(p3[0]);

    while(wait(NULL)>0);
}
```

#### 예제: 좀비/고아 관찰
```c
// zombie_orphan.c
#include <sys/wait.h>
#include <unistd.h>
#include <stdio.h>
#include <stdlib.h>

int main(){
    pid_t p=fork();
    if(p==0){
        printf("child pid=%d, parent=%d\n", getpid(), getppid());
        _exit(0); // 즉시 종료 → 잠시 좀비가 됨
    }
    // 부모가 기다리지 않으면 child는 zombie
    sleep(2);
    // 이제 회수
    int st; waitpid(p,&st,0);
    printf("reaped %d\n", p);

    // 고아 만들기
    if(fork()==0){
        printf("orphan candidate pid=%d parent=%d\n", getpid(), getppid());
        sleep(3);
        // 여기서 부모가 이미 종료되었을 가능성 → parent가 1(systemd)로 바뀜
        printf("after sleep, parent=%d\n", getppid());
        _exit(0);
    }
    // 부모 즉시 종료 → 자식이 입양됨
    _exit(0);
}
```
```bash
gcc -O2 zombie_orphan.c -o zo && ./zo & ps -o pid,ppid,stat,comm | grep zo
```

### 3.3.2 IPC (Inter-Process Communication)

#### 1) 파이프(익명/명명)

- **익명 파이프**: 부모–자식 간 단방향 바이트스트림.
- **FIFO(명명 파이프)**: 파일 시스템 경로로 여러 프로세스 간 통신.

```c
// pipe_echo.c — 부모가 쓰고, 자식이 읽어서 대문자로 돌려줌
#include <unistd.h>
#include <ctype.h>
#include <string.h>
#include <sys/wait.h>
#include <stdio.h>
int main(){
    int a[2], b[2]; pipe(a); pipe(b);
    if(fork()==0){
        close(a[1]); close(b[0]);
        char buf[256]; int n=read(a[0],buf,sizeof(buf));
        for(int i=0;i<n;i++) buf[i]=toupper((unsigned char)buf[i]);
        write(b[1], buf, n); _exit(0);
    }
    close(a[0]); close(b[1]);
    write(a[1], "hello pipe\n", 11);
    char out[256]={0}; int n=read(b[0], out, sizeof(out));
    write(1, out, n);
    wait(NULL);
}
```

#### 2) 소켓(로컬/네트워크)

```c
// tcp_echo.c — 단일 클라이언트 에코 (개념)
#include <sys/socket.h>
#include <netinet/in.h>
#include <unistd.h>
int main(){
    int s=socket(AF_INET,SOCK_STREAM,0);
    struct sockaddr_in a={.sin_family=AF_INET,.sin_port=htons(9001),.sin_addr={0}};
    bind(s,(struct sockaddr*)&a,sizeof(a)); listen(s,1);
    int c=accept(s,NULL,NULL);
    char buf[1024]; int n;
    while((n=read(c,buf,sizeof(buf)))>0) write(c,buf,n);
}
```

#### 3) 공유 메모리 + 동기화

```c
// shm_sem_demo.c (요약 — POSIX shm + sem)
#define _GNU_SOURCE
#include <fcntl.h>
#include <sys/mman.h>
#include <semaphore.h>
#include <unistd.h>
#include <string.h>
#include <stdio.h>

typedef struct { sem_t lock; char buf[256]; } shm_t;

int main(int argc, char**argv){
    int fd = shm_open("/p3demo", O_CREAT|O_RDWR, 0600);
    ftruncate(fd, sizeof(shm_t));
    shm_t* s = mmap(NULL,sizeof(shm_t),PROT_READ|PROT_WRITE,MAP_SHARED,fd,0);
    if(argc>1 && !strcmp(argv[1],"init")){ sem_init(&s->lock,1,1); return 0; }
    if(argc>1 && !strcmp(argv[1],"w")){
        sem_wait(&s->lock); strcpy(s->buf,"shared hello"); sem_post(&s->lock); return 0;
    }
    if(argc>1 && !strcmp(argv[1],"r")){
        sem_wait(&s->lock); puts(s->buf); sem_post(&s->lock); return 0;
    }
    return 0;
}
```
```bash
gcc -O2 shm_sem_demo.c -o shm_sem_demo -pthread
./shm_sem_demo init
./shm_sem_demo w & ./shm_sem_demo r
```

#### 4) 시그널

- 비동기 알림. 종료/중단/사용자 정의 신호(`SIGUSR1/2`) 등.
- 처리기에서 **async-signal-safe** 함수만 호출(주의).

```c
// sig_usr.c
#include <signal.h>
#include <unistd.h>
#include <stdio.h>
void h(int s){ write(1,"SIGUSR1\n",8); }
int main(){
    struct sigaction sa={0}; sa.sa_handler=h; sigaction(SIGUSR1,&sa,NULL);
    printf("pid=%d\n", getpid());
    for(;;) pause();
}
```
```bash
./sig_usr &
kill -USR1 <pid>
```

### 3.3.3 협력(Producer–Consumer) — 파이프/공유메모리 버전 비교

- **파이프**: 구현 쉬우나 커널 경유 복사 비용(Zero-copy 아님).
- **공유 메모리**: 빠르지만 **동기화** 필수(뮤텍스/세마포/조건변수).

#### 공유 메모리 링버퍼 개념(요약 코드)
```c
// ringbuf.h (학습용, 동기화 미니)
typedef struct { size_t cap, head, tail; char data[4096]; } ring;
int rb_push(ring* r, char c){
    size_t n=(r->head+1)%r->cap; if(n==r->tail) return -1; r->data[r->head]=c; r->head=n; return 0;
}
int rb_pop(ring* r, char* out){
    if(r->head==r->tail) return -1; *out=r->data[r->tail]; r->tail=(r->tail+1)%r->cap; return 0;
}
```

---

## 요약 & 체크리스트

- **프로세스**: PCB/상태/주소 공간/컨텍스트 스위치/스레드 대비 격리성
- **스케줄링**: FCFS/SJF/SRTF/RR/우선순위/MLFQ/CFS, 지표(대기/응답/처리량)
- **연산**: 생성(fork/exec), 종료(exit/wait), 좀비/고아, IPC(파이프/소켓/공유메모리), 시그널
- **실습 포인트**: `strace`로 시스템콜 경로 보기, `time`으로 체감, 작은 스케줄러 시뮬로 정책 비교

---

## 추가 연습

1) **SRTF**와 **우선순위 스케줄러**를 `sched_sim.py`에 추가하고, 랜덤 작업 세트(포아송 도착, 지수 분포 서비스)를 생성해 **평균 대기/응답시간**을 비교하라.  
2) `pipe_chain.c`를 **N단계 파이프라인**으로 일반화하고, 각 단계의 **CPU vs I/O** 특성에 따라 **스루풋 병목**을 찾아라.  
3) 공유 메모리 링버퍼에 **세마포어**를 붙여 **다생산자/다소비자**로 확장하고, 경쟁을 유발하여 **락 경합**을 측정하라.  
4) `zombie_orphan.c`에서 부모가 `SIGCHLD` 신호를 수신하면 즉시 `waitpid(-1, …, WNOHANG)`으로 **비동기 회수**하도록 수정하라.

---

## 부록 — 간단 계산 예시(응답성 튜닝 직관)

라운드로빈에서 타임 슬라이스를 $$q$$, 컨텍스트 스위치 비용을 $$c$$, 평균 서비스 시간을 $$\bar{s}$$라 할 때,  
**오버헤드 비율**의 러프 모델은  
$$
\text{overhead} \approx \frac{c}{q+c}.
$$
- $$q \ll c$$이면 오버헤드가 커지고,  
- $$q \gg \bar{s}$$이면 RR의 장점(반응성)이 줄어듦.  
실무에서는 **워크로드**(I/O 바운드 vs CPU 바운드)를 관측하며 $$q$$를 설정한다.
