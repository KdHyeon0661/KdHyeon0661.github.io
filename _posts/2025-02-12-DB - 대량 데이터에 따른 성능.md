---
layout: post
title: DB - 대량 데이터에 따른 성능
date: 2025-02-12 19:20:23 +0900
category: DB
---
# 대량 데이터에 따른 성능 이슈와 대응 전략

## 0. 대량 데이터 개념과 **부하 추정** 빠른 감 잡기

### 0.1 “대량”의 감각적 기준
- **행 수 기준**: 수백만~수억 행
- **용량 기준**: 수십~수백 GB(OLTP 경계), 수 TB 이상(MPP/데이터웨어하우스 검토)
- **카디널리티/선택도**: 저선택도 필터(예: `status IN (...)`만으로 70%+)는 대량에서 Full/Range Scan 경향

### 0.2 **간단 용량/작업량** 근사
- 행당 평균 바이트를 \(\bar{b}\), 행 수 \(N\)이라면 **테이블 크기 근사**:
$$
\text{TableBytes} \approx N \cdot \bar{b} \cdot (1+\rho)
$$
- \(\rho\): 헤더/얼라인/TOAST/프리블록/인덱스 오버헤드 보정계수(경험적으로 0.2~0.6)
- 인덱스 1개 추가 시 **쓰기 부하 증가**:
$$
\Delta \text{WriteCost} \propto \log_2 N \quad(\text{B-Tree 갱신})
$$
- 정렬/집계의 **메모리 임계 판단**(정렬 대상 행수 \(M\), 행당 정렬키 크기 \(k\)):
$$
\text{SortMem} \approx M\cdot k \quad \text{(메모리 초과 시 디스크 스필 발생)}
$$

---

## 1. 성능 저하 원인 — 원리와 증상별 점검 포인트

| 증상 | 주요 원인 | 점검 쿼리/도구 |
|---|---|---|
| Full Scan 빈발 | 인덱스 부재/부적합, 조건 함수화, 통계 부정확 | `EXPLAIN (ANALYZE, BUFFERS)`, `pg_stat_statements`, `EXPLAIN FORMAT=JSON` |
| 인덱스 성능 저하 | 과다 인덱스, 카디널리티 저하, 블로트 | `\di+`, `pg_stat_user_indexes`, `OPTIMIZE TABLE`, `REINDEX` |
| I/O 병목 | 큰 Range Scan/스필 | 블록 캐시 적중률, `BUFFERS`, temp read/write 통계 |
| 정렬/그룹/조인 폭증 | 잘못된 조인 순서, 대량 정렬, 해시 빌드 스필 | 실행계획 “Sort/Hash” 노드 메모리/스필 |
| 통계 부정확 | 샘플 편향/갱신 지연 | `ANALYZE`, `DBMS_STATS.GATHER_*`, 히스톨그램 옵션 |

---

## 2. 파티셔닝(Partitioning) — **먼저 구조로 자르는** 가장 강력한 레버

### 2.1 절차(추천)
1) **파티션 키 선정**: 날짜(시계열), 범위/해시(고르게 분배), 지역/테넌트(멀티테넌시)
2) **Pruning 조건과 일치**하는 쿼리 패턴 확인
3) **핫/콜드 분리**(최근 N개월 Hot, 과거 Cold)
4) **교체/Drop 정책**(월단위 Drop으로 아카이빙)
5) **인덱스/PK 전략**(Global vs Local)

### 2.2 PostgreSQL 예제: 월 파티션

```sql
-- 1) 부모 테이블
CREATE TABLE logs (
  id          BIGSERIAL,
  log_ts      timestamptz NOT NULL,
  level       text NOT NULL,
  service     text NOT NULL,
  message     text NOT NULL,
  PRIMARY KEY (id, log_ts)
) PARTITION BY RANGE (log_ts);

-- 2) 자식(월 단위)
CREATE TABLE logs_2025_11 PARTITION OF logs
  FOR VALUES FROM ('2025-11-01') TO ('2025-12-01');

-- 3) Pruning이 되는 쿼리
EXPLAIN (ANALYZE, BUFFERS)
SELECT count(*) FROM logs
WHERE log_ts >= '2025-11-15' AND log_ts < '2025-11-16';
```

**포인트**: `WHERE log_ts ...`가 파티션 키를 직접 사용해야 Pruning. 함수 래핑(`date_trunc`)은 피하거나 **생성열/함수 인덱스**로 보완.

### 2.3 MySQL RANGE/INTERVAL 파티션 스케치

```sql
CREATE TABLE orders (
  id BIGINT PRIMARY KEY,
  ordered_at DATETIME NOT NULL,
  amount DECIMAL(12,2) NOT NULL
)
PARTITION BY RANGE COLUMNS (ordered_at) (
  PARTITION p2025m11 VALUES LESS THAN ('2025-12-01'),
  PARTITION pmax     VALUES LESS THAN (MAXVALUE)
);
```

### 2.4 Oracle Interval Partition(자동 증설)

```sql
CREATE TABLE SALES (
  ID NUMBER PRIMARY KEY,
  ORDER_DATE DATE,
  AMOUNT NUMBER
)
PARTITION BY RANGE (ORDER_DATE)
INTERVAL (NUMTOYMINTERVAL(1,'MONTH'))
(
  PARTITION P0 VALUES LESS THAN (DATE '2025-11-01')
);
```

### 2.5 운영 팁
- **파티션 유지보수**: 과거 파티션 `ALTER TABLE ... DETACH/ATTACH`, `DROP`으로 관리
- **인덱스 전략**: 월별 Local Index → 재빌드 영향 축소, Pruning과 정합
- **아카이빙**: DETACH 후 별도 스키마/스토리지로 Move, 읽기 전용

---

## 3. 인덱스 최적화 — **읽기 경로를 커버링**하라

### 3.1 설계 원칙
- **선두 컬럼** = 선택도 높은 컬럼 → 필터 성능
- **커버링 인덱스**: SELECT 목록/WHERE/ORDER BY를 포괄(순서 주의)
- **Too Many Indexes 금지**: DML 비용 및 유지비 급증 → **Top-K 쿼리 기반 설계**

### 3.2 커버링 인덱스 예: 고객 주문 목록

```sql
-- 최근 주문 리스트: 고객, 상태, 최신순 정렬
CREATE INDEX idx_order_list
  ON orders(customer_id, status, ordered_at DESC)
  INCLUDE (amount); -- PG 11+, 다른 DB는 복합키/클러스터 등으로 대체

EXPLAIN (ANALYZE, BUFFERS)
SELECT order_id, ordered_at, amount
FROM orders
WHERE customer_id = :cid AND status = 'PAID'
ORDER BY ordered_at DESC
LIMIT 50;
```

### 3.3 함수/표현식 인덱스

```sql
-- 날짜만 비교가 잦다면
CREATE INDEX idx_logs_date ON logs ((date_trunc('day', log_ts)));

SELECT count(*) FROM logs
WHERE date_trunc('day', log_ts) = '2025-11-06'::date;
```

**주의**: 표현식을 **인덱스와 동일하게** 써야 사용됨.

### 3.4 인덱스 블로트 관리(압축/재색인)
- PostgreSQL: `REINDEX CONCURRENTLY`, `VACUUM (FULL)` 신중히
- MySQL: `OPTIMIZE TABLE`
- Oracle: `ALTER INDEX ... REBUILD`

---

## 4. 통계(Statistics) — **옵티마이저의 눈**을 맑게

### 4.1 주기적 최신화
- PostgreSQL: `ANALYZE`, `autovacuum_vacuum_scale_factor`, `default_statistics_target`
- MySQL: `ANALYZE TABLE`
- Oracle: `DBMS_STATS.GATHER_TABLE_STATS(..., method_opt => 'FOR ALL COLUMNS SIZE AUTO')`

```sql
-- PostgreSQL 예
ANALYZE orders;
ALTER TABLE orders ALTER COLUMN status SET STATISTICS 200; -- 컬럼별 샘플 강화
```

### 4.2 히스토그램/Top-N 빈도
- 편향 컬럼(예: `status='PAID' 95%`)은 히스토그램/Top-N을 활성화하여 **선택도 추정 오차**를 줄인다.

---

## 5. 아카이빙 & 이력 분리 — **핫/콜드 계층화**

### 5.1 패턴
- **핫 테이블**: 최근 N개월 실시간 트랜잭션
- **콜드 테이블**: 과거 데이터(읽기 드묾), 별도 파티션/스키마/DB
- **정책**: 보존주기(예: 13개월), 익월 1일 **Move/Drop** 작업 자동화

### 5.2 예제: 월말 아카이빙(PG)

```sql
-- 한 달치 파티션을 아카이브 스키마로 이동
ALTER TABLE logs DETACH PARTITION logs_2025_05;
ALTER TABLE logs_2025_05 SET SCHEMA archive;

-- 운영 테이블에는 핫 파티션만 유지
DROP TABLE IF EXISTS archive.logs_2024_11; -- 보존주기 만료시 삭제
```

### 5.3 규정/감사 대응
- 삭제 대신 **불변 스토리지**(S3/Glacier, WORM)로 복제
- 조회는 별도 리포트 DB/External Table로 제공(운영 DB 부하 차단)

---

## 6. 분산·병렬 처리 — RDB의 PQ부터 MPP까지

### 6.1 RDB 내부 **병렬 쿼리**
- PostgreSQL: `max_parallel_workers_per_gather`, `parallel_setup_cost` 조절
- Oracle: `/*+ PARALLEL(table N) */`, `PARALLEL_ENABLE` 뷰/인덱스 전략
- MySQL: 8.0은 내부 병렬 제한적 → 파티션 병렬 등 우회

```sql
-- Oracle 예: 병렬 힌트
SELECT /*+ PARALLEL(o 8) */ COUNT(*)
FROM ORDERS o
WHERE ORDER_DATE >= DATE '2025-11-01';
```

### 6.2 외부 MPP/클라우드 웨어하우스
- **BigQuery/Snowflake/Redshift**: 초대형 스캔·조인을 ELT로 처리
- OLTP-OLAP **분리(CQRS/CDC)**: 변경 데이터 스트림을 DW로 적재하여 리포트/데시전 서빙

---

## 7. 메모리 기반 설계·캐싱 — **읽기는 메모리로 빼라**

### 7.1 캐시 레이어(키 전략)
- Key: `user:{id}:last_orders`, TTL: 300s, **캐시 일관성**: 갱신 시 **캐시 무효화** 우선

```python
# 의사코드
val = redis.get(key)
if not val:
    val = db.query(...)
    redis.setex(key, 300, serialize(val))
return val
```

### 7.2 Materialized View/요약 테이블
- PG 물질화뷰: `REFRESH MATERIALIZED VIEW CONCURRENTLY`
- Oracle MV: FAST REFRESH(로그 기반), DW/리포트에 최적

```sql
CREATE MATERIALIZED VIEW daily_sales AS
SELECT order_date::date AS d, SUM(amount) AS rev
FROM fact_order GROUP BY 1;

REFRESH MATERIALIZED VIEW CONCURRENTLY daily_sales;
```

### 7.3 In-Memory Table
- HANA/Oracle In-Memory/PG `pg_prewarm` 등으로 **핫셋 상주시킴**

---

## 8. 대량 환경에서의 **트랜잭션** & **조인 전략**

### 8.1 트랜잭션 크기 제한
- 너무 큰 배치는 Undo/Redo 폭증·락 유지·WAL 압박 → **청크 단위 커밋(예: 10k행)**

```sql
-- 배치 DML: 10k 행 단위 커밋
BEGIN;
-- 10k행 INSERT/UPDATE
COMMIT;
-- 반복
```

### 8.2 조인 전 필터링
- **세미 조인** 패턴, **EXISTS** 사용, **선 필터 테이블**로 중간집합 축소

```sql
-- 비효율
SELECT * FROM big_a a JOIN big_b b ON a.k=b.k WHERE a.dt>... AND b.flag='Y';

-- 개선: 먼저 작은 집합으로 줄인다
WITH f AS (
  SELECT k FROM big_b WHERE flag='Y'
)
SELECT a.*
FROM big_a a
JOIN f USING(k)
WHERE a.dt > ...;
```

### 8.3 정렬/집계 스필 방지
- 워크메모리/정렬메모리 상향(서비스별), **부분집계(partial agg)**, **윈도우 함수를 피하고 사전 집계** 고려

---

## 9. **우선순위 로드맵**(실전 체크리스트)

1) **WHERE 절 최적화**: 함수 제거/연산 좌변 컬럼화/불필요 와일드카드 제거
2) **인덱스**: 선두 선택도/커버링/불필요 인덱스 제거
3) **통계 최신화**: 히스토그램/Top-N/샘플 강화
4) **파티셔닝**: 키/주기/Drop/교체 프로세스
5) **아카이빙/반정규화**: 핫/콜드 분리, 요약/스냅샷(동기화 설계 포함)
6) **병렬화/분산**: PQ 파라미터, CDC→DW
7) **모니터링/알람**: p95/스필/버퍼미스/락경합/용량추세

---

## 10. 운영 자동화 — **회귀 방지와 자가치유**

### 10.1 대표 쿼리 벤치마크 파이프라인(CI)
```sql
-- 베이스라인/개선안 모두 저장
EXPLAIN (ANALYZE, BUFFERS) /* tag:baseline:order_top50 */
SELECT c.customer_id, SUM(o.amount) AS last30
FROM customer c JOIN orders o USING(customer_id)
WHERE o.ordered_at >= now() - interval '30 days'
GROUP BY 1 ORDER BY last30 DESC LIMIT 50;
```
- 결과를 파일/테이블에 저장 → PR 시 **비교**로 회귀 탐지

### 10.2 불일치/스필/락 감시
- PG: `pg_stat_statements`, `pg_locks`, `pg_stat_io`, `pg_stat_wal`
- MySQL: Performance Schema, sys 스키마
- Oracle: AWR/ASH, v$ 뷰

### 10.3 자동 수선(Repair) 잡
- **요약/카운터** 반정규화 오차 검출→자동 재계산 DML
- **인덱스 블로트** 임계 초과 시 REINDEX 스케줄

---

## 11. 실전 예제 세트

### 11.1 로그 분석(OLTP→OLAP 분리)

**OLTP 스키마(정규화, 파티션)**
```sql
CREATE TABLE web_log (
  id BIGSERIAL,
  ts timestamptz NOT NULL,
  user_id BIGINT,
  path text NOT NULL,
  status smallint NOT NULL,
  bytes int NOT NULL,
  PRIMARY KEY (id, ts)
) PARTITION BY RANGE (ts);

CREATE TABLE web_log_2025_11 PARTITION OF web_log
  FOR VALUES FROM ('2025-11-01') TO ('2025-12-01');

CREATE INDEX idx_weblog_user_ts ON web_log(user_id, ts DESC);
```

**CDC → DW(BigQuery) 적재**
- Debezium/Logical Replication로 변경분 스트리밍
- DW에서 세션 집계/경로 분석, Looker/BI 서빙

### 11.2 커머스 대시보드(요약 테이블 + 검증)

```sql
CREATE TABLE daily_customer_sales (
  customer_id BIGINT,
  d DATE,
  revenue NUMERIC(18,2) NOT NULL,
  PRIMARY KEY (customer_id, d)
);

-- 적재(배치/스트림)
INSERT INTO daily_customer_sales(customer_id, d, revenue)
SELECT customer_id, ordered_at::date, SUM(amount)
FROM orders
WHERE ordered_at::date = current_date - 1
GROUP BY 1,2
ON CONFLICT (customer_id, d) DO UPDATE
SET revenue = EXCLUDED.revenue;

-- 검증
WITH led AS (
  SELECT customer_id, ordered_at::date d, SUM(amount) amt
  FROM orders
  WHERE ordered_at >= now() - interval '30 days'
  GROUP BY 1,2
)
SELECT count(*) diff_rows
FROM led l LEFT JOIN daily_customer_sales s
  ON (l.customer_id,s.d)=(s.customer_id,l.d)
WHERE l.amt IS DISTINCT FROM s.revenue;
```

### 11.3 대용량 업데이트(청크 커밋 + 인덱스 전략)

```sql
-- 1) 작업 전 인덱스 정리(불필요/중복 제거)
-- 2) 청크 처리
DO $$
DECLARE
  _limit int := 10000;
  _cnt   int;
BEGIN
  LOOP
    WITH upd AS (
      SELECT id FROM big_table
      WHERE need_fix = true
      LIMIT _limit
      FOR UPDATE SKIP LOCKED
    )
    UPDATE big_table t
       SET need_fix = false, updated_at = now()
      FROM upd
     WHERE t.id = upd.id;

    GET DIAGNOSTICS _cnt = ROW_COUNT;
    EXIT WHEN _cnt = 0;
    COMMIT;  -- 청크 커밋
    BEGIN;   -- 다음 청크
  END LOOP;
END $$;
```

---

## 12. 대량 데이터 FAQ

**Q1. 인덱스 몇 개가 적당?**
A. “쿼리로 정한다.” Top-K 트래픽 쿼리의 **WHERE/ORDER BY/SELECT 컬럼**을 기준으로 설계. 쿼리로 안 쓰는 인덱스는 제거.

**Q2. 파티셔닝만 하면 빨라지나?**
A. 키와 쿼리가 **정렬**되어야 한다. 파티션 키와 WHERE가 맞지 않으면 효과 제한.

**Q3. 반정규화 언제?**
A. 정규화+인덱스+파티션+캐시로도 SLA 미달일 때, **동기화/검증/롤백** 계획을 갖춘 후.

**Q4. 통계는 얼마나 자주?**
A. 고변동 테이블은 매일/시간당, 저변동은 주기적으로. 배포·대량 적재 후 즉시.

---

## 13. 결론 — **장기전**을 설계하라

- 대량 데이터는 **시간이 만들고**, 성능은 **구조(파티션/인덱스)→통계→쿼리→아카이빙→분산**의 순서로 만든다.
- “대량=느림”은 필연이 아니라 **절차 부재**의 결과다.
- **핵심 쿼리 기반 설계**와 **지속적 모니터링/수선 자동화**가 회귀를 막고, **핫/콜드 분리**가 수명을 연장한다.
