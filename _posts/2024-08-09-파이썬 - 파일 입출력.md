---
layout: post
title: 파이썬 - 파일 입출력
date: 2024-08-09 19:20:23 +0900
category: Python
---
# 파이썬 파일 입출력

## 파일 열기: `open(path, mode, encoding, newline, buffering, errors, ...)`

```python
f = open("파일이름.txt", "모드")
```

### 주요 모드

| 모드     | 의미(존재/생성/파괴)                                         | 읽기 | 쓰기 | 위치 초기화 | 비고 |
|----------|---------------------------------------------------------------|------|------|-------------|-----|
| `'r'`    | **읽기 전용** (파일 없으면 `FileNotFoundError`)               | O    | X    | 파일 시작    | 텍스트 기본 |
| `'w'`    | **쓰기 전용** (기존 내용 **삭제**)                           | X    | O    | 파일 시작    | 새로 씀 |
| `'a'`    | **추가(append)** (없으면 생성, 항상 파일 **끝**에 기록)       | (X)  | O    | 파일 끝      | 로그 등에 적합 |
| `'x'`    | **배타적 생성** (이미 있으면 예외)                           | X    | O    | 파일 시작    | 안전 생성 |
| `'r+'`   | **읽기+쓰기** (삭제 X)                                       | O    | O    | 파일 시작    | 랜덤액세스 |
| `'w+'`   | 읽기+쓰기(기존 내용 **삭제**)                                 | O    | O    | 파일 시작    | 초기화 후 사용 |
| `'a+'`   | 읽기+추가(없으면 생성, 쓰기는 끝에서만)                        | O    | O    | 파일 끝(쓰기) | 로그 읽기/쓰기 |
| `'t'`    | **텍스트 모드**(기본)                                         | -    | -    | -            | 인코딩 적용 |
| `'b'`    | **바이너리 모드**                                            | -    | -    | -            | 바이트 I/O |

> **조합**: `"rb"`, `"wb"`, `"r+b"`, `"wb+"` 등. 텍스트 모드는 `encoding`/`newline` 영향, 바이너리는 **그대로 바이트**.

### 버퍼링/인코딩/개행 변환 핵심 파라미터

- `encoding="utf-8"` 권장(콘솔/툴 일관성). BOM 있는 파일은 `"utf-8-sig"`로 읽으면 BOM 무시.
- `newline=None`(기본): `\r\n`, `\r`, `\n` → **유니버설 개행**으로 `\n`으로 변환해 줌.
  - `newline=''`: 변환 **하지 않음**(그대로 유지/쓰기). CSV 같은 바이너리적 텍스트에서 유용.
- `buffering`: `0`(unbuffered, 바이너리만), `1`(line-buffered, 텍스트만), `>1`(chunk 크기), `-1`(기본).
- `errors`: `"strict"`(기본), `"ignore"`, `"replace"`, `"backslashreplace"` 등 인코딩 에러 처리.

---

## 파일 쓰기: `write() / writelines() / print(..., file=f)`

```python
f = open("example.txt", "w", encoding="utf-8")
f.write("안녕하세요!\n파이썬 파일 입출력입니다.")
f.close()
```

> `close()`를 누락하면 **버퍼 미플러시**로 데이터 유실 가능. 가능하면 **with 문** 사용.

### 권장: `with` 컨텍스트 (자동 close/플러시/예외에도 안전)

```python
with open("example.txt", "w", encoding="utf-8") as f:
    f.write("with문: 자동 close & flush\n")
```

### 줄 단위 쓰기

```python
lines = ["A\n", "B\n", "C\n"]
with open("out.txt", "w", encoding="utf-8") as f:
    f.writelines(lines)  # 개행 포함 여부는 호출자가 책임
```

### `print()`로 쓰기 (자동 개행/구분자)

```python
with open("log.txt", "a", encoding="utf-8") as f:
    print("time=12:00", "status=OK", sep=" | ", file=f)
```

---

## 파일 읽기: `read / readline / readlines / for line in f`

### 전체 읽기

```python
with open("example.txt", "r", encoding="utf-8") as f:
    content = f.read()           # 문자열 전체
    print(content)
```

### 한 줄 읽기

```python
with open("example.txt", "r", encoding="utf-8") as f:
    line = f.readline()
    print(line.rstrip("\n"))
```

### 여러 줄 리스트로

```python
with open("example.txt", "r", encoding="utf-8") as f:
    for line in f:                # 권장: 이터레이터 사용 (메모리 효율/간결)
        print(line.rstrip("\n"))
```

> `readlines()`는 전체를 리스트에 넣으므로 **대용량 시 메모리 부담**. 가능하면 `for line in f`.

---

## 텍스트 vs 바이너리

### 바이너리 읽기/쓰기

```python
with open("image.png", "rb") as f:
    data = f.read()    # type: bytes

with open("copy.png", "wb") as f:
    f.write(data)
```

- 바이너리는 **인코딩/개행 변환 없음**.
- 텍스트는 `str`(유니코드), 바이너리는 `bytes`.

### 텍스트 ↔ 바이트 변환

```python
s = "안녕"
b = s.encode("utf-8")     # str -> bytes
print(b)                  # b'\xec...'

print(b.decode("utf-8"))  # bytes -> str
```

---

## 안전한 파일 처리: `with`와 예외/flush/fsync

### `with`의 장점

- 예외 발생 시에도 **자동 close**.
- 버퍼 데이터의 **자동 flush** 보장.

### 강제 디스크 동기화

```python
import os
with open("critical.log", "a", encoding="utf-8") as f:
    f.write("중요 로그\n")
    f.flush()                 # 사용자 공간 → OS 버퍼
    os.fsync(f.fileno())      # OS 버퍼 → 디스크(가능한 한)
```

> 빈번한 `fsync`는 성능 비용이 큼. 진짜 중요한 구간에만.

---

## 파일 위치/랜덤 액세스: `seek/tell`

```python
with open("data.bin", "rb") as f:
    head = f.read(4)
    f.seek(0, 2)       # 파일 끝으로
    size = f.tell()
    f.seek(size-4)     # 끝에서 4바이트 앞으로
    tail = f.read(4)
```

| `seek(offset, whence)` | 의미                             |
|------------------------|----------------------------------|
| `whence=0`            | 파일 **시작** 기준               |
| `whence=1`            | **현재 위치** 기준               |
| `whence=2`            | 파일 **끝** 기준                 |

---

## 대용량/스트리밍 패턴

### 청크 단위 복사 (메모리 효율)

```python
CHUNK = 1024 * 1024  # 1MB
with open("big.iso", "rb") as src, open("copy.iso", "wb") as dst:
    while True:
        buf = src.read(CHUNK)
        if not buf:
            break
        dst.write(buf)
```

### `iter(callable, sentinel)` 패턴 (EOF 센티넬)

```python
from functools import partial

with open("big.iso", "rb") as f:
    for chunk in iter(partial(f.read, 1 << 20), b""):  # 빈 바이트가 센티넬
        process(chunk)
```

### 텍스트 라인 스트리밍(메모리 안전)

```python
def iter_lines(path, encoding="utf-8"):
    with open(path, "r", encoding=encoding, newline="") as f:
        for line in f:
            yield line.rstrip("\n")

for line in iter_lines("huge.csv"):
    handle(line)
```

---

## JSON/CSV/피클 등 실전 포맷

### JSON (사람/언어 친화, 텍스트)

```python
import json

obj = {"name": "Alice", "age": 25, "tags": ["py", "ml"]}

with open("user.json", "w", encoding="utf-8") as f:
    json.dump(obj, f, ensure_ascii=False, indent=2)

with open("user.json", "r", encoding="utf-8") as f:
    data = json.load(f)
```
- `ensure_ascii=False`로 한글 깨짐 방지.
- JSON은 **텍스트**이므로 `encoding` 필수.

### CSV (스프레드시트/표 형식)

```python
import csv

rows = [
    {"name": "kim", "score": 90},
    {"name": "lee", "score": 85},
]

with open("score.csv", "w", encoding="utf-8", newline="") as f:
    w = csv.DictWriter(f, fieldnames=["name", "score"])
    w.writeheader()
    w.writerows(rows)

with open("score.csv", "r", encoding="utf-8", newline="") as f:
    r = csv.DictReader(f)
    for row in r:
        print(row)
```
> `newline=""`는 CSV에서 **이중 개행 문제 방지**(플랫폼 개행과 중첩을 막음).

### Pickle (파이썬 객체 직렬화, **동형성/성능**, 단 보안 주의)

```python
import pickle

obj = {"a": 1, "b": [1,2,3]}
with open("obj.pkl", "wb") as f:
    pickle.dump(obj, f, protocol=pickle.HIGHEST_PROTOCOL)

with open("obj.pkl", "rb") as f:
    x = pickle.load(f)
```
> **신뢰할 수 없는 소스의 pickle은 절대 로드 금지**(임의 코드 실행 위험).

---

## 압축/아카이브: `gzip`, `bz2`, `zipfile`, `tarfile`

### gzip 텍스트/바이너리

```python
import gzip

with gzip.open("data.txt.gz", "wt", encoding="utf-8") as f:
    f.write("압축 텍스트\n")

with gzip.open("data.txt.gz", "rt", encoding="utf-8") as f:
    print(f.readline().strip())
```

### zip 아카이브

```python
import zipfile

with zipfile.ZipFile("arch.zip", "w", compression=zipfile.ZIP_DEFLATED) as z:
    z.write("a.txt")
    z.writestr("b.txt", "inline text")
```

---

## 메모리 맵 파일: `mmap` (랜덤액세스/대용량 슬라이싱)

```python
import mmap

with open("large.bin", "r+b") as f:
    with mmap.mmap(f.fileno(), length=0, access=mmap.ACCESS_WRITE) as m:
        print(m[0:4])    # 앞 4바이트
        m[0:4] = b"ABCD" # 제자리 수정
```

- 커널 페이지 캐시 활용, **매핑 기반 랜덤액세스**.
- 파일 크기만큼 주소 공간 필요(32bit 환경 주의).

---

## 임시 파일/디렉터리: `tempfile`

```python
import tempfile, pathlib

with tempfile.NamedTemporaryFile("w", delete=False, encoding="utf-8") as f:
    f.write("temp")
    tmp_path = pathlib.Path(f.name)

print(f"임시파일: {tmp_path}")
tmp_path.unlink(missing_ok=True)
```

```python
import tempfile, os
with tempfile.TemporaryDirectory() as d:
    p = os.path.join(d, "a.txt")
    with open(p, "w", encoding="utf-8") as f:
        f.write("hello")
    # 블록 종료 시 디렉터리/내용 자동 삭제
```

---

## 원자적(Atomic) 저장 패턴 (중요 파일 안전 기록)

**전략**: 임시 파일에 완전히 쓴 뒤 **`os.replace`(원자적 교체)**

```python
import os, tempfile, pathlib

def atomic_write(path: str, data: str, encoding="utf-8"):
    path = pathlib.Path(path)
    tmp = path.with_suffix(path.suffix + ".tmp")

    with open(tmp, "w", encoding=encoding) as f:
        f.write(data)
        f.flush()
        os.fsync(f.fileno())      # 디스크에 보증

    os.replace(tmp, path)          # 대부분 OS에서 원자적 교체

atomic_write("config.json", "{\"ok\":true}\n")
```

> 시스템/파일 시스템에 따라 완전한 원자성 보장은 달라질 수 있으나, 일반적으로 **크래시 내성**이 크게 향상됩니다.

---

## 권한/보안: `os.open`/모드/umask/경로 검증

### 권한 제어로 파일 열기 (저수준 FD)

```python
import os, stat

fd = os.open("secret.txt", os.O_WRONLY | os.O_CREAT | os.O_TRUNC, 0o600)
with os.fdopen(fd, "w", encoding="utf-8") as f:
    f.write("owner read/write only")
```
- `0o600`: 사용자 읽기/쓰기만 허용.
- 프로세스의 **umask**에 의해 실제 권한이 더 제한될 수 있음.

### 경로 검증/디렉터리 트래버설 방지

```python
from pathlib import Path

def safe_join(base: Path, *parts: str) -> Path:
    base = base.resolve(strict=True)
    candidate = (base / Path(*parts)).resolve()
    if base not in candidate.parents and candidate != base:
        raise ValueError("경로 탈출 탐지")
    return candidate

base = Path("/safe/base").resolve()
file_path = safe_join(base, "../etc/passwd")  # ValueError
```

---

## 경로/파일 작업: `pathlib` (현대적/가독성 높은 경로 API)

```python
from pathlib import Path

p = Path("data") / "logs" / "app.log"
p.parent.mkdir(parents=True, exist_ok=True)
p.write_text("hello\n", encoding="utf-8")

print(p.read_text(encoding="utf-8"))
print(p.exists(), p.stat().st_size)
for child in p.parent.glob("*.log"):
    print(child.name)
```

- `Path.read_text()/write_text()/read_bytes()/write_bytes()` 편리.
- `glob`, `rglob`로 패턴 탐색.

---

## 버퍼링/성능/플랫폼 차이

- **라인 버퍼**: 텍스트모드 `buffering=1` + 터미널 연결 시 줄단위 flush 가능. 파일 출력은 구현/플랫폼에 따라 다름.
- **대용량**: 큰 청크로 `read()/write()`, 또는 제너레이터/이터레이터로 스트리밍.
- **네트워크/파이프**: `os.fstat().st_mode`로 파이프/정규파일 구분 가능(진단 시).
- **윈도우 줄바꿈**: 텍스트 모드 기본은 유니버설 개행. CSV는 `newline=""` 권장.

---

## `io` 모듈 계층: Text/Buffered/Raw & 메모리 파일

```python
import io

bio = io.BytesIO()          # 메모리 바이트 파일
bio.write(b"ABC")
bio.seek(0)
print(bio.read())           # b'ABC'

sio = io.StringIO()
sio.write("가나다")
sio.seek(0)
print(sio.read())           # '가나다'
```

- 디스크 없이 **메모리 상 파일 인터페이스**(테스트/임시 변환에 유용).
- `io.TextIOWrapper`, `io.BufferedReader/Writer` 등으로 수동 조합 가능.

---

## 에러 처리/로깅/복구

```python
import logging
logging.basicConfig(level=logging.INFO)

try:
    with open("maybe.txt", "r", encoding="utf-8") as f:
        data = f.read()
except FileNotFoundError:
    logging.warning("파일이 없습니다. 기본값으로 진행합니다.")
    data = ""
except UnicodeDecodeError as e:
    logging.error("인코딩 오류: %s", e)
    # fallback
    with open("maybe.txt", "r", encoding="cp949", errors="replace") as f:
        data = f.read()
```

---

## 동시성/파일 잠금(락)

- 표준 라이브러리만으로 **크로스플랫폼 강제 락**은 제공하지 않음.
- 리눅스: `fcntl.flock` / 윈도우: `msvcrt.locking`. 또는 외부 라이브러리(예: `portalocker`) 활용.

```python
# POSIX 예 (Linux/Mac)

import fcntl

with open("shared.txt", "a+", encoding="utf-8") as f:
    fcntl.flock(f, fcntl.LOCK_EX)
    try:
        f.write("locked write\n")
    finally:
        fcntl.flock(f, fcntl.LOCK_UN)
```

---

## 테스트 가능성과 리팩터링

- I/O 의존 로직을 **함수 인자(경로/스트림)** 로 주입하면 테스트 쉬움.
- `StringIO`/`BytesIO`로 **가짜 파일** 주입 가능.

```python
from io import StringIO

def read_first_line(fobj) -> str:
    return fobj.readline().rstrip("\n")

fake = StringIO("line1\nline2\n")
assert read_first_line(fake) == "line1"
```

---

## 흔한 함정 & 예방

1. **`close()` 누락** → with 사용.
2. **인코딩 미지정** → `encoding="utf-8"` 명시.
3. CSV에서 **이중 개행** → `newline=""`.
4. 가짜 안전 저장(바로 덮어쓰기) → **원자적 저장 패턴**(`os.replace`).
5. **신뢰 불가 소스 피클 로드 금지**.
6. 대용량에서 **`readlines()` 남용** 금지(스트리밍).
7. 윈도우 경로 구분자/권한 차이 → `pathlib` 사용, 권한은 `os.open` + 모드.
8. 개행/인코딩 혼재된 파일 → `errors="replace"` 등 완화 전략 + 사후 정규화.
9. 로그 파일 **동시 쓰기** → 락·회전(log rotation) 고려.
10. 바이너리 파일을 텍스트 모드로 열기 → **반드시 `'b'`**.

---

## 실전 미니 프로젝트: 로그 회전(rotate) + 압축 + 안전 저장

```python
from __future__ import annotations
import os, gzip, time, shutil
from pathlib import Path

def rotate_log(path: str | Path, max_keep: int = 7):
    p = Path(path)
    if not p.exists() or p.stat().st_size == 0:
        return

    ts = time.strftime("%Y%m%d-%H%M%S")
    rotated = p.with_name(f"{p.stem}-{ts}{p.suffix}")
    # 원자적으로 이름 변경 (열린 핸들 영향 최소화)
    os.replace(p, rotated)

    # 새 빈 파일 준비
    p.touch()

    # 압축
    gz = rotated.with_suffix(rotated.suffix + ".gz")
    with open(rotated, "rb") as src, gzip.open(gz, "wb") as dst:
        shutil.copyfileobj(src, dst)

    rotated.unlink(missing_ok=True)

    # 최대 보관 개수 정리
    keeps = sorted(p.parent.glob(f"{p.stem}-*{p.suffix}.gz"))
    for old in keeps[:-max_keep]:
        old.unlink(missing_ok=True)

# 사용 예

LOG = Path("app.log")
with open(LOG, "a", encoding="utf-8") as f:
    f.write("line...\n")

rotate_log(LOG, max_keep=3)
```

- **핵심 포인트**: 원자적 교체(`os.replace`), 대용량 압축(`shutil.copyfileobj`), **보관 개수 관리**.

---

## 요약 체크리스트

- [ ] 텍스트는 `encoding="utf-8"`(혹은 `utf-8-sig`), CSV는 `newline=""`.
- [ ] **항상 `with open(...) as f:`** 사용.
- [ ] 대용량은 **스트리밍/청크**(`for line in f`, `iter(partial(...), sentinel)`).
- [ ] 중요 파일은 **원자적 저장**(`os.replace` + `fsync`).
- [ ] 권한 요구 파일은 `os.open(..., mode=0o600)` + `os.fdopen`.
- [ ] 경로는 **`pathlib`**로 조작, 필요 시 **경로 탈출 방지**.
- [ ] 피클은 **신뢰 가능한 소스만**.
- [ ] 바이너리는 `'b'` 모드, 텍스트 개행은 `newline` 이해.
- [ ] 성능은 버퍼/청크/메모리맵 고려, 락은 플랫폼 차이 인지.
- [ ] 테스트는 `StringIO/BytesIO`로 I/O 대체.

---

## 부록 A) 빠른 레시피 모음

**원자적 JSON 저장**
```python
import json, os, pathlib

def atomic_dump_json(path, obj, encoding="utf-8"):
    path = pathlib.Path(path)
    tmp = path.with_suffix(path.suffix + ".tmp")
    with open(tmp, "w", encoding=encoding) as f:
        json.dump(obj, f, ensure_ascii=False, indent=2)
        f.flush()
        os.fsync(f.fileno())
    os.replace(tmp, path)
```

**파일 복사 (큰 파일 안전)**
```python
import shutil
shutil.copyfile("src.bin", "dst.bin")  # 메타데이터 제외
# 또는

with open("src.bin", "rb") as s, open("dst.bin", "wb") as d:
    shutil.copyfileobj(s, d, length=1<<20)
```

**안전한 라인 카운트(대용량)**
```python
def count_lines(path, chunk=1<<20):
    cnt = 0
    with open(path, "rb") as f:
        while True:
            b = f.read(chunk)
            if not b: break
            cnt += b.count(b"\n")
    return cnt
```

**문자열 정규화(개행/트레일링 공백 제거)**
```python
def normalize_text(s: str) -> str:
    return "\n".join(line.rstrip() for line in s.replace("\r\n", "\n").replace("\r", "\n").split("\n"))
```
