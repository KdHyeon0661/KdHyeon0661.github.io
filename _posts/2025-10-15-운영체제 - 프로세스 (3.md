---
layout: post
title: 운영체제 - 프로세스 (3)
date: 2025-10-15 22:25:23 +0900
category: 운영체제
---
# Examples of IPC Systems & Client–Server Communication

이 장은 교과서의 개념을 **실제 도구/코드**에 매핑한다.  

---

## 3.7 Examples of IPC Systems

“IPC(Interprocess Communication)”는 크게 **공유 메모리**와 **메시지 패싱**으로 나뉜다.  
아래 예제들은 리눅스/유닉스를 중심으로, macOS·Android·Windows에서도 통하는 **원리와 관측 포인트**를 함께 설명한다.

### 3.7.1 POSIX Shared Memory + futex(저오버헤드 대기)
공유 메모리는 **복사 없이** 데이터를 전달한다. 단, **동기화**가 필요하다. 세마포어 대신 **futex**(커널 도움을 받는 유저 공간 대기)로 바쁜대기를 제거해 보자.

```c
// shm_futex_ring.c — 단일 생산자/소비자 링버퍼 (학습용, 에러처리 축약)
#define _GNU_SOURCE
#include <linux/futex.h>
#include <sys/syscall.h>
#include <sys/mman.h>
#include <sys/stat.h>
#include <fcntl.h>
#include <stdatomic.h>
#include <unistd.h>
#include <string.h>
#include <stdio.h>

static int futex_wait(volatile int* addr, int val) {
  return syscall(SYS_futex, addr, FUTEX_WAIT, val, NULL, NULL, 0);
}
static int futex_wake(volatile int* addr, int n) {
  return syscall(SYS_futex, addr, FUTEX_WAKE, n, NULL, NULL, 0);
}

typedef struct {
  _Atomic size_t head, tail, cap;
  _Atomic int    not_empty;
  _Atomic int    not_full;
  char data[];
} ring;

int main(int argc, char** argv){
  const char* name="/shm_futex_ring";
  size_t cap = 1<<20;

  if(argc>1 && !strcmp(argv[1],"init")){
    int fd=shm_open(name,O_CREAT|O_RDWR,0600);
    ftruncate(fd, sizeof(ring)+cap);
    ring* r=mmap(NULL,sizeof(ring)+cap,PROT_READ|PROT_WRITE,MAP_SHARED,fd,0);
    close(fd);
    r->head=r->tail=0; r->cap=cap; r->not_empty=0; r->not_full=1;
    return 0;
  }
  int fd=shm_open(name,O_RDWR,0600);
  ring* r=mmap(NULL,sizeof(ring)+cap,PROT_READ|PROT_WRITE,MAP_SHARED,fd,0);
  close(fd);

  if(argc>1 && !strcmp(argv[1],"prod")){
    const char* msg="hello via futex ring\n";
    for(size_t i=0;i<strlen(msg);i++){
      size_t next=(r->head+1)%r->cap;
      while(next==r->tail){ // full
        r->not_full=0;
        futex_wait(&r->not_full,0); // 소비자가 깨워줄 때까지 잠깐 잠든다
      }
      r->data[r->head]=msg[i]; r->head=next;
      r->not_empty=1; futex_wake(&r->not_empty,1);
    }
    return 0;
  }

  if(argc>1 && !strcmp(argv[1],"cons")){
    char out[256]; size_t k=0;
    while(k<strlen("hello via futex ring\n")){
      while(r->head==r->tail){ // empty
        r->not_empty=0;
        futex_wait(&r->not_empty,0);
      }
      out[k++]=r->data[r->tail]; r->tail=(r->tail+1)%r->cap;
      r->not_full=1; futex_wake(&r->not_full,1);
    }
    write(1,out,k);
    return 0;
  }
  dprintf(2,"usage: %s init|prod|cons\n", argv[0]);
  return 1;
}
```

```bash
gcc -O2 shm_futex_ring.c -o sfr
./sfr init
./sfr cons & ./sfr prod
```

**관찰 포인트**
- **복사 없음**(page 공유), 커널 진입은 **대기/깨우기 순간**으로 최소화.
- 다생산자/다소비자로 확장 시 **메모리 배리어**와 공정성 고려.

---

### 3.7.2 POSIX Message Queue (우선순위 있는 커널 큐)
메시지 큐는 **형태가 정해진 메시지**를 **커널이 보관**한다. 우선순위를 활용해 중요 이벤트를 먼저 꺼낼 수 있다.

```c
// posix_mq_prio.c
#define _GNU_SOURCE
#include <mqueue.h>
#include <fcntl.h>
#include <sys/stat.h>
#include <stdio.h>
#include <string.h>
#include <unistd.h>

int main(int argc,char**argv){
  const char* Q="/mqprio";
  struct mq_attr at={.mq_flags=0,.mq_maxmsg=16,.mq_msgsize=256,.mq_curmsgs=0};
  if(argc>1 && !strcmp(argv[1],"w")){
    mqd_t mq=mq_open(Q,O_CREAT|O_WRONLY,0600,&at);
    mq_send(mq,"low",3,1);
    mq_send(mq,"HIGH",4,9);
    mq_send(mq,"mid",3,5);
    mq_close(mq); return 0;
  }
  if(argc>1 && !strcmp(argv[1],"r")){
    mqd_t mq=mq_open(Q,O_CREAT|O_RDONLY,0600,&at);
    char buf[256]; unsigned pr;
    for(int i=0;i<3;i++){
      ssize_t n=mq_receive(mq,buf,sizeof(buf),&pr);
      dprintf(1,"prio=%u msg=%.*s\n",pr,(int)n,buf);
    }
    mq_close(mq); mq_unlink(Q); return 0;
  }
  dprintf(2,"usage: %s w|r\n",argv[0]); return 1;
}
```

```bash
gcc -O2 posix_mq_prio.c -o mq -lrt
./mq r & ./mq w
```

---

### 3.7.3 UNIX Domain Sockets — FD 전달(핸드오프)
로컬 IPC에서 **열린 FD를 다른 프로세스에 넘기는** 패턴은 서버 가동/롤링 업그레이드에 유용하다.

```c
// uds_sendfd.c — 서버: 열린 파일 FD를 클라이언트로 전송
#define _GNU_SOURCE
#include <sys/socket.h>
#include <sys/un.h>
#include <sys/stat.h>
#include <fcntl.h>
#include <unistd.h>
#include <string.h>
#include <stdio.h>

int main(){
  const char* path="/tmp/uds_fd";
  unlink(path);
  int s=socket(AF_UNIX,SOCK_STREAM,0);
  struct sockaddr_un a={.sun_family=AF_UNIX};
  strncpy(a.sun_path,path,sizeof(a.sun_path)-1);
  bind(s,(struct sockaddr*)&a,sizeof(a)); listen(s,1);
  int c=accept(s,NULL,NULL);
  int fd=open("/etc/hostname",O_RDONLY);

  struct msghdr msg={0}; char buf[1]={'X'}; struct iovec iov={.iov_base=buf,.iov_len=1};
  msg.msg_iov=&iov; msg.msg_iovlen=1;

  char cmsgbuf[CMSG_SPACE(sizeof(fd))];
  msg.msg_control=cmsgbuf; msg.msg_controllen=sizeof(cmsgbuf);
  struct cmsghdr* cmsg=CMSG_FIRSTHDR(&msg);
  cmsg->cmsg_level=SOL_SOCKET; cmsg->cmsg_type=SCM_RIGHTS; cmsg->cmsg_len=CMSG_LEN(sizeof(fd));
  memcpy(CMSG_DATA(cmsg), &fd, sizeof(fd));
  sendmsg(c, &msg, 0);
  return 0;
}
```

```c
// uds_recvfd.c — 클라이언트: 받은 FD로 파일 읽기
#include <sys/socket.h>
#include <sys/un.h>
#include <unistd.h>
#include <string.h>
#include <stdio.h>

int main(){
  const char* path="/tmp/uds_fd";
  int s=socket(AF_UNIX,SOCK_STREAM,0);
  struct sockaddr_un a={.sun_family=AF_UNIX};
  strncpy(a.sun_path,path,sizeof(a.sun_path)-1);
  connect(s,(struct sockaddr*)&a,sizeof(a));

  struct msghdr msg={0}; char b; struct iovec iov={.iov_base=&b,.iov_len=1};
  msg.msg_iov=&iov; msg.msg_iovlen=1;

  char cbuf[256]; msg.msg_control=cbuf; msg.msg_controllen=sizeof(cbuf);
  recvmsg(s,&msg,0);
  struct cmsghdr* cmsg=CMSG_FIRSTHDR(&msg);
  int fd; memcpy(&fd, CMSG_DATA(cmsg), sizeof(fd));
  char out[128]={0}; read(fd,out,sizeof(out)-1);
  dprintf(1,"read: %s\n", out);
}
```

```bash
gcc -O2 uds_sendfd.c -o sendfd && gcc -O2 uds_recvfd.c -o recvfd
./sendfd & sleep 0.2; ./recvfd
```

---

### 3.7.4 TCP/UDP 소켓 — 로컬을 넘어 네트워크까지
- **TCP**: 신뢰성, 순서 보장, 바이트 스트림
- **UDP**: 메시지 경계 유지, 무연결, 멀티캐스트

> 고성능 서버는 **epoll**/kqueue/IOCP, 또는 **io_uring**을 사용한다(리눅스).

---

### 3.7.5 D-Bus (데스크톱/시스템 IPC 버스)
리눅스 데스크톱/서버에서 **서비스 간 신호/메소드 호출**을 표준화.  
CLI만으로도 호출 가능:

```bash
# 시스템 버스의 호스트네임 질의(환경에 따라 경로/인터페이스 다름)
busctl get-property org.freedesktop.hostname1 /org/freedesktop/hostname1 org.freedesktop.hostname1 Hostname
```

**장점**: 이름 기반 서비스 디스커버리, 권한/정책.  
**단점**: 바이너리 대용량 데이터 전송에는 부적합 → 파일/공유메모리 병행.

---

### 3.7.6 Android Binder (커널 레벨 RPC)
- **핵심**: 커널 드라이버가 객체 참조를 추적, **고성능 로컬 RPC** 제공.
- **AIDL**로 인터페이스 정의 → 빌드 시 Stub/Proxy 생성, 프로세스 간 호출은 Binder가 중개.

AIDL 간단 예(개념):
```
// ICalc.aidl
interface ICalc {
  int add(int a, int b);
}
```

앱/서비스는 생성된 Stub/Proxy를 통해 `calc.add(2,3)` 같은 **메소드 호출**을 IPC로 수행.

---

### 3.7.7 Windows Named Pipe & MailSlot (개요)
- **Named Pipe**: 서버·클라이언트 스트림, 로컬/원격 모두 가능(UNC 경로 `\\.\pipe\name`)
- **MailSlot**: 단방향 메시지 기반(브로드캐스트 용도), 신뢰성 낮음
- 프로그래밍은 `CreateNamedPipe/ConnectNamedPipe/ReadFile/WriteFile`.

---

### 3.7.8 Mach IPC (XNU 기반, macOS/iOS)
- **mach_port**를 통해 **메시지(mach_msg)** 송수신.
- XPC(상위 추상화)로 현대 macOS는 서비스 간 안전한 메시지 교환/런치/보호를 제공.

---

### 3.7.9 ZeroMQ & nanomsg (패턴 내장 메시징)
**REQ/REP**, **PUB/SUB**, **PUSH/PULL** 등 패턴이 내장된 라이브러리.

간단 Python 예(설치: `pip install pyzmq`):
```python
# zmq_reqrep.py
import zmq, time, threading
def server():
    ctx=zmq.Context(); s=ctx.socket(zmq.REP); s.bind("tcp://127.0.0.1:5555")
    while True:
        m=s.recv()
        s.send(b"echo:"+m)
def client():
    ctx=zmq.Context(); c=ctx.socket(zmq.REQ); c.connect("tcp://127.0.0.1:5555")
    for i in range(3):
        c.send(f"m{i}".encode()); print(c.recv().decode())
t=threading.Thread(target=server,daemon=True); t.start(); time.sleep(0.1); client()
```

---

### 3.7.10 gRPC (HTTP/2 기반 RPC)
스키마(프로토버퍼)로 인터페이스를 정의하고, 언어별 Stub/Server를 자동 생성한다.  
**스트리밍, mTLS, 로드밸런싱** 등 현대 분산 환경에 적합.

예: Python(간단 흐름) — *개발 환경에서 실행*
```bash
pip install grpcio grpcio-tools
python -m grpc_tools.protoc -I. --python_out=. --grpc_python_out=. calc.proto
```

`calc.proto` (개념):
```
syntax = "proto3";
service Calc { rpc Add (AddReq) returns (AddRes); }
message AddReq { int32 a=1; int32 b=2; }
message AddRes { int32 sum=1; }
```

서버/클라이언트 코드는 생성된 모듈 기반으로 수십 줄이면 완성된다.

---

### 3.7.11 Redis/Kafka를 IPC로 쓰기 (운영 실전)
- **Redis Pub/Sub**: 같은 호스트 또는 LAN에서 **빠른 알림/브로드캐스트**  
- **Kafka**: 디스크 기반 **내구적 로그** + **소비자 그룹** → 백프레셔/재처리/스케일

운영 팁: **로컬 IPC(UDS/공유메모리)** → **에이전트** → **Kafka**로 **핫·콜드 경로**를 분리하라.

---

## 3.8 Communication in Client–Server Systems

클라이언트–서버는 **요청/응답** 패턴과 **연결 관리**, **신뢰성/보안/관측**이 핵심이다.

### 3.8.1 서버 구조 선택

- **스레드-Per-Connection**: 구현 단순, 스택/컨텍스트 비용↑  
- **이벤트 루프(reactor: epoll/kqueue)**: 고동시성, 코드 복잡성↑  
- **풀링(Thread/Connection Pool)**: 스레드 수 고정, 큐잉 지연 고려  
- **비동기 I/O(io_uring)**: 경계 비용↓, 러닝 커브↑

#### 예: 스레드 풀 + 블로킹 I/O (C, 축약)
```c
// pool_echo.c — 간단 스레드 풀 에코
#define _GNU_SOURCE
#include <pthread.h>
#include <sys/socket.h>
#include <netinet/in.h>
#include <unistd.h>
#include <stdlib.h>
#include <string.h>
#include <stdio.h>

#define NWORK 4
int q[1024], qh=0, qt=0; pthread_mutex_t m=PTHREAD_MUTEX_INITIALIZER; pthread_cond_t c=PTHREAD_COND_INITIALIZER;
void* worker(void* _){
  for(;;){
    pthread_mutex_lock(&m);
    while(qh==qt) pthread_cond_wait(&c,&m);
    int fd=q[qt++%1024]; pthread_mutex_unlock(&m);
    char buf[4096]; int n; while((n=read(fd,buf,sizeof(buf)))>0) write(fd,buf,n);
    close(fd);
  }
}
int main(){
  for(int i=0;i<NWORK;i++){ pthread_t t; pthread_create(&t,NULL,worker,NULL); pthread_detach(t); }
  int s=socket(AF_INET,SOCK_STREAM,0),one=1; setsockopt(s,SOL_SOCKET,SO_REUSEADDR,&one,sizeof(one));
  struct sockaddr_in a={.sin_family=AF_INET,.sin_port=htons(8008),.sin_addr={0}};
  bind(s,(struct sockaddr*)&a,sizeof(a)); listen(s,512);
  for(;;){
    int cfd=accept(s,NULL,NULL);
    pthread_mutex_lock(&m); q[qh++%1024]=cfd; pthread_mutex_unlock(&m); pthread_cond_signal(&c);
  }
}
```

```bash
gcc -O2 pool_echo.c -o pe -lpthread
./pe & printf "ok\n" | nc 127.0.0.1 8008
```

**관측 포인트**: 워커 수 조절로 **맥시멈 동시 처리**와 **대기시간**의 균형을 맞춘다.

---

### 3.8.2 HTTP/1.1 Keep-Alive, HTTP/2 Multiplexing, gRPC

- **HTTP/1.1 Keep-Alive**: TCP 연결을 재사용해 **핸드셰이크 비용** 절감.
- **HTTP/2**: 한 연결에서 **멀티플렉싱**(Head-of-line 완화), HPACK 압축.
- **gRPC(HTTP/2)**: **바이너리 프로토콜**, 스트리밍, **스키마 기반** RPC.

#### Python “미니 HTTP/1.1 Keep-Alive 서버”(학습용)
```python
# http_keepalive.py (간단, 프로덕션 X)
import socket, threading

def handle(c):
    c.settimeout(10)
    while True:
        req=b""
        while b"\r\n\r\n" not in req:
            chunk=c.recv(4096)
            if not chunk: c.close(); return
            req+=chunk
        # 응답
        body=b"hello"
        resp=(b"HTTP/1.1 200 OK\r\n"
              b"Connection: keep-alive\r\n"
              b"Content-Length: "+str(len(body)).encode()+b"\r\n\r\n")+body
        c.sendall(resp)

s=socket.socket(); s.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
s.bind(("0.0.0.0",8081)); s.listen(200)
while True:
    c,_=s.accept()
    threading.Thread(target=handle,args=(c,),daemon=True).start()
```

```bash
python3 http_keepalive.py & curl -v http://127.0.0.1:8081/ http://127.0.0.1:8081/
```

---

### 3.8.3 RPC 설계 팁 — Idempotency·타임아웃·재시도
- **Idempotency-Key**: 동일 요청이 **중복 적용되지 않도록** 키를 부여(결제/주문).
- **타임아웃/재시도/백오프**: 네트워크 오류는 정상적이다. **지수 백오프 + Jitter**를 기본으로.
- **서킷 브레이커**: 연속 실패 시 빠르게 실패하여 자원 고갈을 보호.

간단 수식(재시도 기대 지연):
$$
E[T] \approx T_0 + p \cdot (T_{\text{timeout}} + \Delta_1) + p^2 \cdot (T_{\text{timeout}} + \Delta_2) + \cdots
$$
- $$p$$: 1회 실패 확률, $$\Delta_i$$: 백오프 지연. **큰 $$p$$**일수록 **빠른 실패**/폴백이 유리.

---

### 3.8.4 로드밸런싱 & 커넥션 관리

- **L4 LB**: 포트 앞단 해시/헬스체크(예: LVS, AWS NLB)
- **L7 LB/프록시**: 헤더/경로 기반 라우팅(예: Envoy, NGINX)
- **커넥션 풀**: DB/백엔드 연결을 재사용, **풀 부하**를 계측해 튜닝
- **백프레셔**: 큐 길이, 윈도우/배치 크기, **429/503**로 클라이언트에 신호

---

### 3.8.5 보안: TLS/mTLS, OAuth2/JWT, 권한 분리

- **TLS**: 전송 암호화/무결성
- **mTLS**: 상호 인증(서비스-간)
- **OAuth2 + JWT**: 사용자/서비스 권한 전달(만료/스코프/서명 키 롤링)
- **프로세스 권한 분리**: 네트워크 종료(프론트)는 **비특권** 유저로, 비밀 키 접근은 최소화

간단 JWT 검증 훅(파이썬 Flask 예, 개념):
```python
# jwt_mw.py
from flask import Flask, request, abort
import jwt, time
app=Flask(__name__)
PUB="-----BEGIN PUBLIC KEY-----\n...\n-----END PUBLIC KEY-----"

@app.before_request
def check():
    token=request.headers.get("Authorization","").replace("Bearer ","")
    try:
        payload=jwt.decode(token, PUB, algorithms=["RS256"], audience="api", options={"require":["exp","aud"]})
        if payload["exp"]<time.time(): abort(401)
    except Exception:
        abort(401)

@app.route("/v1/echo")
def echo(): return "ok"
```

---

### 3.8.6 관측성: 로그·지표·분산 트레이싱

- **메트릭**: QPS/에러율/지연 p50/p95/p99, 풀 사용률
- **로그**: 구조화(JSON), 상관 ID(Trace/Span ID)
- **분산 트레이싱**: OpenTelemetry로 **서비스 경로**의 지연을 시각화

---

### 3.8.7 완성 예제 — “UDS 수집 → 공유메모리 배치 → TCP 응답”
로컬 앱들은 **UNIX DGRAM**으로 수집기에 로그를 던지고, 수집기는 **공유메모리 링버퍼**에 쓰며,  
외부 조회 요청이 오면 **TCP**로 최신 배치를 응답하는 파이프라인을 만든다고 하자.

구성:
1) **앱**: `sendto(AF_UNIX, SOCK_DGRAM)` 로 작은 로그 전송  
2) **수집기**: UDS로 수신 → `mmap` 링버퍼에 append  
3) **조회 서버**: TCP에서 `read` 요청 → 링버퍼에서 최근 N개 반환

핵심 관찰:
- UDS(로컬) → 낮은 오버헤드  
- 공유메모리 → **복사 없는 배치**  
- TCP 응답은 **배치로 sendfile/서버 캐시** 고려

---

## 체크리스트 요약

**IPC 시스템**
- 공유 메모리(+futex/세마포) — 최고 성능, 동기화/일관성 책임
- 메시지 큐/파이프/UDS — 인터페이스 명확, 로컬 IPC 강자(FD 전달/권한 관리)
- TCP/UDP — 호스트 간 확장, 신뢰/순서/경계 특성 이해
- D-Bus/Binder/Mach — 플랫폼 표준 IPC
- ZeroMQ/gRPC/Redis/Kafka — 실전 프레임워크/브로커

**클라이언트–서버**
- 구조: 스레드풀 vs 이벤트루프 vs io_uring
- HTTP/1.1 Keep-Alive, HTTP/2/gRPC 멀티플렉싱
- 신뢰성: 타임아웃, 재시도, 서킷 브레이커, Idempotency
- 보안: TLS/mTLS, JWT, 원천 분리(권한 최소화)
- 관측: p95/p99, 에러율, 상관 ID, 트레이싱

---

## 추가 실습 과제

1) **FD 전달 서버**를 확장해, **리스너 소켓** 자체를 새 프로세스에 넘겨 **무중단 재시작**을 구현하라.  
2) **POSIX MQ**에서 우선순위 분포를 바꿔 p99 지연이 어떻게 달라지는지 측정하라.  
3) **HTTP/1.1 vs HTTP/2** 동일 워크로드에서 **핵심 지표(QPS/p95)** 비교 그래프를 그려라.  
4) **gRPC** 스트리밍으로 로그 tail을 구현하고, **백프레셔**(윈도우/배치)로 메모리 사용을 안정화하라.  
5) **io_uring**으로 에코 서버를 작성해 epoll 대비 **시스템콜 수/컨텍스트 스위치**를 비교하라.

---

## 결론

IPC는 “**복사 비용 vs 동기화 비용 vs 격리/확장성**”의 균형 게임이다.  
로컬 고성능은 **공유 메모리 + 적절한 동기화**, 서비스 경계/분산은 **메시지 패싱 + RPC**가 정석이다.  
운영 환경에서는 **관측성/보안/롤링 업그레이드**까지 포함해 **엔드-투-엔드 경로**를 설계하라. 위 예제들을 조합해 **당신만의 표준 IPC/통신 템플릿**을 구축하면, 새로운 시스템에서도 빠르게 안정적인 성능을 얻을 수 있다.