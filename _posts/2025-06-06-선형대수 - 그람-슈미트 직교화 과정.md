---
layout: post
title: 선형대수 - 그람-슈미트 직교화 과정
date: 2025-06-06 23:20:23 +0900
category: 선형대수
---
# 그람-슈미트 직교화 (Gram–Schmidt)

> **핵심 한 줄**  
> 선형독립 벡터 \(v_1,\dots,v_k\)에서, “이미 만든 축 방향 성분을 빼고 정규화”를 반복하면 **정규직교(orthonormal) 기저** \(u_1,\dots,u_k\)를 얻는다.  
> 이 과정을 열벡터 행렬 \(V=[v_1\ \cdots\ v_k]\)에 적용하면 \(V=QR\) (**QR 분해**)가 되고, \(Q=[u_1\ \cdots\ u_k]\)는 정규직교, \(R\)은 상삼각이다.

---

## 1) 직관: “그림자를 걷어내고 뼈대만 남긴다”
- \(v_1\)을 정규화 → 첫 축 \(u_1\).  
- \(v_2\)에서 **\(u_1\) 방향 성분**을 뺌 → 남은 직교 성분을 정규화 → \(u_2\).  
- \(v_3\)에서 **\(u_1,u_2\) 방향 성분**을 모두 뺌 → 정규화 → \(u_3\).  
- … 반복.

이렇게 얻은 \(u_i\)들은 서로 직교(\(u_i^\top u_j=0\), \(i\ne j\))이고, 길이가 1이다(\(\|u_i\|=1\)).

---

## 2) 수식: 클래식 GS(=CGS)와 QR 연계

### 2.1 투영(projection)
\[
\mathrm{proj}_{u}(v) \;=\; \frac{v^\top u}{u^\top u}\,u
\qquad(\text{실수 내적})
\]

### 2.2 알고리즘(클래식 GS, CGS)
\[
\begin{aligned}
&u_1 \;=\; \frac{v_1}{\|v_1\|}, \quad r_{11}=\|v_1\|\\[4pt]
&\text{for } j=2,\dots,k:\\
&\quad \text{for } i=1,\dots,j-1:\quad r_{ij}=u_i^\top v_j,\;\; v_j \leftarrow v_j - r_{ij}u_i\\
&\quad r_{jj}=\|v_j\|,\;\; u_j=v_j/r_{jj}
\end{aligned}
\]

### 2.3 QR 분해와의 관계
- \(Q=[u_1\ \cdots\ u_k]\) (열직교), \(R=[r_{ij}]\) (상삼각) 이면  
  \[
  \boxed{V=QR,\quad R=Q^\top V,\quad Q^\top Q=I}
  \]
- **최소제곱** \( \min_x\|Ax-b\|_2 \): \(A=QR\)이면 \(Rx=Q^\top b\) (상삼각 풀기).

> **복소수**의 경우 내적은 에르미트 내적 \(\langle x,y\rangle = \overline{x}^\top y\)을 쓰고, 투영은 \(\mathrm{proj}_u(v)=\dfrac{\langle v,u\rangle}{\langle u,u\rangle}u\).

---

## 3) 손계산 예제(정확값) — \( \mathbb{R}^3 \)

\[
v_1=\begin{bmatrix}1\\1\\0\end{bmatrix},\ 
v_2=\begin{bmatrix}1\\0\\1\end{bmatrix},\ 
v_3=\begin{bmatrix}0\\1\\1\end{bmatrix}
\]

### 3.1 첫 축
\[
\|v_1\|=\sqrt{2},\qquad
u_1=\frac{1}{\sqrt{2}}\!\begin{bmatrix}1\\1\\0\end{bmatrix}
\]

### 3.2 두 번째 축
\[
v_2\cdot u_1=\frac{1}{\sqrt{2}},\quad 
\mathrm{proj}_{u_1}(v_2)=\frac{1}{\sqrt{2}}u_1=\begin{bmatrix}\tfrac12\\ \tfrac12\\ 0\end{bmatrix}
\]
\[
u_2' = v_2-\mathrm{proj}=\begin{bmatrix}\tfrac12\\ -\tfrac12\\ 1\end{bmatrix},\quad 
\|u_2'\|=\sqrt{\tfrac{3}{2}}
\]
\[
\Rightarrow\;
u_2=\frac{u_2'}{\|u_2'\|}
=\begin{bmatrix}\tfrac{\sqrt{6}}{6}\\ -\tfrac{\sqrt{6}}{6}\\ \tfrac{\sqrt{6}}{3}\end{bmatrix}
\quad(\approx[0.4082,-0.4082,0.8165]^\top)
\]

### 3.3 세 번째 축
\[
v_3\cdot u_1=\tfrac{1}{\sqrt2},\;\; \mathrm{proj}_{u_1}(v_3)=\begin{bmatrix}\tfrac12\\ \tfrac12\\ 0\end{bmatrix}
\]
\[
v_3\cdot u_2=\tfrac{\sqrt6}{6},\;\; \mathrm{proj}_{u_2}(v_3)=\tfrac{\sqrt6}{6}u_2=\begin{bmatrix}\tfrac16\\ -\tfrac16\\ \tfrac13\end{bmatrix}
\]
\[
u_3' = v_3 - \mathrm{proj}_{u_1}(v_3) - \mathrm{proj}_{u_2}(v_3)
= \begin{bmatrix}-\tfrac{2}{3}\\ \tfrac{2}{3}\\ \tfrac{2}{3}\end{bmatrix},\quad
\|u_3'\|=\tfrac{2}{\sqrt3}
\]
\[
\Rightarrow\;
u_3=\frac{u_3'}{\|u_3'\|}
=\begin{bmatrix}-\tfrac{\sqrt3}{3}\\ \tfrac{\sqrt3}{3}\\ \tfrac{\sqrt3}{3}\end{bmatrix}
\]

### 3.4 \(Q,R\)과 검산
\[
Q=\big[u_1\ u_2\ u_3\big],\quad
R=
\begin{bmatrix}
\sqrt2 & \tfrac{1}{\sqrt2} & \tfrac{1}{\sqrt2} \\
0 & \sqrt{\tfrac{3}{2}} & \tfrac{\sqrt6}{6} \\
0 & 0 & \tfrac{2}{\sqrt3}
\end{bmatrix},
\qquad V=QR,\quad Q^\top Q=I
\]

---

## 4) 구현: 클래식 GS, 수정형 GS(MGS), 검증 유틸

### 4.1 NumPy — 클래식 GS(벡터화)
```python
import numpy as np

def gram_schmidt_cgs(V, eps=1e-12):
    """V: (m,n) with rank n (ideally). Returns Q (m,n), R (n,n)."""
    V = V.astype(float).copy()
    m, n = V.shape
    Q = np.zeros((m, n))
    R = np.zeros((n, n))
    for j in range(n):
        v = V[:, j]
        for i in range(j):
            R[i, j] = np.dot(Q[:, i], v)
            v = v - R[i, j] * Q[:, i]
        R[j, j] = np.linalg.norm(v)
        if R[j, j] < eps:
            raise np.linalg.LinAlgError("Linearly dependent or nearly so (pivot too small).")
        Q[:, j] = v / R[j, j]
    return Q, R

def orthonormality_error(Q):
    I = np.eye(Q.shape[1])
    return np.linalg.norm(Q.T @ Q - I, ord=2)
```

### 4.2 NumPy — 수정형 GS(MGS, 안정성↑)
```python
def gram_schmidt_mgs(V, eps=1e-12, reorth=False):
    V = V.astype(float).copy()
    m, n = V.shape
    Q = np.zeros((m, n))
    R = np.zeros((n, n))
    for j in range(n):
        v = V[:, j].copy()
        for i in range(j):
            R[i, j] = np.dot(Q[:, i], v)
            v -= R[i, j] * Q[:, i]
        if reorth:  # 필요시 재직교(골라 쓰기)
            for i in range(j):
                corr = np.dot(Q[:, i], v)
                v -= corr * Q[:, i]
                R[i, j] += corr
        R[j, j] = np.linalg.norm(v)
        if R[j, j] < eps:
            raise np.linalg.LinAlgError("Linearly dependent or nearly so (pivot too small).")
        Q[:, j] = v / R[j, j]
    return Q, R
```

### 4.3 테스트: 손계산 예제 그대로
```python
V = np.array([[1,1,0],
              [1,0,1],
              [0,1,1]], dtype=float)
Q, R = gram_schmidt_cgs(V)
print("||Q^T Q - I||_2 =", orthonormality_error(Q))
print("reconstruction error =", np.linalg.norm(Q @ R - V))
```

---

## 5) (중요) 수치 안정성: CGS vs MGS vs 하우스홀더

- **클래식 GS(CGS)**: 직관적·빠름. 하지만 벡터가 **거의 종속**이면 **직교성 손실** 발생.  
- **수정형 GS(MGS)**: 투영을 “현재 남은 벡터”에 즉시 적용해 안정성 개선. 필요시 **재직교(re-orth)** 1회로 품질↑.  
- **하우스홀더 QR**: 가장 안정. 대규모·민감 문제는 보통 **하우스홀더** 또는 **Givens** 권장.

### 5.1 불량 예제로 차이 보기
```python
# 거의 종속한 열들
V_bad = np.array([[1.0, 1.0, 1.0],
                  [0.0, 1e-10, 2e-10],
                  [0.0, 0.0, 1e-20]])

Q1, R1 = gram_schmidt_cgs(V_bad)
Q2, R2 = gram_schmidt_mgs(V_bad)
print("CGS orth err:", orthonormality_error(Q1))
print("MGS orth err:", orthonormality_error(Q2))
```
> 일반적으로 **MGS가 훨씬 작다**. 실무에서는 `scipy.linalg.qr`(기본 하우스홀더) 사용이 안전.

---

## 6) QR로 최소제곱 \(\min\|Ax-b\|\) 풀기 (직접 구현)

### 6.1 예제 데이터(선형회귀 느낌)
\[
A=\begin{bmatrix}
1&1\\
1&2\\
1&3\\
1&4
\end{bmatrix},\quad
b=\begin{bmatrix} 6\\5\\7\\10\end{bmatrix}
\]
- \(A=QR\), \(Q^\top b = c\)라 두면, 상삼각 \(R x=c\) 후방대입.

```python
def back_substitute(R, y):
    n = R.shape[0]
    x = np.zeros(n)
    for i in reversed(range(n)):
        x[i] = (y[i] - R[i, i+1:] @ x[i+1:]) / R[i, i]
    return x

A = np.array([[1,1],[1,2],[1,3],[1,4]], float)
b = np.array([6,5,7,10], float)

Q, R = gram_schmidt_mgs(A)          # 안정형 권장
x_ls = back_substitute(R, Q.T @ b)   # 최소제곱해
print("x* =", x_ls)
res = np.linalg.norm(A @ x_ls - b)
print("residual norm =", res)
```

---

## 7) 직교 투영과 정사영 행렬 \(P\)
- 열공간 \( \mathcal{W}=\mathrm{Col}(A) \)에 대한 **정사영**:
  \[
  \mathrm{proj}_{\mathcal{W}}(v) = Q Q^\top v,\quad P = Q Q^\top
  \]
  (여기서 \(A=QR\)일 때의 \(Q\)는 \(A\)의 열공간에 대한 정규직교 기저)
- \(P\)는 **대칭**·**멱등**(\(P^2=P\)).

```python
# A의 열공간으로 임의 벡터 v를 투영
v = np.array([2., -1., 3., 0.])  # A는 (4x2), v는 (4,)
Q, _ = gram_schmidt_mgs(A)
P = Q @ Q.T
p = P @ v
print("projection:", p)
print("orthogonality (v-p) ⟂ Col(A)?", np.allclose(Q.T @ (v - p), 0, atol=1e-10))
```

---

## 8) 복소·가중 내적, 일반화

### 8.1 복소 벡터
- 내적 \(\langle x,y\rangle = \overline{x}^\top y\).  
- 투영 \(\mathrm{proj}_u(v)=\dfrac{\langle v,u\rangle}{\langle u,u\rangle}u\) (반드시 **켤레** 포함).

### 8.2 가중/일반 내적
- \(\langle x,y\rangle_W = x^\top W y\) (대칭 양정치 \(W\)).  
- 알고리즘은 동일하되 \(\langle\cdot,\cdot\rangle\)만 바꿔 쓰면 된다(예: 가중 최소제곱).

---

## 9) 계산 복잡도와 실무 팁
- CGS/MGS 비용: 대략 \(O(m n^2)\) (행 \(m\), 열 \(n\), \(m\ge n\)).  
- **진단**: \(\|Q^\top Q - I\|\)로 직교성 체크.  
- **방어**: 축 길이 \(<\varepsilon\)이면 종속 판단(중단/경고).  
- **규모↑/민감**: 가능하면 **하우스홀더 QR**(예: `np.linalg.qr`, `scipy.linalg.qr`) 사용.

```python
# 하우스홀더 QR (권장 루틴)
Qh, Rh = np.linalg.qr(A)  # mode='reduced' 기본
x_qr = back_substitute(Rh, Qh.T @ b)
```

---

## 10) PyTorch 스니펫(배치 직교화, 빠른 검증)
> 딥러닝 파이프라인에서 임베딩/특징축 직교화 체크 등에 유용.

```python
import torch

def torch_mgs(V, eps=1e-12):
    # V: (m, n), float64 권장
    V = V.clone().to(dtype=torch.float64)
    m, n = V.shape
    Q = torch.zeros((m, n), dtype=V.dtype)
    R = torch.zeros((n, n), dtype=V.dtype)
    for j in range(n):
        v = V[:, j].clone()
        for i in range(j):
            R[i, j] = torch.dot(Q[:, i], v)
            v -= R[i, j] * Q[:, i]
        R[j, j] = torch.linalg.vector_norm(v)
        if R[j, j] < eps:
            raise RuntimeError("Dependent columns")
        Q[:, j] = v / R[j, j]
    return Q, R

V_t = torch.tensor([[1.,1.,0.],
                    [1.,0.,1.],
                    [0.,1.,1.]])
Q_t, R_t = torch_mgs(V_t)
orth_err = torch.linalg.matrix_norm(Q_t.T @ Q_t - torch.eye(3, dtype=Q_t.dtype))
print("orth err:", orth_err.item())
```

---

## 11) 실전 시나리오 모음

- **QR 기반 최소제곱 회귀**: 선형회귀·스플라인·기저함수 회귀에서 안정적 해 구하기.  
- **서브스페이스 투영**: 신호에서 특정 기저 성분 제거(노이즈/잡음 억제).  
- **PCA 전처리**: 표준화된 축 정렬(직교 기저)로 해석 용이성↑(※ PCA 자체는 SVD가 핵심이지만, GS 직관이 도움).  
- **다항 기저 정규직교화**: \(\{1,x,x^2,\dots\}\)를 샘플 집합에 대한 내적으로 직교화(수치 안정성↑).

---

## 12) 자주 하는 실수 & 체크리스트

1. **거의 종속 데이터에 CGS**만 사용 → 직교성 손실. ⇒ **MGS/재직교 or 하우스홀더**.  
2. **정규화 누락** → 단지 직교일 뿐 정규직교 아님. ⇒ 반드시 \(\|u_j\|=1\) 확인.  
3. **복소 내적에서 켤레 빠뜨림** ⇒ 투영값 오류.  
4. **랭크 결함 무시** ⇒ \(r_{jj}\approx 0\)일 때 예외 처리·정지.  
5. **무한/NaN** 발생 ⇒ 입력 스케일링·정규화, `eps` 방어.

---

## 13) TL;DR

- **과정**: 기존 축 성분을 **빼고** 정규화 → 반복.  
- **산출**: \(V=QR\), \(Q\) 정규직교, \(R\) 상삼각.  
- **용도**: 최소제곱, 투영, 기저 구성.  
- **현업 권장**: **MGS(재직교 옵션)** 또는 **하우스홀더 QR** 사용, \(\|Q^\top Q-I\|\)로 품질 점검.

---
```python
# 끝판왕: 한 번에 묶은 데모 (수치품질까지)
import numpy as np

def demo_all(V, b=None):
    print("=== Classical GS ===")
    Qc, Rc = gram_schmidt_cgs(V)
    print("orth err (CGS):", orthonormality_error(Qc))
    print("recon err (CGS):", np.linalg.norm(Qc @ Rc - V))

    print("\n=== Modified GS ===")
    Qm, Rm = gram_schmidt_mgs(V, reorth=True)
    print("orth err (MGS+reorth):", orthonormality_error(Qm))
    print("recon err (MGS):", np.linalg.norm(Qm @ Rm - V))

    if b is not None and V.shape[0] >= V.shape[1]:
        # 최소제곱
        xm = back_substitute(Rm, Qm.T @ b)
        print("\nleast-squares x (MGS):", xm)
        print("residual norm:", np.linalg.norm(V @ xm - b))

# 사용 예: 앞서의 회귀 행렬
A = np.array([[1,1],[1,2],[1,3],[1,4]], float)
b = np.array([6,5,7,10], float)
demo_all(A, b)
```