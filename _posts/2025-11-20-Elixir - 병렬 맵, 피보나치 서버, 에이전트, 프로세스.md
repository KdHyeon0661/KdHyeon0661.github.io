---
layout: post
title: Elixir - 병렬 맵, 피보나치 서버, 에이전트, 프로세스
date: 2025-11-20 16:25:23 +0900
category: Elixir
---
# 병렬 맵, 피보나치 서버, 에이전트, 프로세스 관점

## _15.4 병렬 맵 — 얼랭의 “Hello, World”_

> 리스트의 각 원소를 함수로 변환하는 `map/2`를, **여러 프로세스**로 나눠 병렬 처리한다.
> 교훈: **정렬 보장**, **에러/타임아웃 전파**, **동시성 상한(bounded concurrency)**, **리소스 정리**.

### 가장 순수한 형태: spawn + send/receive

먼저 **가장 순수한 형태의 병렬 맵**부터 시작한다.
핵심 아이디어는 간단하다.

1. 입력 리스트의 각 원소마다 프로세스를 하나씩 만든다.
2. 각 프로세스는 주어진 함수 `fun.(x)`를 실행해 결과를 부모에게 보낸다.
3. 부모는 모든 결과를 모아서, **입력 순서**와 동일하게 다시 정리한다.

```elixir
defmodule PMap.Minimal do
  # 순서 보장 버전
  def pmap(enum, fun) when is_function(fun, 1) do
    parent = self()

    refs =
      enum
      |> Enum.with_index()
      |> Enum.map(fn {x, i} ->
        pid =
          spawn(fn ->
            send(parent, {:result, i, safe_apply(fun, x)})
          end)

        {pid, i}
      end)

    gather(refs, length(refs), [])
    |> Enum.sort_by(fn {i, _} -> i end)
    |> Enum.map(fn {_i, v} -> v end)
  end

  defp gather(_refs, 0, acc), do: acc

  defp gather(refs, left, acc) do
    receive do
      {:result, i, v} ->
        gather(refs, left - 1, [{i, v} | acc])
    after
      5_000 ->
        # 데모용 타임아웃—실전에서는 취소·로그·재시도 전략이 필요
        raise "pmap timeout"
    end
  end

  defp safe_apply(fun, x) do
    try do
      {:ok, fun.(x)}
    rescue
      e ->
        {:error, {e, __STACKTRACE__}}
    end
  end
end
```

#### 동작 해부

1. `Enum.with_index/1`
   - 각 원소에 인덱스를 붙인다. 예: `[10,20,30]` → `[{10,0},{20,1},{30,2}]`.
   - 나중에 결과를 **원래 순서로 되돌리기 위해** 필요한 정보다.

2. `spawn/1`
   - 각 `(x, i)`마다 프로세스를 만든다.
   - 자식 프로세스는 `safe_apply/2`로 함수 실행 후 결과를 보낸다.
   - 메시지 형태: `{:result, i, {:ok, value}}` 혹은 `{:result, i, {:error, {exception, stacktrace}}}`.

3. `gather/3`
   - `left` 개수만큼 `receive`로 결과를 기다린다.
   - 모든 결과를 `[{index, tagged_result}, ...]` 형태로 모은다.
   - 5초 안에 다 못 받으면 `raise "pmap timeout"`.

4. 정렬 & 값 추출

   ```elixir
   |> Enum.sort_by(fn {i, _} -> i end)
   |> Enum.map(fn {_i, v} -> v end)
   ```

   - 인덱스 기준으로 정렬 → 입력 순서 복원.
   - 값 부분만 꺼내서 최종 리스트 반환.

#### 예제 실행

```elixir
iex> PMap.Minimal.pmap(1..5, fn x -> x * x end)
[{:ok, 1}, {:ok, 4}, {:ok, 9}, {:ok, 16}, {:ok, 25}]

iex> PMap.Minimal.pmap(1..5, fn
...>   3 -> raise "boom"
...>   x -> x * 2
...> end)
[{:ok, 2}, {:ok, 4}, {:error, {%RuntimeError{message: "boom"}, _}}, {:ok, 8}, {:ok, 10}]
```

- 실패한 원소는 `{:error, {exception, stacktrace}}` 로 명시된다.
- 필요한 경우, pmap 호출한 쪽에서 에러를 더 다루기 편하다.

#### 예외 처리 전략 변형

`safe_apply/2` 를 바꾸면 **에러 처리 정책**을 쉽게 변경할 수 있다.

1) **즉시 실패 전략 (fail-fast)**

```elixir
defp safe_apply(fun, x) do
  fun.(x)
end

# gather에서 {:result, i, v} 대신 특정 원소에서 예외가 나면
# 그 프로세스는 크래시하고, 부모는 EXIT 신호를 링크/모니터로 감지할 수도 있다.

```

2) **에러 수집 전략**

```elixir
defp safe_apply(fun, x) do
  try do
    {:ok, fun.(x)}
  rescue
    e -> {:error, Exception.message(e)}
  end
end
```

- 전체 리스트 내에서 **어디가 실패했는지** 통계 내고 싶을 때 유용하다.

#### 복잡도 직관

입력 크기 \(n\), 각 작업 시간 \(t\), 동시성 \(c\) 인 환경에서 이상적으로는

$$
T \approx \left\lceil\frac{n}{c}\right\rceil \cdot t
$$

- 순수 병렬화가 잘 되면, \(c\)가 클수록 \(T\)는 줄어든다.
- 실제로는:
  - 스케줄러 컨텍스트 스위칭,
  - GC,
  - 메시지 복사,
  - 시스템 호출 등의 오버헤드 때문에
    위 공식의 **상수항이 꽤 크다**.

`PMap.Minimal` 방식은 **원소당 하나의 프로세스**라서:

- n이 매우 크면 (예: 백만 이상) 프로세스 생성 비용이 커진다.
- 실전에서는 아래에서 보게 될 **Task 기반** 또는 **배치 기반** 변형이 더 적절하다.

---

### `Task.async_stream/3` — 실전 기본형

실무에서는 거의 항상 **직접 spawn** 대신 `Task.async_stream/3` 을 쓰는 편이 낫다.

```elixir
defmodule PMap.Tasky do
  def pmap(enum, fun, opts \\ []) do
    maxc      = Keyword.get(opts, :max_concurrency, System.schedulers_online() * 2)
    timeout   = Keyword.get(opts, :timeout, 15_000)
    on_timeout = Keyword.get(opts, :on_timeout, :kill_task)

    enum
    |> Task.async_stream(fun,
         max_concurrency: maxc,
         timeout: timeout,
         on_timeout: on_timeout
       )
    |> Enum.map(fn
      {:ok, v} -> v
      {:exit, reason} -> raise "task exited: #{inspect(reason)}"
      {:error, reason} -> raise "task error: #{inspect(reason)}"
    end)
  end
end
```

#### 특징 정리

- **동시성 상한**: `max_concurrency`
  - CPU 바운드 작업: 대략 `스케줄러 수 ~ 스케줄러 수 * 2`.
  - I/O 바운드 작업: 그보다 더 높은 값을 줄 수 있다.
- **타임아웃/취소**:
  - `timeout` ms 동안 응답이 없으면 `{:exit, :timeout}` 등의 결과.
  - `on_timeout: :kill_task` 를 주면 해당 Task 프로세스를 **실제로 죽인다**.
- **정렬 보장**:
  - `Task.async_stream/3` 은 기본적으로 **입력 순서**와 같은 순서로 결과를 준다.
  - 병렬 실행되지만, 결과 리스트는 순서를 보존한다.

#### 예제

```elixir
iex> slow_double = fn x ->
...>   Process.sleep(100)
...>   x * 2
...> end

iex> PMap.Tasky.pmap(1..5, slow_double, max_concurrency: 5)
[2, 4, 6, 8, 10]
```

- 동시성 5 → 1..5 가 거의 동시에 실행 → 전체 시간은 대략 100ms + 오버헤드 수준.

타임아웃 예제:

```elixir
iex> sometimes_slow = fn x ->
...>   if x == 3 do
...>     Process.sleep(10_000)
...>   else
...>     Process.sleep(100)
...>   end
...>   x
...> end

iex> PMap.Tasky.pmap(1..5, sometimes_slow, timeout: 500)
** (RuntimeError) task exited: :timeout
```

- 3번째 입력이 너무 느려서 시간 안에 끝나지 못하면 전체를 실패 처리하도록 설계했다.

#### 부분 실패 허용 버전

전체 실패 대신, **부분 결과**를 허용하는 버전도 흔하다.

```elixir
defmodule PMap.TaskyPartial do
  def pmap(enum, fun, opts \\ []) do
    maxc      = Keyword.get(opts, :max_concurrency, System.schedulers_online() * 2)
    timeout   = Keyword.get(opts, :timeout, 15_000)
    on_timeout = Keyword.get(opts, :on_timeout, :kill_task)

    enum
    |> Task.async_stream(fun,
         max_concurrency: maxc,
         timeout: timeout,
         on_timeout: on_timeout
       )
    |> Enum.map(fn
      {:ok, v} -> {:ok, v}
      {:exit, reason} -> {:error, {:exit, reason}}
      {:error, reason} -> {:error, reason}
    end)
  end
end
```

- 이 경우, 호출자는 결과 리스트를 돌면서 **성공/실패를 구분**해서 처리한다.

---

### 배치 + 병렬 — 큰 입력에 유리

리스트 크기가 매우 크면(예: 수십만~수백만), **원소당 1프로세스** 전략은 비효율적이다.
이때는 “**배치 + 병렬**”을 조합하는 것이 유리하다.

```elixir
defmodule PMap.Batch do
  def pmap_batch(enum, fun, opts) do
    bsz = Keyword.fetch!(opts, :batch)
    mc  = Keyword.fetch!(opts, :max_concurrency)

    enum
    |> Stream.chunk_every(bsz)
    |> Task.async_stream(
         fn chunk -> Enum.map(chunk, fun) end,
         max_concurrency: mc,
         timeout: 30_000
       )
    |> Stream.flat_map(fn {:ok, list} -> list end)
    |> Enum.to_list()
  end
end
```

#### 동작 방식

1. `Stream.chunk_every(bsz)`
   - 입력을 `[ [x1..x_bsz], [x_{bsz+1}..], ... ]` 형태로 잘라낸다.
   - ex) bsz=100, 길이 10_000 → 100개의 청크.

2. 각 청크마다 `Enum.map(chunk, fun)` 실행
   - Task 하나가 **청크 전체**를 담당한다.

3. `Task.async_stream/3` 로 각 청크를 병렬 처리.

4. 결과는 `{:ok, [v1..v_bsz]}` 형태이므로, `Stream.flat_map/2` 으로 다시 낱개로 펼친다.

#### 장단점

| 항목 | 원소당 1프로세스 | 배치 + 병렬 |
|------|------------------|-------------|
| 프로세스 수 | 입력 길이 n | n / batch |
| 컨텍스트 스위칭 | 상대적으로 많음 | 상대적으로 적음 |
| 적합한 경우 | n이 작고, 각 작업이 매우 무거운 경우 | n이 크고, 각 작업이 비교적 가벼운 경우 |

실제 환경에서 **최적의 batch 크기**는:

- 작업 성격,
- CPU/메모리,
- 외부 I/O 패턴 등에 따라 달라지므로,
  `Benchee` 등으로 여러 값(bsz=10,100,1000,...)을 실험해 보는 것이 좋다.

---

### 실패·취소·부분 결과

병렬 처리에서는 반드시 **실패 전략**을 명시적으로 설계해야 한다.

#### 전략 선택지

1. **즉시 실패(fail-fast)**
   - 하나라도 실패하면 전체를 실패 처리.
   - 금융 등 **일관성이 매우 중요한 도메인**에서 적합.
2. **부분 결과 허용(partial success)**
   - 실패한 항목만 제외하고 나머지는 사용.
   - 로그/알람을 남기고, 이후 재시도 큐에 넣을 수도 있다.
3. **재시도(retry)**
   - 네트워크/일시 장애일 가능성이 큰 작업은
     일정 횟수, 백오프를 두고 재시도.

#### 간단한 재시도 래퍼

```elixir
defmodule Retry do
  def with_backoff(fun, tries \\ 3) do
    try do
      fun.()
    rescue
      e when tries > 1 ->
        # 100, 200, 400ms 식의 지수 백오프
        delay_ms = :math.pow(2, 4 - tries) |> round() * 100
        Process.sleep(delay_ms)
        with_backoff(fun, tries - 1)

      e ->
        reraise e, __STACKTRACE__
    end
  end
end
```

이제 병렬 맵에 재시도 정책을 쉽게 입힐 수 있다.

```elixir
defmodule PMap.Retrying do
  def pmap(enum, fun, opts \\ []) do
    wrapped = fn x -> Retry.with_backoff(fn -> fun.(x) end) end
    PMap.Tasky.pmap(enum, wrapped, opts)
  end
end
```

---

### 간단 벤치 힌트 (설명용 코드)

CPU 바운드와 I/O 바운드는 병렬화에서 **양상이 완전히 다르다**.
실제 앱에서는 아래와 같은 방식으로 **벤치마크를 돌려보는 것**이 중요하다.

```elixir
# mix.exs deps:
# {:benchee, "~> 1.3", only: :dev}

Benchee.run(%{
  "Enum.map" => fn ->
    Enum.map(1..40_000, &(&1 * &1))
  end,
  "Task.async_stream" => fn ->
    1..40_000
    |> Task.async_stream(&(&1 * &1), max_concurrency: System.schedulers_online() * 2)
    |> Stream.run()
  end
})
```

- 순수 CPU 연산(제곱 계산)은 이미 **매우 빠른 단일 코어 연산**이기 때문에
  병렬화에 따른 이득이 크지 않을 수 있고,
  스케줄링/메시징 오버헤드로 **오히려 느려질 수도 있다**.
- 반면, HTTP 호출, 디스크 I/O, DB 쿼리 같은 I/O 바운드 작업은
  `max_concurrency` 를 적절히 조절하면 **큰 이득**을 얻을 수 있다.

핵심은:

- 병렬화가 항상 이득이 되는 것이 아니라,
- **작업의 성격을 이해하고 실측으로 조정**해야 한다는 점이다.

---

### 분산 병렬 맵(개념 맛보기)

한 노드만 쓰는 것이 아니라, **여러 노드**에서 병렬로 map을 돌리고 싶을 수도 있다.
이때 `Task.Supervisor` 와 분산 노드를 조합한다.

```elixir
# 노드 A, B가 있다고 하자.
# A에서 B에 Task.Supervisor가 떠 있다고 가정.

Task.Supervisor.start_link(name: RemoteSup)

defmodule PMap.Distributed do
  def pmap_remote(enum, fun, remote_node, opts \\ []) do
    maxc    = Keyword.get(opts, :max_concurrency, System.schedulers_online())
    timeout = Keyword.get(opts, :timeout, 30_000)

    {:ok, sup} =
      Task.Supervisor.start_link(
        name: __MODULE__.LocalSup
      )

    enum
    |> Task.Supervisor.async_stream_nolink(
         sup,
         fn x ->
           :rpc.call(remote_node, fun.module, fun.function, [x | fun.args])
         end,
         max_concurrency: maxc,
         timeout: timeout
       )
    |> Enum.to_list()
  end
end
```

이 예시는 단순화된 개념 예이지만:

- 작업을 **원격 노드**로 보내고,
- 결과는 현재 노드에서 수집하는 구조를 보여준다.

실전 분산 설계에서는:

- 네트워크 장애,
- 노드 다운,
- 작업 재시도/재할당 등 고려해야 할 점이 많지만,
기본 패턴은 “**각 노드는 프로세스로 일하고, 메시지로 결과를 가져온다**”이다.

---

## _15.5 피보나치 서버_

> “피보나치”는 **순수 계산**, **메모이제이션**, **서버 상태**, **캐싱 계층**의 교훈을 한 자리에 모은다.

### 순진 재귀 vs. 메모이제이션

가장 단순한 피보나치는 다음과 같다.

```elixir
defmodule Fib.Naive do
  def fib(0), do: 0
  def fib(1), do: 1
  def fib(n) when n > 1, do: fib(n - 1) + fib(n - 2)
end
```

- 이 구현은 **중복 호출**이 많아, 시간 복잡도가

  $$
  T(n) \approx T(n-1) + T(n-2) \Rightarrow T(n) = \Theta(\varphi^n),\quad \varphi \approx 1.618
  $$

  로 **지수 시간**이다.

간단한 메모이제이션을 붙이면:

```elixir
defmodule Fib.MemoInline do
  def fib(n), do: do_fib(n, %{0 => 0, 1 => 1})

  defp do_fib(n, cache) do
    case cache do
      %{^n => v} ->
        v

      _ ->
        v = do_fib(n - 1, cache) + do_fib(n - 2, cache)
        v
    end
  end
end
```

- 이 코드는 cache 업데이트를 생략해 있어서 실제로는 온전한 메모이제이션이 아니고,
  예제 목적상 “**캐시를 쓰고 싶지만 순수 함수만으로는 번거롭다**”는 점을 보여준다.
- 실전에서는 **캐시를 프로세스 상태**로 두는 편이 훨씬 자연스럽다.

---

### GenServer 기반 피보 캐시

이제 피보나치 값을 **GenServer 상태에 캐시하는 서버**를 만들어보자.

```elixir
defmodule Fib.Server do
  use GenServer

  # API
  def start_link(opts \\ []) do
    name = Keyword.get(opts, :name, __MODULE__)
    GenServer.start_link(__MODULE__, :ok, name: name)
  end

  def fib(n, server \\ __MODULE__) when is_integer(n) and n >= 0 do
    GenServer.call(server, {:fib, n}, 15_000)
  end

  # 콜백
  @impl true
  def init(:ok) do
    {:ok, %{0 => 0, 1 => 1}}
  end

  @impl true
  def handle_call({:fib, n}, _from, cache) do
    case cache do
      %{^n => v} ->
        {:reply, v, cache}

      _ ->
        v = compute(n, cache)
        {:reply, v, Map.put(cache, n, v)}
    end
  end

  defp compute(n, cache) do
    fib_local(n, cache)
  end

  defp fib_local(n, cache) when n <= 1, do: n

  defp fib_local(n, cache) do
    v1 = Map.get_lazy(cache, n - 1, fn -> fib_local(n - 1, cache) end)
    v2 = Map.get_lazy(cache, n - 2, fn -> fib_local(n - 2, cache) end)
    v1 + v2
  end
end
```

#### 동작 포인트

- `cache`는 단순한 맵 `%{정수 => 정수}`.
- 클라이언트는 항상 `GenServer.call/3` 로 서버에 요청한다.
  - 동시에 여러 클라이언트가 `fib(40)`을 요청해도,
    서버가 하나하나 순서대로 응답하므로 **캐시 일관성**이 유지된다.
- 처음 호출 때는 계산이 느릴 수 있지만, 이후 호출은 맵에서 바로 읽는다.

#### 예제

```elixir
{:ok, _} = Fib.Server.start_link()

# 처음 호출: cache에 없어 계산

Fib.Server.fib(40)

# 같은 n을 다시 호출하면 즉시 응답

Fib.Server.fib(40)
```

여기서 느낄 수 있는 점:

- 피보나치는 **재귀 구조가 단순해서 캐시 효과가 극적**으로 나타나는 좋은 예다.
- 실제 서비스에서는 피보나치 대신 **외부 API 응답, DB 결과** 같은 것을 캐시한다.

---

### ETS 캐시로 읽기 병렬화

`Fib.Server` 구조에서는 모든 읽기/쓰기 요청이 **GenServer를 거쳐야** 한다.
읽기 요청이 매우 많다면, 이를 **ETS(Table)** 로 옮겨 읽기 병렬화를 할 수 있다.

```elixir
defmodule Fib.ETS do
  use GenServer

  def start_link(opts \\ []) do
    name = Keyword.get(opts, :name, __MODULE__)
    GenServer.start_link(__MODULE__, :ok, name: name)
  end

  # API
  def fib(n, server \\ __MODULE__) when n >= 0 do
    case :ets.lookup(:fib_cache, n) do
      [{^n, v}] ->
        v

      [] ->
        GenServer.call(server, {:fib, n})
    end
  end

  @impl true
  def init(:ok) do
    :ets.new(:fib_cache, [:set, :public, :named_table, read_concurrency: true])
    :ets.insert(:fib_cache, [{0, 0}, {1, 1}])
    {:ok, %{}}
  end

  @impl true
  def handle_call({:fib, n}, _from, st) do
    case :ets.lookup(:fib_cache, n) do
      [{^n, v}] ->
        {:reply, v, st}

      [] ->
        v = compute(n)
        :ets.insert(:fib_cache, {n, v})
        {:reply, v, st}
    end
  end

  defp compute(n) when n <= 1, do: n
  defp compute(n), do: fib(n - 1) + fib(n - 2)
end
```

#### 설계 요점

- **읽기**:
  - 먼저 ETS에서 찾는다(`:ets.lookup/2`).
  - 존재하면 GenServer를 거치지 않고 **즉시 반환**.
- **쓰기**:
  - 캐시 미스일 때만 GenServer를 통해 계산 후 ETS에 저장.
  - 쓰기는 여전히 GenServer가 직렬화하므로,
    복잡한 쓰기 정책(만료 시간, 크기 제한 등)을 안전하게 구현할 수 있다.

#### ETS 옵션

- `:public`
  - 어떤 프로세스든 읽기/쓰기가 가능하다.
  - 읽기를 병렬화하려면 보통 `:public` + `read_concurrency: true` 를 쓴다.
- `read_concurrency: true`
  - 읽기 락 경합을 줄이는 방향으로 최적화한다.
- 필요하다면 `write_concurrency: true` 도 고려할 수 있다.

---

### 수학적 체크(근사/검증)

피보나치 수열은 **황금비**와 깊은 관련이 있다.
비네 공식(Binet’s formula) 근사:

$$
F_n = \frac{\varphi^n - (1-\varphi)^n}{\sqrt{5}}
\approx \left\lfloor \frac{\varphi^n}{\sqrt{5}} + \frac{1}{2} \right\rfloor
$$

여기서 \(\varphi = \frac{1 + \sqrt{5}}{2}\).

간단한 프로퍼티 테스트로 이를 검증해 보자.

```elixir
# mix.exs : {:stream_data, "~> 0.6", only: :test}

defmodule Fib.PropertyTest do
  use ExUnit.Case
  use ExUnitProperties

  property "fib(n) ~= phi^n/sqrt(5) 근사" do
    check all n <- integer(0..40) do
      phi = (1 + :math.sqrt(5.0)) / 2.0
      approx = round(:math.pow(phi, n) / :math.sqrt(5.0))

      v = Fib.Server.fib(n)

      assert v in [approx - 1, approx, approx + 1]
    end
  end
end
```

- `n <= 40` 정도에서는 부동소수점 오차가 크지 않아 근사가 잘 맞는다.
- 엘릭서 정수는 **임의 정밀도(BigInt)** 이므로 오버플로우 걱정은 덜하다.
  다만 값 자체가 기하급수적으로 커지므로 **시간/메모리**는 주의해야 한다.

---

### 분산으로 확장(개념 맛보기)

피보나치 계산은 CPU 바운드라,
여러 노드로 분산해서 계산하면 이득을 볼 수 있는 전형적인 예이기도 하다.

- 캐시 계층:
  - **로컬 ETS/Agent** → 빠른 응답
  - **원격 캐시(예: Redis)** → 노드 간 공유
- 계산 계층:
  - 각 노드에 Fib 서버를 띄우고,
  - 분산 작업 스케줄러가 `:rpc.call/4` 등으로 특정 노드에 계산 위임.

이 장에서는 개념만 맛만 보고,
실제 분산 설계 세부사항(정합성, 네트워크 분할, 재시도, idempotency 등)은
별도의 분산/클러스터링 장에서 깊게 다루는 것이 어울린다.

---

## _15.6 에이전트: 예고편_

> **Agent** 는 “작은 상태를 캡슐화”하는 경량 서버.
> **읽기/쓰기 함수**만 제공하면 끝나는 단순한 API를 가진다.

### 가장 작은 카운터

```elixir
{:ok, pid} = Agent.start_link(fn -> 0 end, name: :counter)

Agent.get(:counter, & &1)           # 0
Agent.update(:counter, &(&1 + 1))   # :ok
Agent.get(:counter, & &1)           # 1
```

- `Agent.start_link/2` 의 첫 번째 인자는 **초기 상태를 만드는 함수**.
- `Agent.get/3` 은 현재 상태를 읽기만 한다.
- `Agent.update/3` 은 상태를 주어진 함수에 넣어 **새 상태를 만든다**.

내부적으로는 Agent도 결국 **GenServer 래퍼**다.

- `get`/`update` 호출은 내부적으로 `GenServer.call/cast` 로 구현되어 있다.
- 다만, **API가 단순해서 “상태 박스”처럼 느껴진다**는 것이 장점.

---

### 캐시·메모 구조로 사용

Agent는 작은 캐시/메모 구조에 잘 어울린다.

```elixir
defmodule Cache do
  def start_link(name), do: Agent.start_link(fn -> %{} end, name: name)

  def get(name, k, fun) do
    Agent.get_and_update(name, fn m ->
      case m do
        %{^k => v} ->
          {v, m}

        _ ->
          v = fun.()
          {v, Map.put(m, k, v)}
      end
    end)
  end
end

{:ok, _} = Cache.start_link(:memo)
Cache.get(:memo, 40, fn -> Fib.Server.fib(40) end)  # 캐시 후 반환
```

- `Agent.get_and_update/3` 는 **읽기와 쓰기를 하나의 원자적 연산으로** 수행한다.
- “**없으면 계산 후 저장, 있으면 바로 반환**” 같은 패턴이 한 번에 구현된다.

---

### Agent vs GenServer 선택 기준

두 도구는 어느 정도 겹치지만, 성격이 다르다.

| 조건 | Agent | GenServer |
|------|-------|----------|
| 단순 상태 get/set | 적합 | 적합 |
| 복합 트랜잭션(다중 단계) | 가능하지만 코드가 길어짐 | 적합 |
| 커스텀 메시지 프로토콜 | 부적합 | 적합 |
| 시간/타임아웃·지연 작업 | 제한적 | 풍부 (handle_info, timeout 등) |
| 복잡한 라이프사이클 관리 | 제한적 | 적합 |

경험적으로:

- **정말 단순한 캐시/계수기/스냅샷** 정도면 Agent.
- 장기적으로 **프로토콜/정책/타임아웃/역압**이 필요해질 가능성이 있으면
  처음부터 GenServer로 시작하는 편이 낫다.

---

### Agent에서 GenServer로의 자연스러운 진화

초기에 Agent로 시작했다가, 요구사항이 늘어나서 GenServer로 갈아타는 경우가 많다.

예시: TTL이 있는 캐시

```elixir
defmodule TTLCache do
  use GenServer

  def start_link(opts \\ []), do: GenServer.start_link(__MODULE__, :ok, opts)

  def get(pid, key, ttl_ms, fun) do
    GenServer.call(pid, {:get, key, ttl_ms, fun})
  end

  @impl true
  def init(:ok), do: {:ok, %{}}

  @impl true
  def handle_call({:get, key, ttl_ms, fun}, _from, state) do
    now = System.monotonic_time(:millisecond)

    case state do
      %{^key => {value, inserted_at}} when now - inserted_at < ttl_ms ->
        {:reply, value, state}

      _ ->
        value = fun.()
        new_state = Map.put(state, key, {value, now})
        {:reply, value, new_state}
    end
  end
end
```

- 단순히 값만 저장하던 Agent를,
  “**삽입 시각과 함께 저장 → TTL 기준으로 만료**”하는 GenServer로 진화시키는 예.

---

### Agent와 리소스 관리

Agent에 **파일 핸들/소켓** 같은 외부 리소스를 넣어 관리하는 것은 추천되지 않는다.

```elixir
{:ok, pid} =
  Agent.start_link(fn -> File.open!("log.txt", [:append]) end, name: :log_agent)

Agent.update(:log_agent, fn io ->
  IO.write(io, "hello\n")
  io
end)
```

이렇게 하면:

- Agent가 죽을 때 파일을 어떻게 닫을지 불명확하다.
- `terminate/2` 등 콜백이 없기 때문에,
  리소스 정리를 확실하게 할 수 없다.

외부 리소스는 가능하면:

- `GenServer` 상태에 넣고,
- `terminate/2` + `after` 블록으로 **명시적 정리**를 보장하는 패턴이 좋다.

---

## _15.7 프로세스 관점에서 생각하기_

> 시스템을 **객체/함수 호출**이 아니라 **프로세스들의 대화**로 그려라.
> 각 프로세스는 **작은 책임 하나**, 메시지 규약은 **문서화된 프로토콜**이다.

### “프로세스 캔버스”로 재구성

전통적인 계층 구조:

- 컨트롤러 → 서비스 → 리포지토리 → DB

를 프로세스 관점으로 표현하면 대략 이렇게 된다(텍스트 다이어그램):

```text
[HTTP Entry] --> [Router/Controller Proc]
                 |
                 v
            [Command Bus Proc]
                 |
      +----------+-----------+
      |                      |
      v                      v
[Validation Proc]      [Domain Server(s)]
                              |
                              v
                         [Repo Proc]
                              |
                              v
                            [DB]
```

각 박스는:

- GenServer, Task, Agent 중 하나로 구현 가능하다.
- 책임은 **하나**만 가지게 한다.
- 링크/슈퍼비전 관계는 별도의 트리에서 관리한다.

---

### 메시지 프로토콜 규약

프로세스 간 통신은 결국 **메시지 형식**에 의해 정의된다.

- 태그드 튜플: `{:cmd, param}`, `{:event, payload}` 등
- 요청/응답 상관관계: `ref`(참조)를 포함하여 구분

```elixir
ref = make_ref()
send(server, {:get_user, ref, self(), id})

receive do
  {:get_user_reply, ^ref, {:ok, user}} -> user
after
  5_000 -> {:error, :timeout}
end
```

프로토콜 설계 시 체크리스트:

- [ ] 요청/응답에 **고유 ref** 포함 (특히 병렬 요청 시 필수)
- [ ] **버전 태그** (예: `{:v1, ...}`) 로 미래 변경에 대비
- [ ] 에러는 `{:error, reason}` 형태로 일관되게 전달
- [ ] 필요한 메타데이터(tenant, trace id, user id 등)를 메시지에 포함

---

### 공정성 vs 선택적 수신

앞에서 본 것처럼, 선택적 수신은 강력하지만 **굶주림(starvation)**을 부른다.

```elixir
receive do
  {:priority, m} -> handle_prio(m)
after
  0 -> :ok
end

receive do
  any -> handle_normal(any)
after
  0 -> :ok
end
```

이런 패턴으로:

- 먼저 우선순위 메시지를 처리하되,
- 이후 **남은 시간 동안 일반 메시지도 처리**하도록 루프를 돌릴 수 있다.

또는 아예:

- 우선순위 큐/일반 큐를 **서버 내부 상태**로 운용하고,
- `receive`는 모든 메시지를 받아 **큐에만 넣고**,
  실제 우선순위 결정은 상태 레벨에서 할 수도 있다.

---

### 역압과 경계

시스템 전체에서 가장 중요한 사실 중 하나:

$$
\text{외부 입력 속도} \le \text{시스템 처리 속도}
$$

이를 지키기 위해:

1. **외부 입력 경계에서 역압 설계**

   - HTTP: 요청 수 제한(예: 라이브러리 또는 reverse proxy), 큐 길이 제한.
   - 메시지 큐: 소비자 수 조절, 재시도 정책 설정.

2. **내부 프로세스 간 역압**

   - `GenServer.call/3` 사용 → 호출자 차단.
   - `Task.async_stream/3` 의 `max_concurrency` 설정.
   - 메일박스 길이 측정 후 **드롭/거부/샘플링**.

---

### 실패를 모델에 포함

실패는 예외가 아니라 **독립적인 상태 전이**로 생각할 수 있다.

예: 외부 API 클라이언트의 상태 머신

```text
:opening -> :open -> :error(:timeout) -> :retrying -> :open -> ...
```

이를 GenServer 상태로 옮기면:

```elixir
def handle_info(:tick, %{state: :open} = st) do
  case HTTP.get(st.url) do
    {:ok, resp} ->
      {:noreply, st}

    {:error, :timeout} ->
      {:noreply, %{st | state: {:error, :timeout}, retry_at: now() + 1000}}
  end
end
```

그리고 Supervisor 정책과 결합하면:

- 일정 횟수 이상 실패하면 프로세스를 재시작,
- 재시작이 너무 잦으면 상위 Supervisor가 전체 서브트리를 재시작하는 등,
  **자기 치유(self-healing)** 구조를 만들 수 있다.

---

### 관찰 가능성(Observability)

모니터링 없이 추측으로 디버깅하면,
언젠가 규모가 커졌을 때 **문제 재현**이 거의 불가능해진다.

기본 전략:

1. **Telemetry 이벤트**를 주요 경로에 심는다.

   ```elixir
   :telemetry.execute(
     [:my_app, :pmap, :stop],
     %{duration: native_time},
     %{count: length(enumerable)}
   )
   ```

2. **메일박스 길이**와 **레덕션** 지표를 주기적으로 보고한다.

   ```elixir
   def report_mailbox() do
     len = Process.info(self(), :message_queue_len) |> elem(1)
     :telemetry.execute([:my_app, :proc, :mailbox], %{len: len}, %{})
   end
   ```

3. Prometheus/StatsD 등으로 지표를 수집하고,
   대시보드(예: Grafana, LiveDashboard)를 통해 시각화한다.

---

### 작은 지침 모음

정리 차원에서, 이 장 전체의 핵심 지침을 다시 모아보면:

- **한 프로세스 = 한 책임**
  - 너무 많은 역할을 한 프로세스에 몰지 않는다.
- **메시지는 불변 데이터**
  - 공유 상태 대신, 불변 메시지를 교환한다.
- **프로토콜은 문서화**
  - 메시지 형태, 버전, 에러 규약을 글로 적어둔다.
- **역압은 설계의 일부**
  - `call`/배치/상한/큐 정책 등으로 항상 상한선을 둔다.
- **정리 보장**
  - 파일/소켓/포트는 `after`와 `terminate/2`에서 닫는다.
- **큰 바이너리는 짧게 보관**
  - 오래 보관할 필요가 있다면 `:binary.copy/1`을 써서 작은 단위로 분리한다.
- **동시성 상한은 항상 명시**
  - `Task.async_stream`, 워커 풀, 외부 큐 소비자 수 등.

---

## 전체 샘플: 병렬 맵 + 피보 서버 + 에이전트 메모 통합

마지막으로, 지금까지 다룬 요소들을 간단히 **한 코드 조각**으로 엮어 보자.

```elixir
defmodule Demo do
  def start() do
    {:ok, _} = Fib.Server.start_link(name: Fib.Server)
    {:ok, _} = Agent.start_link(fn -> %{} end, name: :memo)
    :ok
  end

  def fibs(ns) do
    ns
    |> Task.async_stream(&memo_fib/1,
         max_concurrency: System.schedulers_online() * 2,
         timeout: 10_000
       )
    |> Enum.map(fn {:ok, v} -> v end)
  end

  defp memo_fib(n) do
    CacheLike.get(:memo, n, fn -> Fib.Server.fib(n) end)
  end
end

defmodule CacheLike do
  def get(name, k, fun) do
    Agent.get_and_update(name, fn m ->
      case m do
        %{^k => v} -> {v, m}
        _ ->
          v = fun.()
          {v, Map.put(m, k, v)}
      end
    end)
  end
end

# 실행

Demo.start()
Demo.fibs([35, 36, 37, 38, 39, 40])
```

구조 요약:

- `Fib.Server`
  - 피보나치 값을 캐시하는 GenServer.
- `:memo` Agent
  - 추가적인 메모 계층(예: 워커 로컬 캐시)으로 활용.
- `Task.async_stream/3`
  - 여러 n에 대해 **병렬로 피보나치 계산 + 캐시**.
- 역압/상한은 `max_concurrency` 로 제어.

---

## 연습 문제

1. **고급 PMap**
   - 실패 태스크가 나오면 **즉시 나머지 태스크를 취소**하고,
     이미 완료된 부분 결과만 반환하는 `pmap_cancel/3` 를 작성해 보라.
     힌트: `Task.Supervisor` + 태스크 PID 관리.

2. **Fib 서버 확장**
   - ETS 캐시 + **주기적 스냅샷(파일 저장)** 기능을 추가하고,
     재시작 시 스냅샷을 로드하도록 구현해 보라.

3. **Agent→GenServer 리팩터**
   - Agent로 만든 캐시를 **TTL 만료 정책**과 **최대 용량(LRU)** 를 가진 GenServer로 바꿔 보라.

4. **프로토콜 설계**
   - `{:request, ref, from, payload}` ↔ `{:reply, ref, result}` 프로토콜을 정의하고,
     선택적 수신 굶주림을 방지하는 수신 루프를 작성해 보라.

5. **관찰 가능성**
   - 병렬 맵 수행 시간과 각 워커의 **메일박스 길이**를 Telemetry로 계측하고,
     Phoenix LiveDashboard 또는 Prometheus 기반 대시보드로 시각화해 보라.

---

## 마무리

- **병렬 맵**은 “많은 프로세스가 일하고, 우리는 결과만 모은다”는 BEAM/얼랭/엘릭서의 기본 미학이다.
- **피보나치 서버**는 “상태(캐시)를 프로세스에 넣어 직렬화/병렬화를 제어”하는 패턴을 명확히 보여준다.
- **Agent**는 간단한 상태 캡슐에 잘 맞지만, 정책/프로토콜/역압이 필요해지면 **GenServer**가 자연스러운 다음 단계다.
- 무엇보다, 시스템을 **프로세스들의 대화**로 그리는 습관을 들이면,
  **격리·복구·확장**이 쉬운 구조를 만들 수 있다.

이 장에서 다룬 패턴들을 실제 프로젝트에 하나씩 옮겨보면,
엘릭서의 동시성/장애 복구 특성이 어떻게 “코드 구조”로 드러나는지 몸으로 느끼게 될 것이다.
