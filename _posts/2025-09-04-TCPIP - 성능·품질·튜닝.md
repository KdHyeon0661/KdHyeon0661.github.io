---
layout: post
title: TCPIP - 성능·품질·튜닝
date: 2025-09-04 17:25:23 +0900
category: TCPIP
---
# 13. 성능·품질·튜닝
**(🔰 대역폭·지연·Jitter·손실과 체감 품질, ⚙️ MTU/MSS/PMTUD 블랙홀, ⚙️ 큐관리/버퍼블로트·QoS/DSCP·ECN, 🚀 서버·클라이언트 튜닝 체크리스트)**

> 이 글은 “네트워크가 빠르고 매끄럽게 느껴지려면 무엇을 건드려야 하는가?”를 **측정 → 원인 → 해결** 순으로 정리합니다.  
> 핵심 수식은 *MathJax*, 명령/설정은 ``` 코드 블록으로 제공합니다.

---

## 13.1 체감 품질을 좌우하는 4대 요소 (🔰)

### 13.1.1 용어 정의
- **대역폭(Bandwidth)**: 링크가 *이론상* 보낼 수 있는 최대 속도(예: 1 Gbps).  
- **처리량(Throughput/Goodput)**: 실제 **유효 데이터**가 전달되는 속도(헤더/재전송 제외).  
- **지연(Latency/RTT)**: 요청→응답까지 왕복 시간.  
- **지터(Jitter)**: 지연의 변동성(분산/편차).  
- **손실(Loss)**: 전송 중 드롭된 패킷 비율.

### 13.1.2 체감 품질과의 관계
- 웹/앱 시작속도(TTFB) = `DNS + 연결 + 핸드셰이크 + 1 RTT`  
- 스트리밍/통화: **지터**가 크면 **끊김/로봇보이스**.  
- 다운로드: **대역폭×RTT(=BDP)**를 채우려면 **윈도우/버퍼**가 충분해야 함.

\[
\text{BDP} = \text{Bandwidth} \times \text{RTT}
\]
\[
\text{필요 윈도우(바이트)} \ge \text{BDP}
\]

> 예) 1 Gbps, RTT 100 ms → BDP ≈ \(1\ \text{Gbps} \times 0.1\ \text{s} = 100\ \text{Mb} \approx 12.5\ \text{MB}\).  
> 송수신 버퍼/윈도우가 이보다 작으면 **속도가 대역폭에 못 미침**.

### 13.1.3 큐잉 지연과 버퍼블로트
\[
\text{Queue Delay} \approx \frac{\text{큐에 쌓인 바이트}}{\text{병목 링크 속도}}
\]
- 큐가 크면 혼잡 시 **지연이 수백 ms~수초**로 치솟는 현상 = **버퍼블로트**.  
- 해결: **AQM(CoDel/fq_codel/PIE)**, **Pacing**, **정확한 트래픽 쉐이핑**.

### 13.1.4 TCP 처리량의 손실 민감도(근사)
\[
\text{Throughput} \propto \frac{\text{MSS}}{\text{RTT} \cdot \sqrt{p}}
\]
- \(p\): 손실률. 손실이 4배 늘면 처리량은 **반**으로.  
- ECN·AQM·패이싱으로 **드롭을 마킹으로 대체**하면 이득.

---

## 13.2 MTU / MSS / PMTUD 블랙홀 (⚙️)

### 13.2.1 개념 요약
- **MTU**: 한 프레임의 L3 최대 크기(이더넷 보통 1500).  
- **MSS**: TCP 세그먼트의 **페이로드** 최대(보통 1460 = 1500 - 20(IP) - 20(TCP); 옵션/IPv6에 따라 달라짐).  
- **PMTUD**: DF(분할금지)로 보냈을 때 경로 장치가 **ICMP Frag Needed/Too Big**로 알려주며 MTU를 낮추는 과정.  
- **블랙홀**: ICMP가 차단/유실되어 **큰 패킷은 사라지고 응답이 없어** “큰 것만 끊김”.

### 13.2.2 증상
- “작은 요청은 OK, 큰 파일/응답만 타임아웃”  
- “TLS 핸드셰이크/HTTP/3만 실패, H2는 간헐 성공”  
- VPN/터널(WireGuard/IPsec/VXLAN/PPPoE) 경로에서 빈발.

### 13.2.3 계측/재현
```bash
# 경로 MTU 추정(리눅스)
tracepath <host>         # 각 홉의 MTU 힌트
# DF 고정 ping(IPv4)
ping -M do -s 1472 <host>   # 1500-28(IP+ICMP)=1472 → 실패하면 -s를 줄여 안전 크기 찾기
# DF 고정 ping(IPv6)
ping -M do -s 1452 -6 <host> # IPv6 헤더 40B 감안
```

### 13.2.4 해결 전략
- **MSS 클램핑**(경계 라우터/방화벽에서): TCP SYN 시 **MSS를 안전값으로 낮춤**.
```bash
# nftables 예(개념): WAN 인터페이스 출구에서 MSS 1360으로 클램핑
add rule inet filter forward tcp flags syn tcp option maxseg size set 1360
```
- **ICMP PTB 허용**: 방화벽에서 **Frag Needed/Too Big** 통과.  
- **PLPMTUD**: ICMP 없이도 **프로빙 재전송으로 MTU 추정**(현대 TCP/QUIC에 도입).  
- **터널 오버헤드 감안**: VLAN/QinQ/PPPoE/GRE/VXLAN/IPsec 등 **오버헤드 표** 참고 후 MTU 축소.

**오버헤드 예(대략)**
```
VLAN 802.1Q: +4
QinQ: +8
PPPoE: +8
GRE: +24
VXLAN: +50 (IP+UDP+VXLAN)
WireGuard: ~+32
IPsec ESP(터널): +50~70 (알고리즘/패딩/리플레이에 따라)
```

> **IPv6**: 링크 MTU **최소 1280** 보장. 경로 전체가 1500이 아닐 수 있으므로 **MSS 보수적 설계** 권장.

---

## 13.3 큐관리(AQM)/버퍼블로트, QoS/DSCP, ECN (⚙️)

### 13.3.1 AQM 개요
- **RED**: 확률적 드롭으로 혼잡 신호를 미리 제공(튜닝 난이도↑).  
- **CoDel**: 지연(큐 체류시간) 기준으로 드롭 결정(자동화).  
- **fq_codel**: **플로우별 큐 + CoDel** → 상호 간섭↓, **상호작용 트래픽 품질↑**.  
- **PIE**: 케이블/사업자 장비에서 흔함(지연 목표 기반 확률적 드롭).  
- **CAKE**: fq_codel 고도화(가정/소규모 엣지에 강력).

**리눅스 qdisc 적용 예**
```bash
# 엣지 인터페이스에 fq_codel
sudo tc qdisc replace dev eth0 root fq_codel
# 또는 fq(패이싱 친화)
sudo sysctl -w net.core.default_qdisc=fq
```

### 13.3.2 패이싱(Pacing)
- 대량 송신을 **시간 간격으로 분산** → 큐 스파이크/드롭 감소.  
- **CUBIC/BBR + fq qdisc** 조합 권장.

### 13.3.3 QoS/DSCP
- **DSCP**로 트래픽 클래스 표기(EF=46: 음성, AFxy: 보장 포워딩, CSx: 클래스 선택).  
- **도메인 경계에서 재마킹/블리칭** 가능 → **엔드-투-엔드 보장 아님**.  
- **Wi-Fi(WMM)** 맵핑(대략):  
  - **EF/Voice → AC_VO**,  
  - **Video → AC_VI**,  
  - **Best Effort → AC_BE**,  
  - **Background → AC_BK**.

**설정 예(애플리케이션 단)**
```c
// POSIX 소켓에서 DSCP = EF(46)
int tos = 46 << 2;                        // DSCP는 상위 6비트, 커널마다 시프트 상이
setsockopt(fd, IPPROTO_IP, IP_TOS, &tos, sizeof(tos));
```

**방화벽 마킹 예(개념)**
```bash
# VoIP 서브넷에서 나가는 UDP를 EF로 재마킹
iptables -t mangle -A POSTROUTING -s 10.10.10.0/24 -p udp -j DSCP --set-dscp 46
```

> **주의**: **임의 재마킹은 상호운용 이슈**. 도메인 내부/사내망에서 정책 합의 후 사용.

### 13.3.4 ECN(Explicit Congestion Notification)
- **드롭 대신 마킹**으로 혼잡 알림: **ECT(0/1)**로 송신 의사, 라우터가 **CE**로 마킹, 수신자는 **TCP ECE**로 알리고 송신자는 **CWR**로 혼잡 반응.  
- 장점: 드롭/재전송 감소 → **지연·손실 동시 감소**.  
- 조건: **경로 중간 장비가 ECN 패스/마킹** 지원, OS에서 **ECN 활성화**.

```bash
# 리눅스: TCP ECN 활성화
sudo sysctl -w net.ipv4.tcp_ecn=1
```

---

## 13.4 서버·클라이언트 튜닝 체크리스트 (🚀)

> **원칙**: “**측정 → 병목 가설 → 최소한의 변경 → 재측정**” 사이클.  
> 무턱대고 모든 튜닝을 켜지 말고 **서비스 특성/트래픽 패턴**에 맞춰 적용합니다.

### 13.4.1 공통(관측/도구)
```bash
ss -tin                     # 소켓 상태, cwnd/rwnd/rtt/rto
ss -s                       # 전체 통계
tc -s qdisc show dev eth0   # 큐 지연/드롭 관찰
ethtool -k eth0             # NIC 오프로드 기능
ethtool -S eth0             # 드롭/에러 카운터
mtr -rwzbc100 <host>        # 손실/지연 프로파일
iperf3 -c <host> -t 30      # 처리량/RTT 측정
flent rrul -H <host>        # 버퍼블로트 테스트(혼합 트래픽)
```

### 13.4.2 서버 OS(리눅스) — 네트워크 스택
```bash
# 혼잡제어
sysctl -w net.ipv4.tcp_congestion_control=cubic    # 또는 bbr (A/B 권장)

# ECN·SACK·타임스탬프·RACK/TLP(커널 의존)
sysctl -w net.ipv4.tcp_ecn=1
sysctl -w net.ipv4.tcp_sack=1
sysctl -w net.ipv4.tcp_timestamps=1
sysctl -w net.ipv4.tcp_recovery=1        # RACK
sysctl -w net.ipv4.tcp_early_retrans=1   # TLP 유사

# 버퍼 오토튜닝 상한(환경에 맞게)
sysctl -w net.ipv4.tcp_rmem="4096 87380 134217728"
sysctl -w net.ipv4.tcp_wmem="4096 65536 134217728"
sysctl -w net.core.rmem_max=134217728
sysctl -w net.core.wmem_max=134217728

# 큐디스크/패이싱
sysctl -w net.core.default_qdisc=fq      # pacing-friendly
tc qdisc replace dev eth0 root fq_codel  # 엣지/게이트에서 유익

# 백로그/동시성
sysctl -w net.core.somaxconn=4096
sysctl -w net.ipv4.tcp_max_syn_backlog=4096

# PMTUD/블랙홀 내성
sysctl -w net.ipv4.tcp_mtu_probing=1

# TIME_WAIT/포트 재사용 (의미 이해 후 제한적으로)
# sysctl -w net.ipv4.tcp_tw_reuse=1
```

**주의**
- **BBR** 사용 시 **fq qdisc + pacing** 필수. AQM과 **공존성 테스트** 할 것.  
- **tcp_fastopen**(서버/클라): 중간장비 호환성 이슈 있는 환경은 신중.

### 13.4.3 서버 하드웨어·NIC
- **RSS/멀티큐** 활성화(다핵 분산), **IRQ affinity/NUMA** 정렬.  
- **TSO/GSO/GRO/LRO**: CPU↓지만 지연↑ 가능 → **지연 민감 서비스**는 조정.
```bash
# 오프로드 토글(예시)
ethtool -K eth0 tso on gso on gro on      # 기본은 on, 서비스별 검증
```
- **링 버퍼**(ethtool -g) 조정으로 드롭 완화(과도하면 지연↑).
- **BQL(Bufferbloat Control)** 지원 NIC/드라이버 선호.

### 13.4.4 애플리케이션/프록시
- **HTTP/2/3 지원**, **TLS 1.3**, **0-RTT는 멱등만**.  
- **Keep-Alive/풀링**: 커넥션 수 최소화, **코얼레싱** 가능 도메인 설계.  
- 작은 write 다발 → **코알레싱**(버퍼링) 또는 **TCP_NODELAY** 전략화.  
- **SO_REUSEPORT**로 멀티워커 부하 균등(핫스팟/스케줄링 확인).  
- **sendfile/zerocopy(io_uring/MSG_ZEROCOPY)**로 CPU·복사 감소.

### 13.4.5 데이터센터/엣지
- **AQM(fq_codel/PIE)**, **ECN**(스위치/서버 양단 일치).  
- **링크 레벨 ECN/RED** 정책 표준화, **모바일/위성** 구간은 **큐 제어 엄격**.  
- **Anycast/다중 엣지**: 헬스·자동 리라우팅, **qlog/H3 관측**.

### 13.4.6 클라이언트(모바일/PC)
- **UDP NAT 타임아웃** 고려 Keepalive(15~30s).  
- **QUIC/H3 우선**(모바일·로스 환경).  
- **Wi-Fi**: WMM, 드라이버/펌웨어 최신, 간섭 채널 회피(5/6 GHz).  
- **OS 소켓 버퍼**: 고지연 고대역 링크에서 **읽기/쓰기 버퍼 확대**.

---

## 13.5 워크플로우: “느리다/끊긴다” 디버깅 순서

1) **증상 분류**  
   - 작은 건 됨, **큰 것만 끊김** → MTU/PMTUD.  
   - 왕복 느림, **손실 없음** → 큐/버퍼블로트/경로 RTT.  
   - 지터/무음 → **무선/모바일 QoS**, AQM/패이싱.  

2) **기본 계측**
```bash
ping -c 20 <host>                 # RTT 평균/표준편차
mtr -rwzbc100 <host>              # 홉별 손실/지연
iperf3 -R -t 20 -C cubic|bbr      # 역방향 포함 처리량
tracepath <host>                  # 경로 MTU 힌트
```

3) **가설별 테스트**
- **MTU**: DF ping, MSS 클램핑 적용/해제 A/B.  
- **버퍼블로트**: flent rrul, 업/다운 동시 송신 시 RTT 폭증?  
- **혼잡제어**: CUBIC↔BBR 전환 A/B, fq qdisc 적용.  
- **ECN**: 경로 ECN 지원 여부 확인(마킹율/재전송율 비교).

4) **조치→검증**  
   - 지표: `RTT(P95)`, `Jitter`, `Loss`, `Throughput`, `TTFB`, `Drop/CE` 마킹율.

---

## 13.6 실전 시나리오 (예제)

### 13.6.1 “VPN 켜면 큰 파일만 타임아웃”
```
가설: 터널 오버헤드로 MTU↓ + ICMP PTB 차단 → PMTUD 블랙홀
조치: 경계에서 TCP MSS 1360으로 클램핑, ICMP Too Big 허용
검증: tracepath, DF ping, 재시도율↓, 대용량 전송 성공
```

### 13.6.2 “회의 콜이 로봇보이스”
```
가설: 업로드 큐 포화(가정 공유망 업로드 10~30Mbps), 버퍼블로트
조치: 엣지 라우터에 fq_codel/CAKE, 업로드 90~95%로 Smart Queue
검증: 통화 중 ping 지연(P95) 30→10ms, 패킷 손실↓, MOS 개선
```

### 13.6.3 “H3 실패, H2는 됨”
```
가설: 443/UDP 차단 또는 PMTUD 실패(초기 1200B QUIC 패킷)
조치: 방화벽 443/UDP 허용, ICMP PTB 허용; 초기 크기 준수 확인
검증: H3 비율↑, Fallback(H2)↓, qlog 오류 해소
```

---

## 13.7 성능 수식·감각 메모

### 13.7.1 유효 처리량
\[
\text{Goodput} \approx \frac{\text{Payload}}{\text{Payload} + \text{헤더} + \text{재전송}} \times \text{Rate}
\]

### 13.7.2 큐 지연(근사)
\[
D_{\text{queue}} \approx \frac{B_{\text{queue}}}{R_{\text{bottleneck}}}
\]
- \(B_{\text{queue}}\): 큐 바이트, \(R_{\text{bottleneck}}\): 병목 링크 속도.

### 13.7.3 지터(지연 변화) 지표(일례)
\[
J \leftarrow J + \frac{|(D_i - D_{i-1})| - J}{16}
\]
- RTP/RTCP에서 흔히 쓰는 근사.

---

## 13.8 운영 템플릿 / 베스트 프랙티스

### 13.8.1 네트워크 레벨
- [ ] **ICMP PTB 허용**, PMTUD/PLPMTUD 신뢰.  
- [ ] **MSS 클램핑**(터널/PPPoE/모바일 경계).  
- [ ] **AQM 적용(fq_codel/PIE)**, 엣지에서 **정확한 쉐이핑**.  
- [ ] **ECN 활성화**(스위치/서버/애플리케이션 합치).  
- [ ] DSCP는 **내부 도메인 정책 합의** 후 사용.

### 13.8.2 서버 스택
- [ ] **CUBIC 기본**, 지연 민감/대역폭 큰 환경 **BBR A/B**.  
- [ ] **fq qdisc + pacing**, **SACK/Timestamps/RACK/TLP** On.  
- [ ] rmem/wmem 상한, somaxconn/backlog, SYN cookies/큐 용량.  
- [ ] NIC **RSS/멀티큐/IRQ-CPU 핀닝**, 오프로드/링버퍼 검증.  
- [ ] H2/H3, TLS1.3, 0-RTT(멱등만), 프리로드/프리커넥트.

### 13.8.3 애플리케이션
- [ ] **연결 재사용/풀링**, 작은 write **코알레싱**(또는 NODELAY).  
- [ ] **압축**(Brotli), **콘텐츠 캐싱**(ETag/stale-while-revalidate).  
- [ ] **백프레셔**: 소비자 속도 기반 레이트 조절.  
- [ ] **관측성**: qlog(QUIC), APM, 커스텀 지표(loss/RTT/jitter/CE).

### 13.8.4 클라이언트/모바일
- [ ] Wi-Fi 채널·WMM, 최신 드라이버.  
- [ ] NAT Keepalive(UDP 15~30s), H3 우선.  
- [ ] 고RTT 링크 버퍼 확대, 오프라인 큐·재시도 설계.

---

## 13.9 “한 장 요약(포스터)”
- **속도**는 **BDP**로, **반응성**은 **지연/지터**로 결정.  
- **MTU/PMTUD**를 존중하고, 터널에는 **MSS 클램핑**.  
- **버퍼블로트**는 **AQM+패이싱**으로 잡고, 필요 시 **ECN**.  
- **튜닝**은 **측정→가설→최소 변경→재측정**의 과학적 루프.  
- **현대 스택**: H2/H3+TLS1.3, fq/fq_codel, CUBIC/BBR, qlog/지표.

---

### 부록 A — 빠른 점검 명령 모음
```bash
# 1) RTT/지터
ping -c 20 <host> | tail -n2

# 2) 경로 손실/지연
mtr -rwzbc100 <host>

# 3) 처리량/혼잡제어 A/B
iperf3 -c <host> -t 20 -C cubic
iperf3 -c <host> -t 20 -C bbr --pacing-timer 1000

# 4) PMTUD/MTU
tracepath <host>
ping -M do -s 1472 <host>    # IPv4 DF
ping -M do -s 1452 -6 <host> # IPv6 DF

# 5) 큐/드롭
tc -s qdisc show dev eth0
ethtool -S eth0 | egrep 'drop|err|miss'

# 6) 소켓/윈도우
ss -tin | head
```

### 부록 B — 리눅스 커널 파라미터 힌트표(요지)
```
net.ipv4.tcp_congestion_control   = cubic|bbr
net.core.default_qdisc            = fq|fq_codel
net.ipv4.tcp_ecn                  = 1
net.ipv4.tcp_sack                 = 1
net.ipv4.tcp_timestamps           = 1
net.ipv4.tcp_mtu_probing          = 1
net.core.rmem_max / wmem_max      = (환경별 확대)
net.ipv4.tcp_rmem / tcp_wmem      = (오토튜닝 상한)
net.core.somaxconn                = 4096+
net.ipv4.tcp_max_syn_backlog      = 4096+
```

### 부록 C — 변경 전/후 기록 템플릿
```text
[환경] RTT/대역폭/MTU/터널/무선/큐 정책
[증상] 예) 대용량만 타임아웃 / 통화 지터↑ / TTFB↑
[가설] PMTUD 블랙홀 / 버퍼블로트 / 윈도우 부족 / ECN 미지원
[변경] MSS=1360, fq_codel 적용, ECN=1, rmem/wmem 상향
[결과] RTT(P95)↓, 지터↓, 손실↓, 처리량↑, 오류율↓ (수치 명시)
[다음] A/B 확장, 롤백 조건, 문서화
```