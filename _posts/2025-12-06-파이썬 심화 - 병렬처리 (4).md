---
layout: post
title: 파이썬 심화 - 병렬처리 (4)
date: 2025-12-06 18:30:23 +0900
category: 파이썬 심화
---
# 병렬처리 (4)

## 스레드의 대안으로 제너레이터 사용하기: 협력적 멀티태스킹

제너레이터는 파이썬에서 스레드의 경량 대안으로 활용될 수 있는 강력한 기능입니다. `yield` 키워드를 통해 실행을 일시 중지하고 나중에 재개할 수 있는 특성을 활용하면, 단일 스레드 내에서 여러 작업을 협력적으로 전환하며 실행하는 시스템을 구축할 수 있습니다.

### 제너레이터 기반 이벤트 루프 시스템

```python
import time
import heapq
from typing import Generator, Any, Callable, Optional, Dict, List, Union
from enum import Enum
from dataclasses import dataclass, field
from collections import deque

class TaskState(Enum):
    """태스크 상태 관리"""
    READY = "ready"
    RUNNING = "running"
    WAITING = "waiting"
    COMPLETED = "completed"
    ERROR = "error"

@dataclass(order=True)
class Task:
    """제너레이터 기반 태스크 객체"""
    task_id: int
    generator: Generator
    priority: int = 0
    created_at: float = field(default_factory=time.time)
    started_at: Optional[float] = None
    completed_at: Optional[float] = None
    state: TaskState = TaskState.READY
    result: Any = None
    error: Optional[Exception] = None
    wait_until: Optional[float] = None
    
    def run_step(self) -> bool:
        """태스크 한 단계 실행"""
        if self.state == TaskState.COMPLETED:
            return True
            
        if self.wait_until and time.time() < self.wait_until:
            return False
            
        if self.started_at is None:
            self.started_at = time.time()
            
        self.state = TaskState.RUNNING
        
        try:
            # 제너레이터에서 다음 값 가져오기
            value = next(self.generator)
            
            # 특수 명령어 처리
            if isinstance(value, tuple) and len(value) == 2:
                cmd, arg = value
                if cmd == "sleep":
                    self.wait_until = time.time() + arg
                    self.state = TaskState.WAITING
                    return False
                elif cmd == "yield":
                    # 일반적인 yield - 계속 실행
                    self.state = TaskState.READY
                    return False
                    
            self.state = TaskState.READY
            return False
            
        except StopIteration as e:
            # 제너레이터 완료
            self.state = TaskState.COMPLETED
            self.completed_at = time.time()
            self.result = e.value
            return True
            
        except Exception as e:
            # 오류 발생
            self.state = TaskState.ERROR
            self.completed_at = time.time()
            self.error = e
            return True
    
    def get_execution_time(self) -> Optional[float]:
        """실행 시간 계산"""
        if self.started_at is None:
            return None
        if self.completed_at:
            return self.completed_at - self.started_at
        return time.time() - self.started_at

class GeneratorScheduler:
    """
    제너레이터 기반 협력적 스케줄러
    
    단일 스레드에서 여러 제너레이터를 라운드로빈 방식으로 실행
    """
    
    def __init__(self, max_tasks: int = 1000):
        self.tasks: Dict[int, Task] = {}
        self.ready_queue: List[tuple] = []  # (priority, timestamp, task_id)
        self.waiting_tasks: Dict[int, Task] = {}
        self.task_counter = 0
        self.max_tasks = max_tasks
        self.running = False
        
        # 통계
        self.stats = {
            'tasks_created': 0,
            'tasks_completed': 0,
            'tasks_failed': 0,
            'total_switches': 0,
            'total_execution_time': 0.0
        }
    
    def create_task(self, generator_func: Callable, *args, 
                   priority: int = 0, **kwargs) -> Optional[int]:
        """새 태스크 생성"""
        if len(self.tasks) >= self.max_tasks:
            return None
            
        try:
            generator = generator_func(*args, **kwargs)
            self.task_counter += 1
            task_id = self.task_counter
            
            task = Task(
                task_id=task_id,
                generator=generator,
                priority=priority
            )
            
            self.tasks[task_id] = task
            heapq.heappush(self.ready_queue, (priority, task.created_at, task_id))
            self.stats['tasks_created'] += 1
            
            return task_id
            
        except Exception as e:
            print(f"태스크 생성 실패: {e}")
            return None
    
    def schedule(self) -> bool:
        """태스크 스케줄링 및 실행"""
        # 대기 중인 태스크 확인
        current_time = time.time()
        ready_tasks = []
        
        for task_id, task in list(self.waiting_tasks.items()):
            if task.wait_until and current_time >= task.wait_until:
                task.wait_until = None
                task.state = TaskState.READY
                ready_tasks.append((task.priority, task.created_at, task_id))
                del self.waiting_tasks[task_id]
        
        for item in ready_tasks:
            heapq.heappush(self.ready_queue, item)
        
        # 실행할 태스크 선택
        if not self.ready_queue:
            return False
            
        priority, timestamp, task_id = heapq.heappop(self.ready_queue)
        
        if task_id not in self.tasks:
            return False
            
        task = self.tasks[task_id]
        completed = task.run_step()
        
        self.stats['total_switches'] += 1
        
        if completed:
            # 태스크 완료 처리
            exec_time = task.get_execution_time()
            if exec_time:
                self.stats['total_execution_time'] += exec_time
                
            if task.state == TaskState.COMPLETED:
                self.stats['tasks_completed'] += 1
            else:
                self.stats['tasks_failed'] += 1
                
            del self.tasks[task_id]
            
        elif task.state == TaskState.WAITING:
            # 대기 상태로 이동
            self.waiting_tasks[task_id] = task
            
        else:
            # 다시 준비 큐에 추가
            heapq.heappush(self.ready_queue, (task.priority, task.created_at, task_id))
        
        return True
    
    def run(self, timeout: Optional[float] = None):
        """스케줄러 실행"""
        self.running = True
        start_time = time.time()
        
        print(f"제너레이터 스케줄러 시작 (최대 태스크: {self.max_tasks})")
        
        while self.running and self.tasks:
            # 타임아웃 체크
            if timeout and (time.time() - start_time) > timeout:
                print(f"타임아웃 ({timeout}초) 도달")
                break
            
            # 태스크 실행
            executed = self.schedule()
            
            if not executed and self.waiting_tasks:
                # 대기 중인 태스크가 있는 경우 다음 대기 시간까지 sleep
                next_wakeup = min(t.wait_until for t in self.waiting_tasks.values() 
                                if t.wait_until)
                sleep_time = max(0, next_wakeup - time.time())
                if sleep_time > 0:
                    time.sleep(min(sleep_time, 0.1))
            elif not executed:
                # 실행할 태스크가 없는 경우
                time.sleep(0.01)
        
        self.running = False
        self._print_stats()
    
    def _print_stats(self):
        """통계 출력"""
        print("\n" + "="*50)
        print("제너레이터 스케줄러 통계")
        print("="*50)
        print(f"생성된 태스크: {self.stats['tasks_created']}")
        print(f"완료된 태스크: {self.stats['tasks_completed']}")
        print(f"실패한 태스크: {self.stats['tasks_failed']}")
        print(f"총 컨텍스트 스위치: {self.stats['total_switches']}")
        print(f"총 실행 시간: {self.stats['total_execution_time']:.3f}초")
        
        if self.stats['tasks_completed'] > 0:
            avg_time = self.stats['total_execution_time'] / self.stats['tasks_completed']
            print(f"평균 태스크 실행 시간: {avg_time:.3f}초")

# 사용 예시
def example_generator_task(task_id: int, steps: int = 5):
    """예시 제너레이터 태스크"""
    print(f"[Task {task_id}] 시작")
    
    for i in range(steps):
        print(f"[Task {task_id}] 단계 {i+1}/{steps}")
        yield ("sleep", 0.5)  # 0.5초 대기
        
    print(f"[Task {task_id}] 완료")
    return f"Task {task_id} 결과"

def demonstrate_generator_scheduler():
    """제너레이터 스케줄러 데모"""
    print("="*60)
    print("제너레이터 기반 협력적 멀티태스킹 데모")
    print("="*60)
    
    scheduler = GeneratorScheduler(max_tasks=10)
    
    # 여러 태스크 생성
    task_ids = []
    for i in range(3):
        task_id = scheduler.create_task(
            example_generator_task,
            i,  # task_id
            3,  # steps
            priority=i
        )
        if task_id:
            task_ids.append(task_id)
            print(f"태스크 {task_id} 생성됨 (우선순위: {i})")
    
    # 스케줄러 실행 (5초간)
    scheduler.run(timeout=5)
    
    # 결과 확인
    print("\n태스크 결과:")
    for task_id in task_ids:
        if task_id in scheduler.tasks:
            task = scheduler.tasks[task_id]
            print(f"태스크 {task_id}: {task.state.value}")
        else:
            print(f"태스크 {task_id}: 완료됨")

# 고급 패턴: 제너레이터 파이프라인
def generator_pipeline_example():
    """제너레이터 파이프라인 예시"""
    
    def number_generator(limit: int):
        """숫자 생성기"""
        for i in range(limit):
            yield i
    
    def square_numbers(numbers):
        """제곱 변환"""
        for n in numbers:
            yield n * n
    
    def filter_even(numbers):
        """짝수 필터링"""
        for n in numbers:
            if n % 2 == 0:
                yield n
    
    def pipeline(limit: int):
        """파이프라인 구성"""
        numbers = number_generator(limit)
        squared = square_numbers(numbers)
        filtered = filter_even(squared)
        
        for result in filtered:
            print(f"결과: {result}")
            yield ("sleep", 0.1)
    
    # 파이프라인 실행
    scheduler = GeneratorScheduler()
    scheduler.create_task(pipeline, 10)
    scheduler.run(timeout=2)

if __name__ == "__main__":
    demonstrate_generator_scheduler()
    print("\n" + "="*60)
    print("제너레이터 파이프라인 예시")
    print("="*60)
    generator_pipeline_example()
```

## 다중 스레드 큐 폴링 시스템

큐 기반의 다중 스레드 시스템은 생산자-소비자 패턴을 구현하는 효과적인 방법으로, 작업 분배와 부하 관리에 적합합니다.

### 스레드 풀과 작업 큐 시스템

```python
import threading
import queue
import time
import random
from typing import Callable, Any, Optional, Dict, List
from enum import Enum
from dataclasses import dataclass, field
import uuid

class JobPriority(Enum):
    LOW = 0
    NORMAL = 1
    HIGH = 2
    URGENT = 3

class JobStatus(Enum):
    PENDING = "pending"
    PROCESSING = "processing"
    COMPLETED = "completed"
    FAILED = "failed"

@dataclass
class Job:
    """작업 단위"""
    job_id: str
    task: Callable
    args: tuple = ()
    kwargs: Dict = field(default_factory=dict)
    priority: JobPriority = JobPriority.NORMAL
    created_at: float = field(default_factory=time.time)
    started_at: Optional[float] = None
    completed_at: Optional[float] = None
    status: JobStatus = JobStatus.PENDING
    result: Any = None
    error: Optional[Exception] = None
    retries: int = 0
    max_retries: int = 3
    
    def execute(self):
        """작업 실행"""
        self.started_at = time.time()
        self.status = JobStatus.PROCESSING
        
        try:
            self.result = self.task(*self.args, **self.kwargs)
            self.status = JobStatus.COMPLETED
            return self.result
        except Exception as e:
            self.error = e
            self.status = JobStatus.FAILED
            raise
        finally:
            self.completed_at = time.time()

class ThreadSafeJobQueue:
    """스레드 안전 작업 큐"""
    
    def __init__(self, maxsize: int = 0):
        self.queue = queue.PriorityQueue(maxsize=maxsize)
        self.jobs: Dict[str, Job] = {}
        self.lock = threading.RLock()
        
    def put(self, job: Job):
        """작업 추가"""
        with self.lock:
            self.jobs[job.job_id] = job
            priority_value = job.priority.value
            # 우선순위 큐는 작은 값이 먼저 나오므로 음수로 변환
            self.queue.put((-priority_value, job.created_at, job.job_id))
    
    def get(self, block: bool = True, timeout: Optional[float] = None) -> Optional[Job]:
        """작업 가져오기"""
        try:
            priority, timestamp, job_id = self.queue.get(block, timeout)
            with self.lock:
                return self.jobs.get(job_id)
        except queue.Empty:
            return None
    
    def task_done(self):
        """작업 완료 표시"""
        self.queue.task_done()
    
    def qsize(self) -> int:
        """큐 크기 반환"""
        return self.queue.qsize()

class WorkerThread(threading.Thread):
    """작업자 스레드"""
    
    def __init__(self, worker_id: int, job_queue: ThreadSafeJobQueue):
        super().__init__(name=f"Worker-{worker_id}", daemon=True)
        self.worker_id = worker_id
        self.job_queue = job_queue
        self.processed = 0
        self.failed = 0
        self.running = True
        
    def run(self):
        """작업자 실행 루프"""
        print(f"[Worker {self.worker_id}] 시작됨")
        
        while self.running:
            try:
                job = self.job_queue.get(timeout=1.0)
                if job is None:
                    continue
                    
                print(f"[Worker {self.worker_id}] 작업 {job.job_id} 처리 시작")
                
                try:
                    result = job.execute()
                    print(f"[Worker {self.worker_id}] 작업 {job.job_id} 완료: {result}")
                    self.processed += 1
                except Exception as e:
                    print(f"[Worker {self.worker_id}] 작업 {job.job_id} 실패: {e}")
                    self.failed += 1
                    
                    # 재시도 로직
                    if job.retries < job.max_retries:
                        job.retries += 1
                        job.status = JobStatus.PENDING
                        self.job_queue.put(job)
                        print(f"[Worker {self.worker_id}] 작업 {job.job_id} 재시도 ({job.retries}/{job.max_retries})")
                        
                finally:
                    self.job_queue.task_done()
                    
            except queue.Empty:
                continue
            except Exception as e:
                print(f"[Worker {self.worker_id}] 오류: {e}")
                time.sleep(0.1)
        
        print(f"[Worker {self.worker_id}] 종료됨 (처리: {self.processed}, 실패: {self.failed})")
    
    def stop(self):
        """작업자 정지"""
        self.running = False

class ThreadPool:
    """스레드 풀 관리자"""
    
    def __init__(self, num_workers: int = 4, queue_size: int = 100):
        self.num_workers = num_workers
        self.job_queue = ThreadSafeJobQueue(maxsize=queue_size)
        self.workers: List[WorkerThread] = []
        self.job_counter = 0
        
        # 통계
        self.stats = {
            'jobs_submitted': 0,
            'jobs_completed': 0,
            'jobs_failed': 0
        }
    
    def start(self):
        """스레드 풀 시작"""
        for i in range(self.num_workers):
            worker = WorkerThread(i, self.job_queue)
            self.workers.append(worker)
            worker.start()
        
        print(f"스레드 풀 시작됨 (작업자: {self.num_workers}명)")
    
    def stop(self):
        """스레드 풀 정지"""
        for worker in self.workers:
            worker.stop()
        
        for worker in self.workers:
            worker.join(timeout=2)
        
        print("스레드 풀 정지됨")
    
    def submit(self, task: Callable, *args, 
               priority: JobPriority = JobPriority.NORMAL,
               **kwargs) -> str:
        """작업 제출"""
        job_id = str(uuid.uuid4())
        job = Job(
            job_id=job_id,
            task=task,
            args=args,
            kwargs=kwargs,
            priority=priority
        )
        
        self.job_queue.put(job)
        self.stats['jobs_submitted'] += 1
        self.job_counter += 1
        
        return job_id
    
    def wait_for_completion(self, timeout: Optional[float] = None):
        """모든 작업 완료 대기"""
        start_time = time.time()
        
        while True:
            queue_size = self.job_queue.qsize()
            
            if queue_size == 0:
                # 모든 작업자가 유휴 상태인지 확인
                active_workers = sum(1 for w in self.workers if w.is_alive())
                if active_workers == self.num_workers:
                    print("모든 작업 완료됨")
                    break
            
            if timeout and (time.time() - start_time) > timeout:
                print(f"타임아웃 ({timeout}초) - 완료되지 않은 작업 있음")
                break
                
            time.sleep(0.1)
    
    def get_stats(self):
        """통계 정보 반환"""
        queue_size = self.job_queue.qsize()
        active_workers = sum(1 for w in self.workers if w.running)
        
        return {
            'queue_size': queue_size,
            'active_workers': active_workers,
            'jobs_submitted': self.stats['jobs_submitted'],
            'jobs_completed': sum(w.processed for w in self.workers),
            'jobs_failed': sum(w.failed for w in self.workers)
        }

# 예시 작업 함수들
def cpu_intensive_task(n: int) -> int:
    """CPU 집약적 작업"""
    print(f"[CPU Task] 시작: n={n}")
    time.sleep(0.5)  # 작업 시뮬레이션
    result = sum(i * i for i in range(n))
    print(f"[CPU Task] 완료: 결과={result}")
    return result

def io_intensive_task(task_id: str) -> str:
    """I/O 집약적 작업"""
    print(f"[IO Task] 시작: {task_id}")
    time.sleep(random.uniform(0.1, 1.0))
    result = f"IO 완료: {task_id}"
    print(f"[IO Task] 완료: {result}")
    return result

def unreliable_task(task_id: str) -> str:
    """가끔 실패하는 작업"""
    print(f"[Unreliable Task] 시작: {task_id}")
    
    if random.random() < 0.3:  # 30% 확률로 실패
        raise RuntimeError(f"작업 {task_id} 실패!")
    
    time.sleep(0.2)
    return f"안정적 완료: {task_id}"

def demonstrate_thread_pool():
    """스레드 풀 데모"""
    print("="*60)
    print("다중 스레드 큐 폴링 시스템 데모")
    print("="*60)
    
    # 스레드 풀 생성
    pool = ThreadPool(num_workers=3, queue_size=20)
    pool.start()
    
    # 다양한 작업 제출
    job_ids = []
    
    print("\n1. 다양한 우선순위 작업 제출:")
    
    # 높은 우선순위 작업
    for i in range(2):
        job_id = pool.submit(
            cpu_intensive_task, 
            1000,
            priority=JobPriority.HIGH
        )
        job_ids.append(job_id)
        print(f"  높은 우선순위 작업 제출: {job_id}")
    
    # 일반 우선순위 작업
    for i in range(5):
        job_id = pool.submit(
            io_intensive_task,
            f"normal-{i}",
            priority=JobPriority.NORMAL
        )
        job_ids.append(job_id)
        print(f"  일반 우선순위 작업 제출: {job_id}")
    
    # 낮은 우선순위 작업
    for i in range(3):
        job_id = pool.submit(
            unreliable_task,
            f"low-{i}",
            priority=JobPriority.LOW
        )
        job_ids.append(job_id)
        print(f"  낮은 우선순위 작업 제출: {job_id}")
    
    print(f"\n총 {len(job_ids)}개 작업 제출됨")
    
    print("\n2. 진행 상황 모니터링:")
    
    # 5초간 진행 상황 모니터링
    for i in range(5):
        time.sleep(1)
        stats = pool.get_stats()
        print(f"  시간 {i+1}초: 큐={stats['queue_size']}, "
              f"완료={stats['jobs_completed']}, "
              f"실패={stats['jobs_failed']}")
    
    print("\n3. 추가 작업 제출 및 대기:")
    
    # 추가 작업 제출
    for i in range(3):
        pool.submit(
            io_intensive_task,
            f"extra-{i}",
            priority=JobPriority.NORMAL
        )
    
    # 모든 작업 완료 대기
    pool.wait_for_completion(timeout=10)
    
    print("\n4. 최종 통계:")
    final_stats = pool.get_stats()
    print(f"  제출된 작업: {final_stats['jobs_submitted']}")
    print(f"  완료된 작업: {final_stats['jobs_completed']}")
    print(f"  실패한 작업: {final_stats['jobs_failed']}")
    print(f"  남은 큐 크기: {final_stats['queue_size']}")
    
    # 스레드 풀 정지
    pool.stop()

if __name__ == "__main__":
    demonstrate_thread_pool()
```

## UNIX에서 데몬 프로세스 실행

UNIX 데몬은 백그라운드에서 장기간 실행되는 서비스 프로세스로, 시스템 관리와 서비스 제공에 핵심적입니다.

### 완전한 데몬 프로세스 구현

```python
#!/usr/bin/env python3
"""
UNIX 데몬 프로세스 구현

데몬 프로세스의 표준 구현 패턴:
1. 포크하여 백그라운드 실행
2. 세션 리더십 포기
3. 파일 디스크립터 정리
4. PID 파일 관리
5. 시그널 처리
"""

import os
import sys
import time
import signal
import atexit
import logging
from typing import Optional, NoReturn
import argparse

class DaemonProcess:
    """
    UNIX 데몬 프로세스 기본 클래스
    
    표준 데몬화 절차를 구현합니다.
    """
    
    def __init__(self, 
                 pidfile: str = '/tmp/daemon.pid',
                 logfile: str = '/tmp/daemon.log',
                 name: str = 'mydaemon'):
        """
        데몬 초기화
        
        Args:
            pidfile: PID 파일 경로
            logfile: 로그 파일 경로
            name: 데몬 이름
        """
        self.pidfile = pidfile
        self.logfile = logfile
        self.name = name
        self.daemon_running = False
        
        # 로깅 설정
        self.setup_logging()
        
        # 시그널 핸들러 등록
        signal.signal(signal.SIGTERM, self.handle_sigterm)
        signal.signal(signal.SIGHUP, self.handle_sighup)
        signal.signal(signal.SIGINT, self.handle_sigint)
        
    def setup_logging(self):
        """로깅 시스템 설정"""
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(self.logfile),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger(self.name)
    
    def daemonize(self) -> NoReturn:
        """
        데몬화 프로세스 실행
        
        UNIX 데몬의 표준 절차:
        1. 첫 번째 fork로 부모 프로세스 종료
        2. setsid로 새 세션 생성
        3. 두 번째 fork로 세션 리더가 아님을 보장
        4. 작업 디렉토리 변경
        5. 파일 디스크립터 정리
        6. 표준 스트림 재지정
        """
        self.logger.info("데몬화 프로세스 시작")
        
        try:
            # 첫 번째 fork
            pid = os.fork()
            if pid > 0:
                # 부모 프로세스 종료
                sys.exit(0)
                
        except OSError as e:
            self.logger.error(f"첫 번째 fork 실패: {e}")
            sys.exit(1)
        
        # 새 세션 생성
        os.setsid()
        os.umask(0)
        
        try:
            # 두 번째 fork
            pid = os.fork()
            if pid > 0:
                sys.exit(0)
                
        except OSError as e:
            self.logger.error(f"두 번째 fork 실패: {e}")
            sys.exit(1)
        
        # 작업 디렉토리 변경
        os.chdir('/')
        
        # 파일 디스크립터 정리
        import resource
        maxfd = resource.getrlimit(resource.RLIMIT_NOFILE)[1]
        if maxfd == resource.RLIM_INFINITY:
            maxfd = 1024
        
        for fd in range(maxfd):
            try:
                os.close(fd)
            except OSError:
                pass
        
        # 표준 스트림 재지정
        os.open(os.devnull, os.O_RDWR)  # stdin
        os.dup2(0, 1)  # stdout
        os.dup2(0, 2)  # stderr
        
        # PID 파일 생성
        self.create_pid_file()
        
        # 종료 처리기 등록
        atexit.register(self.cleanup)
        
        self.daemon_running = True
        self.logger.info("데몬화 완료")
    
    def create_pid_file(self):
        """PID 파일 생성"""
        pid = str(os.getpid())
        
        try:
            # PID 파일 디렉토리 생성
            pid_dir = os.path.dirname(self.pidfile)
            if pid_dir and not os.path.exists(pid_dir):
                os.makedirs(pid_dir, exist_ok=True)
            
            with open(self.pidfile, 'w') as f:
                f.write(pid)
            
            self.logger.info(f"PID 파일 생성: {self.pidfile} (PID: {pid})")
            
        except Exception as e:
            self.logger.error(f"PID 파일 생성 실패: {e}")
            sys.exit(1)
    
    def remove_pid_file(self):
        """PID 파일 삭제"""
        try:
            if os.path.exists(self.pidfile):
                os.remove(self.pidfile)
                self.logger.info(f"PID 파일 삭제: {self.pidfile}")
        except Exception as e:
            self.logger.error(f"PID 파일 삭제 실패: {e}")
    
    def get_pid(self) -> Optional[int]:
        """PID 파일에서 PID 읽기"""
        try:
            if os.path.exists(self.pidfile):
                with open(self.pidfile, 'r') as f:
                    pid = int(f.read().strip())
                return pid
        except Exception as e:
            self.logger.error(f"PID 파일 읽기 실패: {e}")
        
        return None
    
    def is_running(self) -> bool:
        """데몬 실행 여부 확인"""
        pid = self.get_pid()
        
        if pid is None:
            return False
        
        try:
            # 시그널 0은 프로세스 존재 여부만 확인
            os.kill(pid, 0)
            return True
        except OSError:
            return False
    
    def start(self, foreground: bool = False):
        """데몬 시작"""
        if self.is_running():
            self.logger.error(f"{self.name} 데몬이 이미 실행 중입니다")
            print(f"{self.name} 데몬이 이미 실행 중입니다")
            sys.exit(1)
        
        if foreground:
            self.logger.info("포그라운드 모드로 데몬 시작")
            print(f"{self.name} 데몬을 포그라운드 모드로 시작합니다...")
            self.run()
        else:
            self.logger.info("백그라운드 데몬으로 시작")
            print(f"{self.name} 데몬을 백그라운드로 시작합니다...")
            self.daemonize()
            self.run()
    
    def stop(self):
        """데몬 정지"""
        pid = self.get_pid()
        
        if pid is None:
            self.logger.error(f"{self.name} 데몬이 실행 중이지 않습니다")
            print(f"{self.name} 데몬이 실행 중이지 않습니다")
            return
        
        try:
            self.logger.info(f"데몬 정지 시도 (PID: {pid})")
            os.kill(pid, signal.SIGTERM)
            
            # 종료 대기
            for i in range(10):
                time.sleep(0.5)
                try:
                    os.kill(pid, 0)
                except OSError:
                    self.logger.info(f"{self.name} 데몬 정지됨")
                    print(f"{self.name} 데몬 정지됨")
                    return
            
            self.logger.warning(f"{self.name} 데몬이 정상적으로 종료되지 않았습니다")
            print(f"{self.name} 데몬이 정상적으로 종료되지 않았습니다")
            
        except OSError as e:
            self.logger.error(f"데몬 정지 실패: {e}")
            print(f"데몬 정지 실패: {e}")
    
    def restart(self):
        """데몬 재시작"""
        self.logger.info(f"{self.name} 데몬 재시작")
        print(f"{self.name} 데몬 재시작...")
        
        if self.is_running():
            self.stop()
            time.sleep(1)
        
        self.start(foreground=False)
    
    def status(self):
        """데몬 상태 확인"""
        if self.is_running():
            pid = self.get_pid()
            print(f"{self.name} 데몬이 실행 중입니다 (PID: {pid})")
        else:
            print(f"{self.name} 데몬이 실행 중이지 않습니다")
    
    def run(self):
        """
        데몬 메인 실행 루프
        
        서브클래스에서 오버라이드해야 함
        """
        self.logger.info(f"{self.name} 데몬 메인 루프 시작")
        
        try:
            while self.daemon_running:
                # 데몬의 주요 작업 수행
                self.perform_task()
                
                # 대기 (시그널 체크를 위해 짧은 간격)
                for _ in range(10):
                    if not self.daemon_running:
                        break
                    time.sleep(0.1)
                    
        except Exception as e:
            self.logger.error(f"데몬 실행 중 오류: {e}")
            
        finally:
            self.logger.info(f"{self.name} 데몬 메인 루프 종료")
    
    def perform_task(self):
        """데몬 작업 수행 (오버라이드용)"""
        # 기본 구현: 간단한 로깅
        self.logger.debug(f"{self.name} 데몬 실행 중...")
        time.sleep(1)
    
    def cleanup(self):
        """정리 작업"""
        self.logger.info("정리 작업 수행")
        self.remove_pid_file()
    
    # 시그널 핸들러들
    def handle_sigterm(self, signum, frame):
        """SIGTERM 처리 - 정상 종료"""
        self.logger.info("SIGTERM 수신 - 정상 종료 시작")
        self.daemon_running = False
    
    def handle_sighup(self, signum, frame):
        """SIGHUP 처리 - 설정 재로드"""
        self.logger.info("SIGHUP 수신 - 설정 재로드")
        # 설정 재로드 로직 구현
    
    def handle_sigint(self, signum, frame):
        """SIGINT 처리 - 인터럽트"""
        self.logger.info("SIGINT 수신 - 인터럽트 처리")
        self.daemon_running = False

# 구체적인 데몬 구현 예시
class ExampleDaemon(DaemonProcess):
    """예시 데몬 구현"""
    
    def __init__(self):
        super().__init__(
            pidfile='/tmp/example_daemon.pid',
            logfile='/tmp/example_daemon.log',
            name='exampledaemon'
        )
        
        # 추가 초기화
        self.counter = 0
    
    def perform_task(self):
        """커스텀 데몬 작업"""
        self.counter += 1
        self.logger.info(f"데몬 작업 실행 중... 카운터: {self.counter}")
        
        # 실제 작업 시뮬레이션
        time.sleep(2)
        
        # 주기적으로 상태 리포트
        if self.counter % 5 == 0:
            self.generate_status_report()
    
    def generate_status_report(self):
        """상태 리포트 생성"""
        import psutil
        import datetime
        
        process = psutil.Process(os.getpid())
        
        report = {
            'timestamp': datetime.datetime.now().isoformat(),
            'daemon': self.name,
            'pid': os.getpid(),
            'counter': self.counter,
            'cpu_percent': process.cpu_percent(),
            'memory_mb': process.memory_info().rss / 1024 / 1024
        }
        
        self.logger.info(f"상태 리포트: {report}")

# 명령줄 인터페이스
def main():
    """메인 CLI 함수"""
    parser = argparse.ArgumentParser(description='UNIX 데몬 프로세스 관리')
    parser.add_argument(
        'action',
        choices=['start', 'stop', 'restart', 'status', 'foreground'],
        help='데몬 동작'
    )
    
    args = parser.parse_args()
    
    daemon = ExampleDaemon()
    
    if args.action == 'start':
        daemon.start(foreground=False)
    elif args.action == 'stop':
        daemon.stop()
    elif args.action == 'restart':
        daemon.restart()
    elif args.action == 'status':
        daemon.status()
    elif args.action == 'foreground':
        daemon.start(foreground=True)

def demonstrate_daemon_process():
    """데몬 프로세스 데모"""
    print("="*60)
    print("UNIX 데몬 프로세스 구현 데모")
    print("="*60)
    
    print("\n1. 데몬화 프로세스 단계:")
    print("  1. 첫 번째 fork(): 부모 프로세스 종료")
    print("  2. setsid(): 새 세션 생성")
    print("  3. 두 번째 fork(): 세션 리더가 아님 보장")  
    print("  4. chdir('/'): 작업 디렉토리 변경")
    print("  5. umask(0): 파일 권한 마스크 재설정")
    print("  6. 파일 디스크립터 정리 및 재지정")
    print("  7. PID 파일 생성")
    
    print("\n2. 데몬 시그널 처리:")
    print("  SIGTERM: 정상 종료 요청")
    print("  SIGHUP: 설정 재로드 (로그 파일 재오픈 등)")
    print("  SIGINT: 인터럽트 처리")
    
    print("\n3. 데몬 관리 명령:")
    print("  start    - 데몬 백그라운드 실행")
    print("  stop     - 데몬 정지 (SIGTERM 전송)")
    print("  restart  - 데몬 재시작")
    print("  status   - 데몬 상태 확인")
    print("  foreground - 포그라운드 디버그 모드")
    
    print("\n4. 데몬 구현 모범 사례:")
    print("  ✓ PID 파일로 중복 실행 방지")
    print("  ✓ 로그 회전 구현 (logrotate와 통합)")
    print("  ✓ 설정 파일 지원")
    print("  ✓ 상태 모니터링 및 리포트")
    print("  ✓ 안전한 종료 처리")
    
    print("\n5. 실제 사용 예:")
    print("""
    # 데몬 시작
    $ python daemon.py start
    
    # 상태 확인  
    $ python daemon.py status
    
    # 로그 확인
    $ tail -f /tmp/example_daemon.log
    
    # 데몬 정지
    $ python daemon.py stop
    
    # 포그라운드 디버그 모드
    $ python daemon.py foreground
    """)
    
    # 간단한 데몬 시뮬레이션
    print("\n6. 데몬 시뮬레이션 실행 (3초간):")
    
    class SimpleDaemon:
        def run(self):
            for i in range(3):
                print(f"  데몬 작업 중... ({i+1}/3)")
                time.sleep(1)
            print("  데몬 종료")
    
    simple_daemon = SimpleDaemon()
    simple_daemon.run()

if __name__ == "__main__":
    # 실제 데몬 실행 시
    # main()
    
    # 데모 실행
    demonstrate_daemon_process()
```

## 결론

제너레이터 기반 협력적 멀티태스킹, 다중 스레드 큐 폴링, UNIX 데몬 프로세스는 각각 다른 시나리오에 최적화된 고급 프로그래밍 패턴입니다.

**제너레이터 기반 협력적 멀티태스킹**은 스레드나 프로세스의 오버헤드 없이 단일 스레드 내에서 여러 작업을 효율적으로 관리할 수 있는 방법입니다. `GeneratorScheduler` 클래스는 이벤트 루프 패턴을 구현하여 `yield` 문을 통해 실행 제어권을 넘겨주는 방식으로 작업을 관리합니다. 이 접근법은 I/O 바운드 작업, 이벤트 기반 시스템, 데이터 스트림 처리에 특히 효과적이며, Python의 `asyncio` 라이브러리가 채택한 근본 개념입니다. 메모리 사용량이 적고 컨텍스트 스위칭 오버헤드가 없다는 장점이 있지만, CPU 집약적 작업에는 적합하지 않습니다.

**다중 스레드 큐 폴링 시스템**은 생산자-소비자 패턴의 고도화된 구현으로, `ThreadPool`과 `ThreadSafeJobQueue` 클래스를 통해 우선순위 기반 작업 관리, 동적 워커 할당, 오류 복구 메커니즘을 제공합니다. 이 시스템은 작업을 큐에 저장하고 여러 작업자 스레드가 병렬로 처리하는 방식으로, 웹 서버 요청 처리, 데이터베이스 작업, 배치 처리 등에 적합합니다. 작업 우선순위 지정, 재시도 로직, 통계 수집 등의 기능을 포함하여 실제 프로덕션 환경에서의 요구사항을 충족시킵니다.

**UNIX 데몬 프로세스**는 백그라운드에서 장기간 실행되는 시스템 서비스를 구현하기 위한 표준적인 방법입니다. `DaemonProcess` 클래스는 이중 분리 프로세스, PID 파일 관리, 시그널 처리, 로깅 시스템 등을 포함한 완전한 데몬 구현을 제공합니다. 데몬은 로그 수집기, 모니터링 에이전트, 네트워크 서버, 백그라운드 작업 스케줄러 등 시스템 수준 서비스에 필수적입니다. 안정적인 데몬 구현을 위해서는 정상적인 종료 처리, 설정 재로드, 리소스 모니터링, 로그 회전 등의 기능이 필수적입니다.

각 기술의 적용 시나리오를 정리하면:

1. **제너레이터**: 네트워크 서버, 웹 크롤러, 실시간 데이터 처리, 이벤트 드리븐 애플리케이션
2. **스레드 풀 큐**: 웹 애플리케이션 서버, 이미지/동영상 처리, 대규모 데이터 배치 작업, 동시 API 호출
3. **UNIX 데몬**: 시스템 모니터링, 로그 집계, 예약 작업 실행, 백그라운드 데이터 동기화

이러한 패턴들은 상호 배타적이지 않으며, 실제 시스템에서는 이들을 조합하여 사용하는 경우가 많습니다. 예를 들어, 데몬 프로세스 내부에 스레드 풀을 구현하거나, 제너레이터 기반 코루틴과 스레드를 혼합하여 사용할 수 있습니다. 기술 선택 시 고려해야 할 요소는 작업의 성격(I/O 바운드 vs CPU 바운드), 실행 환경 제약사항, 유지보수성 요구사항, 성능 요구사항 등입니다.

마지막으로, 모든 동시성 및 백그라운드 처리 시스템에서 공통적으로 중요한 것은 오류 처리, 모니터링, 로깅, 설정 관리입니다. 이러한 기반 기능들을 튼튼하게 구현하는 것이 안정적인 시스템을 구축하는 핵심입니다.