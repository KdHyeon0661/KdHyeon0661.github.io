---
layout: post
title: 이산수학 - 알고리즘의 복잡도
date: 2025-05-29 20:20:23 +0900
category: 이산수학
---
# 알고리즘의 복잡도 — 시간과 공간을 측정하는 기준

## 1) 복잡도란?

**복잡도(Complexity)**는 알고리즘이 소요하는 **시간(연산 횟수)**과 **공간(메모리 사용량)**을 입력 크기 $$n$$ 의 함수로 기술한 것이다. 핵심 목적은 두 가지다:

- 대규모 입력에서의 **성장률 비교**(정성적 판단)
- 구현·최적화 전 **현실 가능성 검증**(정량적 추정)

실행 시간의 절대값은 언어/하드웨어/컴파일러에 좌우된다. 복잡도는 그런 상수 요인을 추상화하여 **점근적 성장**만 본다.

---

## 2) 시간 복잡도와 공간 복잡도

- **시간 복잡도**: 기본 연산(할당, 비교, 산술, 배열 인덱싱 등)의 총 횟수.  
- **공간 복잡도**: 입력 외 **보조 메모리** 사용량(스택 프레임, 임시 배열, 해시테이블 등).

보통 “최악(worst)”, “평균(average)”, “최선(best)”을 구분하며, 실무에서는 **최악 + 평균**을 함께 본다.

---

## 3) 점근적 표기법(Asymptotic Notation)

정의역은 충분히 큰 $$n(\ge n_0)$$ 이다.

$$
\begin{aligned}
&f(n)=O(g(n))\iff \exists c>0,\exists n_0: 0\le f(n)\le c\,g(n)\ (\forall n\ge n_0).\\
&f(n)=\Omega(g(n))\iff \exists c>0,\exists n_0: 0\le c\,g(n)\le f(n)\ (\forall n\ge n_0).\\
&f(n)=\Theta(g(n))\iff f(n)=O(g(n))\ \text{이면서}\ f(n)=\Omega(g(n)).\\
&f(n)=o(g(n))\iff \lim_{n\to\infty}\frac{f(n)}{g(n)}=0,\quad
f(n)=\omega(g(n))\iff \lim_{n\to\infty}\frac{f(n)}{g(n)}=\infty.
\end{aligned}
$$

**자주 쓰는 서열**:  
$$
1\ll \log n\ll \sqrt n\ll n\ll n\log n\ll n^2\ll n^3\ll 2^n\ll n!.
$$

---

## 4) Big-O 연산 법칙(조합 규칙)

- **순차 합성**: $$T(n)=T_1(n)+T_2(n)\Rightarrow T(n)=\Theta(\max\{T_1,T_2\}).$$  
- **중첩 루프**: 곱으로 결합(대략) — 바깥 $$n$$, 안쪽 $$m$$ 이면 $$\Theta(nm)$$.
- **조건 분기**: 최악 분기를 따른다.
- **함수 합성**: $$T(n)=T_1(n)+T_2(T_1(n))$$ 같은 형태 주의.
- **로그 밑변환**: $$\log_a n=\dfrac{\log n}{\log a}=\Theta(\log n).$$

---

## 5) 반복문 패턴별 분석

### (a) 선형 루프
```python
for i in range(n):  # Θ(n)
    pass
```
$$\Theta(n).$$

### (b) 삼각 루프(누적 합)
```python
for i in range(n):          # i = 0..n-1
    for j in range(i+1):    # j = 0..i
        pass
```
총 반복은 $$\sum_{i=0}^{n-1}(i+1)=\frac{n(n+1)}{2}=\Theta(n^2).$$

### (c) 로그 루프(지수 증가/감소)
```python
while x>0:   # x는 n으로 시작해 매번 절반
    x//=2
```
반복 횟수 $$\lfloor \log_2 n\rfloor+1=\Theta(\log n).$$

### (d) 등비 누적(두 배씩 증가)
```python
s=1; count=0
while s<n:
    s*=2; count+=1
```
반복 $$\Theta(\log n).$$

---

## 6) 재귀 분석: 마스터 정리와 재귀 트리

### 6.1 마스터 정리
$$
T(n)=a\,T(n/b)+f(n),\quad a\ge 1,\ b>1.
$$
- **케이스 1**: $$f(n)=O(n^{\log_b a-\epsilon})\Rightarrow T(n)=\Theta(n^{\log_b a}).$$
- **케이스 2**: $$f(n)=\Theta(n^{\log_b a}\log^k n)\Rightarrow T(n)=\Theta(n^{\log_b a}\log^{k+1}n).$$
- **케이스 3**: $$f(n)=\Omega(n^{\log_b a+\epsilon})$$ 그리고 **정규성** $$a\,f(n/b)\le c\,f(n)\ (c<1)$$  
  $$\Rightarrow T(n)=\Theta(f(n)).$$

**예 1) 병합 정렬**: $$a=2,b=2,f(n)=\Theta(n)\Rightarrow T(n)=\Theta(n\log n).$$  
**예 2) 이진 탐색**: $$T(n)=T(n/2)+\Theta(1)\Rightarrow T(n)=\Theta(\log n).$$

### 6.2 마스터로 안 되는 경우(예: 로그 인자, 비균등 분할)

- **Akra–Bazzi**를 쓰거나 **재귀 트리**로 근사한다.

**예) $$T(n)=2T(n/2)+\frac{n}{\log n}$$**:  
분할 레벨별 비용이 대략 $$\frac{n}{\log n}$$ 이고 레벨 수가 $$\log n$$이므로 총 $$\Theta(n)$$(엄밀히는 Akra–Bazzi로 $$\Theta(n)$$).

---

## 7) 평균·최악·암ortized

- **최악**: 어떤 입력에서도 넘지 않는 상한.  
- **평균**: 분포 가정 하 기댓값(가정이 중요).  
- **암ortized**: 연산열의 평균 비용(드물게 비싼 연산 포함).

### 7.1 동적 배열 push 암ortized $$\Theta(1)$$
용량이 꽉 차면 2배 확장.

- 총 이동 비용은 **지수적 간헐** 덕에 $$\Theta(n)$$.
- 평균(연산당) 비용은 $$\Theta(1)$$.

**포텐셜 증명 스케치**:  
포텐셜 $$\Phi=2m-C\ (\ge 0)$$, 여기서 $$m$$ 은 원소 수, $$C$$ 용량.  
삽입의 실제비용 + 포텐셜증가 ≤ 상수.

### 7.2 해시테이블
- 기대: 탐색/삽입/삭제 $$\Theta(1)$$ (균등 해싱, 적절한 로드 팩터).  
- 최악: 모든 키 충돌시 $$\Theta(n)$$.

---

## 8) 공간 복잡도 깊게 보기

- **보조 공간**(aux space) vs **총 공간**(입력 포함).  
- **재귀 깊이** = 호출 스택 비용. tail recursion은 반복으로 대체 가능.
- **제자리(in-place)**: 보조 공간 $$\Theta(1)$$ 또는 $$O(\log n)$$(분할·트리 깊이).

**예) 병합 정렬**: 표준 구현은 $$\Theta(n)$$ 보조 배열.  
**예) 퀵 정렬**: 보조 공간 $$\Theta(\log n)$$(평균, 스택 깊이).

---

## 9) 비용 모델과 현실의 갭 메우기

- **RAM 모델**: 단위 시간 산술/인덱싱 가정(워드 크기 제한).  
- **캐시/I-O 모델**: 블록 크기 $$B$$, 메모리 $$M$$, I/O 횟수 최소화가 목표.  
- **상수 요인**: 언어/런타임/Python vs C++ 차이가 큼.  
- **브랜치 예측/메모리 지역성**: 같은 Big-O라도 차이가 큼(예: 연속 스캔 vs 랜덤 접근).

---

## 10) 1초 예산 감 잡기(경험적 가이드)

다음은 **대략적** 감이다(환경에 따라 변동).

| 시간 복잡도 | 1초 내 권장 입력 규모(정수 연산 기준) |
|---|---|
| $$O(1),O(\log n)$$ | 매우 큼(실질적으로 제약 없음) |
| $$O(n)$$ | $$n\approx 10^7$$ 수준(빠른 언어), Python은 더 작음 |
| $$O(n\log n)$$ | $$n\approx 10^6$$ |
| $$O(n^2)$$ | $$n\approx 10^4\sim 10^5$$(상수 의존 큼) |
| $$O(2^n)$$ | $$n\le 20$$ |
| $$O(n!)$$ | $$n\le 8$$ |

**팁**: 테스트 케이스 수 $$t$$ 가 있으면 **총 입력 합** 기준으로 본다.

---

## 11) 예제: 이중 반복 제거(두 수 합 문제)

### O($$n^2$$) 풀이
```python
def count_pairs_quadratic(A, target):
    n=len(A); cnt=0
    for i in range(n):
        for j in range(i+1, n):
            if A[i]+A[j]==target:
                cnt+=1
    return cnt
```

### O($$n$$) 풀이(해시)
```python
def count_pairs_linear(A, target):
    seen=set(); cnt=0
    for a in A:
        if (target-a) in seen:
            cnt+=1
        seen.add(a)
    return cnt
```

복잡도: 첫 코드는 $$\Theta(n^2)$$, 두 번째는 기대 $$\Theta(n)$$ 공간도 $$\Theta(n)$$.

---

## 12) 예제: 누적합과 슬라이딩 윈도우

### 연속 구간 합 = $$k$$ 인 구간 수(양수 배열)

- **슬라이딩 윈도우**: 두 포인터로 $$O(n)$$.

```python
def count_subarrays_sum_k_pos(A, k):
    n=len(A); s=0; left=0; ans=0
    for right,x in enumerate(A):
        s+=x
        while s>k and left<=right:
            s-=A[left]; left+=1
        if s==k: ans+=1
    return ans
```

- 0·음수 포함이면 **prefix-sum + 해시**로 $$O(n)$$.

```python
from collections import defaultdict
def count_subarrays_sum_k_any(A, k):
    freq=defaultdict(int); freq[0]=1
    s=0; ans=0
    for x in A:
        s+=x
        ans+=freq[s-k]
        freq[s]+=1
    return ans
```

---

## 13) 예제: 재귀 점화 분석

### 13.1 이분 탐색
$$
T(n)=T(n/2)+\Theta(1)\Rightarrow T(n)=\Theta(\log n).
$$

### 13.2 병합 정렬
$$
T(n)=2T(n/2)+\Theta(n)\Rightarrow T(n)=\Theta(n\log n).
$$

### 13.3 퀵 정렬(평균)
분할이 랜덤이면 기대
$$
T(n)=T(X)+T(n-1-X)+\Theta(n),\ \mathbb{E}[X]=(n-1)/2
$$
으로 $$\Theta(n\log n)$$.

최악(정렬된 입력 + 마지막 피벗)은 $$\Theta(n^2)$$ → **랜덤 피벗/삼중 중앙값**으로 회피.

---

## 14) 정렬 하한: 비교 기반은 $$\Omega(n\log n)$$

결정 트리 높이 하한:

$$
\text{리프 수}\ge n!\ \Rightarrow\ \text{높이}\ge \log_2(n!)=\Omega(n\log n).
$$

따라서 비교 기반 정렬은 최악에 $$\Omega(n\log n)$$. (계수·기수 정렬은 전제 하에서 선형 가능)

---

## 15) 공간 최적화 테크닉

- **롤링 배열**: DP 테이블에서 이전 행/열만 보관 → $$\Theta(nm)\to \Theta(\min\{n,m\})$$.  
- **비트셋**: 불리언/소규모 정수 상태를 비트로 압축 → 32/64배 절약.  
- **In-place 변환**: 인덱스 치환, 파티션(퀵셀렉트) 사용.  
- **재귀→반복**: 스택 제거, tail-call 제거.

---

## 16) 평균/확률적 분석 한 걸음

- **저수지 샘플링**: 스트리밍에서 균등 1개 선택, 기대 $$\Theta(1)$$ 메모리.
```python
import random
def reservoir(stream):
    res=None
    for i,x in enumerate(stream, start=1):
        if random.randrange(i)==0:
            res=x
    return res
```
- **해시 기대 시간**: 균등 해싱 가정과 리사이징 정책(로드 팩터 유지)이 핵심.

---

## 17) 캐시/입출력 관점

- **지역성**: 순차 스캔이 랜덤 접근보다 빠름.  
- **외부 정렬**: 분할-병합(스풀 정렬, 멀티웨이 병합)로 디스크 I/O 최소화.  
- **블록 연산**: 행렬 곱 블로킹으로 캐시 히트율 향상.

---

## 18) 흔한 실수와 디버깅 체크리스트

1) **숨은 상수 무시**: $$n=10^3$$ 에서 $$n\log n$$ 보다 잘 튜닝된 $$n^2$$ 가 빠를 수 있다.  
2) **평균 시간 오해**: 해시테이블/퀵정렬의 최악 입력 대비 방어책(랜덤화, 리해싱).  
3) **입력 합 제약 무시**: 테스트케이스 합계가 큰지 확인.  
4) **재귀 깊이**: 파이썬 최대 재귀 한계, 꼬리 재귀 최적화 부재.  
5) **I/O 병목**: 빠른 입출력 사용(버퍼링).  
6) **메모리 파편화**: 대용량 리스트 append 패턴 점검.

---

## 19) 실전 의사결정 플로우

1) **문제 구조 파악**: 정렬 필요? 그래프? 구간 질의?  
2) **제약 읽기**: $$n, m, q, t$$ 의 최대/합계.  
3) **목표 복잡도 설정**: 예) $$n\le 2\times 10^5$$ → $$O(n\log n)$$ 이하 모색.  
4) **기술 선택**: 해시/트리/스위핑/세그트리/DSU/DP/분할정복.  
5) **경계 케이스**: 빈 입력, 중복, 음수, 오버플로우.  
6) **벤치마킹**: 랜덤·최악·패턴 데이터.

---

## 20) 추가 예제들

### 20.1 이진 탐색(하한/상한 인덱스)
```python
def lower_bound(a, x):
    lo, hi = 0, len(a)
    while lo < hi:
        mid=(lo+hi)//2
        if a[mid] < x: lo=mid+1
        else: hi=mid
    return lo

def upper_bound(a, x):
    lo, hi = 0, len(a)
    while lo < hi:
        mid=(lo+hi)//2
        if a[mid] <= x: lo=mid+1
        else: hi=mid
    return lo
```
시간 $$\Theta(\log n)$$.

### 20.2 LIS 길이 $$\Theta(n\log n)$$
```python
import bisect
def lis_len(a):
    d=[]
    for v in a:
        i=bisect.bisect_left(d, v)
        if i==len(d): d.append(v)
        else: d[i]=v
    return len(d)
```

### 20.3 0-1 배낭(공간 최적화)
```python
def knapsack_01(W, wt, val):
    dp=[0]*(W+1)
    for w,v in zip(wt,val):
        for cap in range(W, w-1, -1):
            dp[cap]=max(dp[cap], dp[cap-w]+v)
    return dp[W]
```
시간 $$\Theta(nW)$$, 공간 $$\Theta(W)$$.

---

## 21) 수학 팁: 합과 로그 다루기

- 등차 합:
$$
\sum_{i=1}^n i=\frac{n(n+1)}{2}=\Theta(n^2).
$$
- 등비 합(비율 $$r>1$$):
$$
\sum_{k=0}^{\lfloor \log_r n \rfloor} r^k=\Theta(n).
$$
- 조화 급수:
$$
\sum_{i=1}^n \frac{1}{i}=\Theta(\log n).
$$

---

## 22) 요약 표

| 패턴 | 전형적 복잡도 | 비고 |
|---|---|---|
| 선형 스캔 | $$\Theta(n)$$ | 캐시 친화적 |
| 정렬(비교기반) | $$\Theta(n\log n)$$ | 하한 존재 |
| 균형 BST 연산 | $$\Theta(\log n)$$ | Red-Black/AVL |
| 해시 기대 연산 | $$\Theta(1)$$ | 최악 $$\Theta(n)$$ |
| BFS/DFS | $$\Theta(n+m)$$ | 그래프 크기 기준 |
| 다익스트라 | $$\Theta((n+m)\log n)$$ | 양의 가중 |
| 플로이드-워셜 | $$\Theta(n^3)$$ | 모든 쌍 최단 |
| 병합 정렬 공간 | $$\Theta(n)$$ | 안정 |

---

## 23) 연습 문제

1) 다음 루프의 복잡도를 $$n$$ 의 함수로 구하라.
```python
s=0
for i in range(1, n+1):
    j=1
    while j<=i:
        s+=1
        j*=2
```
힌트: 내부는 $$\lfloor \log_2 i\rfloor+1$$, 합은 $$\Theta(n\log n)$$.

2) 점화 $$T(n)=3T(n/2)+n$$ 을 마스터 정리로 풀어라. (해: $$\Theta(n^{\log_2 3})\approx \Theta(n^{1.585})$$)

3) 동적 배열 push의 암ortized 비용을 포텐셜 함수로 엄밀히 상계하라.

4) 비교 기반 정렬 하한을 결정 트리 리프 개수로 증명하라.

5) 해시테이블에서 로드 팩터 $$\alpha$$ 를 제한하면 기대 탐색 길이가 $$\Theta(1+\alpha)$$ 임을 보이라.

---

## 24) 결론

- **복잡도는 성장률**을 통해 설계 대안을 비교하는 표준 언어다.  
- **Big-O/Ω/Θ**로 상·하·정확한 경계를 기술하고, 루프/재귀/분할정복을 **법칙·정리**로 해석한다.  
- 성능은 **자료구조 선택**, **알고리즘 패턴**, **메모리/캐시 모델**과 함께 결정된다.  
- 실무에선 “**제약→목표 복잡도→설계→검증**”의 루프를 빠르게 돌려라.

이 문서의 코드와 수식 골격을 바탕으로, 각 문제의 구조와 입력 한계에 맞춰 적정 복잡도를 설계·검증하면 된다.