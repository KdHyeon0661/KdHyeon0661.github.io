---
layout: post
title: 선형대수 - SVD의 계산과 해석
date: 2025-06-22 20:20:23 +0900
category: 선형대수
---
# 🔍 SVD의 계산과 해석

SVD(Singular Value Decomposition, 특이값 분해)는 모든 행렬에 적용 가능하며,  
복잡한 행렬을 세 개의 단순한 행렬로 분해하여 **해석과 계산을 단순화**해 줍니다.

이 글에서는 SVD가 어떻게 계산되는지,  
그리고 그 결과를 **기하학적으로, 수치적으로 어떻게 해석**할 수 있는지 알아봅니다.

---

## 📘 1. 복습: SVD의 기본 형태

어떤 \( m \times n \) 행렬 \( A \)에 대해,

\[
\boxed{
A = U \Sigma V^T
}
\]

- \( U \in \mathbb{R}^{m \times m} \): 좌측 특이벡터 (orthonormal basis of column space)
- \( \Sigma \in \mathbb{R}^{m \times n} \): 대각 행렬 (특이값들)
- \( V \in \mathbb{R}^{n \times n} \): 우측 특이벡터 (orthonormal basis of row space)

---

## 🧠 2. SVD 계산 절차 (이론적)

### Step 1️⃣: \( A^T A \) 계산 → 고유값과 고유벡터 구하기

\[
A^T A \vec{v}_i = \lambda_i \vec{v}_i \quad \Rightarrow \quad \vec{v}_i: \text{우측 특이벡터}
\]

- \( V = [\vec{v}_1, \dots, \vec{v}_n] \): 정규직교 행렬
- \( \lambda_i \geq 0 \): \( A^T A \)의 고유값
- \( \sigma_i = \sqrt{\lambda_i} \): 특이값

### Step 2️⃣: \( A \vec{v}_i = \sigma_i \vec{u}_i \) → 좌측 특이벡터 구하기

\[
\vec{u}_i = \frac{1}{\sigma_i} A \vec{v}_i
\]

- \( U = [\vec{u}_1, \dots, \vec{u}_m] \)

---

## 🧮 3. 예제: \( 2 \times 2 \) 행렬

\[
A = 
\begin{bmatrix}
3 & 1 \\
0 & 2
\end{bmatrix}
\]

### Step 1️⃣: \( A^T A \)

\[
A^T A = 
\begin{bmatrix}
3 & 0 \\
1 & 2
\end{bmatrix}
\begin{bmatrix}
3 & 1 \\
0 & 2
\end{bmatrix}
=
\begin{bmatrix}
9 & 3 \\
3 & 5
\end{bmatrix}
\]

### Step 2️⃣: 고유값 구하기

\[
\det(A^T A - \lambda I) = 0
\Rightarrow \lambda^2 - 14\lambda + 36 = 0
\]

\[
\lambda = 7 \pm \sqrt{13} \Rightarrow \sigma_1 = \sqrt{7 + \sqrt{13}}, \ \sigma_2 = \sqrt{7 - \sqrt{13}}
\]

→ 특이값 두 개

### Step 3️⃣: 우측 특이벡터 \( \vec{v}_1, \vec{v}_2 \)  
→ \( V \) 구성

### Step 4️⃣: \( \vec{u}_i = \frac{1}{\sigma_i} A \vec{v}_i \)  
→ \( U \) 구성

> 수작업으로는 복잡하므로 실제 계산은 수치 라이브러리 활용 권장

---

## 💻 4. Python으로 계산

```python
import numpy as np

A = np.array([
    [3, 1],
    [0, 2]
])

U, S, VT = np.linalg.svd(A)

print("U:\n", U)
print("Sigma (singular values):\n", S)
print("V^T:\n", VT)

# 재구성 확인
Sigma_full = np.zeros_like(A, dtype=float)
np.fill_diagonal(Sigma_full, S)
A_reconstructed = U @ Sigma_full @ VT
print("복원된 A:\n", A_reconstructed)
```

- `S`는 특이값만 1D 배열로 반환됨 → `np.diag(S)`로 대각 행렬 생성 가능
- `A ≈ U @ Σ @ V^T` 확인 가능

---

## 📐 5. 기하학적 해석

### 벡터 \( x \)가 변환될 때:

\[
A x = U \Sigma V^T x
\]

1. \( x \)를 우측 특이벡터(V)의 기저로 표현  
2. \( \Sigma \)가 **축 방향으로 늘리거나 줄임**  
3. \( U \)가 새로운 공간으로 **회전**

> SVD는 선형 변환을 "**회전 → 늘림 → 회전**"으로 분해한 것

### 시각화 (2D 기준)

- 원 → 타원으로 변환됨
- 타원의 반지름 방향 = 특이벡터
- 반지름 크기 = 특이값

---

## 📉 6. 해석: 특이값이 의미하는 것

| 특이값 \( \sigma_i \) | 의미 |
|------------------|------|
| 크기 | 해당 축 방향으로의 정보량 (또는 변형량) |
| 0에 가까움 | 해당 축은 거의 무시됨 (차원 축소 가능성) |
| 0 | 차원 축소 가능, 계수(rank) 감소 |

---

## 🧩 7. SVD의 수치적 안정성

- 모든 행렬에 대해 항상 존재
- 대칭/정방/비정방 행렬 모두 처리 가능
- 노이즈에 강함 → 데이터 압축, 필터링에 매우 적합

---

## ✅ 요약

| 항목 | 설명 |
|------|------|
| 정의 | \( A = U \Sigma V^T \) |
| 계산 | \( A^T A \)의 고유값 → 특이값 |
| 해석 | 회전 → 크기 조정 → 회전 |
| 특이값 | 스케일, 정보량, 중요도 |
| 활용 | PCA, 이미지 압축, 추천시스템 등 |