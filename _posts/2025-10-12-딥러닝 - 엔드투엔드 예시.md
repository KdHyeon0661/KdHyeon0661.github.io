---
layout: post
title: 딥러닝 - 엔드투엔드 예시
date: 2025-10-12 19:25:23 +0900
category: 딥러닝
---
# Projects (엔드투엔드 예시)

> 무엇을 얻나
> - **3개 엔드투엔드 프로젝트**를 통해, **폴더 구조·데이터 파이프라인·학습/검증·평가·배포(HTTP 서버)·모니터링**까지 한 번에 연결합니다.
> - 외부 프레임워크 없이 **PyTorch만** 사용합니다(필요한 곳에서 `torchvision`, `torchtext`는 선택적으로 사용 가능하나 아래 예시는 모두 순수 PyTorch 혹은 표준 라이브러리만으로 동작).
> - 공통 유틸(재현성, AMP, 체크포인팅, 조기종료, 로그)을 제공하고, **실시간 서빙(동적 마이크로배칭)** + **배치 파이프라인** 스켈레톤을 포함합니다.
> - 각 프로젝트는 **실제 적용 가능한 최소 MVP**를 목표로 하며, 여러분의 도메인 데이터에 즉시 이식할 수 있도록 설계되었습니다.

---

## 공통 구조 — 레포 폴더 & 런북

```text
ml-e2e/
├── common/
│   ├── seed.py              # 재현성: seed_all()
│   ├── amp_ckpt.py          # AMP/체크포인팅/조기종료/EMA
│   ├── meter.py             # 평균/지표 집계, confusion matrix, ECE
│   ├── log.py               # JSONL/CSV 로거
│   ├── monitor_core.py      # 레이턴시 p95, PSI/KS/MMD, 알람 (간단판)
│   └── server_microbatch.py # HTTP + 동적 마이크로배칭(실시간 공통)
├── project_vision_cls/      # 프로젝트 A: 이미지 분류(전이학습 X, 경량 CNN)
│   ├── data.py              # 폴더데이터/증강/로더
│   ├── model.py             # SmallCNN
│   ├── train.py             # 학습 루프(AMP/조기종료)
│   ├── eval.py              # 평가/혼동행렬/ECE
│   ├── inference.py         # 배치 추론(오프라인)
│   └── serve.py             # 실시간 서빙(마이크로배칭 포함)
├── project_nlp_intent/      # 프로젝트 B: 의도 분류(간단 토크나이저+TextCNN)
│   ├── data.py              # 토큰화/단어사전/텐서화
│   ├── model.py             # TextCNN(Conv1d)
│   ├── train.py
│   ├── eval.py
│   ├── inference.py
│   └── serve.py
└── project_ts_forecast/     # 프로젝트 C: 시계열 예측+이상탐지(LSTM)
    ├── data.py
    ├── model.py             # LSTM 예측기
    ├── train.py
    ├── eval.py
    ├── batch_predict.py     # 야간 배치 생성
    └── serve.py
```

> 실행 TL;DR
> ```bash
> # (A) Vision 분류
> python project_vision_cls/train.py --epochs 20 --bs 128
> python project_vision_cls/eval.py --ckpt runs/vision/best.pt
> python project_vision_cls/serve.py --ckpt runs/vision/best.pt --port 8080
>
> # (B) NLP Intent
> python project_nlp_intent/train.py --epochs 10 --bs 256
> python project_nlp_intent/eval.py --ckpt runs/nlp/best.pt
> python project_nlp_intent/serve.py --ckpt runs/nlp/best.pt --port 8081
>
> # (C) TS Forecast
> python project_ts_forecast/train.py --epochs 12
> python project_ts_forecast/batch_predict.py --ckpt runs/ts/best.pt --out preds.csv
> python project_ts_forecast/serve.py --ckpt runs/ts/best.pt --port 8082
> ```

---

## 공통 유틸 (재현성·AMP·체크포인팅·지표·로깅)

### `common/seed.py`

```python
# common/seed.py

import random, os, numpy as np, torch

def seed_all(seed: int = 42, deterministic: bool = True):
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    if deterministic:
        torch.backends.cudnn.deterministic = True
        torch.backends.cudnn.benchmark = False
    os.environ["PYTHONHASHSEED"] = str(seed)
```

### `common/amp_ckpt.py` — AMP, 체크포인팅, 조기종료, EMA

```python
# common/amp_ckpt.py

import os, torch, math, time
from dataclasses import dataclass

class AmpScaler:
    def __init__(self, enabled=True):
        self.enabled = enabled and torch.cuda.is_available()
        self.scaler = torch.cuda.amp.GradScaler(enabled=self.enabled)
    def backward(self, loss): self.scaler.scale(loss).backward()
    def step(self, opt):
        if self.enabled:
            self.scaler.step(opt); self.scaler.update()
        else:
            opt.step()

@dataclass
class EarlyStopper:
    patience: int = 5
    mode: str = "max" # "min" for loss
    best: float = None
    count: int = 0
    def update(self, value: float) -> bool:
        if self.best is None: self.best = value; return False
        improve = (value > self.best) if self.mode=="max" else (value < self.best)
        if improve: self.best = value; self.count = 0; return False
        self.count += 1
        return self.count >= self.patience

class EMA:
    def __init__(self, model, decay=0.999):
        self.decay=decay; self.shadow={}
        for n,p in model.named_parameters():
            if p.requires_grad: self.shadow[n]=p.detach().clone()
    @torch.no_grad()
    def update(self, model):
        for n,p in model.named_parameters():
            if not p.requires_grad: continue
            self.shadow[n].mul_(self.decay).add_(p, alpha=1-self.decay)
    @torch.no_grad()
    def apply_to(self, model):
        for n,p in model.named_parameters():
            if n in self.shadow: p.copy_(self.shadow[n])

def save_ckpt(path, model, opt, epoch, metrics: dict):
    os.makedirs(os.path.dirname(path) or ".", exist_ok=True)
    torch.save({"model": model.state_dict(),
                "opt": opt.state_dict(),
                "epoch": epoch,
                "metrics": metrics}, path)

def load_ckpt(path, model, opt=None):
    ckpt = torch.load(path, map_location="cpu")
    model.load_state_dict(ckpt["model"])
    if opt and "opt" in ckpt: opt.load_state_dict(ckpt["opt"])
    return ckpt
```

### `common/meter.py` — 지표/혼동행렬/ECE

```python
# common/meter.py

import torch, math

class AverageMeter:
    def __init__(self): self.n=0; self.s=0.0
    def add(self, v, k=1): self.s += float(v)*k; self.n += k
    def avg(self): return self.s/max(1,self.n)

@torch.no_grad()
def accuracy_topk(logits, y, k=1):
    topk = logits.topk(k, dim=1).indices
    correct = (topk == y.view(-1,1)).any(dim=1).float().mean().item()
    return correct

@torch.no_grad()
def confusion_matrix(num_classes, preds, y):
    cm = torch.zeros(num_classes, num_classes, dtype=torch.long)
    for p, t in zip(preds, y):
        cm[t, p] += 1
    return cm

@torch.no_grad()
def ece(probs, y, bins=10):
    p = probs[:,1] if probs.shape[1]==2 else probs.softmax(-1).max(-1).values
    edges = torch.linspace(0,1,bins+1, device=p.device)
    ece=0.0; N=p.numel()
    for i in range(bins):
        msk = (p>=edges[i])&(p<edges[i+1])
        k = msk.sum().item()
        if k==0: continue
        conf = float(p[msk].mean())
        if probs.shape[1]==2:
            acc = float((y[msk]==(probs[msk][:,1]>0.5)).float().mean())
        else:
            acc = float((probs[msk].argmax(1)==y[msk]).float().mean())
        ece += (k/N)*abs(conf-acc)
    return ece
```

### `common/log.py` — JSONL/CSV 로거

```python
# common/log.py

import json, csv, os, time

class JsonlLogger:
    def __init__(self, path):
        os.makedirs(os.path.dirname(path) or ".", exist_ok=True)
        self.f = open(path, "a", buffering=1)
    def log(self, **kw):
        kw["ts"]=int(time.time())
        self.f.write(json.dumps(kw, ensure_ascii=False)+"\n")
    def close(self): self.f.close()

class CsvLogger:
    def __init__(self, path, fieldnames):
        os.makedirs(os.path.dirname(path) or ".", exist_ok=True)
        self.f=open(path, "w", newline=""); self.w=csv.DictWriter(self.f, fieldnames=fieldnames); self.w.writeheader()
    def log(self, **kw): self.w.writerow(kw)
    def close(self): self.f.close()
```

> (옵션) 모니터/알람 유틸은 이전 “모니터링(드리프트·지표·알람)” 장의 `monitor_core.py`를 복사해 사용하세요.

---

# — 데이터→학습→평가→서빙

## 데이터 로더 & 증강

```python
# project_vision_cls/data.py

import os, glob, random
from typing import List, Tuple
import torch
from torch.utils.data import Dataset, DataLoader
from PIL import Image, ImageOps, ImageEnhance

CLASSES = ["class0","class1","class2"]  # 예시 3클래스

def simple_augment(img: Image.Image, train=True):
    if train:
        if random.random()<0.5: img=ImageOps.mirror(img)
        if random.random()<0.5: img=ImageOps.flip(img)
        if random.random()<0.5:
            enh = ImageEnhance.Brightness(img); img=enh.enhance(0.8+0.4*random.random())
    img = img.resize((224,224))
    return img

def to_tensor(img: Image.Image):
    x = torch.from_numpy((torch.ByteTensor(torch.ByteStorage.from_buffer(img.tobytes()))
                          .view(img.size[1], img.size[0], 3).numpy()).copy()).float()/255.0
    x = x.permute(2,0,1).contiguous()
    mean = torch.tensor([0.485,0.456,0.406]).view(3,1,1); std = torch.tensor([0.229,0.224,0.225]).view(3,1,1)
    return (x-mean)/std

class ImageFolder(Dataset):
    """폴더 구조: root/classX/*.jpg"""
    def __init__(self, root: str, train=True):
        self.items=[]
        for ci, c in enumerate(CLASSES):
            for p in glob.glob(os.path.join(root, c, "*.jpg")):
                self.items.append((p, ci))
        self.train=train

    def __len__(self): return len(self.items)

    def __getitem__(self, idx):
        p, y = self.items[idx]
        img = Image.open(p).convert("RGB")
        img = simple_augment(img, train=self.train)
        x = to_tensor(img)
        return x, y

def make_loader(root, train=True, bs=128, nw=4, shuffle=True):
    ds = ImageFolder(root, train=train)
    return DataLoader(ds, batch_size=bs, shuffle=shuffle if train else False,
                      num_workers=nw, pin_memory=True, drop_last=train)
```

> 실제 데이터가 없다면, 간단히 `root/class0, class1, class2` 폴더를 만들고 이미지를 복사해 테스트하세요.

## 모델

```python
# project_vision_cls/model.py

import torch, torch.nn as nn, torch.nn.functional as F

class SmallCNN(nn.Module):
    def __init__(self, in_ch=3, num_classes=3):
        super().__init__()
        self.conv1 = nn.Conv2d(in_ch, 32, 3, padding=1)
        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)
        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)
        self.pool  = nn.AdaptiveAvgPool2d(1)
        self.fc    = nn.Linear(128, num_classes)
        self.bn1 = nn.BatchNorm2d(32)
        self.bn2 = nn.BatchNorm2d(64)
        self.bn3 = nn.BatchNorm2d(128)

    def forward(self, x):
        x = F.silu(self.bn1(self.conv1(x)))
        x = F.max_pool2d(x, 2)
        x = F.relu(self.bn2(self.conv2(x)))
        x = F.max_pool2d(x, 2)
        x = F.relu(self.bn3(self.conv3(x)))
        x = self.pool(x).flatten(1)
        return self.fc(x)
```

## 학습 루프(AMP/조기종료/EMA)

```python
# project_vision_cls/train.py

import os, argparse, time, torch, torch.nn as nn
from torch.optim import AdamW
from common.seed import seed_all
from common.amp_ckpt import AmpScaler, EarlyStopper, EMA, save_ckpt
from common.meter import AverageMeter, accuracy_topk
from common.log import JsonlLogger
from .data import make_loader
from .model import SmallCNN

def train(args):
    seed_all(args.seed)
    device = "cuda" if torch.cuda.is_available() else "cpu"

    train_loader = make_loader(args.train_root, train=True, bs=args.bs)
    val_loader   = make_loader(args.val_root,   train=False, bs=args.bs)

    model = SmallCNN(num_classes=args.num_classes).to(device)
    opt = AdamW(model.parameters(), lr=args.lr, weight_decay=1e-4)
    scaler = AmpScaler(enabled=args.amp)
    stopper = EarlyStopper(patience=args.patience, mode="max")
    ema = EMA(model, decay=0.999) if args.ema else None

    os.makedirs(args.run_dir, exist_ok=True)
    logger = JsonlLogger(os.path.join(args.run_dir, "train.jsonl"))
    best = -1; best_ep=0

    for ep in range(1, args.epochs+1):
        model.train()
        loss_m=AverageMeter(); acc_m=AverageMeter()
        for x,y in train_loader:
            x=x.to(device, non_blocking=True); y=y.to(device, non_blocking=True)
            opt.zero_grad(set_to_none=True)
            with torch.autocast(device_type="cuda", dtype=torch.bfloat16, enabled=args.amp):
                logits = model(x)
                loss = nn.CrossEntropyLoss()(logits, y)
            scaler.backward(loss); scaler.step(opt)
            if ema: ema.update(model)
            loss_m.add(loss.item(), x.size(0))
            acc = accuracy_topk(logits.detach(), y, k=1); acc_m.add(acc, x.size(0))

        # 평가(Ep 마다)
        model.eval()
        if ema:
            shadow = SmallCNN(num_classes=args.num_classes).to(device)
            shadow.load_state_dict(model.state_dict()); ema.apply_to(shadow); eval_model=shadow
        else:
            eval_model=model

        v_acc, v_loss = evaluate(eval_model, val_loader, device)
        logger.log(epoch=ep, train_loss=loss_m.avg(), train_acc=acc_m.avg(), val_acc=v_acc, val_loss=v_loss)

        # 체크포인트
        metrics = {"val_acc": v_acc, "epoch": ep}
        save_ckpt(os.path.join(args.run_dir, "last.pt"), model, opt, ep, metrics)
        if v_acc>best:
            best=v_acc; best_ep=ep
            save_ckpt(os.path.join(args.run_dir, "best.pt"), model, opt, ep, metrics)

        if stopper.update(v_acc):
            print(f"[EarlyStop] epoch={ep}, best={best:.4f} @ {best_ep}")
            break

    print("done. best acc:", best, "epoch:", best_ep); logger.close()

@torch.no_grad()
def evaluate(model, val_loader, device):
    loss_m=AverageMeter(); acc_m=AverageMeter()
    for x,y in val_loader:
        x=x.to(device); y=y.to(device)
        logits = model(x)
        loss = nn.CrossEntropyLoss()(logits, y)
        loss_m.add(loss.item(), x.size(0))
        acc_m.add(accuracy_topk(logits, y, k=1), x.size(0))
    return acc_m.avg(), loss_m.avg()

if __name__=="__main__":
    p=argparse.ArgumentParser()
    p.add_argument("--train_root", default="data/vision/train")
    p.add_argument("--val_root",   default="data/vision/val")
    p.add_argument("--num_classes", type=int, default=3)
    p.add_argument("--epochs", type=int, default=20)
    p.add_argument("--bs", type=int, default=128)
    p.add_argument("--lr", type=float, default=3e-4)
    p.add_argument("--amp", action="store_true", default=True)
    p.add_argument("--ema", action="store_true", default=True)
    p.add_argument("--patience", type=int, default=5)
    p.add_argument("--seed", type=int, default=42)
    p.add_argument("--run_dir", default="runs/vision")
    args=p.parse_args()
    train(args)
```

## 평가 & 캘리브레이션

```python
# project_vision_cls/eval.py

import os, argparse, torch
from .model import SmallCNN
from .data import make_loader
from common.amp_ckpt import load_ckpt
from common.meter import confusion_matrix, ece, accuracy_topk

@torch.no_grad()
def main(args):
    device="cuda" if torch.cuda.is_available() else "cpu"
    loader = make_loader(args.val_root, train=False, bs=args.bs)
    model = SmallCNN(num_classes=args.num_classes).to(device).eval()
    load_ckpt(args.ckpt, model)

    all_logits=[]; all_y=[]
    for x,y in loader:
        x=x.to(device); y=y.to(device)
        logits = model(x)
        all_logits.append(logits.cpu()); all_y.append(y.cpu())
    logits = torch.cat(all_logits); y = torch.cat(all_y)
    probs = logits.softmax(-1)
    top1 = accuracy_topk(logits, y, k=1)
    cm = confusion_matrix(args.num_classes, probs.argmax(1), y)
    cal = ece(probs, y, bins=10)
    print("Top1:", top1, "ECE:", cal)
    torch.save(cm, os.path.join(os.path.dirname(args.ckpt), "confusion_matrix.pt"))

if __name__=="__main__":
    ap=argparse.ArgumentParser()
    ap.add_argument("--val_root", default="data/vision/val")
    ap.add_argument("--num_classes", type=int, default=3)
    ap.add_argument("--ckpt", required=True)
    ap.add_argument("--bs", type=int, default=256)
    args=ap.parse_args()
    main(args)
```

## 배치 추론(오프라인)

```python
# project_vision_cls/inference.py

import os, glob, argparse, csv, torch
from PIL import Image
from .model import SmallCNN
from .data import to_tensor
from common.amp_ckpt import load_ckpt

@torch.no_grad()
def main(args):
    device="cuda" if torch.cuda.is_available() else "cpu"
    model = SmallCNN(num_classes=args.num_classes).to(device).eval()
    load_ckpt(args.ckpt, model)

    paths=sorted(glob.glob(os.path.join(args.input_dir, "*.jpg")))
    os.makedirs(os.path.dirname(args.out_csv) or ".", exist_ok=True)
    with open(args.out_csv, "w", newline="") as f:
        w=csv.writer(f); w.writerow(["path","pred","prob"])
        for p in paths:
            x = to_tensor(Image.open(p).convert("RGB")).unsqueeze(0).to(device)
            with torch.autocast(device_type="cuda", dtype=torch.bfloat16, enabled=True):
                prob = model(x).softmax(-1)[0]
            pred = int(prob.argmax().item())
            w.writerow([p, pred, float(prob[pred].item())])

if __name__=="__main__":
    ap=argparse.ArgumentParser()
    ap.add_argument("--ckpt", required=True)
    ap.add_argument("--input_dir", default="data/vision/test")
    ap.add_argument("--out_csv", default="runs/vision/preds.csv")
    ap.add_argument("--num_classes", type=int, default=3)
    main(ap.parse_args())
```

## 실시간 서빙(동적 마이크로배칭 + 간단 모니터)

```python
# project_vision_cls/serve.py

import json, time, threading, queue, argparse
from http.server import BaseHTTPRequestHandler, HTTPServer
import torch
from PIL import Image
from io import BytesIO
from .model import SmallCNN
from .data import to_tensor
from common.amp_ckpt import load_ckpt
from common.monitor_core import SlidingWindow, Alarm, AlarmManager  # (모니터링 장의 파일을 common/에 복사)

DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

class Predictor:
    def __init__(self, ckpt, num_classes):
        self.model = SmallCNN(num_classes=num_classes).to(DEVICE).eval()
        load_ckpt(ckpt, self.model)
    @torch.no_grad()
    def predict(self, xb):
        with torch.autocast(device_type="cuda", dtype=torch.bfloat16, enabled=(DEVICE=="cuda")), torch.inference_mode():
            return self.model(xb).softmax(-1)

class Batcher:
    def __init__(self, predictor, max_batch=32, window_ms=5):
        self.q=queue.Queue(maxsize=1024)
        self.pred=predictor; self.maxb=max_batch; self.win=window_ms/1000
        threading.Thread(target=self.worker, daemon=True).start()
    def submit(self, x):
        ev=threading.Event(); slot={}
        self.q.put((x,ev,slot)); ev.wait(timeout=1.0)
        return slot.get("y")
    def worker(self):
        while True:
            items=[self.q.get()]; t0=time.time()
            while len(items)<self.maxb and (time.time()-t0)<self.win:
                try: items.append(self.q.get_nowait())
                except queue.Empty: time.sleep(0.0005)
            xb=torch.cat([it[0] for it in items],0).to(DEVICE, non_blocking=True)
            yb=self.pred.predict(xb).cpu()
            off=0
            for _,ev,slot in items:
                slot["y"]=yb[off:off+1]; off+=1; ev.set()

# 간단 모니터: p95 레이턴시 알람

LAT=SlidingWindow(1000)
AL=AlarmManager(); AL.add(Alarm("lat_p95", threshold=120.0, direction=">=", min_samples=100, consecutive=3, cooldown_sec=120))

class Handler(BaseHTTPRequestHandler):
    batcher=None
    def _json(self, code, obj):
        b=json.dumps(obj).encode(); self.send_response(code)
        self.send_header("Content-Type","application/json")
        self.send_header("Content-Length", str(len(b))); self.end_headers(); self.wfile.write(b)

    def do_POST(self):
        if self.path!="/predict": self._json(404, {"error":"not found"}); return
        ln=int(self.headers.get("Content-Length","0")); body=self.rfile.read(ln)
        t0=time.time()
        try:
            req=json.loads(body.decode())
            # 입력: {"image_base64": "..."} 또는 multipart 대신 간단화
            if "image_base64" in req:
                import base64
                img=Image.open(BytesIO(base64.b64decode(req["image_base64"]))).convert("RGB").resize((224,224))
            else:
                self._json(400, {"error":"image_base64 required"}); return
            x=to_tensor(img).unsqueeze(0)
            y=self.batcher.submit(x)
            prob=y[0].tolist(); pred=int(y[0].argmax().item())
        except Exception as e:
            self._json(400, {"error": str(e)}); return
        lat_ms=(time.time()-t0)*1000; LAT.push(lat_ms)
        p95=LAT.quantile(0.95); ev=AL.run({"lat_p95":(p95, len(LAT.buf))})
        self._json(200, {"pred": pred, "prob": prob, "lat_ms": lat_ms, "p95": p95, "alert": ev})

def main(args):
    pred=Predictor(args.ckpt, num_classes=args.num_classes)
    Handler.batcher=Batcher(pred, max_batch=args.max_batch, window_ms=args.window_ms)
    httpd=HTTPServer(("0.0.0.0", args.port), Handler)
    print(f"listening {args.port} on {DEVICE}"); httpd.serve_forever()

if __name__=="__main__":
    ap=argparse.ArgumentParser()
    ap.add_argument("--ckpt", required=True)
    ap.add_argument("--num_classes", type=int, default=3)
    ap.add_argument("--port", type=int, default=8080)
    ap.add_argument("--max_batch", type=int, default=32)
    ap.add_argument("--window_ms", type=int, default=5)
    main(ap.parse_args())
```

---

# 프로젝트 B. NLP 의도 분류 — 간단 토크나이저 + TextCNN

> 목표: 외부 NLP 프레임워크 없이 **간단 토크나이저(띄어쓰기 기준 + 소문자화 + rare 단어 UNK)**, **단어 임베딩 + 1D CNN(TextCNN)**으로 Intent 분류.

## 데이터 & 토크나이저

```python
# project_nlp_intent/data.py

import re, os, json, random
from collections import Counter
import torch
from torch.utils.data import Dataset, DataLoader

def tokenize(s: str):
    s = s.lower()
    s = re.sub(r"[^a-z0-9가-힣\s]", " ", s)
    return [t for t in s.split() if t]

def build_vocab(texts, min_freq=2, max_size=30000):
    cnt=Counter()
    for t in texts: cnt.update(tokenize(t))
    vocab=["<PAD>","<UNK>"]+[w for w,f in cnt.most_common(max_size) if f>=min_freq]
    stoi={w:i for i,w in enumerate(vocab)}
    return vocab, stoi

def encode(s, stoi, max_len=32):
    toks=tokenize(s)
    ids=[stoi.get(t,1) for t in toks][:max_len]
    ids=ids + [0]*(max_len-len(ids))
    return torch.tensor(ids, dtype=torch.long)

class IntentDataset(Dataset):
    def __init__(self, jsonl_path, stoi, max_len=32):
        # jsonl line: {"text":"...", "label": 0..C-1}
        self.items=[]
        for line in open(jsonl_path, "r", encoding="utf-8"):
            o=json.loads(line)
            self.items.append((encode(o["text"], stoi, max_len), int(o["label"])))
    def __len__(self): return len(self.items)
    def __getitem__(self, i): return self.items[i]

def make_loader(jsonl_path, stoi, bs=256, shuffle=True, max_len=32):
    ds=IntentDataset(jsonl_path, stoi, max_len=max_len)
    return DataLoader(ds, batch_size=bs, shuffle=shuffle, num_workers=0, pin_memory=True)
```

> 데이터 예시(`data/nlp/train.jsonl`)
> ```json
> {"text":"배송 조회하고 싶어요", "label":0}
> {"text":"환불 규정 알려줘", "label":1}
> {"text":"가까운 매장 찾아줘", "label":2}
> ```

## 모델(TextCNN)

```python
# project_nlp_intent/model.py

import torch, torch.nn as nn, torch.nn.functional as F

class TextCNN(nn.Module):
    def __init__(self, vocab_size, num_classes, emb_dim=128, ks=(3,4,5), ch=64, pad_idx=0):
        super().__init__()
        self.emb = nn.Embedding(vocab_size, emb_dim, padding_idx=pad_idx)
        self.convs = nn.ModuleList([nn.Conv1d(emb_dim, ch, k) for k in ks])
        self.fc = nn.Linear(len(ks)*ch, num_classes)
        self.drop = nn.Dropout(0.2)

    def forward(self, ids):
        # ids: [B, L]
        x = self.emb(ids)           # [B, L, E]
        x = x.transpose(1,2)        # [B, E, L]
        xs=[]
        for conv in self.convs:
            h = F.relu(conv(x))     # [B, C, L-k+1]
            h = F.max_pool1d(h, kernel_size=h.size(-1)).squeeze(-1)  # [B, C]
            xs.append(h)
        out = self.drop(torch.cat(xs, dim=1))
        return self.fc(out)
```

## 학습

```python
# project_nlp_intent/train.py

import os, argparse, json
import torch, torch.nn as nn
from torch.optim import AdamW
from common.seed import seed_all
from common.amp_ckpt import AmpScaler, EarlyStopper, save_ckpt
from common.meter import AverageMeter, accuracy_topk
from common.log import JsonlLogger
from .data import build_vocab, make_loader
from .model import TextCNN

def read_texts(jsonl):
    return [json.loads(l)["text"] for l in open(jsonl, "r", encoding="utf-8")]

def train(args):
    seed_all(args.seed)
    device="cuda" if torch.cuda.is_available() else "cpu"

    # vocab
    texts = read_texts(args.train_jsonl)
    vocab, stoi = build_vocab(texts, min_freq=2, max_size=args.max_vocab)
    os.makedirs(args.run_dir, exist_ok=True)
    json.dump({"vocab":vocab}, open(os.path.join(args.run_dir, "vocab.json"), "w", encoding="utf-8"))

    train_loader = make_loader(args.train_jsonl, stoi, bs=args.bs, max_len=args.max_len)
    val_loader   = make_loader(args.val_jsonl,   stoi, bs=args.bs, max_len=args.max_len, shuffle=False)

    model = TextCNN(vocab_size=len(vocab), num_classes=args.num_classes).to(device)
    opt = AdamW(model.parameters(), lr=args.lr)
    scaler = AmpScaler(enabled=args.amp)
    stopper = EarlyStopper(patience=3, mode="max")
    logger = JsonlLogger(os.path.join(args.run_dir, "train.jsonl"))

    best=-1; best_ep=0
    for ep in range(1, args.epochs+1):
        model.train(); loss_m=AverageMeter(); acc_m=AverageMeter()
        for ids, y in train_loader:
            ids=ids.to(device); y=y.to(device)
            opt.zero_grad(set_to_none=True)
            with torch.autocast(device_type="cuda", dtype=torch.bfloat16, enabled=args.amp):
                logits = model(ids)
                loss = nn.CrossEntropyLoss()(logits, y)
            scaler.backward(loss); scaler.step(opt)
            loss_m.add(loss.item(), ids.size(0))
            acc_m.add(accuracy_topk(logits.detach(), y), ids.size(0))

        # val
        model.eval(); v_loss=AverageMeter(); v_acc=AverageMeter()
        with torch.no_grad():
            for ids,y in val_loader:
                ids=ids.to(device); y=y.to(device)
                logits = model(ids)
                l = nn.CrossEntropyLoss()(logits, y)
                v_loss.add(l.item(), ids.size(0))
                v_acc.add(accuracy_topk(logits, y), ids.size(0))

        logger.log(epoch=ep, train_loss=loss_m.avg(), train_acc=acc_m.avg(), val_loss=v_loss.avg(), val_acc=v_acc.avg())
        save_ckpt(os.path.join(args.run_dir, "last.pt"), model, opt, ep, {"val_acc": v_acc.avg()})
        if v_acc.avg()>best:
            best=v_acc.avg(); best_ep=ep
            save_ckpt(os.path.join(args.run_dir, "best.pt"), model, opt, ep, {"val_acc": best})
        if stopper.update(v_acc.avg()): break

    print("best val_acc:", best, "epoch:", best_ep); logger.close()

if __name__=="__main__":
    ap=argparse.ArgumentParser()
    ap.add_argument("--train_jsonl", default="data/nlp/train.jsonl")
    ap.add_argument("--val_jsonl",   default="data/nlp/val.jsonl")
    ap.add_argument("--num_classes", type=int, default=3)
    ap.add_argument("--epochs", type=int, default=10)
    ap.add_argument("--bs", type=int, default=256)
    ap.add_argument("--lr", type=float, default=2e-3)
    ap.add_argument("--max_len", type=int, default=32)
    ap.add_argument("--max_vocab", type=int, default=30000)
    ap.add_argument("--amp", action="store_true", default=True)
    ap.add_argument("--seed", type=int, default=42)
    ap.add_argument("--run_dir", default="runs/nlp")
    train(ap.parse_args())
```

## 평가 & 배치/실시간 추론

```python
# project_nlp_intent/eval.py

import os, argparse, json, torch
from common.amp_ckpt import load_ckpt
from common.meter import AverageMeter, accuracy_topk
from .data import make_loader, build_vocab
from .model import TextCNN

@torch.no_grad()
def main(args):
    device="cuda" if torch.cuda.is_available() else "cpu"
    vocab=json.load(open(os.path.join(args.run_dir,"vocab.json"),"r",encoding="utf-8"))["vocab"]
    stoi={w:i for i,w in enumerate(vocab)}
    loader=make_loader(args.val_jsonl, stoi, bs=args.bs, max_len=args.max_len, shuffle=False)
    model=TextCNN(vocab_size=len(vocab), num_classes=args.num_classes).to(device).eval()
    load_ckpt(args.ckpt, model)

    acc_m=AverageMeter()
    for ids,y in loader:
        ids=ids.to(device); y=y.to(device)
        acc_m.add(accuracy_topk(model(ids), y), ids.size(0))
    print("Val Acc:", acc_m.avg())

if __name__=="__main__":
    ap=argparse.ArgumentParser()
    ap.add_argument("--run_dir", default="runs/nlp")
    ap.add_argument("--val_jsonl", default="data/nlp/val.jsonl")
    ap.add_argument("--ckpt", required=True)
    ap.add_argument("--num_classes", type=int, default=3)
    ap.add_argument("--bs", type=int, default=256)
    ap.add_argument("--max_len", type=int, default=32)
    main(ap.parse_args())
```

```python
# project_nlp_intent/inference.py

import os, json, argparse, torch
from .model import TextCNN
from .data import encode
from common.amp_ckpt import load_ckpt

@torch.no_grad()
def main(args):
    device="cuda" if torch.cuda.is_available() else "cpu"
    vocab=json.load(open(os.path.join(args.run_dir,"vocab.json"),"r",encoding="utf-8"))["vocab"]
    stoi={w:i for i,w in enumerate(vocab)}
    model=TextCNN(vocab_size=len(vocab), num_classes=args.num_classes).to(device).eval()
    load_ckpt(args.ckpt, model)

    with open(args.inp, "r", encoding="utf-8") as f:
        for line in f:
            s=line.strip()
            ids=encode(s, stoi, max_len=args.max_len).unsqueeze(0).to(device)
            prob=model(ids).softmax(-1)[0]
            pred=int(prob.argmax().item())
            print(json.dumps({"text": s, "pred": pred, "prob": prob[pred].item()}, ensure_ascii=False))

if __name__=="__main__":
    ap=argparse.ArgumentParser()
    ap.add_argument("--run_dir", default="runs/nlp")
    ap.add_argument("--ckpt", required=True)
    ap.add_argument("--num_classes", type=int, default=3)
    ap.add_argument("--inp", default="data/nlp/test.txt")
    ap.add_argument("--max_len", type=int, default=32)
    main(ap.parse_args())
```

```python
# project_nlp_intent/serve.py

import os, json, argparse, time
from http.server import BaseHTTPRequestHandler, HTTPServer
import torch
from .model import TextCNN
from .data import encode

DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
VOCAB=None; STOI=None; MODEL=None

class Handler(BaseHTTPRequestHandler):
    def _json(self, code, obj):
        b=json.dumps(obj, ensure_ascii=False).encode()
        self.send_response(code); self.send_header("Content-Type","application/json")
        self.send_header("Content-Length", str(len(b))); self.end_headers(); self.wfile.write(b)

    def do_POST(self):
        if self.path!="/predict": self._json(404, {"error":"not found"}); return
        ln=int(self.headers.get("Content-Length","0")); body=self.rfile.read(ln)
        t0=time.time()
        try:
            req=json.loads(body.decode()); text=req["text"]
            ids=encode(text, STOI, max_len=32).unsqueeze(0).to(DEVICE)
            with torch.autocast(device_type="cuda", dtype=torch.bfloat16, enabled=(DEVICE=="cuda")), torch.inference_mode():
                prob=MODEL(ids).softmax(-1)[0]
            pred=int(prob.argmax().item()); conf=float(prob[pred].item())
        except Exception as e:
            self._json(400, {"error": str(e)}); return
        self._json(200, {"pred": pred, "conf": conf, "lat_ms": (time.time()-t0)*1000})

def main(args):
    global VOCAB, STOI, MODEL
    VOCAB=json.load(open(os.path.join(args.run_dir,"vocab.json"),"r",encoding="utf-8"))["vocab"]
    STOI={w:i for i,w in enumerate(VOCAB)}
    MODEL=TextCNN(vocab_size=len(VOCAB), num_classes=args.num_classes).to(DEVICE).eval()
    from common.amp_ckpt import load_ckpt; load_ckpt(args.ckpt, MODEL)
    httpd=HTTPServer(("0.0.0.0", args.port), Handler)
    print("nlp listening", args.port, "on", DEVICE); httpd.serve_forever()

if __name__=="__main__":
    ap=argparse.ArgumentParser()
    ap.add_argument("--run_dir", default="runs/nlp")
    ap.add_argument("--ckpt", required=True)
    ap.add_argument("--num_classes", type=int, default=3)
    ap.add_argument("--port", type=int, default=8081)
    main(ap.parse_args())
```

---

# — 배치+실시간

> 목표: **단일 시계열(예: 서버 QPS, 센서 값)**을 **다단계 예측**하고, 예측-관측 잔차로 이상을 감지.
> - 배치 모드: 다음날/다음시간대 예측 CSV 생성.
> - 실시간: 최신 윈도 입력에 대해 즉시 1-step 예측 & 이상 플래그.

## 데이터 준비(슬라이딩 윈도)

```python
# project_ts_forecast/data.py

import torch
from torch.utils.data import Dataset, DataLoader

class SeriesWindow(Dataset):
    def __init__(self, series: torch.Tensor, win=64, horizon=1):
        # series: [N] float tensor
        self.x=[]; self.y=[]
        for i in range(len(series)-win-horizon+1):
            self.x.append(series[i:i+win])
            self.y.append(series[i+win:i+win+horizon])
        self.x=torch.stack(self.x); self.y=torch.stack(self.y)
    def __len__(self): return self.x.size(0)
    def __getitem__(self, i): return self.x[i], self.y[i]

def make_loader(series, win=64, horizon=1, bs=256, shuffle=True):
    ds=SeriesWindow(series, win, horizon)
    return DataLoader(ds, batch_size=bs, shuffle=shuffle, pin_memory=True)
```

## 모델(LSTM 예측기)

```python
# project_ts_forecast/model.py

import torch, torch.nn as nn

class LSTMForecaster(nn.Module):
    def __init__(self, hidden=128, layers=2, horizon=1):
        super().__init__()
        self.rnn = nn.LSTM(input_size=1, hidden_size=hidden, num_layers=layers, batch_first=True)
        self.fc  = nn.Linear(hidden, horizon)
    def forward(self, x):
        # x: [B, W], -> [B, W, 1]
        x = x.unsqueeze(-1)
        o, _ = self.rnn(x)          # [B, W, H]
        h = o[:, -1, :]             # [B, H]
        return self.fc(h)           # [B, horizon]
```

## 학습

```python
# project_ts_forecast/train.py

import os, argparse, torch, torch.nn as nn
from torch.optim import AdamW
from common.seed import seed_all
from common.amp_ckpt import AmpScaler, EarlyStopper, save_ckpt
from common.meter import AverageMeter
from .data import make_loader
from .model import LSTMForecaster

def train(args):
    seed_all(args.seed)
    device="cuda" if torch.cuda.is_available() else "cpu"

    # 데모용: 합성 파형 (실전: CSV 로드 → 텐서)
    N=20000
    t=torch.linspace(0, 200, N)
    series=torch.sin(t)*0.5 + torch.cos(t*0.3)*0.2 + 0.05*torch.randn(N)
    train_series=series[:16000]; val_series=series[16000:]

    tr=make_loader(train_series, win=args.win, horizon=args.h, bs=args.bs, shuffle=True)
    va=make_loader(val_series,   win=args.win, horizon=args.h, bs=args.bs, shuffle=False)

    model=LSTMForecaster(hidden=args.hidden, layers=2, horizon=args.h).to(device)
    opt=AdamW(model.parameters(), lr=args.lr)
    scaler=AmpScaler(enabled=args.amp)
    stopper=EarlyStopper(patience=5, mode="min")

    os.makedirs(args.run_dir, exist_ok=True)
    best=1e9; best_ep=0

    for ep in range(1, args.epochs+1):
        model.train(); tr_loss=AverageMeter()
        for x,y in tr:
            x=x.to(device); y=y.to(device)
            opt.zero_grad(set_to_none=True)
            with torch.autocast(device_type="cuda", dtype=torch.bfloat16, enabled=args.amp):
                pred=model(x)
                loss=nn.SmoothL1Loss()(pred, y)
            scaler.backward(loss); scaler.step(opt)
            tr_loss.add(loss.item(), x.size(0))

        # val
        model.eval(); va_loss=AverageMeter()
        with torch.no_grad():
            for x,y in va:
                x=x.to(device); y=y.to(device)
                va_loss.add(nn.SmoothL1Loss()(model(x), y).item(), x.size(0))

        if va_loss.avg()<best:
            best=va_loss.avg(); best_ep=ep
            save_ckpt(os.path.join(args.run_dir, "best.pt"), model, opt, ep, {"val_loss": best})
        if stopper.update(va_loss.avg()): break
        print(f"ep{ep} tr={tr_loss.avg():.4f} va={va_loss.avg():.4f}")
    print("best val:", best, "@", best_ep)

if __name__=="__main__":
    ap=argparse.ArgumentParser()
    ap.add_argument("--epochs", type=int, default=12)
    ap.add_argument("--bs", type=int, default=256)
    ap.add_argument("--lr", type=float, default=3e-4)
    ap.add_argument("--amp", action="store_true", default=True)
    ap.add_argument("--seed", type=int, default=42)
    ap.add_argument("--win", type=int, default=64)
    ap.add_argument("--h", type=int, default=1)
    ap.add_argument("--hidden", type=int, default=128)
    ap.add_argument("--run_dir", default="runs/ts")
    train(ap.parse_args())
```

## 평가 & 이상탐지 규칙

```python
# project_ts_forecast/eval.py

import os, argparse, torch
from .model import LSTMForecaster
from common.amp_ckpt import load_ckpt

@torch.no_grad()
def main(args):
    device="cuda" if torch.cuda.is_available() else "cpu"
    model=LSTMForecaster(hidden=args.hidden, horizon=args.h).to(device).eval()
    load_ckpt(args.ckpt, model)

    # 데모: 동일 합성 시리즈
    N=5000; t=torch.linspace(0,50,N)
    series=torch.sin(t)*0.5 + 0.05*torch.randn(N)
    # 일부 구간 이상 주입
    series[2000:2050]+=1.2

    win=args.win; h=args.h
    preds=[]; gts=[]; res=[]
    for i in range(N-win-h):
        x=series[i:i+win].unsqueeze(0).to(device)
        y=series[i+win:i+win+h]
        p=model(x).cpu()[0,0]
        preds.append(p.item()); gts.append(y[0].item()); res.append(abs(p-y[0]).item())
    import numpy as np
    thr = np.mean(res)+3*np.std(res)
    anomalies = [int(r>thr) for r in res]
    print("MSE:", float(torch.tensor([(a-b)**2 for a,b in zip(preds,gts)]).mean()))
    print("threshold:", thr, "anomaly_count:", sum(anomalies))

if __name__=="__main__":
    ap=argparse.ArgumentParser()
    ap.add_argument("--ckpt", required=True)
    ap.add_argument("--win", type=int, default=64)
    ap.add_argument("--h", type=int, default=1)
    ap.add_argument("--hidden", type=int, default=128)
    main(ap.parse_args())
```

## 배치 예측 CSV

```python
# project_ts_forecast/batch_predict.py

import argparse, csv, torch
from .model import LSTMForecaster
from common.amp_ckpt import load_ckpt

@torch.no_grad()
def main(args):
    device="cuda" if torch.cuda.is_available() else "cpu"
    model=LSTMForecaster(hidden=args.hidden, horizon=args.h).to(device).eval()
    load_ckpt(args.ckpt, model)
    # 실제로는 과거 시계열 CSV 읽기 → 텐서화
    N=1000; t=torch.linspace(0,10,N); series=torch.sin(t)*0.5
    win=args.win; h=args.h
    rows=[]
    for i in range(N-win-h):
        x=series[i:i+win].unsqueeze(0).to(device)
        p=model(x).cpu()[0].tolist()  # h개
        rows.append([i]+p)
    with open(args.out, "w", newline="") as f:
        w=csv.writer(f); w.writerow(["t"]+[f"t+{k+1}" for k in range(h)])
        w.writerows(rows)
    print("wrote", args.out)

if __name__=="__main__":
    ap=argparse.ArgumentParser()
    ap.add_argument("--ckpt", required=True)
    ap.add_argument("--out", default="runs/ts/preds.csv")
    ap.add_argument("--win", type=int, default=64)
    ap.add_argument("--h", type=int, default=1)
    ap.add_argument("--hidden", type=int, default=128)
    main(ap.parse_args())
```

## 실시간 서빙(간단)

```python
# project_ts_forecast/serve.py

import json, argparse, time
from http.server import BaseHTTPRequestHandler, HTTPServer
import torch
from .model import LSTMForecaster
from common.amp_ckpt import load_ckpt

DEVICE="cuda" if torch.cuda.is_available() else "cpu"
MODEL=None; WIN=64; H=1

class Handler(BaseHTTPRequestHandler):
    def _json(self, code, obj):
        b=json.dumps(obj).encode(); self.send_response(code)
        self.send_header("Content-Type","application/json")
        self.send_header("Content-Length", str(len(b))); self.end_headers(); self.wfile.write(b)

    def do_POST(self):
        if self.path!="/forecast": self._json(404, {"error":"not found"}); return
        ln=int(self.headers.get("Content-Length","0")); body=self.rfile.read(ln)
        t0=time.time()
        try:
            req=json.loads(body.decode()); seq=req["values"]  # 길이 WIN float 리스트
            import numpy as np
            x=torch.tensor(seq[-WIN:], dtype=torch.float32).unsqueeze(0).to(DEVICE)
            with torch.autocast(device_type="cuda", dtype=torch.bfloat16, enabled=(DEVICE=="cuda")), torch.inference_mode():
                pred=MODEL(x)[0].tolist()
            lat=(time.time()-t0)*1000
        except Exception as e:
            self._json(400, {"error": str(e)}); return
        self._json(200, {"pred": pred, "lat_ms": lat})

def main(args):
    global MODEL, WIN, H
    WIN=args.win; H=args.h
    MODEL=LSTMForecaster(hidden=args.hidden, horizon=H).to(DEVICE).eval()
    load_ckpt(args.ckpt, MODEL)
    httpd=HTTPServer(("0.0.0.0", args.port), Handler)
    print("ts listening", args.port, "on", DEVICE); httpd.serve_forever()

if __name__=="__main__":
    ap=argparse.ArgumentParser()
    ap.add_argument("--ckpt", required=True)
    ap.add_argument("--win", type=int, default=64)
    ap.add_argument("--h", type=int, default=1)
    ap.add_argument("--hidden", type=int, default=128)
    ap.add_argument("--port", type=int, default=8082)
    main(ap.parse_args())
```

---

## 운영 프리셋 — 공통 모니터링/알람 접목

- **레이턴시 p95**: `SlidingWindow + Alarm("lat_p95", threshold=...)`
- **품질 드리프트(선택)**: Vision에서는 **확률 분포(KS/ECE)**, NLP는 **클래스 비율/최상위 conf 분포**, TS는 **잔차 분포**.
- **알람 정책**: 임계 + 연속 위반 + 쿨다운.
- **로그 스키마**: `ts, req_id, model_id, data_hash, lat_ms, pred/prob` 등.

> 모니터링 유틸은 앞서 제공한 `common/monitor_core.py`를 그대로 재사용하세요.

---

## 모델/데이터 카드 자동화 연결

- Vision/NLP/TS 프로젝트에서 `runs/*/best.pt`, `confusion_matrix.pt`, `train.jsonl` 등 산출물을 기반으로, 앞서 제공한 **모델/데이터 카드 템플릿**과 **자동 생성 스크립트**(`generate_model_card.py`)를 그대로 적용.
- 카드에는 **배포 계획(카나리/롤백)**, **모니터링 임계**를 명확히 포함.

---

## 체크리스트 — 실제 투입 전

### 학습/평가

- [ ] 재현성: `seed_all()` 적용, `cudnn.deterministic=True`
- [ ] AMP: `bfloat16` 우선(가능 시), 불안정 레이어는 FP32 유지
- [ ] 체크포인트: `best.pt`(성능 기준), `last.pt`(재개)
- [ ] 검증: 분할 고정, **과적합** 감시(EarlyStop)

### 배포

- [ ] 실시간 서버: **마이크로배칭**, **백프레셔**(큐 가득 시 429), **타임아웃**
- [ ] 헬스체크: `/health`(간단 OK), 워밍업(더미 배치 3~5회)
- [ ] 로그: JSONL/메타(모델/데이터 버전) 포함
- [ ] 카나리: 1%→5%→25%→100%, 가드레일 위반 시 **자동 롤백**

### 모니터링/알람

- [ ] SLO: p50/p95/p99, 에러율
- [ ] 품질: Top-1/F1/ECE(vision), Acc(회귀는 MSE), TS는 MSE/잔차
- [ ] 드리프트: PSI/KS/MMD 중 1~2개 선택 운영
- [ ] 알람: 임계/연속/쿨다운 문서화 & 코드화

---

## 성능 팁(각 태스크)

- **Vision**: `channels_last` + 배치 크게 + 동적 배칭 2~10ms 윈도.
- **NLP**: 텍스트 전처리 CPU, 모델 전개 GPU. 짧은 문장은 배치 크게(256~1024).
- **TS**: CPU도 충분(모델 작음). 실시간에서는 고정 윈도 크기와 큐 지연 모니터링.

---

## 확장 아이디어

- Vision: CutMix/Mixup, Label Smoothing, 강건성 테스트(압축/노이즈).
- NLP: 서브워드 토크나이저(BPE)로 교체, 간단 TransformerEncoder 구현(여전히 PyTorch 순수).
- TS: 다변량 입력(여러 지표 동시), 변동성 스케일링, 예측 불확실성 추정(예: MC Dropout).

---

## 수학 메모(필요 공식, MathJax)

- **교차 엔트로피**
  \[
  \mathcal{L}_{\text{CE}}=-\frac{1}{N}\sum_{i=1}^N\sum_{c=1}^C y_{ic}\log p_{ic}
  \]
- **ECE**
  \[
  \mathrm{ECE}=\sum_{b=1}^{B}\frac{|S_b|}{N}\left|\mathrm{acc}(S_b)-\mathrm{conf}(S_b)\right|
  \]
- **Smooth L1(허버) 손실**
  \[
  \mathrm{Huber}_\delta(r)=
  \begin{cases}
  \frac{1}{2}r^2 & |r|\le\delta\\
  \delta(|r|-\frac{1}{2}\delta)& \text{otherwise}
  \end{cases}
  \]

---

## 마무리

- 본 문서는 **실전형 최소 뼈대**를 제공합니다. **여기에서 성능/안정성/거버넌스 레이어**(데이터 버저닝, 실험관리, 릴리즈 게이트, 모니터링 대시보드)를 단계적으로 얹으면 **프로덕션 품질**에 도달합니다.
- 원하시면, 귀하의 **실제 데이터 스펙과 지연/정확도 SLO**를 알려주세요. 위 3개 프로젝트 중 하나를 골라, **커스텀 구성/프로파일**까지 바로 맞춰 드릴 수 있어요.
