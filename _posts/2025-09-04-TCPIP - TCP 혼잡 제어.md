---
layout: post
title: TCPIP - TCP 혼잡 제어
date: 2025-09-04 20:25:23 +0900
category: TCPIP
---
# TCP 혼잡 제어

## TCP 혼잡 제어 개요

TCP 혼잡 제어는 인터넷과 같은 패킷 교환 네트워크에서 네트워크의 혼잡을 감지하고, 데이터 전송 속도를 조절하여 네트워크의 정체를 방지하고 전체적인 효율성을 유지하는 메커니즘입니다. 발신자가 수신자의 처리 능력 이상으로 데이터를 빠르게 전송하거나, 네트워크 경로 상의 라우터나 링크가 수용할 수 있는 양 이상의 트래픽이 유입될 때 혼잡이 발생합니다. TCP는 이 문제를 종단 간(end-to-end) 방식으로 해결하며, 명시적인 네트워크의 피드백을 의존하지 않고 패킷 손실을 혼잡의 주요 지표로 삼습니다.

## 기본 개념

### 흐름 제어 vs 혼잡 제어

```
발신자                    네트워크                    수신자
  |                          |                          |
  |  [cwnd: 혼잡 제어]       |      [rwnd: 흐름 제어]  |
  |   네트워크 용량 고려     |       수신자 버퍼 고려   |
  |                          |                          |
  |  실제 전송 = min(cwnd, rwnd)                       |
  |--------------------------------------------------------|
```

- **흐름 제어(Flow Control)**: 수신자의 처리 능력을 초과하지 않도록 제어. rwnd(수신 윈도우) 사용
- **혼잡 제어(Congestion Control)**: 네트워크의 전송 능력을 초과하지 않도록 제어. cwnd(혼잡 윈도우) 사용
- **실제 전송량**: `EffectiveWindow = min(cwnd, rwnd)`

### AIMD 원리 (Additive Increase Multiplicative Decrease)

TCP 혼잡 제어의 핵심 철학으로, 네트워크 공정성과 안정성을 보장합니다.

```
cwnd
 ^
 |     /\        /\        /\
 |    /  \      /  \      /  \
 |   /    \    /    \    /    \
 |  /      \  /      \  /      \
 | /        \/        \/        \
 |________________________________> 시간
    AI  MD   AI   MD   AI   MD
    
AI (Additive Increase): cwnd += 1 MSS per RTT
MD (Multiplicative Decrease): cwnd = cwnd / 2
```

- **가법적 증가(AI)**: 혼잡이 없으면 매 RTT마다 cwnd를 1 MSS씩 선형 증가
- **승법적 감소(MD)**: 혼잡 감지 시 cwnd를 절반으로 급격히 감소
- **효과**: 여러 연결이 공정하게 대역폭을 나누어 사용하도록 수렴

### 대역폭-지연 곱 (Bandwidth-Delay Product, BDP)

```
BDP = Bandwidth × RTT

예시: 100 Mbps 링크, 100ms RTT
BDP = 100 Mbps × 0.1s = 10 Mb = 1.25 MB

이는 파이프를 가득 채우기 위해 필요한 데이터 양
```

## TCP 혼잡 제어의 핵심 구성 요소

혼잡 제어는 크게 **혼잡 탐지(Congestion Detection)** 와 **속도 조절(Rate Adjustment)** 의 두 가지 주요 활동으로 구성됩니다.

```
[연결 시작] → [Slow Start] → [Congestion Avoidance]
                     ↓                ↓
                [패킷 손실 감지]
                     ↓
         ┌───────────┴───────────┐
         ↓                       ↓
    [Timeout]            [3 Duplicate ACKs]
         ↓                       ↓
  [Slow Start]          [Fast Retransmit]
    재시작                      ↓
                        [Fast Recovery]
                              ↓
                    [Congestion Avoidance]
```

## 상세 동작 메커니즘

### 1. 슬로우 스타트 (Slow Start)

연결 초기 또는 패킷 손실 후에 전송 속도를 빠르게 높여 네트워크의 가용 대역폭을 탐색하는 단계입니다.

- **혼잡 창(Congestion Window, cwnd)** 개념 도입: 수신자의 통고 창(advertised window) 외에, 발신자가 네트워크 혼잡을 고려해 자체적으로 유지하는 창입니다.
- **지수적 증가(Exponential Growth)**: 초기 cwnd는 일반적으로 1~10 MSS(Maximum Segment Size)로 작게 시작합니다. 매 전송된 패킷에 대한 ACK를 수신할 때마다 cwnd를 1 MSS만큼 증가시킵니다. 이는 실제로 RTT마다 cwnd가 약 두 배로 증가하는 효과를 냅니다.
- **슬로우 스타트 임계값(ssthresh)**: cwnd가 이 값에 도달하면 슬로우 스타트 단계를 멈추고 혼잡 회피 단계로 전환합니다.

```
RTT:    0    1    2    3    4    5
cwnd:   1    2    4    8   16   32  (지수 증가)
        |    |    |    |    |    |
패킷:   █   ██  ████ ████████ (각 RTT마다 2배)
                           ↑
                      ssthresh 도달
                      
시간 축
|
| cwnd
|  ^
|  |                    (ssthresh)
|  |                  .............
|  | *               .
|  |   **           .
|  |      ****     .
|  |           ****
|  |____________________________> 시간
    슬로우 스타트 구간
```

### 2. 혼잡 회피 (Congestion Avoidance)

슬로우 스타트를 통해 네트워크의 대략적인 용량을 추정한 후, 네트워크를 포화 상태에 가깝게 유지하면서도 혼잡을 피하기 위해 전송 속도를 조심스럽게 증가시키는 단계입니다.

- **가법적 증가(Additive Increase)**: 매 RTT마다 cwnd를 1 MSS만큼 선형적으로 증가시킵니다.
- **구현**: `cwnd += MSS * (MSS / cwnd)` (매 ACK마다)
- **효과**: 한 창 분량의 모든 패킷에 대한 ACK가 도착했을 때 cwnd를 1 MSS 증가

```
cwnd
 ^
 |              혼잡 회피 단계
 |            ******************
 |          *
 |        *
 |      * (선형 증가: +1 MSS per RTT)
 |    *
 |  *
 |*___________________________________> 시간
  슬로우     |
  스타트   ssthresh
```

### 3. 타임아웃 계산 (RTO - Retransmission Timeout)

TCP는 RTT를 지속적으로 측정하여 적절한 타임아웃 값을 동적으로 계산합니다.

```
SRTT (Smoothed RTT):
  SRTT = (1 - α) × SRTT + α × RTT_sample
  (일반적으로 α = 1/8)

RTTVAR (RTT Variation):
  RTTVAR = (1 - β) × RTTVAR + β × |SRTT - RTT_sample|
  (일반적으로 β = 1/4)

RTO (Retransmission Timeout):
  RTO = SRTT + 4 × RTTVAR
  (최소값: 1초, Karn's Algorithm 적용)
```

## 고전적 TCP 알고리즘

### A. TCP Tahoe (1988)

초기 TCP 혼잡 제어 알고리즘으로, 슬로우 스타트와 혼잡 회피를 도입했습니다.

**손실 대응:**
1. ssthresh = cwnd / 2
2. cwnd = 1 MSS
3. 슬로우 스타트 재시작

```
cwnd
 ^
 |                *
 |               * *
 |              *   *
 |             *     *
 |            *       * (Timeout!)
 |           *         |
 |          *          | ssthresh = cwnd/2
 |         *           ↓
 |        *          -----
 |       *         *
 |      *        **
 |     *       ***
 |    *     ****
 |___*___*****_________________> 시간
       ↑
    cwnd=1, 슬로우 스타트 재시작
```

### B. TCP Reno (1990) - Fast Retransmit & Fast Recovery

TCP Tahoe의 단점을 보완하여 단일 패킷 손실에 대한 복구 시간을 크게 단축시킨 알고리즘입니다.

**빠른 재전송(Fast Retransmit):**
- 중복 ACK 3개 수신 시 타임아웃을 기다리지 않고 즉시 재전송
- 대부분의 단일 패킷 손실을 빠르게 복구

**빠른 회복(Fast Recovery):**
1. 중복 ACK 3개 수신
2. ssthresh = cwnd / 2
3. cwnd = ssthresh + 3 MSS
4. 추가 중복 ACK마다 cwnd += 1 MSS
5. 새로운 ACK 수신 시 cwnd = ssthresh, 혼잡 회피 진입

```
cwnd
 ^
 |           혼잡회피
 |          ********
 |                  *
 |                  * (패킷 손실)
 |                  *
 |                  *|||  (3 DupACKs)
 |                  *|||
 |                   |**** (Fast Recovery)
 |                   |   ****
 |                   ↓      **** (혼잡회피)
 |              ssthresh  ********
 |_____________________________> 시간
                   ↑
            cwnd = ssthresh + 3
```

### C. TCP NewReno (1999)

TCP Reno의 확장으로, 빠른 회복 단계에서 여러 패킷이 손실된 경우를 더 잘 처리합니다.

**주요 개선:**
- **Partial ACK 처리**: 빠른 회복 중 부분 ACK를 받으면 다음 손실 패킷을 즉시 재전송
- **Recovery Point**: 한 RTT 동안의 모든 손실을 하나의 복구 기간으로 처리

```
손실: [P1] [P2] [P3] ... [Pn]

Reno:
  3 DupACK → P1 재전송 → Timeout → 모든 패킷 재전송

NewReno:
  3 DupACK → P1 재전송 → Partial ACK → P2 재전송
          → Partial ACK → P3 재전송 ... (빠른 회복 유지)
```

### D. TCP Vegas (1994) - 지연 기반 혼잡 제어

패킷 손실이 아닌 RTT 증가를 혼잡의 조기 신호로 사용하는 선구적 알고리즘입니다.

**핵심 아이디어:**
```
예상 처리율 = cwnd / BaseRTT
실제 처리율 = cwnd / RTT

Diff = (예상 - 실제) × BaseRTT

if Diff < α:
    cwnd += 1  (선형 증가)
elif Diff > β:
    cwnd -= 1  (선형 감소)
else:
    cwnd 유지  (안정 상태)

일반적으로: α = 1, β = 3
```

```
RTT
 ^
 |                    /
 |                  /  (큐 증가)
 |                /
 |              /
 |____________/____________> cwnd
            ↑
      Vegas가 감지하는 지점
      (Reno는 이후 손실까지 대기)
```

**장점:**
- 혼잡 발생 전 사전 대응
- 낮은 지연과 적은 패킷 손실

**단점:**
- 손실 기반 알고리즘과 공존 시 공정성 문제
- 실제 네트워크에서 BaseRTT 측정의 어려움

## 선택적 확인응답 (SACK - Selective Acknowledgment)

여러 패킷 손실 시 효율적인 복구를 위한 TCP 확장 기능입니다.

```
전송 패킷: [1][2][3][4][5][6][7][8]
               ↓  X  X  ↓  ↓  X  ↓
수신 패킷: [1][_][_][4][5][_][7]

기존 ACK: ACK=2 (누적 확인응답)
SACK:     ACK=2, SACK={4-6, 7-8}
          → 발신자는 정확히 2,3,6만 재전송

Without SACK (Reno):
  [2] 재전송 → ACK → [3] 재전송 → ACK → [6] 재전송
  (여러 RTT 필요)

With SACK:
  [2][3][6] 동시 재전송 가능
  (1 RTT로 복구)
```

## 현대 TCP 알고리즘

### TCP BIC (Binary Increase Congestion Control, 2004)

CUBIC의 전신으로, 고속 장거리 네트워크를 위해 설계되었습니다.

**동작 방식:**
```
1. 이진 탐색을 이용한 창 크기 조절
2. 손실 전 최대값(Wmax)을 기억
3. Wmax까지 빠르게 증가 (이진 탐색)
4. Wmax 근처에서 천천히 탐색

cwnd
 ^
 |              Wmax
 |                *
 |              * * *  (이진 탐색)
 |            *     *
 |          *        *
 |        *           * (손실)
 |      *             ↓
 |    *
 |  *___________________________> 시간
    빠른 증가    느린 탐색
```

### TCP CUBIC (2008) - Linux 기본 알고리즘

현재 리눅스 시스템의 기본 TCP 알고리즘으로, BIC를 개선하여 더 부드럽고 공정한 동작을 제공합니다.

**3차 함수 기반 창 증가:**
```
W(t) = C × (t - K)³ + Wmax

여기서:
  C: 스케일링 상수 (0.4)
  t: 마지막 손실 이후 경과 시간
  K: W(K) = Wmax가 되는 시간
  Wmax: 손실 직전 창 크기
```

```
cwnd
 ^
 |              Wmax (손실 지점)
 |                *
 |              /   \
 |            /       \   (3차 곡선)
 |          /           \
 |        /               \
 |      /                   \
 |    *                       *
 |  *                           *
 |________________________________> 시간
    빠른    느린    빠른
    증가    탐색    증가
    
단계:
1. Concave (오목): Wmax까지 빠른 증가
2. Plateau: Wmax 근처에서 안정화
3. Convex (볼록): 새로운 용량 탐색
```

**주요 특징:**
- RTT 독립성: 긴 RTT 연결도 공정한 대역폭 점유
- 스케일러빌리티: 고속 네트워크에서 우수한 성능
- TCP 친화성: 기존 TCP와의 공정한 대역폭 공유

**Reno와 CUBIC 비교:**
```
cwnd
 ^
 |     CUBIC (3차 함수)
 |       /****\
 |      /      \****
 |     /            \
 |    /              \
 |   /    Reno (선형)
 |  /   ************
 | /  **
 |/**____________________> 시간
  손실     Wmax    새로운 최대
```

### TCP Compound (Windows 기본)

Windows 시스템의 기본 알고리즘으로, 손실 기반과 지연 기반 접근을 결합합니다.

```
cwnd = cwnd_loss + cwnd_delay

cwnd_loss: Reno 방식 (손실 기반)
cwnd_delay: Vegas 방식 (지연 기반)

정상 상태:
  cwnd_delay ≈ 30-50 패킷 (적극적)
  총 cwnd는 Reno보다 크지만 안전 범위 유지

혼잡 감지:
  cwnd_delay = 0 (보수적으로 전환)
  cwnd_loss만 사용
```

### TCP Westwood/Westwood+ (무선 최적화)

무선 환경의 랜덤 손실을 구분하여 처리하는 알고리즘입니다.

**핵심 아이디어:**
```
손실 발생 시:
  1. ACK 간격으로 대역폭 추정 (BWE)
  2. ssthresh = BWE × RTTmin
  3. cwnd = ssthresh (Reno의 cwnd/2 대신)

이유:
  무선 오류 → 실제 용량 변화 없음
  → 과도한 감소 방지
  
유선 혼잡 → BWE가 자연히 감소
  → 적절한 조절
```

```
시나리오: 무선 오류로 패킷 손실

Reno:
  cwnd: 100 → 50 (과도한 감소)
  
Westwood+:
  BWE = 80 Mbps
  cwnd: 100 → 85 (대역폭 기반)
  (실제 용량에 더 가까움)
```

### BBR (Bottleneck Bandwidth and RTT, 2016)

Google이 개발한 혁명적 알고리즘으로, 큐가 아닌 병목 대역폭과 RTT를 직접 측정합니다.

**패러다임 전환:**
```
기존 (손실/지연 기반):
  큐 빌드업 → 손실/지연 증가 → 대역폭 추정
  
BBR (모델 기반):
  대역폭(BtlBw) 직접 측정
  RTT(RTprop) 직접 측정
  → Sending_Rate = BtlBw
  → In_flight = BtlBw × RTprop
```

**동작 상태 머신:**
```
   [STARTUP] ← 지수 탐색
       ↓
   [DRAIN] ← 큐 배수
       ↓
   [PROBE_BW] ← 정상 동작 (대부분 시간)
       ↓  ↑
   [PROBE_RTT] ← 주기적 RTT 측정
       ↓
    (재순환)

Pacing Rate 패턴 (PROBE_BW):
  1.25x → 1.0x → 0.75x → 1.0x → 1.0x → ...
  (8 RTT 주기로 순환)
```

**버퍼 점유 비교:**
```
큐 깊이
 ^
 |████████████  CUBIC (큐를 채움)
 |
 |██            BBR (최소 큐)
 |_________________________> 시간

결과:
  CUBIC: 높은 처리량, 높은 지연
  BBR: 비슷한 처리량, 낮은 지연
```

**장점:**
- 낮은 지연 (큐 빌드업 최소화)
- 손실에 강건 (무선 환경에서 우수)
- 빠른 수렴

**단점:**
- 얕은 버퍼에서 공정성 문제
- 기존 TCP와의 공존 시 공격적

## 명시적 혼잡 통지 (ECN - Explicit Congestion Notification)

네트워크가 혼잡을 패킷 손실 없이 명시적으로 알리는 메커니즘입니다.

```
IP 헤더:
  ECN 필드 (2비트):
    00: Non-ECT (ECN 미지원)
    01, 10: ECT (ECN 지원)
    11: CE (Congestion Experienced)

TCP 헤더:
  ECE (ECN-Echo): 혼잡 수신 알림
  CWR (Congestion Window Reduced): 대응 완료

동작 흐름:
  1. 발신자: ECT 설정
  2. 라우터: 큐 > 임계값 → CE 표시
  3. 수신자: CE 감지 → ECE 플래그 설정
  4. 발신자: ECE 수신 → cwnd 감소, CWR 설정
```

```
발신자              라우터               수신자
  |                   |                    |
  |--[ECT=01]-------->|                    |
  |                   | (큐 차는 중)       |
  |                   |--[CE=11]---------->|
  |                   |                    |
  |<-----------------[ACK, ECE]------------|
  |                   |                    |
  | (cwnd 감소)       |                    |
  |--[CWR]----------->|                    |
  |                   |                    |

장점: 손실 없는 혼잡 제어!
```

## 능동 큐 관리 (AQM - Active Queue Management)

라우터가 능동적으로 큐를 관리하여 혼잡을 완화하는 기법입니다.

### RED (Random Early Detection, 1993)

```
큐 길이
  ^
  |            ___
  |          /     \___  (Drop Probability)
  |        /           \
  |      /              \
  |____/________________\________> 평균 큐 길이
      ↑                 ↑
   min_th            max_th

동작:
  avg_q < min_th: 드롭 없음
  min_th ≤ avg_q ≤ max_th: 확률적 드롭
  avg_q > max_th: 모든 패킷 드롭

목적: 큐가 가득 차기 전 조기 신호
```

### CoDel (Controlled Delay, 2012)

큐 길이가 아닌 대기 시간(sojourn time)을 기준으로 제어합니다.

```
if sojourn_time > target (5ms):
    interval 내에서 드롭 간격 줄임
    
드롭 간격 = interval / sqrt(count)
(interval = 100ms)

시간
|-----|-----|-----|-----|-----|
   o     o   o  oo ooo  (드롭 패킷)
   
점점 빠른 드롭으로 빠른 피드백
```

**버퍼블로트 해결:**
```
문제:
  큰 버퍼 → 높은 지연
  작은 버퍼 → 낮은 처리량

CoDel 해결:
  지연 기반 관리 → 버퍼 크기 무관
  적응적 드롭 → 효율과 지연의 균형
```

## 특수 환경의 문제들

### 버퍼블로트 (Bufferbloat)

과도하게 큰 버퍼로 인한 지연 증가 문제입니다.

```
시나리오: 1Gbps 링크, 1초 버퍼

정상 트래픽:
  ↓↓↓↓ (즉시 전송)
  RTT: 20ms

버퍼 가득:
  ↓↓↓↓↓↓↓↓↓↓↓↓↓↓ (큐에 대기)
  RTT: 1020ms (!!!)

게임/VoIP:
  응답 시간 >> 1초 (사용 불가)
```

### Incast 문제 (데이터센터)

다수의 서버가 동시에 응답하여 스위치 버퍼 오버플로우가 발생하는 문제입니다.

```
클라이언트
    ↑
    |← [S1][S2][S3]...[Sn]
    |    동시 응답
    |
  스위치 (작은 버퍼)
    |
  [███████] 버퍼 오버플로우!
    ↓
  다수 패킷 손실
    ↓
  심각한 타임아웃 (RTO_min = 200ms)

해결책:
  - DCTCP (Data Center TCP)
  - 낮은 RTO_min
  - ECN 필수 사용
```

### Long Fat Networks (LFN) 문제

고대역폭-고지연 네트워크에서의 비효율성 문제입니다.

```
BDP = 1Gbps × 100ms = 12.5MB

전통적 TCP:
  rwnd = 65KB (TCP 헤더 제한)
  처리량 = 65KB / 0.1s = 650KB/s
  (실제 용량의 0.5%만 사용!)

해결책:
  - Window Scaling (RFC 1323)
    rwnd 최대 1GB까지 확장
  - CUBIC/BBR 같은 현대 알고리즘
    빠른 증가로 BDP 채우기
```

## L4S (Low Latency, Low Loss, Scalable throughput)

차세대 인터넷 아키텍처로, 낮은 지연과 높은 처리량을 동시에 달성합니다.

```
기존 인터넷:
  Classic Queue          L4S Queue
  [████████]             [█]
  높은 지연              낮은 지연
  
  CUBIC/Reno  ------→   Classic
  BBR/DCTCP   ------→   L4S (ECN 필수)

핵심 기술:
  1. ECN 기반 혼잡 제어 (손실 대신)
  2. 스케일러블 혼잡 제어 (더 작은 감소)
  3. 듀얼 큐 AQM (격리)

혼잡 대응:
  Classic: cwnd = cwnd / 2 (50% 감소)
  L4S: cwnd = cwnd × (1 - α/2) (α는 작은 값)
      → 더 작은 진동, 더 낮은 큐
```

## QUIC의 혼잡 제어

QUIC(Quick UDP Internet Connections)는 TCP를 대체하기 위해 Google이 개발한 전송 프로토콜로, UDP 위에서 동작하며 개선된 혼잡 제어를 제공합니다.

**TCP와의 차이점:**
```
TCP:
  [연결 설정] → [TLS 핸드셰이크] → [데이터 전송]
  1.5 RTT                             패킷 손실 시 HOL 블로킹
  
QUIC:
  [연결 + TLS + 데이터] (0-RTT/1-RTT)
  스트림별 독립적 처리 (HOL 블로킹 없음)

Head-of-Line Blocking 비교:
TCP:
  스트림1: [1][2][X][4]
  스트림2: [A][B][C][D] ← 대기 중! (패킷3 재전송 대기)
  
QUIC:
  스트림1: [1][2][X][4] ← 재전송
  스트림2: [A][B][C][D] ← 계속 전달 (독립적)
```

**혼잡 제어 알고리즘:**
```
QUIC 기본 스택:
  1. NewReno (기본값)
  2. CUBIC (선택 가능)
  3. BBR (Google 서비스)
  4. BBRv2 (최신)

핵심 개선사항:
  - 스트림별 재전송
  - 더 정확한 RTT 측정
  - 패킷 번호 공간 분리
  - 플러거블 혼잡 제어
```

**패킷 번호 공간:**
```
TCP:
  시퀀스 번호: 바이트 단위
  재전송: 같은 번호 재사용
  → ACK 모호성 (Retransmission Ambiguity)
  
  원본 패킷[1000] → 손실
  재전송[1000] → ACK[1000] 도착
  질문: 어느 것에 대한 ACK? → RTT 측정 부정확

QUIC:
  패킷 번호: 순증가
  재전송: 새로운 번호
  
  원본 패킷[42] → 손실
  재전송[43] → ACK[43] 도착
  명확: 43번 패킷의 ACK → 정확한 RTT
```

## 혼잡 제어의 공정성 문제

### Jain's Fairness Index

여러 흐름이 대역폭을 얼마나 공정하게 나누는지 측정하는 지표입니다.

```
n개 흐름의 처리량: x₁, x₂, ..., xₙ

Fairness Index = (Σxᵢ)² / (n × Σxᵢ²)

범위: 1/n (최악) ~ 1 (완벽한 공정성)

예시 (100Mbps 링크, 3 흐름):
완벽한 공정성: [33, 33, 34]
  FI = (100)² / (3 × 3334) = 0.999

불공정: [80, 10, 10]
  FI = (100)² / (3 × 6600) = 0.505
```

### RTT Unfairness

```
시나리오: 1Gbps 링크 공유

연결1: RTT = 10ms  (CUBIC)
연결2: RTT = 100ms (CUBIC)

cwnd 증가 속도:
  연결1: 100 RTT/sec → 빠른 증가
  연결2: 10 RTT/sec → 느린 증가

결과:
  ┌─────────────┬──────┐
  │   연결1 90% │ 연2  │
  │   (짧은RTT)  │ 10%  │
  └─────────────┴──────┘

해결책:
  - CUBIC: RTT 독립적 증가
  - BBR: RTT 기반 pacing
```

### 알고리즘 간 공정성

```
같은 링크에서 경쟁:

CUBIC vs Reno:
  ████████ CUBIC (70%)
  ███ Reno (30%)
  (CUBIC이 더 공격적)

BBR vs CUBIC:
  ██████████ BBR (60-80%)
  ████ CUBIC (20-40%)
  (BBR이 큐를 채우지 않아 유리)

Vegas vs Reno:
  ██ Vegas (20%)
  ████████ Reno (80%)
  (Vegas가 지연 증가 시 양보)
```

## 실무적 고려사항

### 혼잡 제어 튜닝 파라미터

**Linux sysctl 설정:**
```bash
# 혼잡 제어 알고리즘 선택
net.ipv4.tcp_congestion_control = cubic

# 사용 가능한 알고리즘 확인
net.ipv4.tcp_available_congestion_control = reno cubic bbr

# 초기 cwnd (RFC 6928)
net.ipv4.tcp_init_cwnd = 10

# 최소 RTO
net.ipv4.tcp_min_rto = 200  # 밀리초

# ECN 활성화
net.ipv4.tcp_ecn = 1  # 0=비활성화, 1=요청, 2=강제
```

**BBR 설정 예시:**
```bash
# BBR 활성화
modprobe tcp_bbr
echo "tcp_bbr" >> /etc/modules-load.d/modules.conf
sysctl -w net.ipv4.tcp_congestion_control=bbr

# fq (Fair Queue) 스케줄러 필요
sysctl -w net.core.default_qdisc=fq

# 확인
sysctl net.ipv4.tcp_congestion_control
```

### 애플리케이션별 최적 알고리즘

```
┌────────────────┬─────────────┬──────────────┐
│ 애플리케이션   │ 추천 알고리즘│ 이유         │
├────────────────┼─────────────┼──────────────┤
│ 웹 서버        │ CUBIC/BBR   │ 높은 처리량  │
│ 동영상 스트리밍│ BBR         │ 낮은 지연    │
│ 게임 서버      │ BBR/BBRv2   │ 일정한 지연  │
│ 데이터센터     │ DCTCP       │ ECN 기반     │
│ 위성 통신      │ CUBIC       │ 고BDP 대응   │
│ 모바일         │ Westwood+   │ 무선 손실    │
│ VoIP           │ BBR         │ 낮은큐지연   │
└────────────────┴─────────────┴──────────────┘
```

### 모니터링과 디버깅

**ss 명령어로 혼잡 상태 확인:**
```bash
ss -ti

출력 예시:
ESTAB  0  0  192.168.1.1:22  10.0.0.1:54321
  cubic wscale:7,7 rto:204 rtt:3.8/2.4 ato:40
  cwnd:10 ssthresh:7 bytes_acked:1234
  bytes_received:5678 segs_sent:42 segs_received:38
  send 25.3Mbps lastsnd:1200 lastrcv:1200
  
핵심 지표:
  cwnd: 현재 혼잡 윈도우
  ssthresh: 슬로우 스타트 임계값
  rtt: 왕복 시간
  rto: 재전송 타임아웃
```

**tcpdump로 혼잡 이벤트 관찰:**
```bash
tcpdump -i eth0 'tcp[tcpflags] & (tcp-syn|tcp-fin) != 0'

# 중복 ACK 감지
tcpdump -i eth0 'tcp[13] = 16' -n

# ECN 비트 확인
tcpdump -i eth0 'ip[1] & 3 != 0' -v
```

## 미래의 발전 방향

### Programmable Congestion Control

```
전통적 접근:
  [커널 고정 알고리즘]
  → 변경 어려움
  → 실험 느림

새로운 접근:
  [eBPF 기반 프로그래밍]
  → 사용자 공간에서 정의
  → 빠른 반복 실험
  
예시 (eBPF pseudo-code):
  on_ack_received():
    cwnd = custom_increase(cwnd, rtt)
    update_metrics()
```

### 머신러닝 기반 혼잡 제어

```
전통적 알고리즘:
  손실/지연 → [고정 규칙] → cwnd 조절

ML 기반:
  [네트워크 상태] → [신경망] → [최적 cwnd]
       ↓                           ↓
    피드백                      성능 측정
       ↑                           ↓
       └──────── [학습] ←──────────┘

PCC (Performance-oriented Congestion Control):
  목표 유틸리티 함수 최대화
  온라인 학습으로 동작 조정
  
Remy:
  오프라인 학습 (시뮬레이션)
  특정 네트워크 환경 최적화
```

### Multipath TCP (MPTCP) 혼잡 제어

여러 경로를 동시에 사용하는 TCP의 혼잡 제어입니다.

```
단일 경로:
  [클라이언트] ─────────────→ [서버]
       WiFi (100Mbps)

다중 경로:
  [클라이언트] ─WiFi (100Mbps)──→ [서버]
       └───────5G (50Mbps)────→

목표:
  1. 총 처리량 향상
  2. 각 경로의 혼잡 고려
  3. 단일경로 흐름보다 불리하지 않음 (no worse)

Coupled Congestion Control:
  경로1 혼잡 → 경로2로 트래픽 이동
  
  cwndᵢ 증가:
    +min(α/cwnd_total, 1/cwndᵢ) per ACK
  
  cwndᵢ 감소:
    cwndᵢ/2 per loss
    
  α = cwnd_total × min(cwndᵢ/rttᵢ²) / (Σ(cwndⱼ/rttⱼ))²
```

## 알고리즘 선택 가이드

### 의사결정 트리

```
                [시작]
                  |
         네트워크 환경은?
        /        |        \
    유선      무선/위성    데이터센터
      |          |            |
   지연중요?   손실패턴?    ECN지원?
   /    \     /      \      /      \
  Y      N   Random  혼잡   Y       N
  |      |     |       |    |       |
 BBR   CUBIC West+  CUBIC DCTCP  CUBIC
              
고려사항:
  - RTT: >100ms → CUBIC
  - 손실률: >1% → Westwood+
  - 버퍼: 큼 → BBR, 작음 → DCTCP
  - 공정성: 중요 → CUBIC, 덜중요 → BBR
```

### 성능 비교 매트릭스

```
┌────────┬──────┬──────┬──────┬──────┬──────┐
│        │ Reno │CUBIC │Vegas │ BBR  │DCTCP │
├────────┼──────┼──────┼──────┼──────┼──────┤
│처리량  │  ★★  │ ★★★★ │ ★★★  │ ★★★★ │★★★★★│
│지연    │  ★★  │  ★★  │ ★★★★ │★★★★★│★★★★★│
│공정성  │ ★★★★ │ ★★★  │  ★   │  ★★  │ ★★★★ │
│복잡도  │  ★   │  ★★  │  ★★  │ ★★★★ │  ★★★ │
│안정성  │★★★★★│ ★★★★ │ ★★★  │  ★★★ │ ★★★  │
└────────┴──────┴──────┴──────┴──────┴──────┘

적용 환경:
Reno:   기본/호환성
CUBIC:  범용 고성능
Vegas:  낮은지연 필요
BBR:    스트리밍/VoIP
DCTCP:  데이터센터 전용
```

## 핵심 개념 요약

### 혼잡 제어의 기본 원칙

```
1. 보수적 시작 (Slow Start)
   [1] → [2] → [4] → [8] → ...
   
2. 탐색적 증가 (AIMD)
   +1, +1, +1, ..., /2, +1, +1, ...
   
3. 빠른 대응 (Fast Recovery)
   3 DupACKs → 즉시 재전송
   
4. 적응적 학습
   네트워크 상태 → 파라미터 조정
```

### 손실 vs 지연 기반 비교

```
                손실 기반         지연 기반
               (Reno/CUBIC)      (Vegas/BBR)
                    |                |
큐 상태:        [████████]           [██]
지연:            높음                낮음
처리량:          최대                효율적
적응속도:        느림                빠름
공정성:          좋음                보통
복잡도:          낮음                높음

하이브리드 접근 (Compound, BBRv2):
  평상시: 지연 기반
  혼잡 시: 손실 기반
  → 장점 결합
```

### 진화의 역사

```
1988 ─┬─ Tahoe ──────────────────────┐
      │   (Slow Start, CA)            │
      │                               │
1990 ─┼─ Reno ────────────────────────┤ 손실 기반
      │   (Fast Retransmit/Recovery)  │ 시대
      │                               │
1994 ─┼─ Vegas ───────────────────────┤
      │   (Delay-based)               │
      │                               │
1999 ─┴─ NewReno, SACK ───────────────┘

2004 ─┬─ BIC ─────────────────────────┐
      │   (High-speed)                │
      │                               │
2008 ─┼─ CUBIC ───────────────────────┤ 고속
      │   (Linux default)             │ 네트워크
      │                               │ 시대
2010 ─┼─ Compound ────────────────────┤
      │   (Windows default)           │
      │                               │
2012 ─┴─ CoDel (AQM) ─────────────────┘

2016 ─┬─ BBR ─────────────────────────┐
      │   (Model-based)               │ 모델/ML
2018 ─┼─ BBRv2 ───────────────────────┤ 기반
      │                               │ 시대
2020 ─┼─ L4S ─────────────────────────┤
      │                               │
2023 ─┴─ ML-based CC ─────────────────┘
```

## 결론

TCP 혼잡 제어는 인터넷의 견고성과 효율성의 핵심 기둥입니다. 1980년대 후반 Tahoe에서 시작하여, Reno의 빠른 재전송/회복, CUBIC의 고속 네트워크 지원, 그리고 BBR의 모델 기반 접근에 이르기까지 지속적으로 진화해왔습니다.

**핵심 패러다임의 변화:**
```
[1세대] 손실 = 혼잡
   Tahoe, Reno, NewReno
   → 패킷 손실 후 대응

[2세대] 지연도 혼잡 신호
   Vegas, Compound
   → 사전 예방

[3세대] 고속 네트워크
   BIC, CUBIC
   → 빠른 대역폭 탐색

[4세대] 모델 기반
   BBR, BBRv2
   → 네트워크 상태 모델링

[미래] 지능형 제어
   ML-based, Programmable
   → 환경별 최적화
```

그 본질은 **패킷 손실과 지연을 혼잡의 신호로 간주하고, 이를 통해 네트워크의 용량을 탐색하며, 공격적으로 증가시키다가 혼잡이 감지되면 신속히 후퇴하는** 적응형 피드백 제어 시스템에 있습니다. 

현대의 혼잡 제어는 단순히 손실에 반응하는 것을 넘어, 네트워크의 병목 대역폭과 지연을 능동적으로 측정하고 모델링하여, 낮은 지연과 높은 처리량을 동시에 달성하는 방향으로 발전하고 있습니다. ECN, AQM, L4S 같은 네트워크 계층의 지원이 결합되면서, 종단 간 혼잡 제어는 더욱 정교하고 효율적으로 진화하고 있습니다.

이 지속적인 진화는 데이터 양의 폭발적 증가, 다양한 네트워크 환경(유선, 무선, 위성, 데이터센터), 그리고 새로운 애플리케이션 요구사항(초저지연, 초고속)에 맞춰 종단 간 전송 효율과 네트워크 전체의 공정성 및 안정성을 동시에 보장하기 위한 지속적인 노력의 결과물입니다.