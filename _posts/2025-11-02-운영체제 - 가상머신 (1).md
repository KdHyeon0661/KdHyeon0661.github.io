---
layout: post
title: 운영체제 - 가상머신 (1)
date: 2025-11-02 18:25:23 +0900
category: 운영체제
---
# Chapter 18 — Virtual Machines

## Overview

### 가상머신(VM)이란?

**Virtual Machine(가상머신)** 은 **하드웨어 인터페이스(ISA, 장치, 인터럽트, 메모리)** 를 **소프트웨어(하이퍼바이저/VMM)** 로 **에뮬레이션 또는 가상화**하여, 하나의 물리 서버 위에 **여러 독립 OS(게스트)** 를 동시 실행하게 하는 기술이다.

- **System VM**: 전체 OS 실행(예: KVM/QEMU, Xen, Hyper-V, ESXi).
- **Process VM**: 프로세스 단위 ABI/바이트코드 실행(예: JVM, .NET CLR; 이 장의 초점은 System VM).

**용어**
- **VMM/Hypervisor**: 가상화 관리자(Trap-and-Emulate, Binary Translation, Para-virt).
- **Host / Guest**: 호스트 OS(또는 베어메탈) 위에 게스트 OS.
- **vCPU, vNIC, vDisk**: 가상 자원.
- **Type-1**(베어메탈) vs **Type-2**(호스트 OS 위 프로세스로 동작).

```
[HW]──[Hypervisor(Type-1)]──[Guest OS #1,#2,...]
[HW]──[Host OS]──[VMM(Type-2)]──[Guest OS ...]
```

### 가상화의 기본 이론 (Popek & Goldberg)

고전적 기준에 따르면, **모든 민감(sensitive) 명령은 특권(privileged) 명령의 부분집합**이어야 trap으로 포착하여 에뮬레이션 가능하다.

- **민감 명령**: 상태/자원에 영향을 주거나 관찰 가능한 것(CRx 접근 등).
- **특권 명령**: 비특권 모드에서 실행 시 **trap** 발생.

현대 x86은 역사적으로 이 기준을 완벽히 만족하지 않아(특정 명령의 **silent fail**) 초기에 **Binary Translation(BT)** 기법이 필요했으나, 이후 **VT-x/AMD-V** 로 해결.

> 수식 표기(개념):
> $$\text{Sensitive} \subseteq \text{Privileged} \Rightarrow \text{Trap\&Emulate로 완전 가상화 가능}$$

### CPU 가상화

- **Trap & Emulate**: 비특권 모드에서 특권 명령 → **trap** → VMM이 에뮬레이트.
- **Binary Translation(BT)**: 게스트 커널 코드의 민감 부분을 **동적 변환**하여 안전한 시퀀스로 대체(초기 VMware).
- **Para-virtualization**: 게스트가 **hypercall** 사용(Xen PV).
- **HW Assist**: **VT-x/AMD-V** 가 **게스트 Ring-0** 을 **VMX Non-Root** 로 실행, **VM Exit/Entry** 메커니즘 제공.

### 메모리 가상화

- **Shadow Page Tables(SPT)**: 게스트의 가상→물리 매핑을 **호스트 물리**로 치환한 그림자 테이블 유지(오버헤드↑).
- **EPT/NPT(Second Level Address Translation)**: 하드웨어가 **게스트 물리→호스트 물리** 변환을 추가 단계로 지원(성능↑).
- **Ballooning/KSM/HugePages**: 메모리 과할당/페이지 중복제거/거대페이지로 효율 개선.

> 주소 변환(개념):
> $$\text{VA}_{guest}\xrightarrow{\text{guest PT}}\text{PA}_{guest}\xrightarrow{\text{EPT/NPT}}\text{PA}_{host}$$

### I/O 가상화

- **Device Emulation**: e1000, AHCI 등 **구형 디바이스 모형**을 소프트웨어로 구현(호환성↑/성능↓).
- **Para-virt Driver(virtio)**: 디바이스 프런트엔드/백엔드 통신으로 고성능.
- **SR-IOV**: 물리 NIC에서 **가상 함수(VF)** 를 게스트에 직접 할당(우회 경로, 성능↑).
- **VFIO/IOMMU**: 장치 직할(Passthrough) 시 **DMA 격리** 보장.

### 네트워크/스토리지 가상화

- 네트워크: **TAP/TUN + 브리지/OVS**, NAT, VXLAN, SR-IOV VF.
- 스토리지: **이미지 포맷(raw, qcow2)**, Thin-Provision, **스냅샷/백킹 파일**.

### 간단 예제 — QEMU/KVM으로 초미니 VM 만들기

> 아래 코드는 **개념 흐름**을 보여주는 *축약* 예시다. 실제 빌드/권한/커널 구성에 따라 조정 필요.

```bash
# 빈 디스크 만들고, 부트 가능한 미니 ISO로 부팅

qemu-img create -f qcow2 vm.qcow2 4G
qemu-system-x86_64 \
  -enable-kvm -m 1024 -smp 2 \
  -drive if=virtio,file=vm.qcow2,format=qcow2 \
  -cdrom tiny.iso -boot d \
  -device virtio-net-pci,netdev=n0 \
  -netdev user,id=n0,hostfwd=tcp::2222-:22
# 설치 후 ISO 제거하여 디스크로 부팅

```

**핵심 포인트**
- `-enable-kvm`: HW 보조 가상화 사용.
- `virtio-*`: 파라가상 드라이버로 I/O 성능 확보.
- `hostfwd`: 호스트 2222 → 게스트 22 포트 포워딩.

### /dev/kvm 사용자 공간에서 VCPU 실행 최소 예(개념)

KVM은 커널 모듈이 **VMM의 민감 부분**(VM Exit/Entry)을 제공, 사용자 공간(QEMU 등)은 디바이스 모델/이미지 관리 담당.

```c
// kvm_min.c — 매우 축약된 흐름(실습용 참고, 예외처리/레지스터 설정 생략)
// gcc -O2 -Wall kvm_min.c -o kvm_min
#include <fcntl.h>
#include <linux/kvm.h>
#include <sys/ioctl.h>
#include <sys/mman.h>
#include <string.h>
#include <unistd.h>
#include <stdio.h>

int main(){
  int kvm = open("/dev/kvm", O_RDWR);
  int api = ioctl(kvm, KVM_GET_API_VERSION, 0); // 보통 12
  int vm  = ioctl(kvm, KVM_CREATE_VM, 0);

  // 게스트 RAM 1MB
  size_t memsz=0x100000;
  void* mem = mmap(0, memsz, PROT_READ|PROT_WRITE, MAP_SHARED|MAP_ANON, -1, 0);
  struct kvm_userspace_memory_region r = {
    .slot=0, .guest_phys_addr=0x0, .memory_size=memsz, .userspace_addr=(__u64)mem
  };
  ioctl(vm, KVM_SET_USER_MEMORY_REGION, &r);

  // VCPU 생성 및 실행 루프
  int vcpu = ioctl(vm, KVM_CREATE_VCPU, 0);
  size_t mmap_sz = ioctl(kvm, KVM_GET_VCPU_MMAP_SIZE, 0);
  struct kvm_run* run = mmap(NULL, mmap_sz, PROT_READ|PROT_WRITE, MAP_SHARED, vcpu, 0);

  // (여기서 게스트 코드/레지스터 초기화 설정 필요: RIP/RSP/CS 등)
  // ioctl(vcpu, KVM_RUN, 0) 호출 시 VM Entry, 종료 시 VM Exit 이유 run->exit_reason 확인
  for(;;){
    ioctl(vcpu, KVM_RUN, 0);
    if(run->exit_reason == KVM_EXIT_HLT){ puts("HLT"); break; }
    if(run->exit_reason == KVM_EXIT_IO){ /* 포트 I/O 처리 */ }
    // 기타 EXIT_REASON에 맞춰 에뮬레이션
  }
  return 0;
}
```

> 이 코드는 “**사용자 공간이 하이퍼바이저의 일부 역할**을 맡는다”는 감을 주기 위한 초미니 스케치다. 실제 부팅 코드는 세그먼트/페이지/BIOS/EFI 초기화가 필요하다.

---

## History

### 메인프레임의 시작

- **1960s–1970s**: IBM **CP-40/CP-67** → **VM/370**. 하나의 거대한 메인프레임을 **여러 대의 가상 메인프레임**으로 분할, 연구/멀티테넌시/테스트에 활용. **완전 가상화** 개념 정립.

### x86 시대의 도전과 해법

- **1990s 후반**: x86은 가상화 친화적 설계가 아니어서 **Binary Translation**(VMware)이 실용 해법.
- **2005~**: **Intel VT-x / AMD-V** 로 하드웨어 지원 본격화 → **Trap/Emulate + VMCS/VMCB** 프레임.
- **2007~**: **KVM** 이 리눅스 커널에 병합(하이퍼바이저 기능을 커널에 포함) + QEMU 사용자 공간 에뮬.
- 동시대: **Xen**(Para-virt → HVM), **Hyper-V**, **ESXi** 등 상용/오픈 진영 분화.

### 클라우드/DevOps/경량화

- **IaaS** 에서 VM이 표준 인프라 단위로 자리잡고, **라이브 마이그레이션**/스냅샷/템플릿 등 운영 기능 성숙.
- **경량 가상화**: 마이크로VM(예: 네트워크/NVMe만 최소화한 디바이스 모델), **unikernel**(단일 목적 OS) 등으로 **부팅 수 ms~s** 구간까지 최적화.

---

## Benefits and Features

### 왜 VM을 쓰는가 — 이점

1) **격리(Isolation)**: 커널/메모리/디바이스를 게스트별로 격리 → 실패/침해 **폭을 줄임**.
2) **통합(Consolidation)**: 여러 워크로드를 하나의 물리 서버에 → **자원 효율**/TCO 절감.
3) **휴대성(Portability)**: 이미지 단위로 이동/복제/백업/배포.
4) **Dev/Test 속도**: 스냅샷/클론/템플릿로 **재현성 보장**.
5) **가용성/유연성**: 라이브 마이그레이션, 호스트 유지보수 무중단.
6) **보안**: 하드 멀티테넌시(강한 경계), VBS/SR-IOV/IOMMU로 위험 축소.
7) **성능 예측성**: vCPU 핀닝/NUMA 인식/HugePages로 **SLA 정밀화**.

> 간단 계산: **수용률(Host Consolidation Ratio)**
> $$\text{CR} \approx \min\!\left(\frac{\text{Host CPU Cap}}{\sum \text{VM CPU Cap}},\, \frac{\text{Host Mem}}{\sum \text{VM Mem}},\, \frac{\text{I/O BW}}{\sum \text{VM I/O}}\right)$$
> 병목 자원 기준으로 결정되며, **과할당 정책**(CPU time-sharing, 메모리 balloon/KSM)으로 체감 CR을 높일 수 있다.

### 핵심 기능 목록

- **스냅샷 & 클론**: 특정 시점으로 되돌리기/복제.
- **라이브 마이그레이션**: 실행 중인 VM을 다른 호스트로 **무중단** 이관(프리-카피/포스트-카피).
- **오버커밋**: vCPU time-slice, 메모리 ballooning/KSM.
- **NUMA 인식**: vCPU/vMem을 **노드 친화** 배치.
- **I/O 최적화**: virtio, vhost-net, SR-IOV, NVMe-virtio.
- **보안/경계 강화**: IOMMU, Secure Boot, 가상 TPM(vTPM).

---

### 스냅샷/백킹 파일 실습

```bash
# 베이스 이미지

qemu-img create -f qcow2 base.qcow2 8G
# OS 설치 후 base.qcow2를 템플릿으로 보존

# 백킹 파일(얇은 클론)

qemu-img create -f qcow2 -b base.qcow2 vm1.qcow2
qemu-img info vm1.qcow2

# 외부 스냅샷

qemu-img create -f qcow2 -b vm1.qcow2 snap1.qcow2
# 필요 시 qemu-img commit/rebase 로 병합/재지정 가능

```

**개념**
- **backing chain**: `snap1 → vm1 → base` 방식으로 **쓰기 분기**가 상단에 쌓인다.
- **주의**: 백킹 파일 삭제/이동 시 체인 재베이스 필요.

---

### 알고리즘 스케치

```python
# pre_copy.py — 메모리 페이지 더티 추적 기반의 개념 스케치

def pre_copy(vm):
    # 1) 1차 전체 전송
    send_all_pages(vm)
    while True:
        dirties = vm.dirty_pages_since_last_round()
        if len(dirties) < THRESHOLD:
            break
        send_pages(dirties)  # 2) 더티 페이지만 반복 전송
    # 3) 짧은 정지(stop-and-copy)
    vm.pause()
    send_pages(vm.dirty_pages_since_last_round())
    switch_dst_as_primary()
    vm.resume_at_dst()
```

- **장점**: 다운타임 최소화(수 ms~s).
- **과제**: write-intensive 워크로드는 **컨버전스 지연** → **rate-limit/dirty-ring/포스트-카피** 고려.

---

### 리소스 과할당(오버커밋)과 Ballooning

```bash
# 게스트에 virtio-balloon 장치를 추가(QEMU)

qemu-system-x86_64 ... -device virtio-balloon-pci
```

게스트의 balloon 드라이버가 **페이지를 풍선으로 흡수**하여 VMM에 반환 → 호스트가 다른 VM에 재할당.
- **KSM(Merge)**: 동일 내용의 페이지를 **공유**(호스트 메모리 절감).
- **HugePages**: TLB 미스 감소, 오버헤드↓(단, 이동성/스냅샷 고려).

---

### Libvirt를 이용해 VM 정의/시작(파이썬 예)

```python
# libvirt_define.py — 간단한 도메인 XML로 VM 생성/시작
# pip install libvirt-python (호스트 환경에 libvirtd/권한 필요)

import libvirt

conn = libvirt.open('qemu:///system')
xml = """
<domain type='kvm'>
  <name>vm-demo</name>
  <memory unit='MiB'>1024</memory>
  <vcpu>2</vcpu>
  <os>
    <type arch='x86_64' machine='pc-q35-8.2'>hvm</type>
    <boot dev='hd'/>
  </os>
  <devices>
    <disk type='file' device='disk'>
      <driver name='qemu' type='qcow2'/>
      <source file='/var/lib/libvirt/images/vm.qcow2'/>
      <target dev='vda' bus='virtio'/>
    </disk>
    <interface type='network'>
      <source network='default'/>
      <model type='virtio'/>
    </interface>
    <graphics type='vnc' port='-1'/>
  </devices>
</domain>
"""
dom = conn.defineXML(xml)
dom.create()   # start
print("started:", dom.name())
```

---

### vCPU 핀닝/NUMA 배치(성능 튜닝)

```bash
# vCPU 핀닝(virsh)

virsh vcpupin vm-demo 0 2    # vCPU0 → pCPU #2
virsh vcpupin vm-demo 1 3    # vCPU1 → pCPU #3
virsh numatune vm-demo --mode strict --nodeset 0  # 메모리 NUMA 노드 고정
```

- **장점**: 캐시 로컬리티/간섭 최소화, 지터↓.
- **주의**: 과도한 고정은 호스트 스케줄러 유연성↓.

---

### SR-IOV / 디바이스 패스스루

- **SR-IOV**: PF(물리함수)가 다수 **VF(가상함수)** 제공 → VF를 게스트에 직할.
- **VFIO + IOMMU**: DMA를 **IOMMU 도메인**에 가둬 **격리**.

```bash
# VF 바인딩 예(개념): echo <vf-pci-id> > /sys/bus/pci/drivers/vfio-pci/bind
# libvirt XML에서 <hostdev> 로 VF를 guest에 패스스루

```

---

### 클라우드-초기화(cloud-init)로 VM 부팅 시 사용자 설정

```yaml
# — 최초 부팅에서 계정/키/패키지 구성
#cloud-config

users:
  - name: dev
    ssh_authorized_keys:
      - ssh-ed25519 AAAA... dev@laptop
packages: [git, htop]
runcmd:
  - [ sh, -c, "echo 'hello from cloud-init' > /etc/motd" ]
```

- **템플릿 + user-data** 로 **대량 자동화** 배포.

---

### VM vs 컨테이너 (간단 비교)

| 항목 | VM | 컨테이너 |
|---|---|---|
| 격리 경계 | **하드웨어/하이퍼바이저** | **커널 공유**(네임스페이스/cgroup) |
| 부팅 | 느림(수 s~)→마이크로VM은 s~ms | 빠름(ms~s) |
| 이식성 | 이미지/디스크 | 이미지/레이어 |
| 커널 버전 | 게스트마다 독립 | 호스트 커널 공유 |
| 보안 | 경계 강함 | 경계 경량(추가 하드닝 필요) |

> 둘은 경쟁이 아닌 **상호 보완**: 컨테이너를 **VM 위**에 올려 멀티테넌시 경계를 이중화하는 구성이 일반적(IaaS+K8s).

---

## 운영 체크리스트

- **보안**: Secure Boot/TPM/vTPM, IOMMU on, virtio 최신, 마이그레이션 채널 암호화.
- **성능**: virtio/vhost-net, HugePages, NUMA 핀닝, CPU 모델 호환성.
- **스토리지**: qcow2는 간편·스냅샷, 성능은 raw+LVM/NVMe 직할 고려.
- **네트워크**: OVS/DPDK/SR-IOV로 레이턴시/대역폭 최적화.
- **가용성**: 마이그레이션 실패 시 롤백 계획, 스토리지 일관성(공유/복제) 확인.
- **관측성**: VM Exit 지표, CPU Ready, Balloon, Dirty rate, IO 큐, NUMA miss.

---

## 요약

- **Overview**: VM은 **하드웨어 인터페이스 전체**를 가상화하여 **여러 OS** 를 한 물리 머신에 수용. CPU/메모리/I/O 가상화는 Trap&Emulate, HW assist(EPT/NPT), virtio/SR-IOV 등을 조합.
- **History**: 메인프레임 → x86 BT → VT-x/AMD-V → KVM/Xen/Hyper-V/ESXi → 클라우드/마이크로VM.
- **Benefits/Features**: 격리·통합·휴대성·재현성·가용성. 스냅샷/클론/마이그레이션/오버커밋/NUMA/핀닝/SR-IOV 등 **운영 무기**를 상황에 맞게 선택하라.
