---
layout: post
title: 딥러닝 - 모니터링
date: 2025-10-12 15:25:23 +0900
category: 딥러닝
---
# 모니터링(드리프트·지표·알람)

> 목표  
> - **무엇을** 모니터링할지(서비스 SLO, 모델 품질, 데이터/개념 드리프트, 데이터 품질) **체계화**합니다.  
> - **드리프트 검정(PSI/KL/JS/KS/EMD/MMD/코사인)** 을 **PyTorch만**으로 구현합니다(외부 프레임워크 불사용).  
> - **온라인 지표 집계(평균/분산/히스토그램/지연시간 p95)**, **슬라이딩 윈도우**, **알람 정책**(임계·연속 위반·완화) 코드를 제공합니다.  
> - **배치·실시간 서빙** 코드에 삽입하는 **경량 모듈**로 예시를 보입니다(이전 장의 서버/배치 예제에 쉽게 삽입 가능).

---

## 0. 무엇을 모니터링할까? (관측 항목 맵)

1) **서비스 SLO**
   - 레이턴시 p50/p95/p99, 타임아웃율, 4xx/5xx 비율, QPS, 큐 길이, GPU/CPU 메모리·사용률
2) **모델 품질**
   - `val/*`/`prod/*` 정확도, AUROC/F1, 캘리브레이션(예: Brier), 예측 불확실성 통계(엔트로피/최상위 확률)
3) **데이터 품질(DQ)**
   - 결측률, 범위/형식 위반, 이상치 비율(IQR·Z-score), 카테고리 유효성
4) **드리프트 (Data/Label/Concept)**
   - **Feature Drift**: 분포 변화(PSI, KL/JS, KS, EMD)  
   - **Prediction Drift**: 클래스 비율/확률 분포 변화  
   - **Embedding Drift**: 임베딩 **센트로이드·분산**, **MMD**, **코사인 분포**  
   - **Concept Drift**: 입력-라벨 관계 변화(성능 하락, CUSUM 등)

> **원칙**:  
> - **학습 데이터/기준 기간**에서 **기준(Baseline) 통계**를 생성·고정하고, 운영 중 **윈도우 통계**와 비교합니다.  
> - **모든 지표에 모델/데이터 버전 메타**를 붙입니다(`model_id`, `data_hash`, `git_commit`).

---

## 1. PyTorch 유틸: 온라인 통계/히스토그램/슬라이딩 윈도우

아래 모듈은 **학습/서빙 어디서든 임포트**해 사용할 수 있는 경량 라이브러리입니다.

```python
# monitor_core.py (PyTorch only)
import torch, time, math
from collections import deque
from typing import Dict, Optional, Tuple

def to_t(x, dtype=torch.float32, device="cpu"):
    if isinstance(x, torch.Tensor): return x.to(device=device, dtype=dtype)
    return torch.tensor(x, dtype=dtype, device=device)

class OnlineMeanVar:
    """Welford 알고리즘(단일/배치 업데이트 지원)"""
    def __init__(self, device="cpu", dtype=torch.float64):
        self.n = torch.tensor(0.0, device=device, dtype=dtype)
        self.mean = torch.tensor(0.0, device=device, dtype=dtype)
        self.M2 = torch.tensor(0.0, device=device, dtype=dtype)

    @torch.no_grad()
    def update(self, x: torch.Tensor):
        x = x.detach()
        if x.ndim == 0: x = x[None]
        for v in x.view(-1):
            self.n += 1
            delta = v - self.mean
            self.mean += delta / self.n
            delta2 = v - self.mean
            self.M2 += delta * delta2

    @property
    def count(self): return int(self.n.item())

    @property
    def var(self):
        return (self.M2 / (self.n - 1.0)) if self.n.item() > 1 else torch.nan

    @property
    def std(self):
        v = self.var
        return torch.sqrt(v) if torch.isfinite(v) else torch.nan

class SlidingWindow:
    """고정 길이 슬라이딩 윈도우(합/평균/백분위 계산용)"""
    def __init__(self, size: int):
        self.size = size
        self.buf = deque(maxlen=size)

    def push(self, x):
        if isinstance(x, (list, tuple)):
            for v in x: self.buf.append(float(v))
        else:
            self.buf.append(float(x))

    def values(self):
        return torch.tensor(list(self.buf), dtype=torch.float64)

    def quantile(self, q: float):
        v = self.values()
        if v.numel() == 0: return float("nan")
        k = max(0, min(v.numel()-1, int(q * (v.numel()-1))))
        return float(v.kthvalue(k+1).values)  # kthvalue는 1-index 느낌

class Histogram1D:
    """고정 구간 히스토그램: count/smoothed prob, KL/JS/PSI 계산 용"""
    def __init__(self, bins: torch.Tensor):  # shape [B+1] (엣지)
        assert bins.ndim == 1 and bins.numel() >= 2
        self.edges = bins
        self.B = bins.numel()-1
        self.counts = torch.zeros(self.B, dtype=torch.float64)

    @torch.no_grad()
    def update(self, x: torch.Tensor):
        x = x.detach().view(-1)
        # torch.bucketize: 엣지 기준 버킷 인덱스
        idx = torch.bucketize(x, self.edges, right=False) - 1
        idx = torch.clamp(idx, 0, self.B-1)
        hist = torch.bincount(idx, minlength=self.B).to(self.counts.dtype)
        self.counts += hist

    def probs(self, eps=1e-12):
        s = self.counts.sum()
        if s <= 0: return torch.full_like(self.counts, 1.0/self.B)
        p = self.counts / s
        return torch.clamp(p, eps, 1.0)

    # --- 분포 거리 ---
    def kl(self, other:'Histogram1D', eps=1e-12):
        p = self.probs(eps); q = other.probs(eps)
        return torch.sum(p * torch.log(p/q)).item()

    def js(self, other:'Histogram1D', eps=1e-12):
        p = self.probs(eps); q = other.probs(eps); m = 0.5*(p+q)
        return 0.5*(torch.sum(p*torch.log(p/m))+torch.sum(q*torch.log(q/m))).item()

    def psi(self, other:'Histogram1D', eps=1e-6):
        """Population Stability Index (바이닝 기반)"""
        p = self.probs(eps); q = other.probs(eps)
        return torch.sum((p - q) * torch.log(p / q)).item()

# --- 비히스토그램 기반 1D 거리/검정 ---

@torch.no_grad()
def ks_statistic(x: torch.Tensor, y: torch.Tensor) -> float:
    """1D Kolmogorov–Smirnov 통계: sup|F_x - F_y|"""
    x = x.view(-1).sort().values
    y = y.view(-1).sort().values
    i = j = 0
    nx, ny = x.numel(), y.numel()
    cdf_x = cdf_y = 0.0
    d = 0.0
    while i < nx and j < ny:
        if x[i] <= y[j]:
            i += 1; cdf_x = i/nx
        else:
            j += 1; cdf_y = j/ny
        d = max(d, abs(cdf_x - cdf_y))
    return float(d)

@torch.no_grad()
def wasserstein_1d(x: torch.Tensor, y: torch.Tensor) -> float:
    """EMD(W1): 1D에선 정렬 후 평균 절대차의 적분과 동일"""
    x = x.view(-1).sort().values
    y = y.view(-1).sort().values
    n = min(x.numel(), y.numel())
    if n == 0: return float("nan")
    x = x[:n]; y = y[:n]
    return float(torch.mean(torch.abs(x - y)))

@torch.no_grad()
def mmd_rbf(X: torch.Tensor, Y: torch.Tensor, sigma: float = 1.0, max_samples: int = 2048) -> float:
    """MMD^2 with RBF kernel (임베딩용). 메모리 절약 위해 샘플링."""
    def _rbf(a,b):
        # ||a-b||^2 = a^2 + b^2 - 2ab
        a2 = (a*a).sum(dim=1, keepdim=True)
        b2 = (b*b).sum(dim=1, keepdim=True)
        dist2 = a2 + b2.T - 2*a@b.T
        k = torch.exp(-dist2 / (2*sigma*sigma))
        return k
    nX = min(X.size(0), max_samples); nY = min(Y.size(0), max_samples)
    Xs = X[torch.randperm(X.size(0))[:nX]]
    Ys = Y[torch.randperm(Y.size(0))[:nY]]
    Kxx = _rbf(Xs, Xs); Kyy = _rbf(Ys, Ys); Kxy = _rbf(Xs, Ys)
    # 비편향 추정
    m = Kxx.size(0); n = Kyy.size(0)
    mmd2 = (Kxx.sum()-Kxx.diag().sum())/(m*(m-1)) \
         + (Kyy.sum()-Kyy.diag().sum())/(n*(n-1)) \
         - 2*Kxy.mean()
    return float(mmd2)

# --- 알람 엔진 ---

class Alarm:
    def __init__(self, name:str, threshold:float, direction:str=">=", min_samples:int=50, consecutive:int=3, cooldown_sec:int=300):
        self.name=name; self.th=threshold; self.dir=direction
        self.min_samples=min_samples; self.need=consecutive; self.cool=cooldown_sec
        self._viol=0; self._last_fired=0.0

    def _cmp(self, v:float)->bool:
        return (v>=self.th) if self.dir==">=" else (v<=self.th)

    def check(self, value:float, sample_count:int)->Optional[Dict]:
        now=time.time()
        if sample_count < self.min_samples: 
            self._viol=0; return None
        if self._cmp(value):
            self._viol+=1
            if self._viol>=self.need and now - self._last_fired > self.cool:
                self._last_fired=now; self._viol=0
                return {"alarm":self.name,"value":value,"threshold":self.th,"when":int(now)}
        else:
            self._viol=0
        return None

class AlarmManager:
    def __init__(self): self.rules=[]
    def add(self, alarm:Alarm): self.rules.append(alarm)
    def run(self, metrics:Dict[str,Tuple[float,int]]):
        """metrics: {name: (value, sample_count)}"""
        events=[]
        for a in self.rules:
            if a.name in metrics:
                v, n = metrics[a.name]
                ev = a.check(v, n)
                if ev: events.append(ev)
        return events
```

---

## 2. 기준(Baseline) 통계 생성 — 학습/준준동에서 한 번 산출

운영 시 비교 대상으로 쓸 **기준 분포/임계치**를 만듭니다.  
(예시: 연속형 피처 1개, 확률 출력 1개, 임베딩 벡터 1개)

```python
# build_baseline.py (PyTorch)
import torch, json, os
from monitor_core import Histogram1D, to_t

def make_edges(minv, maxv, bins=20):
    return torch.linspace(minv, maxv, bins+1, dtype=torch.float64)

def build_baseline(train_features: torch.Tensor, train_probs: torch.Tensor, train_emb: torch.Tensor, out_path="baseline.json"):
    # 1) Feature histogram (예: f0)
    f0 = train_features[:, 0].to(torch.float64)
    edges = make_edges(float(f0.min()), float(f0.max()), bins=30)
    h_f0 = Histogram1D(edges); h_f0.update(f0)

    # 2) Prediction prob histogram (클래스1 확률)
    p1 = train_probs[:, 1].to(torch.float64)
    edges_p = torch.linspace(0., 1., 21, dtype=torch.float64)
    h_p1 = Histogram1D(edges_p); h_p1.update(p1)

    # 3) Embedding centroid/cov (간단: 평균/분산)
    emb = train_emb.to(torch.float64)
    mu = emb.mean(dim=0)
    var = emb.var(dim=0, unbiased=True)

    base = {
        "f0_edges": h_f0.edges.tolist(),
        "f0_counts": h_f0.counts.tolist(),
        "p_edges": h_p1.edges.tolist(),
        "p_counts": h_p1.counts.tolist(),
        "emb_mu": mu.tolist(),
        "emb_var": var.tolist()
    }
    os.makedirs(os.path.dirname(out_path) or ".", exist_ok=True)
    with open(out_path, "w") as f:
        json.dump(base, f)
    print("baseline saved:", out_path)

if __name__=="__main__":
    # 데모용 랜덤(실전: 학습 데이터 텐서 사용)
    N, D, C, E = 10000, 8, 2, 64
    X = torch.randn(N, D)
    logits = torch.randn(N, C)
    probs = torch.softmax(logits, dim=-1)
    emb = torch.randn(N, E)
    build_baseline(X, probs, emb, out_path="artifacts/baseline.json")
```

---

## 3. 온라인 모니터: 윈도우 통계 수집 + 드리프트 계산 + 알람

```python
# online_monitor.py (PyTorch)
import json, time, os
import torch
from monitor_core import Histogram1D, ks_statistic, wasserstein_1d, mmd_rbf, OnlineMeanVar, SlidingWindow, Alarm, AlarmManager

class OnlineMonitor:
    def __init__(self, baseline_path:str, device="cpu"):
        b = json.load(open(baseline_path))
        self.f0_base = Histogram1D(torch.tensor(b["f0_edges"], dtype=torch.float64))
        self.f0_base.counts = torch.tensor(b["f0_counts"], dtype=torch.float64)

        self.p_base = Histogram1D(torch.tensor(b["p_edges"], dtype=torch.float64))
        self.p_base.counts = torch.tensor(b["p_counts"], dtype=torch.float64)

        self.emb_mu = torch.tensor(b["emb_mu"], dtype=torch.float64)
        self.emb_var = torch.tensor(b["emb_var"], dtype=torch.float64)

        # Online collectors
        self.f0_hist = Histogram1D(self.f0_base.edges.clone())
        self.p_hist  = Histogram1D(self.p_base.edges.clone())
        self.lat_sw  = SlidingWindow(size=5000)
        self.score_stat = OnlineMeanVar()

        # Alarms
        self.al = AlarmManager()
        # 예: 레이턴시 p95 ≥ 400ms, PSI ≥ 0.2, KS ≥ 0.2, 임베딩 MMD^2 ≥ 0.05
        self.al.add(Alarm(name="lat_p95", threshold=400.0, direction=">=", min_samples=200, consecutive=3, cooldown_sec=120))
        self.al.add(Alarm(name="f0_psi", threshold=0.2, direction=">=", min_samples=500, consecutive=2, cooldown_sec=300))
        self.al.add(Alarm(name="p1_ks", threshold=0.2, direction=">=", min_samples=500, consecutive=2, cooldown_sec=300))
        self.al.add(Alarm(name="emb_mmd2", threshold=0.05, direction=">=", min_samples=500, consecutive=2, cooldown_sec=600))

        self.last_metrics = {}

    def update_request(self, latency_ms: float, probs: torch.Tensor, features: torch.Tensor, embedding: torch.Tensor):
        """요청 1건(or 미니배치)에 대한 집계 업데이트"""
        # 1) 레이턴시
        self.lat_sw.push(latency_ms)

        # 2) 확률/스코어 통계
        if probs.ndim==1: probs = probs[None]
        p1 = probs[:, 1].to(torch.float64)
        self.p_hist.update(p1)
        self.score_stat.update(p1)

        # 3) 피처 f0 히스토그램
        if features.ndim==1: features=features[None]
        f0 = features[:, 0].to(torch.float64)
        self.f0_hist.update(f0)

        # 4) 임베딩 샘플 버퍼 (MMD는 요청 시점에 계산)
        if not hasattr(self, "_emb_buf"):
            self._emb_buf = []
        self._emb_buf.append(embedding.detach().to(torch.float64))
        if len(self._emb_buf) > 4096:
            self._emb_buf = self._emb_buf[-4096:]  # 최근 유지

    def compute_metrics(self):
        # 레이턴시 p95
        p95 = self.lat_sw.quantile(0.95)

        # PSI/KL/JS for f0
        f0_psi = self.f0_hist.psi(self.f0_base)
        f0_js  = self.f0_hist.js(self.f0_base)

        # KS for predicted prob
        # 샘플 생성: base 분포에서 샘플링 대신, base 히스토그램 엣지 중앙값으로 역샘플 근사
        base_p = self.p_base.probs(); edges = self.p_base.edges
        mids = 0.5*(edges[:-1]+edges[1:])
        base_samples = torch.repeat_interleave(mids, torch.clamp((base_p*1000).long(), min=1))
        curr_p1 = torch.repeat_interleave(0.5*(self.p_hist.edges[:-1]+self.p_hist.edges[1:]),
                                          torch.clamp((self.p_hist.probs()*1000).long(), min=1))
        p1_ks = ks_statistic(base_samples, curr_p1)

        # Embedding MMD^2 vs baseline 가우시안 근사(샘플 생성 없이, 운영 샘플과 학습 샘플 일부 직접 비교가 이상적이나,
        # 여기서는 운영 임베딩 vs 기준 임베딩 평균/분산을 이용해 centered scaling 후 MMD를 계산)
        if hasattr(self, "_emb_buf") and len(self._emb_buf)>128:
            E = torch.vstack(self._emb_buf)
            # 기준 스케일로 표준화
            std = torch.sqrt(torch.clamp(self.emb_var, 1e-12))
            E_std = (E - self.emb_mu)/std
            # 기준 분포는 N(0, I)로 근사하여 샘플 생성
            Z = torch.randn_like(E_std)
            emb_mmd2 = mmd_rbf(E_std, Z, sigma=1.0, max_samples=1024)
        else:
            emb_mmd2 = float("nan")

        # 평균 스코어(간단 KPI)
        score_mean = float(self.score_stat.mean)

        self.last_metrics = {
            "lat_p95": (p95, len(self.lat_sw.buf)),
            "f0_psi": (f0_psi, int(self.f0_hist.counts.sum().item())),
            "p1_ks": (p1_ks, int(self.p_hist.counts.sum().item())),
            "emb_mmd2": (emb_mmd2, len(self._emb_buf) if hasattr(self,"_emb_buf") else 0),
            "score_mean": (score_mean, self.score_stat.count)
        }
        return self.last_metrics

    def alarms(self):
        return self.al.run(self.last_metrics)
```

---

## 4. 시뮬레이션: 정상 → 드리프트 주입 → 알람 확인

```python
# simulate_drift.py
import torch, time, random
from online_monitor import OnlineMonitor

def simulate():
    mon = OnlineMonitor("artifacts/baseline.json")
    # 정상 구간(평균 0, 분산 1), 확률 분포 유지, 임베딩 표준 정규
    for step in range(2000):
        # 레이턴시(정상 100±30ms)
        lat = max(1.0, random.gauss(100, 30))
        # 피처/확률/임베딩 샘플
        f = torch.randn(8)
        logits = torch.randn(2)
        prob = torch.softmax(logits, -1)
        emb = torch.randn(64)

        mon.update_request(lat, prob, f, emb)
        if (step+1) % 100 == 0:
            metrics = mon.compute_metrics()
            evs = mon.alarms()
            print(f"[{step+1}] metrics:", {k: round(v[0],4) for k,v in metrics.items()}, "events:", evs)

    # 드리프트 주입: f0 평균 +1.2, 확률 분포(양성↑), 임베딩 shift, 레이턴시 악화
    for step in range(2000, 4000):
        lat = max(1.0, random.gauss(430, 40))  # p95 임계 근처
        f = torch.randn(8); f[0] += 1.2
        logits = torch.tensor([random.gauss(-0.5,0.4), random.gauss(0.5,0.4)])  # 양성 ↑
        prob = torch.softmax(logits, -1)
        emb = torch.randn(64) + 0.7  # 분포 이동

        mon.update_request(lat, prob, f, emb)
        if (step+1) % 50 == 0:
            metrics = mon.compute_metrics()
            evs = mon.alarms()
            print(f"[{step+1}] metrics:", {k: round(v[0],4) for k,v in metrics.items()}, "events:", evs)

if __name__=="__main__":
    simulate()
```

**해석 가이드**  
- 정상 구간에서는 `lat_p95`가 400 미만, `f0_psi/ p1_ks/ emb_mmd2`가 작은 값 유지 → 알람 없음.  
- 드리프트 구간에서 **연속 위반**이 충족되면 `lat_p95`, `f0_psi`, `p1_ks`, `emb_mmd2` 알람이 터짐.  
- **쿨다운(cooldown_sec)** 으로 알람 폭주 방지.

---

## 5. 실시간 서버/배치에 삽입하기 (핵심 라인만)

### 5.1 실시간 (이전 장의 `rt_server.py`에 추가)

```python
# rt_server_monitor_patch.py (요지)
from online_monitor import OnlineMonitor
MON = OnlineMonitor("artifacts/baseline.json")

# ... Handler.do_POST 내에서 추론 전후로:
t0 = time.time()
# ... 추론 수행 => probs (shape [C]), features, embedding 준비
lat_ms = (time.time()-t0)*1000.0
MON.update_request(lat_ms, probs, features, embedding)

# 주기적으로(예: 1초마다 스레드) metrics 계산+알람 → 로그/웹훅
def monitor_loop():
    while True:
        m = MON.compute_metrics()
        events = MON.alarms()
        if events:
            # 예: 파일 로그 또는 사내 웹훅 호출(여기선 print)
            print("ALERT", events, "METRICS", {k: round(v[0],4) for k,v in m.items()})
        time.sleep(1.0)
```

### 5.2 배치 파이프라인 끝단(야간 작업)

```python
# batch_postcheck.py
import torch, json
from monitor_core import Histogram1D, ks_statistic

# 배치 출력(예측 점수) 파일을 로드 → 히스토그램/KS/PSI 계산
# 기준(baseline.json)의 p_counts와 비교해 대규모 배치 품질 검사 후,
# 임계 초과 시 배치 산출물을 "격리"하고 이전 버전을 유지(원자적 교체 전 검증).
```

---

## 6. 어떤 검정을 언제 쓰나? (현업 선택 가이드)

| 상황 | 추천 지표/검정 | 장단점/메모 |
|---|---|---|
| **연속형 단일 피처** | **PSI**, **KS**, **EMD** | PSI는 해석 쉬움(>0.2 경보 관행), KS는 임계 기반 빠름, EMD는 이동량 직관적 |
| **확률/스코어 분포** | **KS**, **JS** | Calibration 악화 조짐 감지(최상위 확률 분포가 뾰족/평탄으로 변함) |
| **다차원 임베딩** | **MMD(RBF)**, 코사인 센트로이드 거리 | MMD는 강력하나 비용↑ → 샘플링/주기 낮춤 |
| **레이턴시/SLO** | p95/p99 + 5xx율 + 타임아웃율 | 절대 임계 + 에러 버짓 모델(월간 합산) 병행 |
| **라벨 도착 지연** | Prediction drift + **지연 도착 라벨로 ex-post 성능** | KPI를 즉시 못 볼 때 prediction drift로 proxy 모니터링 |
| **개념 드리프트** | **성능 하락**(ex-post), CUSUM/Paired t-test | 라벨 도착 후 창별 성능 차이를 누적 감지 |

> **경계값(참고 관행)**: PSI > 0.2 주의, > 0.3 심각. KS > 0.2 주의. 단, **도메인별 교정** 필요.

---

## 7. 알람 설계 베스트 프랙티스

- **3요소**: **임계(Threshold)** + **연속 위반(Consecutive)** + **완화(Dampening/Cooldown)**  
- **중요도 등급**: P1(페이징), P2(근무시간 경고), P3(티켓)  
- **자동 조치**: 카나리 단계에서 위반 → **자동 롤백**(+ 슬랙/문자 통지)  
- **다중 신호**: 단일 지표보다 **합성 신호**(예: `lat_p95↑ AND 5xx↑`)에 가중치  
- **샘플 수 가드**: `min_samples` 미만에선 알람 금지(작은 샘플 잡음 억제)  
- **분리 트래킹**: **레인(lane)/팔(AB)/버전** 별로 분리 집계(혼합 금지)

---

## 8. 데이터 품질(DQ) 간단 규칙 (PyTorch 계산)

```python
# dq_rules.py
import torch

@torch.no_grad()
def dq_basic_checks(X: torch.Tensor, minmax: torch.Tensor, allowed_cats=None):
    """
    X: [N, D], minmax: [D,2] (각 피처 최소/최대 허용치)
    allowed_cats: Optional[List[Set]] for categorical features
    """
    N, D = X.shape
    # 1) 결측/NaN
    nan_rate = torch.isnan(X).float().mean().item()
    # 2) 범위 위반
    mn = minmax[:,0].view(1,-1); mx = minmax[:,1].view(1,-1)
    viol = ((X < mn) | (X > mx)).float().mean(dim=0)  # 피처별 위반율
    return {"nan_rate": nan_rate, "range_violation_mean": viol.mean().item()}
```

---

## 9. 캘리브레이션(간단) 모니터

학습 기준 기간의 **신뢰구간**과 운영 기간의 **관찰 빈도**를 비교하여 **과신/과소 신뢰**를 탐지합니다(라벨 지연 시 ex-post 수행).

```python
# calib_monitor.py
import torch

@torch.no_grad()
def brier_score(probs: torch.Tensor, y: torch.Tensor):
    # 이진 가정, probs: [N,2], y: [N] (0/1)
    p = probs[:,1]
    return float(((p - y.float())**2).mean())

@torch.no_grad()
def ece(probs: torch.Tensor, y: torch.Tensor, bins=10):
    p = probs[:,1]; y = y.float()
    edges = torch.linspace(0,1,bins+1)
    mids = 0.5*(edges[:-1]+edges[1:])
    ece=0.0; N = p.numel()
    for i in range(bins):
        msk = (p>=edges[i])&(p<edges[i+1])
        k = msk.sum().item()
        if k==0: continue
        conf = float(p[msk].mean()); acc = float(y[msk].mean())
        ece += (k/N)*abs(conf-acc)
    return float(ece)
```

---

## 10. 운영 체크리스트

- [ ] **기준 통계** 산출·버전 관리(`baseline.json`, `model_id`, `data_hash`)  
- [ ] **윈도우/주기**: 실시간(1s~60s), 배치(작업마다)  
- [ ] **임계·연속·완화** 알람 정책 문서화 + 코드화(리뷰/테스트)  
- [ ] **레인/팔/버전** 분리 집계(카나리/AB 혼합 금지)  
- [ ] **라벨 지연 전략**: prediction drift + ex-post 성능  
- [ ] **관측 로그 스키마**: `ts, req_id, user_id_hash, model_id, data_hash, lat_ms, http, score, feature_hash`  
- [ ] **PII/보안**: 최소화/익명화, 로그 마스킹  
- [ ] **대시보드**: SLO/드리프트/품질 한 화면(알람 링크 포함)  
- [ ] **DR/복구**: 알람 → 롤백/트래픽 전환 스크립트 실행(사전 검증)  
- [ ] **회귀 방지**: 릴리즈 전 **섀도우 + 기준 대비 드리프트 검사** 필수

---

## 11. 자주 묻는 질문(FAQ)

**Q1. PSI/KS/EMD 임계는 어떻게 정하나요?**  
- 기준 기간 여러 샤드에서 **백분위 기반**으로 정하세요(예: PSI의 p95를 경계, p99를 치명). 초기엔 보수적으로(낮게) 두고 **오경보**를 보며 상향.

**Q2. 라벨이 늦게 도착합니다. 개념 드리프트는 어떻게 잡죠?**  
- **Prediction drift**(확률/클래스 비율) + **피처 드리프트**를 먼저 봅니다. 라벨이 도착하면 창별 **성능 곡선**을 ex-post로 누적(CUSUM)하세요.

**Q3. 임베딩 차원 수가 커서 MMD가 느립니다.**  
- **샘플 다운샘플링** + **차원 축소(학습된 프로젝션/고정 랜덤)** + MMD 주기 늘리기(예: 1분/5분).

**Q4. 다중 모델/버전이 공존합니다.**  
- **모델별 모니터 인스턴스**를 따로 두고, **합성 뷰**에선 태그로 rollup 합니다.

---

## 12. 맺음말

- **모니터링 = 제품 품질의 마지막 방어선**입니다.  
- 위 모듈을 **서빙/배치 파이프라인**에 바로 끼워 넣으면, **드리프트**와 **SLO 이탈**을 **수치/알람**으로 즉시 포착할 수 있습니다.  