---
layout: post
title: DB 심화 - PL/SQL 함수 호출 부하 해소 방안
date: 2025-11-01 23:25:23 +0900
category: DB 심화
---
# 함수 성능 최적화: 페이지 처리와 SQL 중심 설계

> **핵심 요약**
> 성능 저하의 주요 원인인 PL/SQL 함수 호출 문제는 두 가지 패턴에서 발생합니다: 첫째는 "행마다 반복 호출"이고, 둘째는 "함수 내부의 재귀적 SQL 실행(N+1 문제)"입니다. 이러한 문제를 해결하는 가장 효과적인 방법은 페이지 처리(부분범위 처리)로 읽어야 할 행 수 자체를 줄이고, DECODE나 CASE 표현식 같은 순수 SQL 구성 요소로 PL/SQL 함수를 대체하는 것입니다. 이 접근법은 컨텍스트 전환 오버헤드를 제거하고 실행 계획 최적화 가능성을 높이며, 인덱스 활용도(SARGability)를 유지하기 쉽게 합니다.

---

## 공통 실습 스키마 구성

실습을 위해 주문 데이터와 상태 코드 매핑 테이블을 생성합니다.

```sql
-- 주문 테이블(2,000,000행 가정)
DROP TABLE orders PURGE;
CREATE TABLE orders (
  order_id     NUMBER PRIMARY KEY,
  customer_id  NUMBER NOT NULL,
  created_at   DATE   NOT NULL,
  region       VARCHAR2(20),
  status_code  NUMBER,
  amount       NUMBER(12,2)
);

INSERT /*+ APPEND */ INTO orders
SELECT level,
       MOD(level, 500000)+1,
       (TRUNC(SYSDATE) - MOD(level, 365)) + (MOD(level,86400)/86400),
       CASE MOD(level,4) WHEN 0 THEN 'APAC' WHEN 1 THEN 'EMEA'
                         WHEN 2 THEN 'AMER' ELSE 'OTHER' END,
       MOD(level, 6),  -- 0~5 코드
       ROUND(DBMS_RANDOM.VALUE(10, 1000), 2)
FROM dual CONNECT BY level <= 2000000;
COMMIT;

-- 상태 코드 사전(룩업 테이블)
DROP TABLE dim_status PURGE;
CREATE TABLE dim_status (
  status_code  NUMBER PRIMARY KEY,
  status_name  VARCHAR2(30) NOT NULL
);
INSERT INTO dim_status VALUES (0, 'NEW');
INSERT INTO dim_status VALUES (1, 'PAID');
INSERT INTO dim_status VALUES (2, 'SHIPPED');
INSERT INTO dim_status VALUES (3, 'DELIVERED');
INSERT INTO dim_status VALUES (4, 'RETURN');
INSERT INTO dim_status VALUES (5, 'CANCEL');
COMMIT;

-- 페이지 처리를 위한 복합 인덱스
CREATE INDEX ix_orders_cust_time
  ON orders(customer_id, created_at DESC, order_id DESC);

BEGIN
  DBMS_STATS.GATHER_TABLE_STATS(USER, 'ORDERS', cascade=>TRUE);
  DBMS_STATS.GATHER_TABLE_STATS(USER, 'DIM_STATUS', cascade=>TRUE);
END;
/
```

---

## 문제 패턴: PL/SQL 함수 호출로 인한 성능 저하

### 전형적인 PL/SQL 함수 예시 (내부 쿼리 포함)

```plsql
CREATE OR REPLACE FUNCTION get_status_name(p_code NUMBER)
  RETURN VARCHAR2
IS
  v VARCHAR2(30);
BEGIN
  -- 이 내부 쿼리가 각 호출마다 실행됩니다
  SELECT status_name INTO v
  FROM   dim_status
  WHERE  status_code = p_code;
  RETURN v;
EXCEPTION WHEN NO_DATA_FOUND THEN
  RETURN 'UNKNOWN';
END;
/
```

### 성능 문제가 있는 쿼리 패턴

```sql
-- 문제점이 많은 쿼리 예시
SELECT order_id,
       created_at,
       amount,
       get_status_name(status_code) AS status_name        -- 각 행마다 함수 호출
FROM   orders
WHERE  customer_id = :cust
  AND  get_status_name(status_code) <> 'CANCEL'          -- 필터 조건에서도 함수 호출
ORDER  BY created_at DESC, order_id DESC
OFFSET :skip ROWS FETCH NEXT :take ROWS ONLY;            -- 비효율적인 OFFSET 방식
```

**이 쿼리의 네 가지 주요 문제점:**

1. **OFFSET 방식의 비효율성**: 페이지 번호가 증가할수록 앞쪽의 모든 행을 읽고 버리는 비용이 누적됩니다.
2. **N+1 쿼리 문제**: `orders` 테이블의 각 행마다 `dim_status` 테이블을 조회하는 별도의 쿼리가 실행됩니다.
3. **인덱스 활용 불가**: 필터 조건에 함수가 적용되어 있으므로 인덱스 범위 스캔을 활용할 수 없습니다.
4. **컨텍스트 전환 오버헤드**: SQL 엔진과 PL/SQL 엔진 사이의 전환이 각 함수 호출마다 발생합니다.

**TKPROF에서 관찰 가능한 증상:**
- `recursive calls` 수치가 매우 높게 나타납니다.
- `db file sequential read` 대기 이벤트가 빈번하게 발생합니다.
- Fetch 단계의 경과 시간(elapsed)이 불필요하게 높습니다.
- `SQL*Net message from client` 대기 이벤트가 많아집니다.

---

## 해법 1: 페이지 처리(부분범위 처리)로 근본적인 호출 수 줄이기

### 기본 원리

키셋 페이지네이션(Keyset Pagination)을 사용하면 항상 필요한 수의 행만 읽을 수 있습니다. 이는 Oracle 실행 계획에서 `STOPKEY` 작업으로 표현되며, 적절한 인덱스가 존재할 경우 정렬 작업 없이도 원하는 행 수만큼만 읽고 즉시 중단됩니다.

### 구현 예시: OFFSET 방식을 키셋 페이지네이션으로 전환

**첫 페이지 조회 (가장 최근 주문 50건)**

```sql
SELECT /*+ index(o ix_orders_cust_time) */
       o.order_id,
       o.created_at,
       o.amount,
       o.status_code
FROM   orders o
WHERE  o.customer_id = :cust
ORDER  BY o.created_at DESC, o.order_id DESC
FETCH FIRST 50 ROWS ONLY;     -- STOPKEY 메커니즘 활성화
```

**다음 페이지 조회 (이전 페이지 마지막 행 이후 50건)**

```sql
SELECT /*+ index(o ix_orders_cust_time) */
       o.order_id,
       o.created_at,
       o.amount,
       o.status_code
FROM   orders o
WHERE  o.customer_id = :cust
  -- 이전 페이지의 마지막 행 키값을 기준으로 범위 제한
  AND (o.created_at, o.order_id) < (:last_ts, :last_id)
ORDER  BY o.created_at DESC, o.order_id DESC
FETCH FIRST 50 ROWS ONLY;     -- STOPKEY 메커니즘 활성화
```

**키셋 페이지네이션의 주요 장점:**

1. **읽기 행 수 제한**: 페이지 크기(예: 50행)만큼만 읽으므로 함수 호출 수도 동일하게 제한됩니다.
2. **OFFSET 오버헤드 제거**: 앞쪽 행을 읽고 버리는 비용이 전혀 발생하지 않습니다.
3. **동시성 보장**: 데이터 변경 중에도 페이지 간 중복이나 누락 없이 안정적인 페이징이 가능합니다.
4. **인덱스 활용 최적화**: 정렬 순서와 인덱스 구성을 맞추면 정렬 작업 없이도 빠른 조회가 가능합니다.

**추가 성능 팁:** 필요한 컬럼만 선택적으로 조회하고, 자주 사용되는 조합에 대해 커버링 인덱스를 고려하세요.

---

## 해법 2: DECODE/CASE 표현식이나 조인으로 함수 대체하기

### 단순 매핑: DECODE/CASE 표현식 활용

**필터 조건에서의 함수 제거**

```sql
-- 상태 코드가 'CANCEL'이 아닌 주문 조회
SELECT o.order_id, o.created_at, o.amount
FROM   orders o
WHERE  o.customer_id = :cust
  -- CASE 표현식을 사용한 필터 조건
  AND  CASE o.status_code
         WHEN 5 THEN 'CANCEL'
         ELSE 'OK'
       END <> 'CANCEL'
ORDER  BY o.created_at DESC, o.order_id DESC
FETCH FIRST 50 ROWS ONLY;
```

**또는 DECODE 함수 사용**

```sql
WHERE DECODE(o.status_code, 5, 'CANCEL', 'OK') <> 'CANCEL'
```

**표시용 컬럼에서의 함수 제거**

```sql
SELECT o.order_id,
       o.created_at,
       o.amount,
       -- SELECT 리스트에서 CASE 표현식 사용
       CASE o.status_code
         WHEN 0 THEN 'NEW'
         WHEN 1 THEN 'PAID'
         WHEN 2 THEN 'SHIPPED'
         WHEN 3 THEN 'DELIVERED'
         WHEN 4 THEN 'RETURN'
         WHEN 5 THEN 'CANCEL'
         ELSE 'UNKNOWN'
       END AS status_name
FROM   orders o
WHERE  o.customer_id = :cust
ORDER  BY o.created_at DESC, o.order_id DESC
FETCH FIRST 50 ROWS ONLY;
```

**DECODE/CASE 방식의 장점:**
- 컨텍스트 전환 오버헤드가 전혀 없습니다.
- 옵티마이저가 전체 쿼리를 단일 실행 계획으로 최적화할 수 있습니다.
- 간단한 매핑 로직에 대해 가장 빠르고 안정적인 성능을 제공합니다.

### 룩업 테이블 조인 방식

```sql
SELECT o.order_id,
       o.created_at,
       o.amount,
       s.status_name
FROM   orders o
JOIN   dim_status s
  ON   s.status_code = o.status_code
WHERE  o.customer_id = :cust
  AND  s.status_name <> 'CANCEL'
ORDER  BY o.created_at DESC, o.order_id DESC
FETCH FIRST 50 ROWS ONLY;
```

**조인 방식의 장점:**
- N+1 쿼리 문제가 완전히 해결됩니다(단일 조인으로 일괄 처리).
- 통계 정보와 카디널리티를 기반으로 최적의 실행 계획을 수립할 수 있습니다.
- 매핑 정보 변경이 빈번한 경우 유지보수성이 뛰어납니다.
- 대량 데이터 처리 시에도 안정적인 성능을 보장합니다.

---

## 통합 해법: 페이지 처리와 함수 제거의 시너지

### 최적화된 쿼리 패턴

```sql
SELECT /*+ index(o ix_orders_cust_time) */
       o.order_id,
       o.created_at,
       o.amount,
       s.status_name
FROM   orders o
JOIN   dim_status s
  ON   s.status_code = o.status_code
WHERE  o.customer_id = :cust
  AND  s.status_name <> 'CANCEL'
ORDER  BY o.created_at DESC, o.order_id DESC
FETCH FIRST 50 ROWS ONLY;   -- STOPKEY 메커니즘으로 읽기 양 제한
```

**통합 개선으로 얻는 이점:**

1. **읽기 양 최소화**: STOPKEY 메커니즘으로 실제 필요한 행 수만큼만 읽습니다.
2. **컨텍스트 전환 제거**: PL/SQL 함수 호출이 전혀 없어집니다.
3. **인덱스 활용 최대화**: 필터 조건이 인덱스 친화적으로 구성됩니다.
4. **네트워크 효율성**: 필요한 컬럼만 선택적으로 전송합니다.

**성능 개선 효과:** 일반적인 목록 조회 API에서 95분위 응답 시간을 수백 밀리초에서 수십 밀리초 수준으로 단축할 수 있습니다.

---

## DECODE/CASE 변환 패턴 모음

### 문자열 정규화 패턴

```sql
-- 다양한 입력값을 표준값으로 정규화
CASE TRIM(UPPER(region))
  WHEN 'APAC' THEN 'APAC'
  WHEN 'ASIA PACIFIC' THEN 'APAC'
  WHEN 'EMEA' THEN 'EMEA'
  WHEN 'EUROPE' THEN 'EMEA'
  WHEN 'AMER' THEN 'AMER'
  WHEN 'US'   THEN 'AMER'
  WHEN 'NA'   THEN 'AMER'
  ELSE 'OTHER'
END
```

**인덱스 활용을 고려한 필터 조건**

```sql
-- 열 자체에는 함수를 적용하지 않고 바인드 변수만 정규화
WHERE region = CASE TRIM(UPPER(:b_region))
                 WHEN 'ASIA PACIFIC' THEN 'APAC'
                 ELSE TRIM(UPPER(:b_region))
               END
```

### 숫자 코드 매핑 패턴

```sql
-- 간결한 DECODE 활용
DECODE(status_code,
  0,'NEW', 1,'PAID', 2,'SHIPPED', 3,'DELIVERED', 4,'RETURN', 5,'CANCEL',
  'UNKNOWN')
```

### 범위 기반 분류 패턴

```sql
-- 금액에 따른 등급 분류
CASE
  WHEN amount <  50  THEN 'LOW'
  WHEN amount < 200  THEN 'MID'
  WHEN amount < 1000 THEN 'HIGH'
  ELSE 'VIP'
END
```

**공통 장점:** 모든 변환 로직이 순수 SQL 내에서 처리되므로 배치 처리, 병렬 실행, 조인 최적화 등과 완벽하게 호환됩니다.

---

## 동적 매핑 관리: SQL 매크로 활용

매핑 정보가 자주 변경되는 환경에서는 하드코딩된 CASE 표현식보다 유연한 접근 방식이 필요합니다. Oracle 19c부터 도입된 SQL 매크로 기능을 사용하면 PL/SQL 함수의 재귀적 SQL 실행 문제 없이도 패턴을 안전하게 캡슐화할 수 있습니다.

```plsql
CREATE OR REPLACE FUNCTION m_orders_page(p_take NUMBER)
  RETURN VARCHAR2 SQL_MACRO(SCALAR) IS
BEGIN
  -- 이 함수는 실행 시점에 SQL 텍스트로 확장됩니다
  RETURN q'{
    SELECT /*+ index(o ix_orders_cust_time) */
           o.order_id, o.created_at, o.amount, s.status_name
    FROM   orders o
    JOIN   dim_status s ON s.status_code = o.status_code
    WHERE  o.customer_id = :cust
    ORDER  BY o.created_at DESC, o.order_id DESC
    FETCH FIRST p_take ROWS ONLY
  }';
END;
/
```

**사용 방법:**

```sql
-- 함수처럼 보이지만 내부적으로는 SQL로 확장됩니다
SELECT * FROM m_orders_page(50);
```

**SQL 매크로의 장점:**
- 컴파일 시점에 SQL로 확장되므로 런타임 오버헤드가 없습니다.
- 재귀적 SQL 실행 문제가 발생하지 않습니다.
- 재사용 가능한 패턴을 깔끔하게 캡슐화할 수 있습니다.

---

## 성능 측정과 검증 방법

### 트레이스 설정과 데이터 수집

```sql
-- 상세 통계 수집 활성화
ALTER SESSION SET statistics_level = ALL;

-- SQL 트레이스 활성화 (대기 이벤트 포함)
ALTER SESSION SET events '10046 trace name context forever, level 8';

-- 개선 전/후 쿼리 실행
SELECT /* 개선 전 쿼리 */ ... ;

-- 트레이스 비활성화
ALTER SESSION SET events '10046 trace name context off';
```

### TKPROF/SQL Monitor에서 확인할 핵심 지표

1. **재귀 호출 감소**: `recursive calls` 수치가 크게 감소해야 합니다.
2. **Fetch 횟수 최적화**: `Fetch count`가 1-2회 수준으로 낮아져야 합니다.
3. **논리적/물리적 읽기 감소**: `consistent gets`와 `physical reads`가 줄어들어야 합니다.
4. **대기 이벤트 변화**: `db file sequential read`, `SQL*Net message from client` 같은 대기 이벤트가 감소해야 합니다.

---

## 실무 적용 시 고려사항

### 인덱스 설계 원칙

1. **복합 인덱스 구성**: 필터 컬럼 + 정렬 컬럼 + 유니크 식별자 순서로 인덱스를 구성하세요.
   ```sql
   -- 예: (customer_id, created_at DESC, order_id DESC)
   CREATE INDEX ix_orders_cust_time
     ON orders(customer_id, created_at DESC, order_id DESC);
   ```

2. **커버링 인덱스 고려**: 자주 조회하는 컬럼을 인덱스에 포함하여 테이블 액세스를 피하세요.

### SARGability 유지 지침

1. **열에 함수 적용 금지**:
   ```sql
   -- 나쁜 예: 인덱스 활용 불가
   WHERE TRUNC(created_at) = :date_value
   
   -- 좋은 예: 인덱스 활용 가능
   WHERE created_at >= TRUNC(:date_value) 
     AND created_at < TRUNC(:date_value) + 1
   ```

2. **필요시 함수 기반 인덱스(FBI) 활용**: 함수 적용이 불가피한 경우 FBI를 고려하되, 생성 및 관리 비용을 고려하세요.

### 클라이언트 측 최적화

1. **배열 페치 크기 조정**:
   ```java
   // JDBC 예시
   preparedStatement.setFetchSize(1000);  // 기본값 10보다 크게 설정
   ```

2. **필요 컬럼만 선택**: 불필요한 컬럼을 제외하여 네트워크 트래픽과 메모리 사용을 줄이세요.

3. **커서 캐시 활용**: `SESSION_CACHED_CURSORS` 파라미터를 적절히 설정하고 클라이언트 드라이버의 Statement Caching 기능을 활성화하세요.

---

## 개선 전후 비교: 실전 예시

### 개선 전 (함수 사용 + OFFSET 방식)

```sql
SELECT order_id,
       get_status_name(status_code) AS status_name
FROM   orders
WHERE  customer_id = :cust
  AND  get_status_name(status_code) <> 'CANCEL'
ORDER  BY created_at DESC, order_id DESC
OFFSET :skip ROWS FETCH NEXT :take ROWS ONLY;
```

**예상 문제점:**
- 재귀적 호출이 각 행마다 발생
- OFFSET 값이 클수록 불필요한 I/O 발생
- 인덱스 활용 불가로 풀 스캔 가능성 높음

### 개선 후 (키셋 페이지네이션 + 조인)

```sql
SELECT /*+ index(o ix_orders_cust_time) */
       o.order_id,
       o.created_at,
       o.amount,
       s.status_name
FROM   orders o
JOIN   dim_status s ON s.status_code = o.status_code
WHERE  o.customer_id = :cust
  AND  s.status_name <> 'CANCEL'
ORDER  BY o.created_at DESC, o.order_id DESC
FETCH FIRST :take ROWS ONLY;
```

**개선된 부분:**
- 재귀적 호출 완전 제거
- STOPKEY 메커니즘으로 필요한 행만 읽음
- 인덱스 범위 스캔 활용
- 네트워크 왕복 최소화

---

## 완성형 실무 예제

### 첫 페이지 조회

```sql
SELECT /*+ index(o ix_orders_cust_time) */
       o.order_id,
       o.created_at,
       o.amount,
       s.status_name
FROM   orders o
JOIN   dim_status s
  ON   s.status_code = o.status_code
WHERE  o.customer_id = :cust
  AND  s.status_name <> 'CANCEL'
ORDER  BY o.created_at DESC, o.order_id DESC
FETCH FIRST :take ROWS ONLY;
```

### 다음 페이지 조회

```sql
SELECT /*+ index(o ix_orders_cust_time) */
       o.order_id,
       o.created_at,
       o.amount,
       s.status_name
FROM   orders o
JOIN   dim_status s
  ON   s.status_code = o.status_code
WHERE  o.customer_id = :cust
  AND  s.status_name <> 'CANCEL'
  -- 키셋 페이지네이션: 이전 페이지 마지막 키 이후 데이터만 조회
  AND (o.created_at, o.order_id) < (:last_ts, :last_id)
ORDER  BY o.created_at DESC, o.order_id DESC
FETCH FIRST :take ROWS ONLY;
```

**이 패턴의 핵심 강점:**
1. 함수 호출 오버헤드가 전혀 없습니다.
2. 부분범위 처리가 완벽하게 동작합니다.
3. 인덱스 활용도가 최대화됩니다.
4. 대부분의 목록/검색 화면에 적용 가능한 안정적인 기본 패턴입니다.

---

## 결론

PL/SQL 함수 호출로 인한 성능 문제는 현장에서 빈번히 발생하는 도전 과제입니다. 이 문제를 효과적으로 해결하기 위해서는 단순한 최적화 기법을 넘어 근본적인 설계 접근 방식의 전환이 필요합니다.

첫 번째 방어선은 **페이지 처리(부분범위 처리)**를 올바르게 구현하는 것입니다. 키셋 페이지네이션과 STOPKEY 메커니즘을 활용하면 읽어야 할 행 수 자체를 줄여 함수 호출 횟수를 근본적으로 제한할 수 있습니다.

두 번째이자 더 근본적인 해결책은 **함수 자체를 제거**하는 것입니다. DECODE와 CASE 같은 순수 SQL 구성 요소로 로직을 구현하거나, 적절한 조인을 활용하면 컨텍스트 전환 오버헤드와 재귀적 SQL 실행 문제를 완전히 해결할 수 있습니다. 이 접근법은 옵티마이저의 최적화 가능성을 높이고 인덱스 활용도를 보장합니다.

이 두 가지 전략을 결합하고, 적절한 인덱스 설계와 클라이언트 측 최적화를 보완하면, 대부분의 목록 조회 API에서 95분위 응답 시간을 한 자릿수 또는 두 자릿수 밀리초 수준으로 안정화할 수 있습니다.

마지막으로, 모든 최적화 작업은 측정과 검증을 동반해야 합니다. SQL Trace, TKPROF, SQL Monitor 같은 도구를 활용하여 개선 전후의 재귀 호출 수, Fetch 횟수, 논리적/물리적 읽기, 대기 이벤트 등을 정량적으로 비교함으로써 최적화 효과를 객관적으로 입증하십시오. 데이터에 기반한 과학적 접근이 지속 가능한 고성능 시스템 구축의 핵심입니다.