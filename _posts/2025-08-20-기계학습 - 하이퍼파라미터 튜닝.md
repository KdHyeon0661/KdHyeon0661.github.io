---
layout: post
title: 기계학습 - 하이퍼파라미터 튜닝
date: 2025-08-20 16:25:23 +0900
category: 기계학습
---
# 🔧 하이퍼파라미터 튜닝 완전 가이드  
**(Grid Search, Random Search, Optuna/TPE, + 실전 팁)**

모델의 **하이퍼파라미터**는 학습 과정에서 자동으로 학습되는 **파라미터(가중치)** 와 달리, 사람이 미리 정해야 하는 설정값(예: `max_depth`, `learning_rate`, `C`, `alpha`)입니다.  
좋은 하이퍼파라미터는 **일반화 성능**(보지 않은 데이터 성능)을 크게 끌어올립니다.

본 글은 세 가지 대표 전략—**Grid Search**, **Random Search**, **Optuna(베이지안 최적화/TPE)**—을 개념부터 실전 코드, 장단점, 선택 가이드까지 자세히 다룹니다.  
마지막에는 **현업 체크리스트**와 **자주 하는 실수**도 제공합니다.

---

## 0) 준비: 튜닝의 기본 원칙

- **자료 분리**: `Train/Validation/Test`를 명확히 분리하거나 **교차검증(CV)** 사용.  
  -> 튜닝은 `Train+CV`만 사용하고, **Test는 최종 1회**만 사용(데이터 누수 방지).
- **메트릭 정의**: 비용 구조에 맞춰 분명한 목적 함수를 선택(예: 회귀는 RMSE/MAE, 분류는 F1/ROC-AUC 등).
- **파이프라인화**: 전처리(스케일링, 인코딩, 선택)를 `Pipeline`에 묶어 **CV 안에서** 함께 튜닝.
- **시계열**: 랜덤 셔플 금지. `TimeSeriesSplit` 사용.
- **재현성**: `random_state/seed` 고정, 버전 기록, 실험 로그 저장.

---

## 1) Grid Search (격자 탐색)

### 1.1 개념
지정한 하이퍼파라미터 **모든 조합**을 **완전 탐색**합니다.
- 예: `max_depth ∈ {3,5,7}`, `min_samples_split ∈ {2,10}` → 3×2 = 6 조합 전수평가.

### 1.2 장점/단점
**장점**
- 단순하고 구현이 매우 쉬움.
- 작은/저차원 공간에서 **재현성** 높고 결과 해석 용이.

**단점**
- 차원과 후보가 늘면 **조합 폭발**(시간·비용 급증).
- 연속형/스케일 민감한 하이퍼파라미터(예: `C`, `lambda`)에 비효율.

### 1.3 언제 쓰나?
- 파라미터가 **2~3개** 정도이고 각 값의 **유의미한 구간을 알고 있을 때**.
- **미세 튜닝(fine-tuning)** 단계에서 좁은 범위를 **정밀 스캔**할 때.

### 1.4 예제 (scikit-learn)
```python
from sklearn.model_selection import GridSearchCV, StratifiedKFold
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVC

pipe = Pipeline([
    ("scaler", StandardScaler()),
    ("svc", SVC())
])

param_grid = {
    "svc__C": [0.1, 1, 10, 100],
    "svc__gamma": [1e-3, 1e-2, 1e-1, 1],
    "svc__kernel": ["rbf"]
}

cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
gs = GridSearchCV(pipe, param_grid, cv=cv, scoring="f1_macro", n_jobs=-1)
gs.fit(X, y)

print(gs.best_score_, gs.best_params_)
best_model = gs.best_estimator_
```

**팁**: `C`, `gamma`, `alpha`, `learning_rate` 등은 **선형 스케일보다 로그 스케일**(예: `[1e-4, 1e-3, ...]`)로 그리드를 잡는 것이 효율적입니다.

---

## 2) Random Search (무작위 탐색)

### 2.1 개념
사용자가 정의한 **분포/범위**에서 **무작위 표본**을 뽑아 평가합니다.
- 같은 예산(실험 횟수)일 때, 고차원 공간에서 **Grid보다 더 좋은 해**를 발견할 확률이 높음 (핵심 아이디어: 중요한 축만 잘 샘플링해도 성능 급상승 가능).

### 2.2 장점/단점
**장점**
- 고차원·넓은 공간에서 **탐색 효율**이 높음.
- 예산(실험 횟수)과 **시간을 명확히 통제** 가능 (`n_iter`).

**단점**
- 운(샘플링)에 영향.  
- “좋은 영역 근처에서 더 촘촘히” 같은 **적응형 개선**은 없음(순수 무작위).

### 2.3 언제 쓰나?
- 파라미터가 많고 **좋은 범위를 모호하게** 알고 있을 때 **초기 탐색**.
- 빠르게 **대략적 최적 영역**을 찾고 싶을 때.

### 2.4 예제 (scikit-learn)
```python
from sklearn.model_selection import RandomizedSearchCV
from scipy.stats import loguniform, randint
from sklearn.ensemble import RandomForestClassifier

param_dist = {
    "n_estimators": randint(100, 800),
    "max_depth": randint(3, 20),
    "max_features": ["sqrt", "log2", None],
    "min_samples_split": randint(2, 20)
}

rs = RandomizedSearchCV(
    RandomForestClassifier(random_state=42),
    param_distributions=param_dist,
    n_iter=60,  # 예산
    cv=5,
    scoring="roc_auc",
    n_jobs=-1,
    random_state=42
)
rs.fit(X, y)
print(rs.best_score_, rs.best_params_)
```

**팁**
- **분포 선택**: 스케일 민감 파라미터는 `loguniform`, 정수형은 `randint`, 범주는 리스트.  
- scikit-learn의 **Successive Halving**도 고려: `HalvingGridSearchCV`, `HalvingRandomSearchCV` (multi-fidelity).

---

## 3) Optuna (베이지안 최적화 / TPE + Pruning)

### 3.1 개념
**Optuna**는 자동화된 하이퍼파라미터 최적화 프레임워크. **TPE(Tree-structured Parzen Estimator)** 샘플러로 **좋은 영역을 점점 더 자주** 탐색합니다. 또한 **Pruner(조기 중단)** 로 **낭비되는 시도**를 줄입니다.

- **Sampler**: `TPESampler`(기본), `CmaEsSampler` 등  
- **Pruner**: `MedianPruner`, `HyperbandPruner`, `PercentilePruner` 등  
- **Study**: 실험 단위를 관리 (저장, 병렬, 중단/재개)

### 3.2 TPE 직관
- 성능이 좋은 trial과 나쁜 trial을 나눠 **밀도 \(p(x|y)\)** 를 추정하고, 성능이 좋은 영역에서 **획득함수**가 높은 샘플을 더 자주 뽑는 **순차적 모델 기반 최적화(SMBO)**.

### 3.3 장점/단점
**장점**
- **적응형** 탐색 → 적은 예산으로도 좋은 성능.
- **Pruning** 으로 시간 절약 (예: 에폭 중간 성능이 나쁘면 중단).
- **조건부 공간** 쉽게 표현(예: `booster='gbtree'`일 때만 `max_depth` 탐색).

**단점**
- 구현 복잡도(초기 러닝 커브) 약간 있음.
- 랜덤/그리드 대비 디버깅 난이도는 높을 수 있음.

### 3.4 기본 사용 패턴
```python
import optuna
from sklearn.model_selection import cross_val_score, StratifiedKFold
from sklearn.ensemble import GradientBoostingClassifier

def objective(trial):
    # 하이퍼파라미터 공간 정의
    params = {
        "n_estimators": trial.suggest_int("n_estimators", 100, 800),
        "learning_rate": trial.suggest_float("learning_rate", 1e-3, 0.3, log=True),
        "max_depth": trial.suggest_int("max_depth", 2, 6),
        "subsample": trial.suggest_float("subsample", 0.5, 1.0),
        "min_samples_split": trial.suggest_int("min_samples_split", 2, 40)
    }
    model = GradientBoostingClassifier(**params, random_state=42)

    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
    scores = cross_val_score(model, X, y, cv=cv, scoring="roc_auc", n_jobs=-1)
    return scores.mean()

study = optuna.create_study(direction="maximize",
                            sampler=optuna.samplers.TPESampler(seed=42),
                            pruner=optuna.pruners.MedianPruner(n_startup_trials=10))
study.optimize(objective, n_trials=100, timeout=None, n_jobs=1)

print("Best:", study.best_value)
print("Params:", study.best_params)
```

**실무 팁**
- **로그 스케일**: `learning_rate`, `C`, `alpha`, `lambda`, `gamma`는 `log=True`.
- **조건부 탐색**:
  ```python
  booster = trial.suggest_categorical("booster", ["gbtree", "dart"])
  if booster == "gbtree":
      max_depth = trial.suggest_int("max_depth", 3, 10)
  ```
- **Pruning 연동**: XGBoost/LightGBM은 `early_stopping` + Optuna의 `LightGBMPruningCallback`, `XGBoostPruningCallback` 사용.
- **병렬**: `study = create_study(storage="sqlite:///study.db", load_if_exists=True)` 후 여러 프로세스/머신에서 동시 실행.
- **다목적(Multi-objective)**: `directions=["maximize","minimize"]` 로 파레토 프론티어 탐색 가능.

---

## 4) 전략 비교

| 항목 | Grid Search | Random Search | Optuna (TPE) |
|---|---|---|---|
| 탐색 방식 | 전수(격자) | 무작위 표본 | 베이지안/적응형 |
| 고차원 효율 | 낮음 | 중간~좋음 | **매우 좋음** |
| 구현 난이도 | 매우 쉬움 | 쉬움 | **중간** |
| 예산 제어 | 조합 수 의존 | **n_iter**로 명확 | **n_trials/timeout** |
| 조기중단 | 없음 | (Successive Halving로 가능) | **Pruner 기본 지원** |
| 조건부·복잡 공간 | 번거로움 | 가능하나 수동 | **아주 쉬움** |
| 추천 용도 | 좁은/확정 범위 미세탐색 | 넓은 초기 탐색 | 최종 고성능, 예산 제한 |

---

## 5) 실전 플레이북 (권장 워크플로)

1) **베이스라인**: 기본값/단순 튜닝으로 파이프라인과 메트릭을 검증.  
2) **랜덤 탐색**(혹은 Optuna 짧은 예산)으로 **거친 영역** 식별.  
3) **Optuna**(또는 Successive Halving 포함 Random)로 **정교 탐색** + **Pruning**.  
4) 발견된 근방을 **Grid로 미세 스윕**(선택).  
5) **독립 Test**로 최종 1회 평가 및 고정.  
6) **재현성/로그**: seed, 코드, 데이터 버전, best params 기록.

---

## 6) 자주 하는 실수 & 예방

- **Test를 여러 번 사용**: 과적합된 모델 선택 → 반드시 마지막에 한 번만.  
- **전처리 누수**: 스케일러/인코더를 CV 외부에서 fit → `Pipeline`으로 **CV 내부에서** fit.  
- **시계열에 KFold**: 순서 깨짐 → `TimeSeriesSplit`.  
- **잘못된 메트릭**: 불균형 데이터에서 Accuracy 사용 → F1/ROC-AUC/PR-AUC 등 목적에 맞게.  
- **스케일 무시**: 로그 스케일 파라미터를 선형 그리드로 → 탐색 낭비.  
- **탐색 공간 비현실적**: 너무 넓거나 모델 제약 무시 → 도메인 지식으로 **합리적 범위** 설정.  
- **재현성 부실**: seed/버전 누락 → 실험 관리 도구(MLflow, Weights & Biases 등) 고려.

---

## 7) 보너스: 리소스 예산이 빡빡할 때

- **Multi-fidelity**: `HalvingRandomSearchCV`, Optuna의 **HyperbandPruner**  
  → **적은 자원**으로 성능 안 좋은 후보를 조기에 탈락.  
- **partial_fit / warm_start**로 **점진 학습**(알고리즘 지원 시).  
- **샘플링/축소 데이터**로 빠른 프록시 튜닝 → 최종 전량 미세 조정.

---

## 8) 요약

- **Grid**: 간단·정밀하지만 조합 폭발. **좁은 구간** 미세탐색에 유리.  
- **Random**: 고차원·넓은 공간 **초기 탐색**에 효율적, 예산 제어 용이.  
- **Optuna(TPE)**: **적응형**으로 좋은 영역에 집중 + **Pruning**으로 속도 최적화.  
- 실무에선 **Random/Optuna로 영역 탐색 → Grid로 미세 조정 → 독립 Test로 확정**이 안정적입니다.

필요하시면 **XGBoost/LightGBM/CatBoost**에 **Optuna Pruner 콜백**을 붙인 고급 예제(시계열 CV 포함)도 이어서 정리해 드릴게요.