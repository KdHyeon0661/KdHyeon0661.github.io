---
layout: post
title: 기계학습 - 하이퍼파라미터 튜닝
date: 2025-08-20 16:25:23 +0900
category: 기계학습
---
# 하이퍼파라미터 튜닝

## 0. 준비: 튜닝의 기본 원칙

### 0.1 문제 정의와 목적 함수
튜닝은 결국 다음을 최대/최소화하는 문제입니다.
$$
\theta^\*=\arg\min_{\theta\in\mathcal{H}}\ \underbrace{\mathbb{E}_{(x,y)\sim \mathcal{D}}\big[\ell\big(y,\hat{f}(x;\theta)\big)\big]}_{\text{일반화 위험}}
$$
실무에서는 데이터를 \(K\)-Fold로 나누어 **교차검증 점수**를 목적 함수로 대체합니다.
- 분류: `ROC-AUC`, `F1(macro/weighted)`, `PR-AUC(AP)`, `Balanced Accuracy`
- 회귀: `RMSE`, `MAE`, `R²` (불균형/이상치 많으면 `MAE`·`Huber`)
- 비용기반: FP/FN 비용이 다르면 **커스텀 스코어**를 정의

### 0.2 데이터 분할/검증
- **Train/Validation/Test** 분리 또는 **(Stratified) K-Fold** 사용  
- **시계열**은 `TimeSeriesSplit`(셔플 금지), 누수 방지(라벨 기간 격리)  
- **그룹 누수**(동일 사용자/세션)는 `GroupKFold`/`StratifiedGroupKFold`

### 0.3 파이프라인과 누수 방지
스케일링/인코딩/특징 선택/차원축소 등은 모두 **`Pipeline`** 안에 두고 **CV 내부**에서 `fit`되어야 합니다.

### 0.4 탐색 예산과 멈춤
- 예산 = **실험 횟수(Trials)** × **CV 폴드 수** × **훈련 비용**  
- 조기중단(Early Stopping/Pruning), **multi-fidelity**(적은 에폭·데이터로 1차 거르기)로 낭비 최소화

### 0.5 재현성/추적
- `random_state/seed` 고정, 라이브러리/데이터 버전 기록  
- 실험 로깅(폴더/CSV/MLflow 등), **최종 선정 모델+파라미터**를 아카이브

---

## 1. 탐색 공간 설계(가장 중요한 단계)

| 유형 | 예 | 권장 스케일/분포 | 시작 범위 가이드(예시) |
|---|---|---|---|
| 학습률 | `learning_rate`, `eta` | **log** (`[1e-4, 3e-1]`) | 부스팅/딥러닝: 1e-3~1e-1 |
| 규제 | `C`(SVM/LogReg), `alpha/lambda` | **log** | `C∈[1e-3,1e3]`, `lambda∈[1e-5,10]` |
| 깊이/리프 | `max_depth`, `min_samples_leaf` | **정수/이산** | depth 3~12, leaf 1~64 |
| 샘플링 | `subsample`, `colsample_bytree` | **연속[0,1]** | 0.6~1.0 |
| 커널 폭 | `gamma` | **log** | `1e-4~1` |
| 임계값 | 분류 threshold | **연속[0,1]** | F1/비용 기준으로 튜닝 |

**팁**
- 스케일 민감 파라미터는 **로그 스케일**로 잡으면 탐색 효율↑  
- **조건부 공간**: 예) `booster='dart'`일 때만 `dropout_rate` 탐색  
- 너무 넓은 범위는 **예산 낭비**, 너무 좁으면 **최적 놓침** → 도메인 지식으로 1차 축소

---

## 2. Grid Search (격자 탐색)

### 2.1 개념/장단점
- **전수조사**: 지정한 후보 조합을 모두 평가  
- 장점: 단순, 재현성/해석 용이, **미세 스윕**에 적합  
- 단점: 조합 폭발(고차원·연속형 비효율)

### 2.2 코드 (scikit-learn + Pipeline)
```python
from sklearn.model_selection import GridSearchCV, StratifiedKFold
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVC

pipe = Pipeline([("scaler", StandardScaler()), ("svc", SVC(probability=True))])

param_grid = {
    "svc__kernel": ["rbf"],
    "svc__C": [1e-2, 1e-1, 1, 10, 100],
    "svc__gamma": [1e-3, 1e-2, 1e-1, 1.0],
}

cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
gs = GridSearchCV(pipe, param_grid, cv=cv, scoring="f1_macro", n_jobs=-1)
gs.fit(X, y)

print(gs.best_score_, gs.best_params_)
best_model = gs.best_estimator_
```

### 2.3 가속: Successive Halving(멀티-피델리티)
```python
from sklearn.experimental import enable_halving_search_cv  # noqa
from sklearn.model_selection import HalvingGridSearchCV

hgs = HalvingGridSearchCV(
    pipe, param_grid, factor=3, resource="n_estimators",
    max_resources=512, scoring="roc_auc", cv=cv, n_jobs=-1
)
```
**아이디어**: 적은 자원(에폭/트리수)으로 1차 평가 → 상위만 **자원을 늘려** 재평가.

---

## 3. Random Search (무작위 탐색)

### 3.1 개념/장단점
- **분포/범위**에서 무작위 표본, 실험 횟수 `n_iter`로 예산 통제  
- 장점: 고차원에서 Grid보다 **좋은 해를 빠르게** 찾기 쉬움  
- 단점: 적응형 정밀화는 없음(완전 무작위)

### 3.2 코드
```python
from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold
from scipy.stats import loguniform, randint
from sklearn.ensemble import RandomForestClassifier
from sklearn.pipeline import Pipeline

pipe = Pipeline([("clf", RandomForestClassifier(random_state=42))])

param_dist = {
    "clf__n_estimators": randint(200, 1200),
    "clf__max_depth": randint(3, 20),
    "clf__min_samples_split": randint(2, 30),
    "clf__min_samples_leaf": randint(1, 20),
    "clf__max_features": ["sqrt", "log2", None],
}

cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
rs = RandomizedSearchCV(
    pipe, param_distributions=param_dist, n_iter=60, cv=cv,
    scoring="roc_auc", n_jobs=-1, random_state=42
)
rs.fit(X, y)
print(rs.best_score_, rs.best_params_)
```

### 3.3 멀티-피델리티 변형
```python
from sklearn.experimental import enable_halving_search_cv  # noqa
from sklearn.model_selection import HalvingRandomSearchCV

hrs = HalvingRandomSearchCV(
    pipe, param_dist, factor=3, resource="n_estimators",
    max_resources=1024, scoring="roc_auc", cv=cv, n_jobs=-1
)
```

---

## 4. Optuna (TPE + Pruning) — 실무 추천

### 4.1 TPE 직관(요약 수식)
좋은 trial 집합 \(\mathcal{L}\)과 나쁜 trial 집합 \(\mathcal{G}\)로 나누고, 각각의 밀도 \(l(x)=p(x\,|\,y \in \mathcal{L})\), \(g(x)=p(x\,|\,y \in \mathcal{G})\)를 추정합니다.  
획득 기준은 **\(l(x)/g(x)\) 최대화** 방향으로 샘플링하여 좋은 영역을 점차 집중 탐색합니다.

### 4.2 기본 패턴 (scikit-learn 모델 튜닝)
```python
import optuna
from sklearn.model_selection import cross_val_score, StratifiedKFold
from sklearn.ensemble import GradientBoostingClassifier

def objective(trial):
    params = {
        "n_estimators": trial.suggest_int("n_estimators", 100, 800),
        "learning_rate": trial.suggest_float("learning_rate", 1e-3, 0.3, log=True),
        "max_depth": trial.suggest_int("max_depth", 2, 6),
        "subsample": trial.suggest_float("subsample", 0.5, 1.0),
        "min_samples_split": trial.suggest_int("min_samples_split", 2, 40),
    }
    model = GradientBoostingClassifier(**params, random_state=42)
    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
    score = cross_val_score(model, X, y, cv=cv, scoring="roc_auc", n_jobs=-1).mean()
    return score

study = optuna.create_study(
    direction="maximize",
    sampler=optuna.samplers.TPESampler(seed=42),
    pruner=optuna.pruners.MedianPruner(n_startup_trials=10),
)
study.optimize(objective, n_trials=100)
print("Best AUC:", study.best_value)
print("Params :", study.best_params)
```

### 4.3 XGBoost/LightGBM + Pruning 콜백
```python
# XGBoost
import xgboost as xgb
from sklearn.model_selection import StratifiedKFold
from optuna.integration import XGBoostPruningCallback

def objective(trial):
    params = {
        "booster": trial.suggest_categorical("booster", ["gbtree","dart"]),
        "eta": trial.suggest_float("eta", 1e-3, 0.3, log=True),
        "max_depth": trial.suggest_int("max_depth", 3, 12),
        "subsample": trial.suggest_float("subsample", 0.5, 1.0),
        "colsample_bytree": trial.suggest_float("colsample_bytree", 0.5, 1.0),
        "lambda": trial.suggest_float("lambda", 1e-5, 10.0, log=True),
        "alpha": trial.suggest_float("alpha", 1e-5, 10.0, log=True),
        "eval_metric": "auc",
        "tree_method": "hist",
        "random_state": 42,
    }
    if params["booster"] == "dart":
        params["rate_drop"] = trial.suggest_float("rate_drop", 0.0, 0.3)

    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
    dtrain = xgb.DMatrix(X, label=y)
    pruner = XGBoostPruningCallback(trial, "validation-auc")
    cv_res = xgb.cv(
        params, dtrain, num_boost_round=2000, nfold=5, stratified=True,
        early_stopping_rounds=100, callbacks=[pruner], seed=42
    )
    return float(cv_res["test-auc-mean"].max())

study = optuna.create_study(direction="maximize")
study.optimize(objective, n_trials=80)
```

```python
# LightGBM
import lightgbm as lgb
from optuna.integration import LightGBMPruningCallback

def objective(trial):
    params = {
        "objective": "binary",
        "metric": "auc",
        "learning_rate": trial.suggest_float("learning_rate", 1e-3, 0.2, log=True),
        "num_leaves": trial.suggest_int("num_leaves", 15, 255),
        "feature_fraction": trial.suggest_float("feature_fraction", 0.6, 1.0),
        "bagging_fraction": trial.suggest_float("bagging_fraction", 0.6, 1.0),
        "bagging_freq": trial.suggest_int("bagging_freq", 1, 10),
        "min_data_in_leaf": trial.suggest_int("min_data_in_leaf", 10, 200),
        "lambda_l1": trial.suggest_float("lambda_l1", 1e-6, 10.0, log=True),
        "lambda_l2": trial.suggest_float("lambda_l2", 1e-6, 10.0, log=True),
        "verbosity": -1,
        "seed": 42,
    }
    dtrain = lgb.Dataset(X, label=y)
    pruning_cb = LightGBMPruningCallback(trial, "auc")
    cv_res = lgb.cv(
        params, dtrain, nfold=5, num_boost_round=4000, early_stopping_rounds=200,
        callbacks=[pruning_cb], stratified=True, seed=42
    )
    return max(cv_res["auc-mean"])

study = optuna.create_study(direction="maximize")
study.optimize(objective, n_trials=80)
```

### 4.4 조건부 공간/멀티목적/병렬
```python
def objective(trial):
    booster = trial.suggest_categorical("booster", ["gbtree","dart"])
    if booster == "gbtree":
        depth = trial.suggest_int("max_depth", 4, 10)
    else:
        depth = trial.suggest_int("max_depth", 3, 8)
    # ...
    return score

# 멀티목적 예: AUC 최대 & 추론지연 최소
study = optuna.create_study(directions=["maximize","minimize"])
```
병렬/재개:
```python
study = optuna.create_study(
    direction="maximize",
    storage="sqlite:///study.db", load_if_exists=True
)
# 여러 프로세스/머신에서 study.optimize(...) 동시 실행 가능
```

---

## 5. 시계열/그룹 데이터 튜닝

- **TimeSeriesSplit**: 검증 폴드가 미래 데이터를 사용하지 않도록 보장  
- **Purged/Embargo**(고급): 레이블 윈도 겹침 제거(금융 시계열)  
- **GroupKFold**: 동일 사용자/세션이 Train/Val에 동시에 존재하지 않도록

```python
from sklearn.model_selection import TimeSeriesSplit
tscv = TimeSeriesSplit(n_splits=5)
# RandomizedSearchCV(cv=tscv, ...) 와 같이 사용
```

---

## 6. 임계값/후처리까지 함께 튜닝하기

많은 분류기는 **확률/점수**를 내고 임계값으로 레이블을 만듭니다.  
목표가 F1/비용 최소라면 **임계값 \(\tau\)** 도 함께 최적화합니다.

### 6.1 간단한 그리드로 F1 최대 임계값
```python
import numpy as np
from sklearn.metrics import f1_score
from sklearn.model_selection import StratifiedKFold

def cv_f1_with_threshold(pipe, X, y, thr_grid=np.linspace(0.2,0.8,25)):
    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
    best_f1, best_thr = -1, 0.5
    for thr in thr_grid:
        f1s = []
        for tr, va in skf.split(X, y):
            pipe.fit(X.iloc[tr], y.iloc[tr])
            p = pipe.predict_proba(X.iloc[va])[:,1]
            pred = (p >= thr).astype(int)
            f1s.append(f1_score(y.iloc[va], pred))
        m = np.mean(f1s)
        if m > best_f1:
            best_f1, best_thr = m, thr
    return best_f1, best_thr
```

### 6.2 Optuna로 임계값 동시 최적화
```python
def objective(trial):
    # ... 하이퍼파라미터 제안/모델 정의 ...
    thr = trial.suggest_float("threshold", 0.2, 0.8)
    # CV 루프에서 proba → (>=thr)로 예측, F1 평균 반환
    return mean_f1
```

**주의**: **확률 보정(calibration)** 후 임계값을 정하면 비용 기반 의사결정에 더 견고합니다(§ 10.3).

---

## 7. 멀티-피델리티/리소스 절약 전략

| 전략 | 아이디어 | 적용 예 |
|---|---|---|
| Successive Halving/Hyperband | 적은 자원으로 대량 후보 평가 → 상위만 자원 증액 | `Halving*SearchCV`, Optuna `HyperbandPruner` |
| Early Stopping | 에폭/트리 수 자동 중단 | XGBoost/LightGBM/딥러닝 |
| 다운샘플 | 데이터 일부로 1차 거른 후 전량 미세 튜닝 | 이미지/텍스트 대용량 |
| `warm_start`/`partial_fit` | 이전 해에서 이어서 학습 | 일부 스킵/증분 학습 가능 모델 |

---

## 8. 알고리즘별 플레이북(현업 감각치)

### 8.1 선형/로지스틱/SVM
- 스케일 **필수** (`StandardScaler`)  
- `C`(규제 역수) **log 스케일** 탐색, SVM `gamma`도 log  
- 불균형: `class_weight="balanced"` + 임계값 튜닝

### 8.2 트리/랜덤포레스트/GBDT
- 과적합: `max_depth`, `min_samples_leaf`, `subsample`(0.6~0.9)  
- 부스팅: `learning_rate`↓, `n_estimators`↑, `early_stopping_rounds`  
- 범주형: OHE 또는 LightGBM의 **native categorical**(가능 시)

### 8.3 XGBoost/LightGBM/CatBoost
- **중요**: 학습률 `1e-2~1e-1` 범위 log 탐색  
- `num_leaves`~`max_depth` 균형, L1/L2 규제, `min_data_in_leaf`  
- **Pruning + EarlyStopping**로 예산 절약

### 8.4 신경망(간략)
- 학습률/스케줄(코사인/Step), 배치 크기, weight decay, dropout  
- **데이터 증강**이 큰 효과 → 학습률/증강 강도 동시 튜닝  
- Optuna로 **레이어 너비/드롭아웃/정규화** 조건부 공간 탐색

---

## 9. 보고/선정/재현성

- **CV 평균±표준편차**로 보고(스코어 분산도 중요)  
- 모델간 비교는 **동일 폴드 분할**로 공정하게  
- 최종 모델은 **독립 Test**에 **딱 한 번** 평가  
- 결과/파라미터/시드/환경(패키지 버전) **모두 기록**  
- 중요하면 **부트스트랩 신뢰구간**(예: AUC 95% CI)도 병기

---

## 10. 자주 하는 실수 & 예방

| 실수 | 증상 | 예방/해법 |
|---|---|---|
| Test를 반복 사용 | 최적화된 테스트 점수(허상) | **최종 1회**만 사용 |
| 전처리 누수 | CV 성능 과대평가 | 전처리 **Pipeline**으로 CV 내부 `fit` |
| 시계열 셔플 | 미래 정보 유출 | `TimeSeriesSplit` |
| 잘못된 스코어 | 불균형에서 Accuracy 남용 | 목적에 맞는 지표(F1/PR-AUC 등) |
| 스케일 무시 | SVM/로지스틱 불안정 | `StandardScaler` |
| 로그 스케일 미적용 | 학습률/규제 튜닝 비효율 | `log=True` 샘플링 |
| 임계값 고정 | F1/비용 최적 미달 | **threshold 튜닝** |
| 확률 불보정 | 비용 기반 의사결정 흔들림 | **Calibration**(Platt/Isotonic) |
| 그룹 누수 | 같은 사용자 Train/Val 동시 | `GroupKFold` |
| 데이터 증강/오버샘플 누수 | CV 과대평가 | **폴드 내부**에서만 fit |

### 10.1 Calibration 예시 (Brier/등가선)
```python
from sklearn.calibration import CalibratedClassifierCV, calibration_curve
from sklearn.metrics import brier_score_loss

base = best_model  # 또는 파이프라인
cal = CalibratedClassifierCV(base, method="isotonic", cv=5)
cal.fit(X, y)
# brier_score로 보정 전/후 품질 비교, calibration_curve 시각화
```

---

## 11. 실전 코드 모음 (끝판왕 스니펫)

### 11.1 End-to-End 튜닝 파이프라인(분류)
```python
# 1. 데이터/파이프라인
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.impute import SimpleImputer
from sklearn.model_selection import StratifiedKFold, cross_validate
from sklearn.metrics import make_scorer, f1_score, roc_auc_score
from sklearn.ensemble import HistGradientBoostingClassifier

num_cols = ["num1","num2","num3"]
cat_cols = ["cat1","cat2"]

numeric = Pipeline([("imputer", SimpleImputer(strategy="median")), ("scaler", StandardScaler())])
categorical = Pipeline([("imputer", SimpleImputer(strategy="most_frequent")),
                        ("ohe", OneHotEncoder(handle_unknown="ignore"))])

prep = ColumnTransformer([("num", numeric, num_cols), ("cat", categorical, cat_cols)])

pipe = Pipeline([("prep", prep), ("clf", HistGradientBoostingClassifier(random_state=42))])

# 2. Optuna로 튜닝
import optuna
from sklearn.model_selection import cross_val_score

def objective(trial):
    clf = HistGradientBoostingClassifier(
        learning_rate=trial.suggest_float("lr", 1e-3, 0.2, log=True),
        max_depth=trial.suggest_int("max_depth", 3, 20),
        min_samples_leaf=trial.suggest_int("min_samples_leaf", 10, 200),
        l2_regularization=trial.suggest_float("l2", 1e-6, 1.0, log=True),
        max_bins=255,
        random_state=42
    )
    model = Pipeline([("prep", prep), ("clf", clf)])
    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
    score = cross_val_score(model, X, y, cv=cv, scoring="roc_auc", n_jobs=-1).mean()
    return score

study = optuna.create_study(direction="maximize", sampler=optuna.samplers.TPESampler(seed=42))
study.optimize(objective, n_trials=80)
best_params = study.best_params

# 3. 최종 학습/보고
best_clf = HistGradientBoostingClassifier(
    learning_rate=best_params["lr"],
    max_depth=best_params["max_depth"],
    min_samples_leaf=best_params["min_samples_leaf"],
    l2_regularization=best_params["l2"],
    max_bins=255, random_state=42
)
final = Pipeline([("prep", prep), ("clf", best_clf)])
cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
scores = cross_validate(final, X, y, cv=cv, scoring=["roc_auc","f1","accuracy"], n_jobs=-1)
print({k: (scores[f"test_{k}"].mean(), scores[f"test_{k}"].std()) for k in ["roc_auc","f1","accuracy"]})
```

### 11.2 HalvingRandomSearchCV로 빠른 초기 탐색
```python
from sklearn.experimental import enable_halving_search_cv  # noqa
from sklearn.model_selection import HalvingRandomSearchCV
from scipy.stats import randint, loguniform

param_dist = {
    "clf__max_depth": randint(3, 20),
    "clf__min_samples_leaf": randint(5, 100),
    "clf__l2_regularization": loguniform(1e-6, 1),
    "clf__learning_rate": loguniform(1e-3, 0.2),
}

hrs = HalvingRandomSearchCV(
    estimator=pipe, param_distributions=param_dist,
    factor=3, resource="clf__max_iter", max_resources=512,
    scoring="roc_auc", cv=StratifiedKFold(5, shuffle=True, random_state=42),
    n_jobs=-1, random_state=42
)
hrs.fit(X, y)
```

### 11.3 시계열: TimeSeriesSplit + Optuna
```python
from sklearn.model_selection import TimeSeriesSplit

def objective(trial):
    clf = xgb.XGBRegressor(
        n_estimators=trial.suggest_int("n_estimators", 200, 1200),
        eta=trial.suggest_float("eta", 1e-3, 0.2, log=True),
        max_depth=trial.suggest_int("max_depth", 3, 10),
        subsample=trial.suggest_float("subsample", 0.6, 1.0),
        colsample_bytree=trial.suggest_float("colsample_bytree", 0.6, 1.0),
        reg_lambda=trial.suggest_float("reg_lambda", 1e-5, 10, log=True),
        reg_alpha=trial.suggest_float("reg_alpha", 1e-5, 10, log=True),
        tree_method="hist", random_state=42
    )
    model = Pipeline([("prep", prep), ("clf", clf)])
    tscv = TimeSeriesSplit(n_splits=5)
    scores = cross_val_score(model, X, y, cv=tscv, scoring="neg_root_mean_squared_error", n_jobs=-1)
    return scores.mean()  # 더 클수록 좋으므로 그대로 사용
```

---

## 12. 체크리스트(현업용)

- [ ] 목적 지표/비용 함수 명확화(불균형·임계값 정책 포함)  
- [ ] 전처리·특징 공학을 **Pipeline**에 포함, CV 내부 `fit`  
- [ ] 데이터 분할 전략(시계열/그룹/층화) 적정성 확인  
- [ ] 탐색 공간: 로그/정수/조건부/제약 반영, 비현실적 범위 제거  
- [ ] 초기 탐색(Random/Optuna 짧게) → 유망영역 미세 Grid  
- [ ] 멀티-피델리티/Pruning/ES로 예산 절감  
- [ ] 임계값/확률 보정 필요 시 함께 튜닝  
- [ ] 결과는 **CV 평균±표준편차**로 보고, 동일 폴드 비교  
- [ ] 최종 1회 Test, 파라미터/시드/버전/아티팩트 아카이브

---

## 13. 요약

- **Grid**: 단순·안정, **좁은 구간 미세탐색**에 강함.  
- **Random**: **초기 넓은 공간**에서 효율적, 예산 통제 용이.  
- **Optuna(TPE)**: **적응형 탐색 + Pruning**으로 실무 효율 최고.  
- 튜닝의 성패는 **탐색 공간 설계**와 **검증/누수 방지**, **목표 지표/임계값 정책**에 달려 있습니다.  
- 권장 플로우: **Random/Optuna로 영역 찾기 → Grid로 미세 조정 → 독립 Test로 확정**.

부족한 부분(예: CatBoost/딥러닝 스케줄 탐색, 다목적 최적화 리포트, 실험 로깅 템플릿)이 더 필요하면 바로 이어서 확장하겠습니다.