---
layout: post
title: 미적분 - 편도함수의 심화학습
date: 2025-08-07 23:25:23 +0900
category: 미적분
---
# 편도함수의 심화학습 — 정의의 정밀화, 미분가능성과 편도연속, 혼합편도(Clairaut–Schwarz), 고계 편도와 다변수 테일러, 헤시안·볼록성, 암시적/역함수 정리, 수치 검증까지

## 0. 표기와 기본 정의의 정밀화

- 도메인 \(U\subset\mathbb{R}^n\), 스칼라장 \(f:U\to\mathbb{R}\), 벡터장 \(F:U\to\mathbb{R}^m\).
- **편도함수**:
  $$
  \frac{\partial f}{\partial x_i}(a)=\lim_{h\to 0}\frac{f(a_1,\dots,a_i+h,\dots,a_n)-f(a)}{h}
  $$
  존재하면 \(x_i\)-방향 **편도함수** 존재.
- **방향도함수(게이트형)**:
  $$
  D_{\mathbf{v}}f(a)=\lim_{t\to 0}\frac{f(a+t\mathbf{v})-f(a)}{t},\qquad \|\mathbf{v}\|=1.
  $$
- **미분가능성(Fréchet)**: 선형사상 \(L:\mathbb{R}^n\to\mathbb{R}\)가 존재하여
  $$
  f(a+h)=f(a)+L(h)+o(\|h\|)\quad (h\to 0).
  $$
  이때 \(L(h)=\nabla f(a)\cdot h\), 즉 **전미분 \(df_a\)**가 존재하고 **접평면**이 제대로 정의된다.

> 핵심 경고: 모든 편도함수가 존재해도 \(f\)가 **미분가능**이 아닐 수 있다(반례 다수). 반대로 \(\nabla f\)가 **연속**이면 (즉 \(f\in C^1\)) 미분가능.

---

## 1. 미분가능성 vs 편도함수 존재: 정교한 구분

### 1.1 편도함수는 있으나 미분가능하지 않은 고전 반례
다음 \(f:\mathbb{R}^2\to\mathbb{R}\)를 보자.
$$
f(x,y)=
\begin{cases}
\dfrac{x^2y}{x^4+y^2}, & (x,y)\neq (0,0),\\[4pt]
0,& (x,y)=(0,0).
\end{cases}
$$
모든 방향에서 편도함수가 존재하지만 \((0,0)\)에서 **연속**도 아니고, 따라서 **미분가능**도 아니다.  
(경로 \(y=x^2\)로 접근하면 \(f(x,x^2)=\frac{x^4}{x^4+x^4}=\frac12\not\to 0\) 등.)

### 1.2 편도함수는 연속이나 혼합편도 교환이 깨지는 예?
연속 편도함수가 있는 경우(정확히는 \(C^1\))엔 그래디언트가 연속이므로 혼합편도 1계 레벨에서 문제가 생기진 않는다. **교환 문제**는 **2계 혼합편도**에서 발생: 연속성이 부족하면 \(\partial_{xy}\neq \partial_{yx}\) 가능(§3 참조).

### 1.3 미분가능성의 충분조건
- \(f\in C^1\) (즉 \(\nabla f\)가 **연속**)이면 \(f\)는 모든 점에서 미분가능.
- 보다 약하게, 각 편도함수가 **근방에서 립시츠**(국소 L-리프시츠)면 Rademacher 정리에 의해 거의 모든 점에서 미분가능(심화: 측도론적 이슈).

---

## 2. 방향도함수·게이트 미분 vs 프레셰 미분

- **게이트(방향) 미분**: 모든 단위 방향 \(\mathbf{v}\)에 대해 \(D_{\mathbf{v}}f(a)\) 존재.  
- **프레셰 미분**: 위에서 본 선형사상 \(L\)이 존재.  

**중요**: 모든 방향도함수가 존재해도 \(f\)가 프레셰 미분가능임을 **보장하지 않는다**.  
그러나 \(f\)가 프레셰 미분가능이면 모든 방향도함수가 존재하고
$$
D_{\mathbf{v}}f(a)=\nabla f(a)\cdot \mathbf{v}.
$$

---

## 3. 혼합편도 및 Clairaut–Schwarz 정리

### 3.1 정의
2계 혼합편도:
$$
\frac{\partial^2 f}{\partial x\partial y}(a)
=\frac{\partial}{\partial x}\left(\frac{\partial f}{\partial y}\right)(a),\qquad
\frac{\partial^2 f}{\partial y\partial x}(a)
=\frac{\partial}{\partial y}\left(\frac{\partial f}{\partial x}\right)(a).
$$

### 3.2 정리(Clairaut–Schwarz)
개방집합 \(U\)에서 \(f\)의 2계 혼합편도들 \(\partial_{xy}f,\,\partial_{yx}f\)가 **근방에서 연속**이면, 모든 점에서
$$
\partial_{xy}f=\partial_{yx}f.
$$

### 3.3 반례(연속성 부족 시)
혼합편도가 존재하지만 한쪽이 불연속이라서 두 혼합편도가 서로 다른 예가 있다(문헌상 고전 예). 결론: **연속성 가정**이 중요.

---

## 4. 고계 편도, 멀티인덱스, 다변수 테일러 정리

### 4.1 멀티인덱스 표기
- 멀티인덱스 \(\alpha=(\alpha_1,\dots,\alpha_n)\in \mathbb{N}^n\),
  \(|\alpha|=\alpha_1+\cdots+\alpha_n\),
  \(\alpha!=\alpha_1!\cdots \alpha_n!\).
- 편도 연산자: \(D^\alpha f=\partial^{|\alpha|}f/\partial x_1^{\alpha_1}\cdots \partial x_n^{\alpha_n}\).
- 모노미얼: \(x^\alpha = x_1^{\alpha_1}\cdots x_n^{\alpha_n}\).

### 4.2 다변수 테일러(정리 형태)
\(f\in C^{k+1}(U)\), \(a\in U\), \(a+h\in U\)이면
$$
f(a+h)=\sum_{|\alpha|\le k} \frac{D^\alpha f(a)}{\alpha!}h^\alpha
+\sum_{|\beta|=k+1}\frac{D^\beta f(a+\theta h)}{\beta!}h^\beta,
\quad \text{어떤 }\theta\in(0,1).
$$
잔차는 Lagrange형 또는 Peano형으로 기술 가능:
$$
f(a+h)=\sum_{|\alpha|\le k} \frac{D^\alpha f(a)}{\alpha!}h^\alpha + o(\|h\|^k).
$$

### 4.3 2차까지의 전개(자주 쓰는 형태, \(n\)-변수)
$$
f(a+h)=f(a)+\nabla f(a)\cdot h + \frac12 h^\top H_f(a)h + o(\|h\|^2),
$$
여기서 \(H_f(a)\)는 **헤시안**(2계 편도들의 대칭행렬, \(C^2\)이면 \(H=H^\top\)).

---

## 5. 헤시안, 양의정부호, 극값 판정(심화)

### 5.1 극값의 필요조건
내부 극값이면 \(\nabla f(a)=0\).

### 5.2 충분조건(2차 판정)
- \(H_f(a)\) **양의정부호** \(\Rightarrow\) **엄격한 국소극솟값**.
- 음의정부호 \(\Rightarrow\) 엄격한 국소극댓값.
- 부정부호(한쪽 양·한쪽 음) \(\Rightarrow\) 안장점(saddle).
- 준정부호(양의 준정부호 등) \(\Rightarrow\) 추가 고계항 분석 필요.

### 5.3 Sylvester 판정법(대칭행렬)
\(2\times 2\)의 경우:
- \(H=\begin{bmatrix}f_{xx}&f_{xy}\\ f_{yx}&f_{yy}\end{bmatrix}\), \(f_{xy}=f_{yx}\).
- \(D_1=f_{xx}\), \(D_2=\det H=f_{xx}f_{yy}-f_{xy}^2\).
  - \(D_1>0, D_2>0\) \(\Rightarrow\) 양의정부호.
  - \(D_2<0\) \(\Rightarrow\) 부정부호.
  - \(D_1<0, D_2>0\) \(\Rightarrow\) 음의정부호.

---

## 6. 편도함수와 연쇄법칙(다변수 체인룰)의 정교화

### 6.1 합성 \(f\circ g\) — \(g:\mathbb{R}^m\to\mathbb{R}^n\), \(f:\mathbb{R}^n\to\mathbb{R}\)
미분가능하면(야코비안 \(J_g\), 그래디언트 \(\nabla f\)):
$$
\nabla(f\circ g)(u)=J_g(u)^\top \nabla f(g(u)).
$$
성분형:
$$
\frac{\partial (f\circ g)}{\partial u_i}
=\sum_{j=1}^n \frac{\partial f}{\partial x_j}(g(u))\frac{\partial g_j}{\partial u_i}(u).
$$

### 6.2 계층적 합성(심화): \(h(x)=f(g(x),x)\)
$$
\nabla h(x)=J_g(x)^\top \nabla_1 f(g(x),x)+\nabla_2 f(g(x),x),
$$
여기서 \(\nabla_1\)은 첫 번째 블록( \(g\)-출력에 대한 그레디언트), \(\nabla_2\)는 두 번째 블록(직접 \(x\)에 대한 그레디언트).

---

## 7. 암시적함수 정리·역함수 정리(편도 관점)

### 7.1 암시적함수 정리(스칼라)
\(F(x,y)=0\)에서 \(F\in C^1\), \(F_y(a,b)\neq 0\)이면, 근방에서 \(y=\varphi(x)\) 유일하게 존재하고
$$
\varphi'(x)=-\frac{F_x(x,\varphi(x))}{F_y(x,\varphi(x))}.
$$
다변수 버전: \(F(x,y)=0\), \(F_y\) (야코비안) 가역이면 \(y=\varphi(x)\) (국소) 존재 및 편도함수:
$$
D\varphi(x)=-F_y(x,\varphi(x))^{-1}F_x(x,\varphi(x)).
$$

### 7.2 역함수 정리
\(F:\mathbb{R}^n\to\mathbb{R}^n\), \(F\in C^1\), \(\det DF(a)\neq 0\)이면 \(F\)는 근방에서 역함수 \(F^{-1}\)를 가지며
$$
D(F^{-1})(F(a))=[DF(a)]^{-1}.
$$

> 편도 구조로 보면 **야코비안의 비특이성**이 국소역함수를 보장한다.

---

## 8. 고급 미분가능성 계층: \(C^k\), Hölder, Lipschitz

- \(C^k\): \(k\)계 편도함수가 **연속**.
- \(C^{k,\alpha}\) (Hölder): \(k\)계 편도함수가 \(\alpha\)-Hölder(\(0<\alpha\le 1\)).
- \(C^{1,1}\) (그래디언트 립시츠): \(\|\nabla f(x)-\nabla f(y)\|\le L\|x-y\|\).  
  → 2차 테일러의 잔차가 \(O(\|h\|^2)\), 최적화에서 **스무스성**의 핵심.

---

## 9. 편도함수·볼록성·강볼록성(최적화 연결)

- \(f\) **볼록** \(\iff\) \(\nabla^2 f(x)\) **양의 준정부호**(a.e. 또는 의미 있는 곳에서).
- **강볼록**(\(\mu>0\)) \(\iff\) \(\nabla^2 f(x)\succeq \mu I\).
- **L-스무스** \(\iff\) \(\nabla^2 f(x)\preceq L I\) (a.e.).  
  → 경사하강법의 수렴율에 직접 반영(\(\kappa=L/\mu\)).

---

## 10. PDE 관점의 편도: 라플라시안, 디버전스, 회전

- **라플라시안**: \(\Delta f=\sum_i \partial_{x_i x_i} f=\mathrm{tr}\,H_f\).  
  조화함수(\(\Delta f=0\))의 정규성·평활성 논의는 고급편.
- **디버전스/컬**: 벡터장의 편도 조합(여기서는 편도-연산자의 구성물이 PDE의 기본 벽돌임을 강조).

---

## 11. 예제 모음(이론→계산→판정)

### 11.1 미분가능성 vs 편도 존재
다음 함수를 분석하라.
$$
f(x,y)=
\begin{cases}
\dfrac{x^2y}{x^4+y^2}, & (x,y)\neq (0,0),\\
0,&(x,y)=(0,0).
\end{cases}
$$
- \(\partial_x f, \partial_y f\)는 \((0,0)\)에서 **존재**함을 보일 수 있다(직접 극한 계산).
- 그러나 \((0,0)\)에서 **연속**이 아니므로 **미분가능**하지 않다.
- 따라서 접평면 \(z=f(0,0)+\nabla f(0,0)\cdot (x,y)\)이라는 1차 근사로 오차 \(o(\|(x,y)\|)\)를 보장할 수 없다.

### 11.2 혼합편도 교환(Clairaut–Schwarz) 확인
\(f(x,y)=x^2y^3+x y^2\sin(xy)\).  
\(f_{xy}, f_{yx}\)를 계산하여 **동일함**을 확인(편도들이 다항·원활이므로 당연히 \(C^\infty\)).

### 11.3 2차 테일러와 헤시안 판정
\(f(x,y)=x^4+2x^2y^2+y^4+x^2-2xy+y^2\)에서 \(\nabla f=0\)을 풀고, 해 \((0,0)\) 주변의 **극값 유형**을 헤시안으로 판정:
- \(H(0,0)=\begin{bmatrix}2&-2\\ -2&2\end{bmatrix}\) → 고유값 \(0,4\) (준정부호),  
  고계항(4차)을 추가로 확인해야 미세한 판정 가능(여기서는 고차항이 양수형이어서 최소임을 알 수 있음).

---

## 12. 수치 실습: SymPy/NumPy로 편도·헤시안·극값 판정

### 12.1 심볼릭 편도/헤시안·혼합편도 교환 확인
```python
import sympy as sp

x, y = sp.symbols('x y', real=True)
f = x**2 * y**3 + x*y**2 * sp.sin(x*y)

fx  = sp.diff(f, x)
fy  = sp.diff(f, y)
fxx = sp.diff(fx, x)
fxy = sp.diff(fx, y)
fyx = sp.diff(fy, x)
fyy = sp.diff(fy, y)

print("fx =", fx)
print("fy =", fy)
print("fxy =", fxy)
print("fyx =", fyx)
print("Equal mixed partials? ->", sp.simplify(fxy - fyx) == 0)

H = sp.hessian(f, (x, y))
print("Hessian =")
sp.pprint(H)
```

### 12.2 수치 헤시안 근사와 양의정부호 판정(최적화 연계)
```python
import numpy as np

def f_np(z):
    x, y = z
    return x**4 + 2*x**2*y**2 + y**4 + x**2 - 2*x*y + y**2

def grad_num(z, h=1e-6):
    z = np.asarray(z, dtype=float)
    g = np.zeros_like(z)
    for i in range(len(z)):
        e = np.zeros_like(z); e[i] = 1.0
        g[i] = (f_np(z + h*e) - f_np(z - h*e)) / (2*h)
    return g

def hessian_num(z, h=1e-4):
    # 중앙 차분 기반의 간단한 수치 헤시안
    z = np.asarray(z, dtype=float)
    n = len(z)
    H = np.zeros((n,n))
    f0 = f_np(z)
    for i in range(n):
        ei = np.zeros(n); ei[i] = 1.0
        for j in range(n):
            ej = np.zeros(n); ej[j] = 1.0
            if i <= j:
                fpp = f_np(z + h*ei + h*ej)
                fpm = f_np(z + h*ei - h*ej)
                fmp = f_np(z - h*ei + h*ej)
                fmm = f_np(z - h*ei - h*ej)
                H[i,j] = (fpp - fpm - fmp + fmm) / (4*h*h)
                if i != j:
                    H[j,i] = H[i,j]
    return H

z0 = np.array([0.0, 0.0])
g0 = grad_num(z0)
H0 = hessian_num(z0)

print("grad at 0 =", g0)
print("Hessian at 0 =\n", H0)

# 양의정부호 판정: 모든 고유값 > 0?
eigvals = np.linalg.eigvalsh(H0)
print("eigenvalues =", eigvals, " -> pos.def?", np.all(eigvals > 1e-8))
```

> 주의: 수치 헤시안은 노이즈에 민감. 실무에서는 자동 미분(autodiff)이나 심볼릭을 선호.

---

## 13. 편도함수와 좌표변환(야코비안) — 체인룰의 행렬형

### 13.1 예: 극좌표 변환의 편도
\(x=r\cos\theta,\ y=r\sin\theta\). \(f(x,y)\)를 \(g(r,\theta)=f(r\cos\theta,r\sin\theta)\)로 두면
$$
\frac{\partial g}{\partial r}=\frac{\partial f}{\partial x}\cos\theta+\frac{\partial f}{\partial y}\sin\theta,\quad
\frac{\partial g}{\partial \theta}=\frac{\partial f}{\partial x}(-r\sin\theta)+\frac{\partial f}{\partial y}(r\cos\theta).
$$
야코비안 \(J=(\partial(x,y)/\partial(r,\theta))\)의 전치가 체인룰에 정확히 들어간다.

---

## 14. 비평활 함수: 편도 존재 vs 아급미분(서브그래디언트) (간단 스케치)

- \(f(x)=\|x\|\)는 \(x=0\)에서 편도함수(프레셰 미분) 부재.  
- **서브그래디언트** \(\partial f(0)=\{g:\|g\|\le 1\}\)로 확장.  
최적화(비평활)에서는 편도 대신 서브편도 개념이 등장한다(본 글의 범위를 살짝 넘어서는 영역이라 개념만 언급).

---

## 15. 실전 시나리오

### 시나리오 A — 감도해석(sensitivity)과 체인룰
네트워크 지연 모델 \(T = f(\ell_1(\theta),\dots,\ell_m(\theta))\), \(\ell_i\)는 링크별 지연 함수, \(\theta\)는 설계변수.  
편도 \(\partial T/\partial \theta_j = \sum_i (\partial f/\partial \ell_i)(\partial \ell_i/\partial \theta_j)\).  
구성 모듈별 편도를 조합(백프로퍼게이션의 원리).

### 시나리오 B — 분류기의 강볼록 손실
로지스틱 손실 \(L(w)=\sum_i \log(1+e^{-y_i w^\top x_i})+\frac{\lambda}{2}\|w\|^2\).  
\(\nabla^2 L(w)\succeq \lambda I\) (강볼록), \(\nabla^2 L(w)\preceq \lambda I + \frac14 \sum_i x_i x_i^\top\) (스무스).  
편도·헤시안의 성질로 최적화 알고리즘 수렴율을 미리 예측.

---

## 16. 추가 예제와 연습문제(스케치 해설 포함)

### 16.1 예제: 체인룰과 혼합편도
\(f(x,y)=e^{x^2y}\), \(g(u,v)=(u+v,u-v)\), \(h=f\circ g\).  
\(\partial h/\partial u\), \(\partial h/\partial v\), \(\partial^2 h/(\partial u\partial v)\)를 구하라.  
- 풀이 스케치: \(x=u+v,\ y=u-v\). \(\nabla f(x,y) = (2xy e^{x^2y},\, x^2 e^{x^2y})\).  
  체인룰로 \(\nabla h=\begin{bmatrix}1&1\\1&-1\end{bmatrix}^\top \nabla f\).

### 16.2 예제: 암시적함수의 편도
\(F(x,y)=x^3+xy+y^3-1=0\)에서 \(y'(x)=-F_x/F_y\).  
특정 점 \((x_0,y_0)\)에서 \(F_y\neq 0\)인지 확인 후 \(y'(x_0)\)을 계산.

### 16.3 연습: 헤시안 판정
\(f(x,y)=x^2+4xy+5y^2\)의 임계점 \(\nabla f=0\)는 \((0,0)\).  
\(H=\begin{bmatrix}2&4\\4&10\end{bmatrix}\) 양의정부호(\(D_1=2>0, D_2=20-16=4>0\)) → 최소.

### 16.4 연습: 미분가능성 반례 찾기
\(f(x,y)=\frac{|xy|}{\sqrt{x^2+y^2}}\) (원점에서 정의를 0으로).  
편도 존재 여부, 연속성, 미분가능성 판단. 힌트: 경로 접근으로 점검.

---

## 17. 수치 검증: 그래디언트 체크(유한차분 vs 심볼릭/오토디프)

```python
import numpy as np

def grad_check(f, g, x0, eps=1e-6, tol=1e-4, verbose=True):
    """
    f: R^n -> R (스칼라 함수)
    g: analytic grad function
    x0: 점
    """
    x0 = np.asarray(x0, dtype=float)
    n = len(x0)
    g_analytic = g(x0)
    g_fd = np.zeros(n)
    for i in range(n):
        e = np.zeros(n); e[i]=1.0
        g_fd[i] = (f(x0 + eps*e)-f(x0 - eps*e))/(2*eps)
    rel_err = np.linalg.norm(g_fd - g_analytic)/(1e-12 + np.linalg.norm(g_fd) + np.linalg.norm(g_analytic))
    if verbose:
        print("analytic:", g_analytic, "finite-diff:", g_fd, "rel.err:", rel_err)
    return rel_err < tol

# 테스트 함수: f(x,y)=x^4+2x^2y^2+y^4 + x^2 - 2xy + y^2
def f_test(z):
    x,y = z
    return x**4 + 2*x**2*y**2 + y**4 + x**2 - 2*x*y + y**2

def g_test(z):
    x,y = z
    dfx = 4*x**3 + 4*x*y**2 + 2*x - 2*y
    dfy = 4*y**3 + 4*x**2*y - 2*x + 2*y
    return np.array([dfx, dfy])

print("grad check at (0.1, -0.2):", grad_check(f_test, g_test, [0.1, -0.2]))
```

---

## 18. 자주 하는 실수와 체크리스트

- □ **편도 존재** \(\centernot\Rightarrow\) **미분가능**. 접평면이 정말 오차 \(o(\|h\|)\)로 근사하는가를 보라.  
- □ **혼합편도 교환**은 연속성 가정(\(C^2\) 근방)이 관건.  
- □ 다변수 테일러에서 **잔차항**을 빼먹지 말 것(특히 최적화에서 근사오차의 차수).  
- □ 헤시안 판정 시 **대칭성**과 **Sylvester 판정**을 정확히.  
- □ 암시적/역함수 정리의 **야코비안 비특이성** 조건 필수.  
- □ 수치 미분은 단계 \(h\) 선택에 민감. 오차-반올림 trade-off를 고려.  
- □ 좌표변환의 편도 계산 시 **체인룰의 행렬형(야코비안 전치)**을 명확히.

---

## 19. 한 페이지 요약

- 편도함수는 방향별 한 변수 극한. **미분가능성**은 선형근사(Fréchet)의 “전역(모든 방향) 일관성”을 뜻한다.  
- \(C^1\Rightarrow\) 미분가능. 하지만 편도만으로는 부족할 수 있다(반례).  
- 혼합편도 교환(Clairaut–Schwarz)은 **연속성**이 핵심 조건.  
- 다변수 테일러와 헤시안은 고계 편도 구조의 요약이며 극값 판정의 표준 도구.  
- 암시적/역함수 정리는 야코비안의 편도 행렬 성질로 국소 구조를 보장한다.  
- 수치·최적화 실무에서 편도의 정규성(립시츠, 스무스성)은 수렴성능과 직결.

---

## 20. 확장 읽기 가이드(개요)

- 측도론적 미분가능성(Rademacher): 립시츠 함수는 **거의 모든 점**에서 미분가능.  
- 비평활 최적화: 서브편도/서브그래디언트, Clarke 미분.  
- PDE 정칙성 이론: 편도 연산자(경계값 문제) 아래에서의 해의 평활성.

---

# 부록: 추가 코드 스니펫(혼합편도 교환 수치 실험)

```python
import numpy as np

def mixed_partials_num(f, x0, h=1e-4):
    """
    f: R^2 -> R
    반환: f_xy, f_yx (중앙 차분 기반 근사)
    """
    x, y = x0
    # f_x = (f(x+h,y)-f(x-h,y))/(2h), etc.
    def fx(x, y):
        return (f([x+h, y]) - f([x-h, y]))/(2*h)
    def fy(x, y):
        return (f([x, y+h]) - f([x, y-h]))/(2*h)
    # f_xy = ∂/∂y (f_x), f_yx = ∂/∂x (f_y)
    f_xy = (fx(x, y+h) - fx(x, y-h))/(2*h)
    f_yx = (fy(x+h, y) - fy(x-h, y))/(2*h)
    return f_xy, f_yx

def f_smooth(z):  # C^∞ 예
    x,y = z
    return np.sin(x*y) + x**2*y**3

print("mixed partials at (0.5, -0.7):", mixed_partials_num(f_smooth, [0.5, -0.7]))
```

---

## 결론

편도함수는 다변수 해석의 입구이자, 미분가능성·혼합편도·테일러 전개·헤시안·최적화·PDE로 이어지는 **핵심 연결고리**다.  
실전에서는  
(1) **정규성 가정**(연속성/립시츠성/스무스성)으로 이론적 보장을 확보하고,  
(2) **체인룰·암시적/역함수**로 모델을 재구성하며,  
(3) **헤시안·볼록성**으로 극값을 판정하고,  
(4) **수치 검증**으로 구현을 신뢰할 수 있게 만드는 것이 핵심 루틴이다.