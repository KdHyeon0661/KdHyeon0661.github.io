---
layout: post
title: AWS - EMR
date: 2025-08-03 14:20:23 +0900
category: AWS
---
# AWS EMR 연계 및 활용

## 한눈에 보기 — EMR가 해결하는 문제

- **문제**: TB~PB급 데이터를 SQL/스파크/ML로 빠르게 가공·분석하고, 운영 중인 데이터 레이크/웨어하우스·실시간 파이프라인과 연결해야 함.
- **해결**: **Amazon EMR**는 Hadoop/Spark/Hive/Presto/Trino/Flink/HBase 등 **오픈소스 빅데이터 프레임워크를 관리형으로 제공**.
  선택형 배포:
  - **EMR on EC2**: 가장 전통적. 세밀 제어(인스턴스/스토리지/네트워크).
  - **EMR on EKS**: 쿠버네티스 표준으로 Spark 런타임을 **Pod**로 구동.
  - **EMR Serverless**: **서버리스**로 Spark/Hive 실행. 용량 계획·노드 운영 無.

---

## 배포 모델 비교와 선택

| 항목 | EMR Serverless | EMR on EKS | EMR on EC2 |
|---|---|---|---|
| 운영 난이도 | 매우 낮음 | 중간(쿠버네티스 지식 필요) | 높음(클러스터 직접 운영) |
| 비용 모델 | 실행량 기반(초/GB) | EKS 노드+Pod 스케줄링 | EC2/스팟/저장소 직접 |
| 튜닝 자유도 | 제한적 | 높음(K8s 자원/네트워킹) | 매우 높음(노드/디스크/AMI) |
| 사용 적합 | 배치/간헐·가변 워크로드 | 플랫폼 표준 K8s 조직 | 장기/고정 대용량·특수 요구 |
| 런타임 | Spark/Hive | Spark | Spark/Hive/Presto/Trino/Flink/HBase 등 |

**의사결정 가이드**
- 빠른 시작·관리 최소화 → **Serverless**
- 조직이 EKS 표준, Job 격리/멀티테넌시 → **on EKS**
- 최대 성능·커스텀 네트워킹/스토리지/캐시 → **on EC2**

---

## 코어 개념 정리

- **EMRFS**: S3를 HDFS처럼 사용하는 계층. **Consistent View**(DynamoDB 기반), **S3 최적화 커미터**(Spark Write 성능/원자성 향상) 제공.
- **Instance Group/Fleet**: 마스터·코어·태스크 노드 풀. **스팟 혼합**/인스턴스 다변화로 비용·안정성 최적화.
- **Managed Scaling**: 클러스터 메트릭 기반 자동 스케일 업/다운.
- **Bootstrap Action**: 노드 프로비저닝 시 사용자 스크립트 실행(라이브러리 설치/커널 튜닝).
- **EMR Steps**: Spark/Hive/Presto 등 잡을 클러스터에 순차 제출하는 디클레어러티브 단계.

---

## 아키텍처 패턴(데이터 레이크 & 분석)

```
[Ingest: Kinesis / Kafka / DMS / App / Batch]
         ↓
        [S3(로우/브론즈)]
         ↓ Spark/Hive(정제·조인·품질검사)
        [S3(실버: Parquet/ORC/Hudi/Iceberg/Delta)]
         ↓ Glue Data Catalog(스키마)
        [Athena/Redshift Spectrum/Presto/Trino/EMR]
         ↓ BI(QuickSight) / ML(SageMaker) / 서비스 API
```

- **거버넌스**: Glue Catalog + Lake Formation(권한), 버저닝/타임트래블(Hudi/Iceberg/Delta).
- **실시간**: Kinesis/MSK → Spark Structured Streaming(Flink도 가능) → S3/Hudi/Iceberg.

---

## 실습 1 — EMR Serverless로 Spark 배치 파이프라인

### Serverless 애플리케이션 생성(콘솔/CLI)

```bash
aws emr-serverless create-application \
  --name "srvless-spark" \
  --type "SPARK" \
  --release-label "emr-6.15.0"
```

### PySpark 잡 코드(로우→실버 전처리 + 파티셔닝)

```python
# file: job_etl.py

from pyspark.sql import SparkSession, functions as F

spark = (SparkSession.builder
         .appName("etl-to-parquet")
         .config("spark.sql.parquet.compression.codec", "snappy")
         .getOrCreate())

raw = spark.read.json("s3://dl-raw/events/2025/11/")

# 품질 필터 & 파생 컬럼

df = (raw
      .filter("event_type is not null and ts is not null")
      .withColumn("event_date", F.to_date(F.col("ts")))
      .withColumn("yyyymmdd", F.date_format("event_date", "yyyyMMdd")))

# + 파티션 단위 저장

(df.repartition(1, "yyyymmdd")  # 데모 목적(실제는 파일 사이즈 128~512MB 맞춤)
   .write.mode("append")
   .partitionBy("yyyymmdd")
   .format("parquet")
   .save("s3://dl-silver/events_parquet/"))
```

### 잡 제출

```bash
aws emr-serverless start-job-run \
  --application-id <app-id> \
  --execution-role-arn arn:aws:iam::<acct>:role/EMRServerlessJobRole \
  --job-driver '{
    "sparkSubmit": {
      "entryPoint": "s3://code-bucket/jobs/job_etl.py",
      "sparkSubmitParameters": "--conf spark.executor.memory=4g --conf spark.executor.cores=2 --conf spark.executor.instances=4"
    }}' \
  --configuration-overrides '{
    "monitoringConfiguration":{
      "s3MonitoringConfiguration":{"logUri":"s3://emr-logs/"},
      "cloudWatchLoggingConfiguration":{"enabled":true}
    }}'
```

- **베스트 프랙티스**
  - 파일 크기는 대략 **128~512MB**로 맞춰 **소파일 문제** 회피.
  - **컬럼형 포맷(Parquet/ORC)** + **파티셔닝(year/month/day)** + **프루닝**.
  - EMR Serverless는 제출 시점에 필요한 컴퓨팅만 할당 → **유휴 비용 없음**.

---

## 실습 2 — EMR on EC2: 클러스터 생성부터 튜닝

### 최소 클러스터(예시, CLI)

```bash
aws emr create-cluster \
  --name "emr-ec2-spark" \
  --release-label emr-6.15.0 \
  --applications Name=Hadoop Name=Spark Name=Hive \
  --ec2-attributes KeyName=mykey,SubnetId=subnet-abc123 \
  --instance-type m6i.xlarge \
  --instance-count 3 \
  --use-default-roles \
  --auto-scaling-role EMR_AutoScaling_DefaultRole \
  --log-uri s3://emr-logs/mycluster/
```

> 운영은 **Instance Fleet** + **스팟 혼합(우선순위 리스트 6~10종)** + **Managed Scaling** 권장.

### Spark 설정(동적 할당 + 최적화)

`/etc/spark/conf/spark-defaults.conf`(부트스트랩 또는 스텝으로 주입)

```
spark.dynamicAllocation.enabled=true
spark.dynamicAllocation.minExecutors=2
spark.dynamicAllocation.maxExecutors=100
spark.shuffle.service.enabled=true
spark.sql.adaptive.enabled=true
spark.sql.adaptive.skewJoin.enabled=true
spark.sql.parquet.mergeSchema=false
spark.sql.files.maxPartitionBytes=268435456
spark.sql.files.openCostInBytes=134217728
```

### EMRFS Consistent View 활성(선택)

```bash
aws emr create-cluster \
  ... \
  --configurations '[
   {"Classification":"emrfs-site","Properties":{"fs.s3.consistent":"true","fs.s3.consistent.retryCount":"5"}}
  ]'
```

- **주의**: Consistent View는 DynamoDB 비용이 발생. 최근에는 **S3 최적화 커미터**(디폴트)로 충분한 케이스 다수.

---

## 실습 3 — EMR on EKS: 쿠버네티스 표준으로 Spark

### 가상 클러스터 생성(요약)

```bash
aws emr-containers create-virtual-cluster \
  --name emr-eks \
  --container-provider '{
    "id": "my-eks-cluster",
    "type": "EKS",
    "info": {"eksInfo":{"namespace":"emr"}}
  }'
```

### Spark 잡 제출(EMR Runtime for EKS)

```bash
aws emr-containers start-job-run \
  --virtual-cluster-id <vc-id> \
  --name spark-etl \
  --execution-role-arn arn:aws:iam::<acct>:role/EMR_EKS_JobRole \
  --release-label emr-6.15.0-latest \
  --job-driver '{
    "sparkSubmitJobDriver":{
      "entryPoint":"s3://code-bucket/jobs/job_etl.py",
      "sparkSubmitParameters":"--conf spark.kubernetes.executor.request.cores=2 --conf spark.executor.instances=10"
    }}' \
  --configuration-overrides '{
    "monitoringConfiguration":{"cloudWatchMonitoringConfiguration":{"logGroupName":"emr-eks","logStreamNamePrefix":"spark"}}
  }'
```

- **장점**: EKS의 멀티테넌시·네임스페이스·네트워킹 정책을 그대로 재사용.
- **유의**: CNI 대역폭/ENI 수, Pod 보안 정책, 스팟-온디맨드 혼합 전략 고려.

---

## 카탈로그/SQL/서빙 — Glue + Athena/Spectrum

### Glue 테이블 등록(SQL)

```sql
-- 외부 스키마 매핑(예: Hive Metastore=Glue)
CREATE EXTERNAL TABLE IF NOT EXISTS silver.events_parquet(
  user_id        string,
  event_type     string,
  ts             timestamp
)
PARTITIONED BY (yyyymmdd string)
STORED AS PARQUET
LOCATION 's3://dl-silver/events_parquet/';

MSCK REPAIR TABLE silver.events_parquet; -- 파티션 로드
```

### Athena 쿼리(Ad-hoc/BI)

```sql
SELECT event_type, count(*) AS cnt
FROM silver.events_parquet
WHERE yyyymmdd BETWEEN '20251101' AND '20251110'
GROUP BY event_type
ORDER BY cnt DESC;
```

- **비용 최적화**: Parquet + 파티셔닝 + 컬럼 프루닝 → **스캔 바이트↓**.

---

## — 변경 데이터/타임트래블

| 포맷 | 장점 | 주의 |
|---|---|---|
| **Apache Hudi** | Upsert/CDC/Incremental Pull/Compaction | 인덱싱/컴팩션 튜닝 |
| **Apache Iceberg** | 스냅샷/타임트래블/Hidden Partition | **Athena/EMR** 폭넓은 지원 |
| **Delta Lake** | 강력한 ACID/Optimize/Z-Order | 엔진 호환관계/커넥터 버전 유의 |

### Spark(EMR)에서 Iceberg 예시

```python
spark.sql("CREATE NAMESPACE IF NOT EXISTS lake.silver")

spark.sql("""
CREATE TABLE IF NOT EXISTS lake.silver.events (
  user_id string, event_type string, ts timestamp
) USING iceberg
PARTITIONED BY (days(ts))
LOCATION 's3://dl-silver/iceberg/events'
""")

spark.table("raw.events").writeTo("lake.silver.events").append()

-- 타임트래블
spark.read.table("lake.silver.events@2025-11-09T22:00:00Z").show()
```

---

## — Kinesis/MSK → Structured Streaming

```python
# file: stream_enrich.py

from pyspark.sql import SparkSession, functions as F

spark = (SparkSession.builder
         .appName("kinesis-enrich")
         .getOrCreate())

events = (spark.readStream
  .format("kinesis")
  .option("streamName", "clicks")
  .option("region", "ap-northeast-2")
  .option("startingposition", "LATEST")
  .load())

json = events.select(F.from_json(F.col("data").cast("string"),
                                 "user_id string, action string, ts string").alias("j"))\
             .select("j.*")\
             .withColumn("ts", F.to_timestamp("ts"))

agg = (json
       .withWatermark("ts", "5 minutes")
       .groupBy(F.window("ts", "1 minute"), "action")
       .count())

query = (agg.writeStream
  .format("memory") # 데모. 운영은 S3/Hudi/Iceberg/Sink Connector
  .queryName("q")
  .outputMode("append")
  .start())
```

- **정확성**: **Checkpoint/S3** 설정, **Output Sinks**는 원자성 보장되는 테이블 포맷 권장.
- **지연/허용 지연**: Watermark로 늦은 이벤트 처리 제어.

---

## 보안·컴플라이언스

### 네트워크

- **전 구간 프라이빗**: EMR 노드는 **프라이빗 서브넷**, S3/STS 등은 **VPC Endpoint**로 연결.
- 보안 그룹 최소화: ALB/예외 트래픽만 화이트리스트.

### IAM

- **서비스 역할(EMR)**, **EC2 인스턴스 프로파일**, **EMR Serverless Job Role** 구분.
- S3 버킷 정책으로 **경로 단위 최소 권한**(prefix 기반).

### 데이터 암호화

- 저장: S3 **SSE-KMS**, HDFS/로컬 **LUKS**(EC2), EMR **At-Rest Encryption**.
- 전송: TLS, Hadoop RPC/Shuffle 암호화 옵션.
- 인증: Kerberos(EMR on EC2), Lake Formation(열/행 권한).

---

## 성능·비용 최적화

### 파일/포맷/파티션

- **Parquet/ORC** + **Dictionary/Statistics** → I/O 감소.
- 파티션 컬럼은 **선택도 높은 시간/지역/상태** 위주.
- **작은 파일 문제 해결**: coalesce/repartition + compaction(포맷 별).

### 클러스터/Executor 크기 산정(근사)

1) 실행기 메모리 추정:
$$
\text{mem\_per\_executor} \approx \frac{\text{node\_mem} - \text{os\_reserve}}{\text{executors\_per\_node}}
$$

2) 병렬성 추정:
$$
\text{target\_parallelism} \approx \frac{\text{input\_bytes}}{\text{block\_size}(256\text{MB} \sim 512\text{MB})}
$$

3) 코어 수:
$$
\text{executors} \times \text{cores\_per\_executor} \ge \text{target\_parallelism}
$$

> 최종 값은 **부하 테스트(k6/Locust+Spark UI)**로 보정.

### EMR on EC2 비용

- **스팟 혼합** + **인스턴스 다변화** + **Capacity-Optimized** 할당전략.
- **Managed Scaling**으로 유휴 시간 축소.
- 로그/임시 버킷 **수명주기 정책** 및 CloudWatch Logs **보존일** 설정.

---

## 오케스트레이션 — Step Functions / Airflow(MWAA)

### Step Functions로 EMR Serverless 파이프라인

```json
{
  "StartAt": "ETL",
  "States": {
    "ETL": {
      "Type": "Task",
      "Resource": "arn:aws:states:::emr-serverless:startJobRun.sync",
      "Parameters": {
        "ApplicationId": "<app-id>",
        "ExecutionRoleArn": "arn:aws:iam::<acct>:role/EMRServerlessJobRole",
        "JobDriver": {
          "SparkSubmit": {
            "EntryPoint": "s3://code-bucket/jobs/job_etl.py",
            "SparkSubmitParameters": "--conf spark.executor.instances=6"
          }
        }
      },
      "Next": "QualityCheck"
    },
    "QualityCheck": {
      "Type": "Task",
      "Resource": "arn:aws:states:::athena:startQueryExecution.sync",
      "Parameters": {
        "QueryString": "SELECT COUNT(*) FROM silver.events_parquet WHERE event_type IS NULL",
        "WorkGroup": "primary",
        "QueryExecutionContext": {"Database": "silver"}
      },
      "End": true
    }
  }
}
```

### Airflow(MWAA)

- `EmrServerlessStartJobOperator`, `EmrAddStepsOperator` 등 사용.
- SLA/리트라이/브랜치/백필 자동화.

---

## 모니터링·디버깅

- **Spark UI**(히스토리 서버), **YARN UI**(on EC2), **CloudWatch Metrics/Logs**, S3 로그 아카이브.
- **EMR Serverless**: 잡별 드라이버/익스큐터 로그 링크.
- 병목: **Shuffle/Skew/GC/스몰 파일/조인 키 정렬**.
  - **AQE**(Adaptive Query Execution), **Skew Join** 활성.
  - 브로드캐스트 조인 임계값 조정(`spark.sql.autoBroadcastJoinThreshold`).

---

## 예제 — 배치 ETL → 품질 점검 → Iceberg 머지 → Athena 서빙

### PySpark(집계·차원 조인·SCD 업서트: Iceberg MERGE)

```python
# file: job_scd_merge.py

from pyspark.sql import SparkSession, functions as F

spark = (SparkSession.builder
         .appName("scd-merge-iceberg")
         .config("spark.sql.extensions", "org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions")
         .config("spark.sql.catalog.lake", "org.apache.iceberg.spark.SparkCatalog")
         .config("spark.sql.catalog.lake.warehouse", "s3://dl-silver/iceberg/")
         .config("spark.sql.catalog.lake.catalog-impl", "org.apache.iceberg.hadoop.HadoopCatalog")
         .getOrCreate())

fact = spark.read.parquet("s3://dl-silver/events_parquet/yyyymmdd=20251110/")
dim  = spark.table("lake.dim.users")  # 미리 생성된 차원 테이블 가정

enriched = (fact.join(F.broadcast(dim), "user_id", "left")
                 .withColumn("event_dt", F.to_date("ts")))

enriched.createOrReplaceTempView("staging")

spark.sql("""
MERGE INTO lake.silver.events t
USING staging s
ON t.user_id = s.user_id AND t.ts = s.ts
WHEN MATCHED THEN UPDATE SET *
WHEN NOT MATCHED THEN INSERT *
""")
```

### Athena로 검증

```sql
SELECT event_type, count(*)
FROM lake.silver.events
WHERE event_dt BETWEEN DATE '2025-11-09' AND DATE '2025-11-10'
GROUP BY 1 ORDER BY 2 DESC;
```

---

## 운영 체크리스트

- [ ] S3 버킷/프리픽스 설계(브론즈/실버/골드, 파티션 표준)
- [ ] Glue Catalog 일관성/스키마 진화 정책(새 컬럼은 nullable)
- [ ] 파일 사이즈/작은 파일 자동 컴팩션 배치
- [ ] Spark AQE/Skew/Adaptive/Tungsten 최적화 활성
- [ ] 오케스트레이션에서 **Idempotent** 설계(중복 실행 대비)
- [ ] 비용 알람(예산/CloudWatch), 로그 보존 기간
- [ ] 보안: VPC Endpoint, KMS, 최소권한, Kerberos/Lake Formation
- [ ] 재현 가능 빌드(코드+런타임 버전 고정), 통합 테스트
- [ ] 재해 복구: 로그/메타/스냅샷 보존, 교차 리전 복제 필요 시 설정

---

## 자주 겪는 문제와 해법

- **소파일 폭증** → `maxRecordsPerFile`/`coalesce`/주기적 compaction
- **Skew로 인한 OOM/느림** → Skew Join, Salting, AQE, Bucketed Join
- **S3 write 실패/일관성 이슈** → S3 최적화 커미터 사용, 중복 커밋 가드
- **스팟 회수** → Fleet 다변화+체크포인트(스트리밍), Managed Scaling, 재시도 전략
- **메타 충돌(동시 writer)** → Hudi/Iceberg/Delta의 트랜잭션 모델로 해결

---

## 비용 계산(근사식)

1) **EMR Serverless**(단순화)
$$
\text{Cost} \approx \sum_{i} (\text{vCPU-초}_i \cdot p_{cpu}) + (\text{메모리-GB-초}_i \cdot p_{mem}) + \text{I/O/스토리지}
$$

2) **EMR on EC2**
$$
\text{Cost} \approx \sum (\text{인스턴스 시간} \cdot \text{단가}) + \text{EBS/S3/네트워크} + \text{스팟 절감}
$$

- **전략**: Job 시간 단축(포맷/파티션/튜닝) + 스팟/Managed Scaling + Serverless 혼용.

---

## 참고 CDK/CloudFormation 스니펫(요약)

### CDK(Typescript, EMR on EC2 기초)

```ts
import * as cdk from 'aws-cdk-lib';
import * as emr from 'aws-cdk-lib/aws-emr';
import * as ec2 from 'aws-cdk-lib/aws-ec2';
import * as iam from 'aws-cdk-lib/aws-iam';

export class EmrEc2Stack extends cdk.Stack {
  constructor(scope: cdk.App, id: string) {
    super(scope, id);
    const vpc = ec2.Vpc.fromLookup(this, 'Vpc', { isDefault: true });

    const role = new iam.Role(this, 'EMRRole', {
      assumedBy: new iam.ServicePrincipal('ec2.amazonaws.com')
    });
    role.addManagedPolicy(iam.ManagedPolicy.fromAwsManagedPolicyName('AmazonS3FullAccess'));

    new emr.CfnCluster(this, 'EMR', {
      name: 'emr-ec2',
      releaseLabel: 'emr-6.15.0',
      applications: [{ name: 'Hadoop' }, { name: 'Spark' }, { name: 'Hive' }],
      instances: {
        ec2SubnetId: vpc.privateSubnets[0].subnetId,
        masterInstanceGroup: { instanceType: 'm6i.xlarge', instanceCount: 1 },
        coreInstanceGroup: { instanceType: 'm6i.xlarge', instanceCount: 2 }
      },
      jobFlowRole: role.roleName,
      serviceRole: 'EMR_DefaultRole',
      logUri: 's3://emr-logs/emr-ec2/'
    });
  }
}
```

> 실제 운영은 **Instance Fleet**, 스팟 혼합, 엔드포인트·보안그룹·KMS·로그 보존 등 세부 구성이 더 필요.

---

## 결론

- **EMR**는 데이터 레이크의 중심에서 **대용량 배치·스트리밍·인터랙티브·ML 전처리**까지 아우르는 **확장가능한 플랫폼**.
- **Serverless / EKS / EC2** 모델 중 요구사항에 맞춰 선택·혼용하고, **컬럼형 포맷·파티션·테이블 포맷·튜닝**을 조합하면 **성능·비용·운영성**을 모두 잡을 수 있다.
- **Glue/Athena/Redshift/SageMaker/Step Functions** 등과의 연계를 표준화하면, **재사용·거버넌스·자동화**가 쉬운 **프로덕션급 데이터 파이프라인**을 완성할 수 있다.

---

## 부록: 명령어/옵션 치트시트

- 클러스터 생성(EC2): `aws emr create-cluster ...`
- 스텝 추가: `aws emr add-steps --steps Type=Spark,Args=[--class,...]`
- Serverless 잡 제출: `aws emr-serverless start-job-run ...`
- EKS 잡 제출: `aws emr-containers start-job-run ...`
- 로그: `s3://<log-bucket>` + CloudWatch Logs
- Spark 주요 옵션:
  - `spark.dynamicAllocation.enabled=true`
  - `spark.sql.adaptive.enabled=true`
  - `spark.sql.files.maxPartitionBytes=268435456`
  - `spark.sql.autoBroadcastJoinThreshold=64MB`(상황에 맞게)
