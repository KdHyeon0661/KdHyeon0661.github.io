---
layout: post
title: 컴퓨터시스템 - 메모리 성능의 이해
date: 2025-08-06 15:20:23 +0900
category: 컴퓨터시스템
---
# 메모리 성능의 이해 — 계층·모델·패턴·최적화·검증까지

> 목표: **왜 메모리가 느려 보이는지**, **무엇을 측정해야 하는지**, **어떻게 코드를 바꿔야 하는지**를 한 눈에 잡는다.  
> 구성: 메모리 계층과 지연/대역 → 성능 모델(AMAT, CPI) → 캐시·TLB·NUMA 핵심 → 접근 패턴과 3C 미스 → 실전 최적화(타일링/프리패치/데이터 레이아웃) → 동시성(코히어런시/폴스 셰어링) → 측정과 체크리스트.

---

## 1) 메모리 계층의 큰 그림

- **계층**: 레지스터 ↔ L1 ↔ L2 ↔ L3(공유) ↔ DRAM(메모리 컨트롤러) ↔ 스토리지.  
- **두 축**  
  - **지연(latency)**: 위로 갈수록 짧다(L1≪DRAM).  
  - **대역(bandwidth)**: 상위 캐시가 폭넓다(코어 근처 병렬 포트/버스).  
- **핵심 교훈**: 캐시에 **자주/가까운** 데이터를 두고, DRAM 왕복을 줄이는 설계가 절대적.

---

## 2) 성능 모델: AMAT·CPI로 보는 병목

### 2.1 평균 메모리 접근 시간 (AMAT)
\[
\text{AMAT} = T_{L1} + m_1\big(T_{L2} + m_2\big(T_{L3} + m_3 T_\text{Mem}\big)\big)
\]
- \(T_{Lk}\): 레벨 \(k\) 히트 시간, \(m_k\): \(k\)레벨 미스율, \(T_\text{Mem}\): DRAM 왕복.

### 2.2 CPI 분해(메모리 스톨)
\[
\text{CPI} \approx \text{CPI}_{\text{base}} + \frac{\text{MemAccesses}}{\text{Instr}}\times \frac{\text{Misses}}{\text{Access}}\times \frac{\text{MissPenalty}}{\text{MLP}}
\]
- **MLP**(Memory-Level Parallelism): 동시에 걸어두는 미스 수(크면 스톨이 겹쳐져 완화).

> OOO(Out-of-Order)·프리패처 덕에 일부 미스는 겹치지만, **포인터 추적**처럼 직렬 의존이 있으면 MLP=1에 가까워진다.

---

## 3) 로컬리티와 접근 패턴

- **시간 지역성**: 같은 데이터를 **다시** 사용.  
- **공간 지역성**: 근처 데이터까지 같이 씀(캐시 라인은 보통 수십 바이트).  
- **좋은 패턴**: 연속 순회(스트리밍), 블록 단위 재사용(타일링).  
- **나쁜 패턴**: 큰 스트라이드, 랜덤 포인터 추적, 자주 변하는 분기·인덱스.

```c
// 행-주도(row-major) 순회(좋음) vs 열-주도(나쁠 수 있음)
int sum_row(int (*a)[N]) {
    int s=0;
    for (int i=0;i<N;i++)
        for (int j=0;j<N;j++)
            s += a[i][j];  // 연속 접근
    return s;
}
int sum_col(int (*a)[N]) {
    int s=0;
    for (int j=0;j<N;j++)
        for (int i=0;i<N;i++)
            s += a[i][j];  // 큰 스트라이드 → 미스↑
    return s;
}
```

---

## 4) 캐시 구조 핵심: 블록·연관도·치환·쓰기 정책

- **라인(블록) 크기**: 공간 지역성 활용 vs 과한 끌어오기(오염).  
- **연관도**: Direct/Set-Assoc/Fully. 낮으면 **충돌(conflict) 미스**↑, 높으면 접근·면적 코스트↑.  
- **치환**: LRU 근사. **스래싱** 방지 위해 데이터 배치/패딩 고려.  
- **쓰기 정책**
  - *Write-back* + *Write-allocate*: 일반적(히트율/대역 효율).  
  - *Write-through* + *No-allocate*: 스트리밍에 유리할 수도(오염↓).  
  - **비휘발(non-temporal) 저장**: 스트리밍 결과를 캐시 오염 없이 DRAM으로.

---

## 5) 3C 미스 모델(+1C)

1. **Compulsory**: 처음 보는 데이터.  
2. **Capacity**: 캐시 용량 부족.  
3. **Conflict**: 같은 세트에 몰려 교체.  
4. **Coherence**(멀티코어): 다른 코어 쓰기로 무효화 → **폴스 셰어링** 유발.

---

## 6) TLB와 가상 메모리

- **TLB**: 가상→물리 주소 변환 캐시.  
- **TLB reach** \(= \text{entries} \times \text{page size}\) 가 워킹셋보다 작으면 **TLB 미스**와 **페이지 워크** 비용↑.  
- **Huge Page**(예: 2MB, 1GB)로 reach 확대(단, 단편화·관리주의).  
- **페이지 배치**가 엉키면 캐시/채널 충돌 증가(페이지 컬러링 개념).

---

## 7) NUMA(Non-Uniform Memory Access)

- **로컬 노드** 메모리는 빠르고, **원격 노드**는 지연·대역 손해.  
- **First-touch**: 쓰는 스레드가 속한 노드에 페이지가 할당되도록 **초기화 스레드 바인딩**.  
- **스레드/메모리 바인딩**: 코어-노드 핀 고정, 데이터 샤딩.

```c
// OpenMP: 초기화도 병렬로 first-touch
#pragma omp parallel for
for (long i=0;i<n;i++) a[i] = 0;  // 각 스레드가 자기 노드에 페이지 할당
```

---

## 8) 메모리 레벨 병렬성(MLP)과 프리패치

- **MLP 높이기**: 독립 로드 여러 개를 미리 발생(언롤/벡터화), **프리패처**가 따라오게.  
- **포인터 추적**: 선형 프리패치가 통하지 않음 → *소프트웨어 프리패치*로 힌트.

```c
void sum_prefetch(const float *a, int n) {
    float s=0;
    for (int i=0;i<n;i+=16) {
        __builtin_prefetch(&a[i+64], 0, 1); // 읽기, 약한 지역성
        for (int k=0;k<16 && i+k<n;k++) s += a[i+k];
    }
    (void)s;
}
```

- **프리패치 거리**: “DRAM 왕복 지연(사이클)” / “반복당 소비 사이클” 근사로 산출 → 측정으로 조정.

---

## 9) 데이터 레이아웃: AoS vs SoA, 정렬, 패딩

- **AoS(배열-의-구조체)** vs **SoA(구조체-의-배열)**  
  - 벡터화/대역 효율이 필요한 **열 단일 연산**은 SoA가 유리.  
- **정렬(alignment)**: 벡터 로드/스토어 정렬 충족 시 포트/μop 효율↑.  
- **패딩**: 같은 캐시 세트로 몰리는 키 배열에 **패딩/색칠**로 충돌 완화.

```c
// SoA 예시
typedef struct { float *x, *y, *z; } vec3_soa;
void norm_soa(vec3_soa v, int n) {
  #pragma omp simd
  for (int i=0;i<n;i++) v.x[i]=v.x[i]*v.x[i]+v.y[i]*v.y[i]+v.z[i]*v.z[i];
}
```

---

## 10) 타일링(블로킹)으로 재사용 극대화

행렬 곱(ijk)을 예로 들면, **블록** 단위로 A/B를 L1/L2에 붙잡고 C에 누적:

```c
void gemm_blocked(int n, float *restrict A, float *restrict B, float *restrict C, int Bsz) {
  for (int ii=0; ii<n; ii+=Bsz)
    for (int jj=0; jj<n; jj+=Bsz)
      for (int kk=0; kk<n; kk+=Bsz) {
        int i_max = (ii+Bsz<n)? ii+Bsz : n;
        int j_max = (jj+Bsz<n)? jj+Bsz : n;
        int k_max = (kk+Bsz<n)? kk+Bsz : n;
        for (int i=ii;i<i_max;i++)
          for (int j=jj;j<j_max;j++) {
            float acc = C[i*n+j];          // 레지스터 누적
            for (int k=kk;k<k_max;k++)     // 블록 내 재사용
              acc += A[i*n+k]*B[k*n+j];
            C[i*n+j]=acc;
          }
      }
}
```

- **블록 크기 선택**(경험칙):  
  \[
  B \approx \sqrt{\frac{\alpha \cdot C_\text{cache}}{\text{element\_size}\times\text{(매트릭스 수)}}}
  \]
  \(\alpha\)는 여유 계수(메타데이터/라인/연관도 고려).

---

## 11) 불필요한 메모리 참조 줄이기(필수 습관)

- **스칼라 치환(SRA)**: 같은 원소를 **한 번만 로드**하고 레지스터에서 재사용.  
- **Dead store 제거**: 곧 덮을 메모리에 쓰지 말 것.  
- **루프 불변 로드 호이스팅**: 상수, 테이블 포인터, 스케일 값 등을 루프 밖으로.

```c
for (int i=0;i<n;i++) {
    float xi = x[i], yi = y[i];     // 두 번 읽지 않기
    y[i] = yi + a * xi;
}
```

---

## 12) 동시성: 코히어런시·폴스 셰어링

- **MESI**류 코히어런시: 코어 간 같은 라인 쓰기 시 **무효화 트래픽**.  
- **폴스 셰어링**: 서로 다른 변수라도 **같은 캐시 라인**이면 경쟁.  
  - 해결: **라인 패딩** / 스레드별 샤딩.

```c
// 폴스 셰어링 방지용 패딩
typedef struct { _Alignas(64) long v; } padded_long;
padded_long cnt[64];
```

---

## 13) Roofline으로 “왜 안 빨라지는지” 빠르게 판단

- **연산집약도(AI)**:
\[
\text{AI} = \frac{\text{FLOPs}}{\text{Bytes moved}}
\]
- **상한**:
\[
\text{Perf} \le \min(\text{Peak FLOPs},\; \text{AI}\times \text{Peak BW})
\]
- **사례**: SAXPY \(y\leftarrow a x + y\). 실수 2 FLOP/요소, 읽기(8B+8B) + 쓰기(8B) = 24B/요소 →  
  \(\text{AI} \approx 2/24 \approx 0.083\ \text{FLOP/B}\) → **메모리 바운드**.

---

## 14) 측정·검증: 올바른 실험 절차

- **타이머**: `clock_gettime(CLOCK_MONOTONIC,…)` (워밍업 후 여러 번, 중앙값).  
- **하드웨어 카운터**(Linux `perf stat`)  
  - `cycles, instructions, L1-dcache-loads/misses, LLC-load-misses, dTLB-load-misses, branches/branch-misses`  
- **NUMA 상태**: `numactl --hardware`, 페이지 배치 확인.  
- **패턴 벤치마크**: STREAM류(대역), 랜덤 포인터 추적(지연), 타일 GEMM(재사용).

```c
// 최소 측정 틀
#include <time.h>
double now(){ struct timespec t; clock_gettime(CLOCK_MONOTONIC,&t);
              return t.tv_sec + t.tv_nsec*1e-9; }
```

---

## 15) 바로 적용할 체크리스트

- [ ] **행-주도** 순서 및 **스트라이드 1**인가?  
- [ ] **타일링**으로 L1/L2 재사용을 극대화했는가? 블록 크기 실험완료?  
- [ ] **스칼라 치환/불변 호이스팅**으로 **중복 로드**를 제거했는가?  
- [ ] **SoA/정렬/패딩**으로 벡터화·충돌을 도왔는가?  
- [ ] **소프트웨어 프리패치**가 이득인가? 거리 튜닝했는가?  
- [ ] **Huge Page/NUMA first-touch**로 TLB·원격 접근을 줄였는가?  
- [ ] **폴스 셰어링** 없이 카운터/버퍼를 샤딩·패딩했는가?  
- [ ] `perf`로 **미스율·dTLB·IPC·BW** 개선을 확인했는가?

---

## 16) 마무리

메모리 성능은 **지연·대역·로컬리티**의 삼각형 위에서 결정된다.  
정리하자면,
1) **패턴을 바꾸어(타일링·SoA·연속 접근)** 캐시에 붙이고,  
2) **불필요한 참조를 없애** 대역을 절약하며,  
3) **TLB/NUMA/코히어런시**의 시스템 이슈를 관리하라.  
그리고 반드시 **측정→수정→재측정**의 루프를 돌리자. 이것이 가장 확실한 메모리 성능의 길이다.