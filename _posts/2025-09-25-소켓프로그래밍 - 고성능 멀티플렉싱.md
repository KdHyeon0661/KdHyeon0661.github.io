---
layout: post
title: 소켓프로그래밍 - 고성능 멀티플렉싱
date: 2025-09-25 14:25:23 +0900
category: 소켓프로그래밍
---
## 고성능 멀티플렉싱 — epoll 제대로 쓰기

> 목표: **epoll** 의 인터페이스(`epoll_create/ctl/wait`)와 **레벨(LEVEL) vs 엣지(ET)** 트리거의 차이를 확실히 이해하고,
> **버퍼 소진(drain) 루프**와 `EAGAIN` 처리의 정석을 익힌다. 이어서 **수천~수만 연결**을 전제로 자료구조/메모리 관리 전략을 설계하고,
> 마지막으로 **epoll(ET) 기반 길이-프리픽스 에코 서버**(C++23, 단일 스레드)를 구현한 뒤 간단 벤치마크 방법을 제시한다.

---

### epoll 빠른 개요

- **핵심 호출**
  - `epoll_create1(EPOLL_CLOEXEC)` → epoll 인스턴스 fd 획득
  - `epoll_ctl(epfd, EPOLL_CTL_ADD|MOD|DEL, fd, &ev)` → 관심 이벤트 등록/수정/삭제
  - `epoll_wait(epfd, events, maxevents, timeout)` → 준비된 이벤트 배열을 받음
- **이벤트 플래그(일부)**
  - `EPOLLIN`(읽기 준비), `EPOLLOUT`(쓰기 준비), `EPOLLERR`(에러), `EPOLLHUP`(상대 종료),
    `EPOLLRDHUP`(반쪽 종료, 수신 방향 close), `EPOLLET`(엣지 트리거), `EPOLLONESHOT`(1회 알림)
- **레벨 vs 엣지**
  - **LEVEL**: 조건이 참인 동안 **매번** 알림(= poll 레벨 트리거와 유사)
  - **ET(Edge Triggered)**: **상태 변화**가 있을 때 **한 번만** 알림 → 알림을 받은 쪽은 **커널 버퍼를 가능한 한 끝까지** 비워(읽기) 또는 채워(쓰기) 놓아야 한다.
    그렇지 않으면 **다음 알림이 오지 않아** 굶는다.

> 결론: ET를 쓰려면 **논블로킹 소켓** + **드레인(drain) 루프** + `EAGAIN` 정석 처리 가 **필수**다.

---

### ET에서의 정석: **버퍼 소진 루프** & `EAGAIN`

- **읽기(EPOLLIN)**: `recv` 를 **반복 호출**하여 **EAGAIN / EWOULDBLOCK** 이 나올 때까지 읽는다.
  - 중간 `recv==0` 은 **원격 종료** → 정리
  - 부분 파싱 상태는 **연결별 상태 머신**에 축적
- **쓰기(EPOLLOUT)**: 출력 큐(버퍼)에서 **가능한 만큼** `send` 를 반복 → **EAGAIN** 나오면 중단, **모두 보냈으면** EPOLLOUT 관심 해제
- **한 번의 이벤트에서 가능한 한 많이** 처리해야 ET가 빛을 발한다.

---

### 대규모 연결을 위한 자료구조/메모리 설계

- **연결 테이블**: `fd → Conn*` 해시/벡터
  - 리눅스의 fd는 보통 작은 정수 **증가형** → **`std::vector<Conn*>`** 를 사용하는 **스파스 인덱스 테이블**이 빠르고 메모리 효율도 좋다(빈 칸 `nullptr`).
- **버퍼 전략**
  - **수신 버퍼**: 상태 머신에 필요한 **헤더(4B)** + **body** 를 갖는 **슬라이스**(오프셋/크기 관리)
  - **송신 큐**: `std::deque<std::vector<std::byte>>` 또는 **단일 연속 버퍼 + head/tail** 인덱스
  - **메모리 풀**(선택): 고정 크기 **슬랩(slab)** 을 만들어 `std::pmr::monotonic_buffer_resource` 등으로 할당 비용 감소
- **구조적 상수**
  - **프레임 CAP**(예: 1MiB)
  - **한 번의 read/write에서 최대 루프 횟수 상한**(pathological 방지; 통상 필요 없음)

---

### epoll(ET) 기반 길이-프리픽스 에코 서버 (C++23, 단일 파일)

> 특징
> - `AF_UNSPEC` + `AI_ADDRCONFIG` 리졸브
> - 리슨/수락 소켓 **논블로킹**
> - **ET(엣지 트리거)** + **레벨-같이 드레인** 패턴
> - **길이-프리픽스(4B, BE)** 프레이밍 + **CAP** 방어
> - **EPOLLRDHUP/EPOLLHUP/EPOLLERR** 엄격 처리
> - **송신 준비 시에만** `EPOLLOUT` 등록

```cpp
// epoll_et_echo.cpp
// 빌드: g++ -std=c++23 -O2 -Wall epoll_et_echo.cpp -o et_echo
// 사용:
//   서버: ./et_echo [bind_host] [port]   # 예) ./et_echo :: 9000  또는  ./et_echo 0.0.0.0 9000
//
// 특징: ET 모드에서 recv/send를 EAGAIN이 날 때까지 드레인하는 정석 구현.

#include <arpa/inet.h>
#include <fcntl.h>
#include <netdb.h>
#include <sys/epoll.h>
#include <sys/socket.h>
#include <sys/types.h>
#include <unistd.h>

#include <array>
#include <cerrno>
#include <cstdint>
#include <cstring>
#include <expected>
#include <print>
#include <span>
#include <string>
#include <string_view>
#include <system_error>
#include <unordered_map>
#include <utility>
#include <vector>
#include <deque>

static inline std::error_code last_errno() { return {errno, std::generic_category()}; }

static int set_nonblock(int fd) {
    int fl = ::fcntl(fd, F_GETFL, 0);
    if (fl == -1) return -1;
    return ::fcntl(fd, F_SETFL, fl | O_NONBLOCK);
}

struct unique_fd {
    int fd{-1};
    unique_fd() = default;
    explicit unique_fd(int f): fd(f) {}
    unique_fd(const unique_fd&) = delete;
    unique_fd& operator=(const unique_fd&) = delete;
    unique_fd(unique_fd&& o) noexcept : fd(std::exchange(o.fd, -1)) {}
    unique_fd& operator=(unique_fd&& o) noexcept {
        if (this != &o) { if (fd!=-1) ::close(fd); fd=std::exchange(o.fd, -1); }
        return *this;
    }
    ~unique_fd(){ if (fd!=-1) ::close(fd); }
    int  get() const noexcept { return fd; }
    explicit operator bool() const noexcept { return fd!=-1; }
    int  release() noexcept { int t=fd; fd=-1; return t; }
};

struct addr_list { addrinfo* head{}; ~addr_list(){ if (head) ::freeaddrinfo(head); } };

static std::expected<addr_list, std::error_code>
resolve(std::string_view host, std::string_view service, int family, int socktype, int flags) {
    addrinfo hints{}; hints.ai_family=family; hints.ai_socktype=socktype; hints.ai_flags=flags;
    addrinfo* res=nullptr;
    int rc = ::getaddrinfo(host.empty()?nullptr:std::string(host).c_str(),
                           std::string(service).c_str(), &hints, &res);
    if (rc!=0) return std::unexpected(std::make_error_code(std::errc::invalid_argument));
    addr_list L; L.head=res; return L;
}

static std::string sa_to_string(const sockaddr* sa, socklen_t salen) {
    char host[NI_MAXHOST]{}, serv[NI_MAXSERV]{};
    if (::getnameinfo(sa, salen, host, sizeof(host), serv, sizeof(serv),
                      NI_NUMERICHOST|NI_NUMERICSERV)==0)
        return std::string(host)+":"+serv;
    return "(unknown)";
}

static std::expected<int, std::error_code>
make_listener(std::string_view host, std::string_view port, int backlog=1024) {
    auto R = resolve(host, port, AF_UNSPEC, SOCK_STREAM,
                     AI_PASSIVE|AI_ADDRCONFIG|AI_NUMERICSERV);
    if (!R) return std::unexpected(R.error());
    for (auto* ai=R->head; ai; ai=ai->ai_next) {
        int s = ::socket(ai->ai_family, ai->ai_socktype, ai->ai_protocol);
        if (s < 0) continue;
        int yes=1; ::setsockopt(s, SOL_SOCKET, SO_REUSEADDR, &yes, sizeof(yes));
        if (ai->ai_family == AF_INET6) {
            int v6only=0; ::setsockopt(s, IPPROTO_IPV6, IPV6_V6ONLY, &v6only, sizeof(v6only));
        }
        if (::bind(s, ai->ai_addr, ai->ai_addrlen)==0 && ::listen(s, backlog)==0) {
            if (set_nonblock(s)!=0) { ::close(s); continue; }
            std::print("[listen] {}\n", sa_to_string(ai->ai_addr, ai->ai_addrlen));
            return s;
        }
        ::close(s);
    }
    return std::unexpected(std::make_error_code(std::errc::address_not_available));
}

// ===================== 연결 상태 =====================
struct Conn {
    enum class State { READ_LEN, READ_BODY, WRITE_BODY };

    State st = State::READ_LEN;
    uint32_t be_len{0};
    uint32_t len{0};
    std::size_t have_len_bytes{0};   // READ_LEN 진행률
    std::size_t have_body_bytes{0};  // READ_BODY 진행률
    std::size_t out_sent_bytes{0};   // WRITE_BODY 진행률 (헤더+바디 총량 기준)

    std::vector<std::byte> in_body;      // 수신된 payload
    std::vector<std::byte> out_frame;    // [4B len | body]
    std::string peer;

    void reset_to_read() {
        st = State::READ_LEN;
        be_len=0; len=0;
        have_len_bytes=0; have_body_bytes=0; out_sent_bytes=0;
        in_body.clear(); out_frame.clear();
    }
};

// 스파스 테이블: fd를 그대로 인덱스로 사용
struct ConnTable {
    std::vector<Conn*> v; // nullptr or Conn*
    ~ConnTable(){ for (auto* p : v) delete p; }
    Conn* get(int fd) const { return (fd>=0 && (size_t)fd<v.size()) ? v[fd] : nullptr; }
    void  set(int fd, Conn* c) {
        if ((size_t)fd >= v.size()) v.resize(fd+1, nullptr);
        v[fd]=c;
    }
    void  erase(int fd) {
        if ((size_t)fd < v.size()) { delete v[fd]; v[fd]=nullptr; }
    }
};

// epoll 이벤트 헬퍼
static inline void ep_add(int epfd, int fd, uint32_t ev) {
    epoll_event e{}; e.data.fd=fd; e.events=ev;
    if (::epoll_ctl(epfd, EPOLL_CTL_ADD, fd, &e)!=0) std::print(stderr, "epoll add: {}\n", std::strerror(errno));
}
static inline void ep_mod(int epfd, int fd, uint32_t ev) {
    epoll_event e{}; e.data.fd=fd; e.events=ev;
    if (::epoll_ctl(epfd, EPOLL_CTL_MOD, fd, &e)!=0) std::print(stderr, "epoll mod: {}\n", std::strerror(errno));
}
static inline void ep_del(int epfd, int fd) {
    if (::epoll_ctl(epfd, EPOLL_CTL_DEL, fd, nullptr)!=0) std::print(stderr, "epoll del: {}\n", std::strerror(errno));
}

int main(int argc, char** argv) {
    std::string host = (argc>1 ? argv[1] : "");
    std::string port = (argc>2 ? argv[2] : "9000");

    auto L = make_listener(host, port);
    if (!L) { std::print(stderr, "listen failed: {}\n", L.error().message()); return 1; }
    int lfd = *L;

    unique_fd ep{ ::epoll_create1(EPOLL_CLOEXEC) };
    if (!ep) { std::print(stderr, "epoll_create1: {}\n", std::strerror(errno)); return 1; }

    // 리스너: EPOLLIN | ET
    ep_add(ep.get(), lfd, EPOLLIN | EPOLLET);

    ConnTable table;

    constexpr int MAX_EVENTS = 256;
    std::array<epoll_event, MAX_EVENTS> events{};
    constexpr std::size_t CAP = 1u<<20; // 1MiB

    auto want_events = [&](int fd, bool want_out){
        uint32_t ev = EPOLLIN | EPOLLRDHUP | EPOLLET;
        if (want_out) ev |= EPOLLOUT;
        ep_mod(ep.get(), fd, ev);
    };

    auto accept_drain = [&](){
        for(;;){
            sockaddr_storage ss{}; socklen_t slen=sizeof(ss);
            int cfd = ::accept4(lfd, (sockaddr*)&ss, &slen, SOCK_NONBLOCK | SOCK_CLOEXEC);
            if (cfd >= 0) {
                // 새 연결 등록
                auto* c = new Conn{};
                c->peer = sa_to_string((sockaddr*)&ss, slen);
                table.set(cfd, c);
                ep_add(ep.get(), cfd, EPOLLIN | EPOLLRDHUP | EPOLLET);
                std::print("[accept] fd={} peer={}\n", cfd, c->peer);
                continue;
            }
            if (errno==EAGAIN || errno==EWOULDBLOCK) break;
            if (errno==EINTR) continue;
            std::print(stderr, "accept: {}\n", std::strerror(errno));
            break;
        }
    };

    auto close_conn = [&](int fd){
        ep_del(ep.get(), fd);
        table.erase(fd);
        ::close(fd);
    };

    auto drain_read = [&](int fd, Conn& C)->bool {
        // true: 계속 진행 가능 / false: 연결 종료됨
        for(;;){
            if (C.st == Conn::State::READ_LEN) {
                std::byte* dst = std::as_writable_bytes(std::span{&C.be_len, 1}).data() + C.have_len_bytes;
                ssize_t n = ::recv(fd, dst, 4 - C.have_len_bytes, 0);
                if (n > 0) {
                    C.have_len_bytes += (std::size_t)n;
                    if (C.have_len_bytes == 4) {
                        C.len = ntohl(C.be_len);
                        if (C.len > CAP) {
                            std::print(stderr, "[{}] frame too large: {}\n", C.peer, C.len);
                            return false;
                        }
                        C.in_body.assign(C.len, std::byte{0});
                        C.have_body_bytes = 0;
                        C.st = Conn::State::READ_BODY;
                    }
                    // 아직 모자라면 루프 반복하여 더 읽기
                    continue;
                }
                if (n == 0) return false; // peer closed
                if (errno == EAGAIN || errno == EWOULDBLOCK) break;
                if (errno == EINTR) continue;
                std::print(stderr, "recv len [{}]: {}\n", C.peer, std::strerror(errno));
                return false;
            }

            if (C.st == Conn::State::READ_BODY) {
                std::byte* dst = C.in_body.data() + C.have_body_bytes;
                ssize_t need = (ssize_t)(C.len - C.have_body_bytes);
                ssize_t n = ::recv(fd, dst, need, 0);
                if (n > 0) {
                    C.have_body_bytes += (std::size_t)n;
                    if (C.have_body_bytes == C.len) {
                        // 에코 프레임 생성: [4B | body]
                        uint32_t be = htonl(C.len);
                        C.out_frame.resize(4 + C.len);
                        std::memcpy(C.out_frame.data(), &be, 4);
                        std::memcpy(C.out_frame.data()+4, C.in_body.data(), C.len);
                        C.out_sent_bytes = 0;
                        C.st = Conn::State::WRITE_BODY;
                        // 쓰기 관심 on
                        want_events(fd, true);
                        // 읽기는 여기서 멈출 필요 없음(ET), 그러나 다음 write가 진행되어야 하므로 루프를 빠져나가도 무방
                        // 계속 읽을 데이터가 커널에 남았는지 모름 -> break 하여 상위 루프에 쓰기 처리 기회를 줌
                        break;
                    }
                    // 아직 부족 → 계속 루프
                    continue;
                }
                if (n == 0) return false;
                if (errno == EAGAIN || errno == EWOULDBLOCK) break;
                if (errno == EINTR) continue;
                std::print(stderr, "recv body [{}]: {}\n", C.peer, std::strerror(errno));
                return false;
            }

            // WRITE 상태면 읽기 드레인을 잠시 중단
            break;
        }
        return true;
    };

    auto drain_write = [&](int fd, Conn& C)->bool {
        if (C.st != Conn::State::WRITE_BODY) return true;
        for(;;){
            std::size_t sent = C.out_sent_bytes;
            std::size_t remain = C.out_frame.size() - sent;
            if (remain == 0) break;
            ssize_t n = ::send(fd, C.out_frame.data()+sent, remain, 0);
            if (n > 0) {
                C.out_sent_bytes += (std::size_t)n;
                continue;
            }
            if (n == 0) break;
            if (errno == EAGAIN || errno == EWOULDBLOCK) break;
            if (errno == EINTR) continue;
            std::print(stderr, "send [{}]: {}\n", C.peer, std::strerror(errno));
            return false;
        }
        if (C.out_sent_bytes == C.out_frame.size()) {
            // 프레임 완료 → 다음 프레임을 위해 읽기 상태로
            C.reset_to_read();
            // 쓰기 관심 off
            want_events(fd, false);
        }
        return true;
    };

    for(;;){
        int n = ::epoll_wait(ep.get(), events.data(), (int)events.size(), /*timeout*/ 10000);
        if (n < 0) {
            if (errno == EINTR) continue;
            std::print(stderr, "epoll_wait: {}\n", std::strerror(errno));
            break;
        }
        if (n == 0) {
            // 타임아웃 시점: 타임아웃 관리/청소 등에 사용 가능
            continue;
        }

        for (int i=0;i<n;++i) {
            int fd = events[i].data.fd;
            uint32_t ev = events[i].events;

            if (fd == lfd) {
                // ET: accept 가능한 만큼 모두 수행
                accept_drain();
                continue;
            }

            Conn* C = table.get(fd);
            if (!C) { // 알 수 없는 fd — 방어
                ep_del(ep.get(), fd);
                ::close(fd);
                continue;
            }

            // 에러/종료 플래그 우선 처리
            if (ev & (EPOLLERR | EPOLLHUP)) {
                close_conn(fd);
                continue;
            }
            if (ev & EPOLLRDHUP) {
                // 원격이 WR을 종료(half-close) → 우리는 읽기 완료 후 닫거나 즉시 닫는 정책
                // 여기서는 즉시 정리
                close_conn(fd);
                continue;
            }

            // 1) 읽기 드레인
            if (ev & EPOLLIN) {
                if (!drain_read(fd, *C)) { close_conn(fd); continue; }
            }

            // 2) 쓰기 드레인
            if (ev & EPOLLOUT) {
                if (!drain_write(fd, *C)) { close_conn(fd); continue; }
            }
        }
    }

    return 0;
}
```

#### 코드 해설(핵심만)

- **ET**: 리스너/클라 모두 `EPOLLET`. → 각 이벤트에서 **accept/recv/send** 를 **EAGAIN** 나올 때까지 드레인.
- **상태 머신**: `READ_LEN(4B)` → `READ_BODY(N)` → `WRITE_BODY(4+N 송신)` → 완료 후 **읽기로 복귀**.
- **EPOLLOUT**: 송신해야 할 데이터가 있을 때만 `want_events(fd, true)` 로 켠다. 다 보냈으면 **끄기**.
- **종료 처리**: `EPOLLERR|EPOLLHUP|EPOLLRDHUP` 를 **즉시 정리**.

---

### ET에서 자주 하는 실수와 처방

1) **`recv` 한 번만 호출**
   - ET에선 **EAGAIN까지 반복 호출**이 정석. 한 번만 읽고 반환하면 **다음 이벤트가 오지 않아 교착**.
2) **`EPOLLOUT` 상시 등록**
   - 소켓이 보내기 가능하면 **항상 깨어난다** → CPU 스핀. **보낼 게 있을 때만** 켜라.
3) **부분 쓰기 무시**
   - `send` 반환값 < 요청 길이 → **진행률** 저장하고, **나머지는 다음 EPOLLOUT에서**.
4) **CAP 없이 대형 프레임 허용**
   - 단일 프레임이 수십/수백 MB면 메모리 폭발. **CAP** 로 방어.
5) **`EPOLLRDHUP` 무시**
   - 상대 Half-close를 감지하지 못하면 **유령 연결**이 남는다.

---

### 수천~수만 연결로 가기 위한 추가 팁

- **메모리 레이아웃**: `Conn`을 **풀 할당**(예: `std::pmr` + 미리 잡은 arena) → 파편화/lock 경합 감소
- **버퍼 재사용**: 빈번한 `std::vector`(capacity 변화) 대신 **고정 블록**(64 KiB 등) 큐를 붙이고 **슬라이스**로 관리
- **로깅 억제**: 심볼릭 로그는 **벤치 때 끄기**(표준 출력은 비용이 크다)
- **NAPI/IRQ affinity**: 고성능 NIC 환경에서 **RSS & 큐 바인딩**과 **SO_REUSEPORT** 멀티 프로세스 분산 고려
- **`EPOLLONESHOT` 패턴(선택)**: 멀티스레딩에서 유용. 이벤트 처리 후 **재등록(EPOLL_CTL_MOD)** 해야 재알림.
  단일 스레드에선 필요 없음.

---

### 간단 벤치마크 방법

#### 단일 프로세스 부하 클라이언트(간단)

- 1000개 연결을 만들어 **순차로 프레임**을 보내고 돌아오는 시간을 측정.
- 또는 `wrk`(HTTP), `hping3` 같은 도구로 레이어-7/4 수준 간접 측정.

#### 샘플 부하 루틴(요지, C++23)

```cpp
// et_echo_load.cpp (요지) — N개의 TCP 연결을 만들고, 4B+payload 프레임을 라운드트립 측정
// 빌드: g++ -std=c++23 -O2 et_echo_load.cpp -o et_load
// 사용: ./et_load <host> <port> <conns> <msg_bytes> <rounds>
```
- 연결 수(`conns`)와 메시지 크기(`msg_bytes`)를 바꿔, **RTT/처리량** 변화를 관찰한다.
- **관측 포인트**: 서버 CPU 사용률, `ss -tinp` 의 큐 길이, `perf`/`pidstat`, `tcpdump` 로 재전송 유무.

---

### 체크리스트

- [ ] 모든 소켓 **논블로킹**
- [ ] **ET + 드레인 루프**: `accept/recv/send` 를 **EAGAIN** 까지
- [ ] **상태 머신**: `READ_LEN → READ_BODY → WRITE_BODY → READ_LEN`
- [ ] **EPOLLOUT** 은 **출력 큐 있을 때만**
- [ ] **종료/에러 플래그** 즉시 정리 (`EPOLLERR|HUP|RDHUP`)
- [ ] **CAP** 으로 자원 공격 방지
- [ ] 연결 테이블은 `fd` 인덱싱으로 **O(1)** 접근
- [ ] 벤치 시 **로그 끄기** / 빌드 `-O2` / NUMA, IRQ affinity 고려

---

### 마무리

`epoll(ET)`은 **커널의 깨움 횟수**를 줄여 **높은 스케일**을 가능하게 한다.
대신 **드레인 루프 + EAGAIN 처리**라는 규율을 지키지 않으면 오히려 **교착/스핀**의 늪에 빠진다.
이 장의 에코 서버는 **ET 정석**을 담은 최소 골격이다. 여기에 **타임아웃 휠**, **송신 큐 상한/백프레셔**, **멀티스레드(accept-워커 분리)**,
또는 **TLS(비차단 핸드셰이크)** 를 얹으면 실전 서비스의 토대가 된다.
