---
layout: post
title: AWS - S3 비용 분석 및 절감
date: 2025-07-18 20:20:23 +0900
category: AWS
---
# AWS S3 비용 분석 및 절감 전략

## 왜 S3 비용 최적화인가?

- 데이터는 **느리게 증가하는 게 아니라, 계단식으로 폭증**한다.
- S3는 **저장 + 요청 + 전송 + 관리 기능**이 모두 비용에 반영된다.
- **버전 관리/Replication/로그**를 켜고 잊는 순간 비용은 눈덩이처럼 불어난다.

핵심은 **(1) 측정 → (2) 계층화 → (3) 자동화 → (4) 감시**의 루프다.

---

## 비용 구조 정확히 이해하기 (모델화)

S3 비용은 크게 4개의 축으로 구성된다.

| 축 | 예시 | 비고 |
|---|---|---|
| **저장(Storage)** | GB·월 x 스토리지 클래스 | Standard, IA, Intelligent-Tiering, Glacier 계열 |
| **요청(Requests)** | PUT/GET/LIST/SELECT 등 1,000건당 | DELETE는 보통 무료 |
| **전송(Data Transfer)** | **S3→인터넷** 과금, **동일 리전 S3→EC2**는 보통 무료 | 리전 간 전송 과금 |
| **관리/부가(Management)** | Inventory, Replication, Object Lambda 등 | 일부 무료/유료 섞임 |

### 간단 근사 수식

$$
\text{Cost}_{\text{S3}} \approx
\underbrace{\sum_{m} G_m \cdot c_m}_{\text{Storage}} \;+\;
\underbrace{\sum_{t} \frac{R_t}{1000} \cdot k_t}_{\text{Requests}} \;+\;
\underbrace{\sum_{e} B_e \cdot d_e}_{\text{Data Transfer}} \;+\;
\text{(옵션: Replication/Inventory/Select/TA 등)}
$$

- \(G_m\): m번째 스토리지 클래스 월 평균 GB
- \(c_m\): 해당 클래스의 GB·월 단가
- \(R_t\): t유형 요청 수(건)
- \(k_t\): t유형 1,000건당 단가
- \(B_e\): e유형 아웃바운드 GB
- \(d_e\): e유형 GB당 단가

> 실제 단가는 지역/시점/옵션에 따라 다르다. **정확 단가 조회**는 콘솔/공식 가격표를 기준으로 하자.

---

## 분석 도구로 “보이는 상태” 만들기

### AWS Cost Explorer (빠른 가시화)

- **Service=S3** 필터 + **태그/버킷/클래스별** 분석
- 월간/일간 비용 추세, 예측(포캐스팅)도 제공

```text
Cost Explorer → Explore costs → Filter: Service = Amazon Simple Storage Service (S3)
Group by: Usage type / Tag (Project, Owner) / Storage class
```

### S3 Storage Lens (버킷 내부 구조 관찰)

- **객체 수/용량/비최신 버전 비율/수명주기 적용률** 등 대시보드
- 무료 요약 리포트 + 상세(유료, 선택)

### AWS Budgets (예산 경보)

- 월 예산 초과 시 이메일/SNS 경보

```bash
ACCOUNT_ID=123456789012
aws budgets create-budget \
  --account-id $ACCOUNT_ID \
  --budget '{
    "BudgetName": "s3-monthly-50usd",
    "BudgetLimit": {"Amount":"50","Unit":"USD"},
    "TimeUnit":"MONTHLY",
    "BudgetType":"COST"
  }' \
  --notifications-with-subscribers '[
    {"Notification":{"NotificationType":"ACTUAL","ComparisonOperator":"GREATER_THAN","Threshold":100,"ThresholdType":"PERCENTAGE"},"Subscribers":[{"SubscriptionType":"EMAIL","Address":"you@example.com"}]}
  ]'
```

### + Athena (정밀 SQL 분석)

- **모든 비용/사용량**을 S3에 **Parquet/ORC**로 적재 → Athena로 쿼리
- 프로젝트/태그/버킷/클래스 단위 상시 리포팅 가능

**Athena 예시(개념 SQL)**:
```sql
-- 최근 30일 S3 비용, 스토리지 클래스별 합산
SELECT
  line_item_product_code,
  product_storage_class AS storage_class,
  SUM(line_item_unblended_cost) AS cost
FROM aws_billing_cur.cur_parquet
WHERE usage_start_date >= date_add('day', -30, current_date)
  AND line_item_product_code = 'AmazonS3'
GROUP BY 1, 2
ORDER BY cost DESC;
```

---

## 절감 전략 ① 스토리지 클래스 최적화 (핵심)

**원칙**: “자주 vs 드물게” 접근 여부에 따라 클래스 선택.

| 클래스 | 개념 | 사용 예 |
|---|---|---|
| **Standard** | 고가용/저지연 | 웹 자산, 핫데이터 |
| **Standard-IA** | 드문 접근 + 빠른 복구 | 백업/리포트 |
| **One Zone-IA** | 단일 AZ, 저가 | 복제/재생 가능 로그(내결함성 요건 낮을 때) |
| **Intelligent-Tiering** | **자동 계층 이동** | 액세스 패턴 불규칙 |
| **Glacier Instant Retrieval** | 드문 접근 + **즉시 복원** | 대용량 미디어 스냅샷 |
| **Glacier Flexible/Bulk(Deep Archive)** | 장기 보관 | 규제/감사용 장기 아카이브 |

**실전 명령: 업로드 시 클래스 지정**
```bash
aws s3 cp myfile.txt s3://my-bucket/ --storage-class STANDARD_IA
```

**boto3 예시**
```python
import boto3
s3 = boto3.client("s3")
s3.upload_file(
    "file.txt", "my-bucket", "archive/file.txt",
    ExtraArgs={"StorageClass": "DEEP_ARCHIVE"}  # or GLACIER, INTELLIGENT_TIERING ...
)
```

> **Intelligent-Tiering**은 모니터링 수수료/아카이브 티어 복원 요금 요소가 있으므로 **작은 객체 대량**엔 적합치 않을 수 있다. **Storage Lens/CUR로 임계값 파악**이 중요.

---

## 절감 전략 ② 수명주기 정책(Lifecycle)으로 자동화

### 기본 패턴

- 30일 후 → IA
- 90일 후 → Glacier
- 365일 후 → 삭제

**Json 예시**
```json
{
  "Rules": [
    {
      "ID": "ArchiveLogs",
      "Filter": { "Prefix": "logs/" },
      "Status": "Enabled",
      "Transitions": [
        { "Days": 30, "StorageClass": "STANDARD_IA" },
        { "Days": 90, "StorageClass": "GLACIER" }
      ],
      "Expiration": { "Days": 365 }
    }
  ]
}
```

적용:
```bash
aws s3api put-bucket-lifecycle-configuration \
  --bucket my-bucket \
  --lifecycle-configuration file://lifecycle.json
```

### **버전 관리와 함께**: 비최신 버전 정리

```json
{
  "Rules": [
    {
      "ID": "Purge-Noncurrent-180",
      "Status": "Enabled",
      "Filter": { "Prefix": "" },
      "NoncurrentVersionTransitions": [
        { "NoncurrentDays": 30, "StorageClass": "GLACIER" }
      ],
      "NoncurrentVersionExpiration": { "NoncurrentDays": 180 }
    }
  ]
}
```

> 버전 관리 + Lifecycle = **비용 폭증을 방지하는 표준 콤보**.

---

## 절감 전략 ③ 중복 제거 & 데이터 정리

- **중복 파일**: 해싱(ETag/Content-MD5) 비교 후 제거
- **임시/테스트 접두사**: `tmp/`, `staging/`에 **단기 만료 규칙**
- **불필요한 비최신 버전**: **NoncurrentVersionExpiration**로 자동 삭제

**간이 스캐너(예시)**
```python
import boto3, hashlib
s3 = boto3.client("s3")
bucket = "my-bucket"

paginator = s3.get_paginator("list_objects_v2")
hash_map = {}
for page in paginator.paginate(Bucket=bucket, Prefix="data/"):
    for obj in page.get("Contents", []):
        key = obj["Key"]
        head = s3.head_object(Bucket=bucket, Key=key)
        etag = head["ETag"].strip('"')
        if etag in hash_map:
            print("[DUP]", key, "==", hash_map[etag])
        else:
            hash_map[etag] = key
```

---

## 비용 최적화

| 요청 | 과금 |
|---|---|
| PUT/COPY/POST/LIST | 과금 |
| GET/SELECT | 과금 |
| DELETE | 보통 무료 |

### 실무 팁

- **Batch Upload**: 많은 작은 PUT → **멀티파트 업로드**로 묶거나 **압축/배치**
- **LIST 최소화**: **키 설계(접두사/파티션)** + **인덱싱/인벤토리** 활용
- **S3 Select**: 객체 전체 대신 필요한 **열/조건**만 읽어 전송량 절감

**S3 Select 예시(압축 CSV에서 특정 컬럼만)**
```bash
aws s3api select-object-content \
  --bucket my-bucket \
  --key logs/2025-11-10.csv.gz \
  --expression "SELECT s._1, s._5 FROM s3object s WHERE s._3 = 'ERROR'" \
  --expression-type SQL \
  --input-serialization '{"CSV":{"FileHeaderInfo":"NONE"},"CompressionType":"GZIP"}' \
  --output-serialization '{"CSV":{}}' out.json
```

---

## 절감 전략 ⑤ 데이터 전송 비용 최적화

| 경로 | 비용 |
|---|---|
| **S3 → 인터넷** | 과금 |
| **S3 → EC2 (동일 리전)** | 보통 무료 |
| **리전 간 전송** | 과금 |

### 실무 팁

- **EC2와 같은 리전**에 버킷 배치
- 대외 배포는 **CloudFront**를 통해 캐시/전송료 최적화
- 내부 트래픽은 **VPC Gateway/Interface Endpoint**로 **사설 경로** 확보(보안 + 요금 예측성)

---

## 시나리오별 종합 예제

### 시나리오 A: “대용량 로그 저장소”

- 요건: `logs/`에 하루 수 TB, 장기 분석용
- 전략:
  - 30일 후 **IA**, 90일 후 **Glacier**, 2년 후 **삭제**
  - Athena/Glue 카탈로그로 **서버리스 분석**, S3 Select로 샘플링

**Lifecycle 예시**
```json
{
  "Rules": [
    {
      "ID": "Logs-Archive-Delete",
      "Status": "Enabled",
      "Filter": { "Prefix": "logs/" },
      "Transitions": [
        { "Days": 30, "StorageClass": "STANDARD_IA" },
        { "Days": 90, "StorageClass": "GLACIER" }
      ],
      "Expiration": { "Days": 730 }
    }
  ]
}
```

**효과**: 저장 단가 대폭 절감 + 요청/전송량도 분석 패턴 최적화로 감소

---

### 시나리오 B: “멀티미디어 자산”

- 요건: 핫/웜/콜드 계층, 예측 어려움
- 전략: **Intelligent-Tiering** + 긴 보존 주기, 썸네일/메타만 핫 보관, 원본은 티어 이동

**업로드**
```bash
aws s3 cp movie.mov s3://media-bkt/ --storage-class INTELLIGENT_TIERING
```

**주의**: 소형 객체 대량이면 IT 모니터링 비용 비효율 가능 → **임계 크기** 기준으로 분리

---

### 시나리오 C: “배포 산출물(웹 정적 자산)”

- 요건: 최신본만 사용, 과거본은 거의 불필요
- 전략: 버전 관리 **활성화**하되, 비최신 버전 **즉시 Glacier 전환** 또는 **짧은 만료**

**Lifecycle(비최신 즉시 Glacier + 90일 만료)**
```json
{
  "Rules": [
    {
      "ID": "Artifacts-Noncurrent-Glacier",
      "Status": "Enabled",
      "NoncurrentVersionTransitions": [
        { "NoncurrentDays": 1, "StorageClass": "GLACIER" }
      ],
      "NoncurrentVersionExpiration": { "NoncurrentDays": 90 }
    }
  ]
}
```

---

## 거버넌스 & 태그 & 자동보고

### **비용 할당 태그(Cost Allocation Tags)**

- `Project`, `Owner`, `Env`, `CostCenter` 등 **표준 태그 강제**
- **Organizations → SCP** 또는 **AWS Config** 규칙으로 비태깅 리소스 차단/경고

**예) S3 태그 일괄 적용**
```bash
aws s3api put-bucket-tagging \
  --bucket my-bucket \
  --tagging '{
    "TagSet":[
      {"Key":"Project","Value":"analytics"},
      {"Key":"Owner","Value":"data-team"},
      {"Key":"Env","Value":"prod"}
    ]
  }'
```

### **S3 Inventory**로 버전/클래스 전수조사

```json
{
  "Destination": {
    "S3BucketDestination": {
      "AccountId": "<ACCOUNT_ID>",
      "Bucket": "arn:aws:s3:::inventory-bucket",
      "Format": "CSV",
      "Prefix": "inv"
    }
  },
  "IsEnabled": true,
  "Id": "daily-all",
  "IncludedObjectVersions": "All",
  "Schedule": { "Frequency": "Daily" }
}
```

적용:
```bash
aws s3api put-bucket-inventory-configuration \
  --bucket my-bucket \
  --id daily-all \
  --inventory-configuration file://inventory.json
```

### 자동 리포트(예: Lambda + Athena + SNS)

- 매일 CUR/Athena 쿼리 → 상위 10 버킷 비용/증감 → SNS 메일/Slack

---

## 요청/전송 최적화 고급 팁

- **리스트 폭발** 방지: **키 접두사 패턴**(연/월/일/해시)로 분할 → LIST 범위 감소
- **Batch Operations**: 메타데이터/클래스 일괄 변경(요청 수를 제어)
- **멀티파트 업로드**: 큰 파일에서 네트워크 효율 극대화
- **CloudFront**: GET 요청을 캐시에 흡수하여 S3 GET/LIST 비용 절감 + 전송료 최적화

**CloudFront 무효화(배포 업데이트)**
```bash
aws cloudfront create-invalidation \
  --distribution-id E123ABC456 \
  --paths "/*"
```

---

## 비용 관리

- **CRR/SRR**은 **스토리지 + 요청 + 전송** 비용을 유발
- 대상 버킷 스토리지 클래스는 **IA/Glacier** 등 선택 가능
- **Delete Marker 복제** 여부/필터(접두사/태그)로 비용 제어

**Replication 스니펫**
```json
{
  "Role": "arn:aws:iam::<ACCOUNT_ID>:role/s3-replication-role",
  "Rules": [
    {
      "ID": "Replicate-Logs",
      "Status": "Enabled",
      "Priority": 1,
      "Filter": { "Prefix": "logs/" },
      "Destination": {
        "Bucket": "arn:aws:s3:::dr-bucket",
        "StorageClass": "STANDARD_IA"
      },
      "DeleteMarkerReplication": { "Status": "Disabled" }
    }
  ]
}
```

---

## 보안과 절감의 동시 달성

| 기능 | 절감 관점 | 비고 |
|---|---|---|
| **SSE-S3** | 추가 요금 없음 | 기본 서버측 암호화 |
| **SSE-KMS** | **KMS 요청/키 관리 비용** | 보안/감사 요구와 균형 |
| **Object Lock** | 불변성 + 장기 아카이브(Class 혼합) | Glacier와 병행 |
| **VPC Endpoint** | 사설 경로, 예측 가능한 비용 | 보안 + 전송비 전략 |

> **CloudTrail**/Storage Lens/Config로 **설정 드리프트**를 즉시 감지해 **불필요 비용 루프**를 차단.

---

## 간단 비용 시뮬레이션 (변수 기반)

예) 월 기준:
- Standard 10 TB, IA 50 TB, Glacier 100 TB
- GET 50M, PUT 1M, LIST 100K
- 인터넷 전송 5 TB

총 비용 근사:
$$
\begin{aligned}
\text{Cost} \approx & \; 10{,}240 \cdot c_{\text{STD}}
+ 51{,}200 \cdot c_{\text{IA}}
+ 102{,}400 \cdot c_{\text{GLA}} \\
& + \frac{50{,}000{,}000}{1000} \cdot k_{\text{GET}}
+ \frac{1{,}000{,}000}{1000} \cdot k_{\text{PUT}}
+ \frac{100{,}000}{1000} \cdot k_{\text{LIST}} \\
& + 5{,}120 \cdot d_{\text{internet}}
\end{aligned}
$$

- 단가 \(c, k, d\)는 **지역/시점/공식 가격표**로 치환
- **민감 파라미터(상위 비용 항목)**를 찾아 **계층/정책/캐시**로 집중 대응

---

## 운영 체크리스트

- [x] **Cost Explorer/Storage Lens** 대시보드 활성
- [x] **Cost Allocation Tags** 승인 + 표준 태그 필수화
- [x] **Lifecycle**: Noncurrent/Transition/Expiration 설계
- [x] **Intelligent-Tiering**: 적합 집합에만 적용(작은 객체 주의)
- [x] **CloudFront**로 GET/전송 최적화
- [x] **Replication**: 범위/클래스/삭제마커 정책으로 비용 통제
- [x] **Athena + CUR**로 월간 리포트 자동화
- [x] **Budgets/Anomaly Detection** 알림

---

## 자동화 스니펫 모음

### 특정 접두사 일괄 클래스 전환(Batch Operations 없이 간단 루프)

```bash
PREFIX=archive/
BUCKET=my-bucket
aws s3api list-objects-v2 --bucket $BUCKET --prefix $PREFIX --query 'Contents[].Key' --output text |
tr '\t' '\n' | while read K; do
  aws s3api copy-object \
    --bucket $BUCKET \
    --copy-source ${BUCKET}/${K} \
    --key "$K" \
    --storage-class GLACIER \
    --metadata-directive REPLACE
done
```

### Athena 리포트 → SNS 발송(Lambda 의사코드)

```python
import boto3, json, time

athena = boto3.client('athena')
sns = boto3.client('sns')

def run_query(sql):
    r = athena.start_query_execution(
        QueryString=sql,
        QueryExecutionContext={'Database':'cur'},
        ResultConfiguration={'OutputLocation':'s3://athena-results/'}
    )
    qid = r['QueryExecutionId']
    # ... wait/poll ...
    # ... fetch results ...
    return results

def handler(event, context):
    sql = """
    SELECT product_storage_class, SUM(line_item_unblended_cost) cost
    FROM aws_billing_cur.cur_parquet
    WHERE usage_start_date >= date_add('day', -7, current_date)
      AND line_item_product_code='AmazonS3'
    GROUP BY 1 ORDER BY cost DESC
    """
    res = run_query(sql)
    msg = json.dumps(res, indent=2)
    sns.publish(TopicArn='arn:aws:sns:ap-northeast-2:123:cost', Message=msg, Subject='Weekly S3 Cost')
```

---

## 트러블슈팅

| 증상 | 원인 | 해결 |
|---|---|---|
| 비용 급증(저장) | 비최신 버전/임시 데이터 누적 | Lifecycle로 Noncurrent/Prefix 만료 |
| 비용 급증(요청) | 폭증하는 LIST/GET | CloudFront 캐시, 접두사 설계, Inventory/Index |
| 복원 비용 과다 | Glacier 복구 러시 | 복구 등급/배치/일정 조정(분산) |
| 전송비 과다 | 인터넷 대역폭 소비 | CloudFront, 동일 리전 처리, 사설 엔드포인트 |
| IT 적용했는데 절감 미약 | 작은 객체 대량 | 크기 임계치/대상 필터 재설계 |

---

## 요약(초안 재정리 + 보강)

| 전략 | 핵심 |
|---|---|
| 스토리지 클래스 | **접근 패턴 디자인**: Standard ↔ IA ↔ Glacier(Instant/Deep) |
| 수명 주기 | **오래된/비최신 버전 자동 이동/삭제** |
| 요청/전송 | **Batch/멀티파트/캐시/사설경로** |
| 거버넌스 | **태그/Inventory/Storage Lens/Config/CloudTrail** |
| 분석 | **Cost Explorer + CUR + Athena**(자동 리포트/알림) |
| 자동화 | **Lambda/Batch Operations**로 반복 제거 |

---

## 치트시트

```bash
# Lifecycle 적용

aws s3api put-bucket-lifecycle-configuration \
  --bucket my-bucket \
  --lifecycle-configuration file://lifecycle.json

# Intelligent-Tiering 업로드

aws s3 cp file.bin s3://my-bucket/ --storage-class INTELLIGENT_TIERING

# Inventory 구성

aws s3api put-bucket-inventory-configuration \
  --bucket my-bucket --id daily-all \
  --inventory-configuration file://inventory.json

# CloudFront 캐시 무효화

aws cloudfront create-invalidation --distribution-id E123ABC456 --paths "/*"

# Budgets 생성(50USD)

aws budgets create-budget --account-id $ACCOUNT_ID \
  --budget '{"BudgetName":"s3-50usd","BudgetLimit":{"Amount":"50","Unit":"USD"},"TimeUnit":"MONTHLY","BudgetType":"COST"}'
```

---

이로써 **S3 비용 구조 → 분석 도구 → 클래스/정책/요청/전송 최적화 → 거버넌스/자동화 → 트러블슈팅**까지,
초안의 내용을 **예제·코드·수식** 기반으로 확장해 **바로 적용 가능한 실전 가이드**로 정리했다.
다음 단계는 **당신의 실제 버킷/태그 체계**에 위 전략을 매핑해 **주간 리포트 & 예산 경보**를 돌리는 것이다.
