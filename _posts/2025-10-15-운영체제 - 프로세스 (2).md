---
layout: post
title: 운영체제 - 프로세스 (2)
date: 2025-10-15 21:25:23 +0900
category: 운영체제
---
# Interprocess Communication (IPC)

## Interprocess Communication (개요)

### 왜 IPC가 필요한가

- **데이터 교환**: 파이프라인 처리, 마이크로서비스 간 요청/응답
- **동기화**: 경쟁조건(race condition) 방지, 순서/원자성 보장
- **격리 수준 선택**: 성능(공유 메모리) ↔ 안정성/분산(메시지)

### IPC 카테고리

- **Shared Memory**: `shm_open`, `mmap`, `shmget`(SysV), 파일 기반 `mmap`, hugepage, 메모리 맵 파일
- **Message Passing**: 파이프, FIFO, 소켓(UNIX/TCP/UDP), POSIX 메시지 큐(`mq_*`), System V 메시지 큐
- **동기화 원시(Primitives)**: 세마포어, 뮤텍스, 조건 변수, futex, 파일 잠금(flock, fcntl)
- **고급 추상화**: gRPC, ZeroMQ, nanomsg, D-Bus, Binder(Android)

### 설계 선택의 기준

- **성능/복사비용**: 공유 메모리는 “복사 없이” 읽기/쓰기, 메시지는 일반적으로 **커널 경유 복사**
- **격리/안전성**: 메시지는 인터페이스가 명확(형식/크기/순서). 공유 메모리는 동기화 책임이 큼
- **스케일/분산**: 메시지는 프로세스/호스트 간 확장 쉬움
- **패턴 적합성**: 스트림(파이프/소켓), 요청-응답(RPC), 브로드캐스트(멀티캐스트), pub/sub

### 지연·처리량 직관

요청당 사용자-커널 경계 횟수를 $$k$$, 경계 비용을 $$C_b$$, 데이터 복사 비용을 $$C_c$$, 사용자 처리비용을 $$C_u$$라 두면
$$
T_{\text{msg}} \approx k\cdot C_b + C_c + C_u,\qquad
T_{\text{shm}} \approx C_{\text{sync}} + C_u.
$$
여기서 **공유 메모리**는 `C_c`(복사)를 줄이는 대신 **동기화 비용** $$C_{\text{sync}}$$에 주의해야 한다.

---

## IPC in Shared-Memory Systems

**핵심 아이디어**: 두(혹은 그 이상) 프로세스가 **같은 물리 메모리**를 매핑해 **복사 없이** 데이터를 교환한다.
대표 수단: POSIX `shm_open` + `mmap`, System V `shmget/shmat`, 파일 지원 `mmap`.

### POSIX 공유 메모리 + 세마포어 (단일 생산자/소비자)

> 목적: **복사 없이** 문자열을 공유 영역에 쓰고 읽기.
> 동기화: POSIX 세마포어(`sem_open`)로 **empty/full** 표현.

#### Writer (Producer)

```c
// shm_posix_writer.c
#define _GNU_SOURCE
#include <fcntl.h>
#include <sys/mman.h>
#include <sys/stat.h>
#include <semaphore.h>
#include <unistd.h>
#include <stdio.h>
#include <string.h>

#define SHM_NAME "/demo_shm"
#define SEM_EMPTY "/demo_sem_empty"
#define SEM_FULL  "/demo_sem_full"
#define BUFSZ 4096

typedef struct {
    size_t len;
    char   buf[BUFSZ];
} shm_block;

int main(){
    int fd = shm_open(SHM_NAME, O_CREAT|O_RDWR, 0600);
    ftruncate(fd, sizeof(shm_block));
    shm_block* p = mmap(NULL, sizeof(*p), PROT_READ|PROT_WRITE, MAP_SHARED, fd, 0);
    close(fd);

    sem_t* sem_empty = sem_open(SEM_EMPTY, O_CREAT, 0600, 1);
    sem_t* sem_full  = sem_open(SEM_FULL , O_CREAT, 0600, 0);

    const char* msgs[] = {"alpha", "beta", "gamma", "quit", NULL};
    for (int i=0; msgs[i]; i++){
        sem_wait(sem_empty);
        size_t n = strlen(msgs[i]);
        p->len = n;
        memcpy(p->buf, msgs[i], n+1);
        sem_post(sem_full);
        usleep(200*1000);
    }
    munmap(p, sizeof(*p));
    return 0;
}
```

#### Reader (Consumer)

```c
// shm_posix_reader.c
#define _GNU_SOURCE
#include <fcntl.h>
#include <sys/mman.h>
#include <sys/stat.h>
#include <semaphore.h>
#include <unistd.h>
#include <stdio.h>
#include <string.h>

#define SHM_NAME "/demo_shm"
#define SEM_EMPTY "/demo_sem_empty"
#define SEM_FULL  "/demo_sem_full"
#define BUFSZ 4096

typedef struct {
    size_t len;
    char   buf[BUFSZ];
} shm_block;

int main(){
    int fd = shm_open(SHM_NAME, O_RDWR, 0600);
    shm_block* p = mmap(NULL, sizeof(*p), PROT_READ|PROT_WRITE, MAP_SHARED, fd, 0);
    close(fd);
    sem_t* sem_empty = sem_open(SEM_EMPTY, 0);
    sem_t* sem_full  = sem_open(SEM_FULL , 0);

    for(;;){
        sem_wait(sem_full);
        if (strncmp(p->buf,"quit",4)==0) { sem_post(sem_empty); break; }
        write(1, p->buf, p->len);
        write(1, "\n", 1);
        sem_post(sem_empty);
    }
    munmap(p, sizeof(*p));
    shm_unlink(SHM_NAME);     // 정리
    sem_unlink(SEM_EMPTY);
    sem_unlink(SEM_FULL);
    return 0;
}
```

```bash
gcc -O2 shm_posix_writer.c -o shm_writer -pthread
gcc -O2 shm_posix_reader.c -o shm_reader -pthread
./shm_reader & ./shm_writer
```

**관찰 포인트**
- **복사 없음**(동일 메모리) → 큰 버퍼일수록 장점
- **동기화 실패**(세마포어 누락/순서 오류) 시 경쟁 상태/데드락 발생

---

### System V 공유 메모리 + 세마포어(요약)

> API는 구식이지만 **운용 환경**에 널리 남아 있다. 키/권한/제거 정책이 POSIX와 다름.

```c
// sysv_shm_writer.c (요약)
#include <sys/ipc.h>
#include <sys/shm.h>
#include <sys/sem.h>

...
key_t k = ftok("/tmp", 0x42);
int shmid = shmget(k, 4096, IPC_CREAT|0600);
char* p = shmat(shmid, NULL, 0);
int semid = semget(k, 2, IPC_CREAT|0600); // 0:empty, 1:full
// semop으로 P/V 연산 구현 (구체 코드는 생략)
```

**Tip**: 운영 중 **잔존 세그먼트**(프로세스 죽고 남은 shm/sem)를 `ipcs`, `ipcrm`로 청소.

---

### 메모리 매핑 파일(`mmap`)을 이용한 Zero-Copy 파이프라인

> 생산자와 소비자가 **같은 파일**을 매핑해 교환(저널/링 버퍼).

#### 고정 길이 헤더 + 페이로드

```c
// mmap_ring.c — 하나의 파일을 링버퍼로 사용(동기화는 간단히 스핀)
#define _GNU_SOURCE
#include <sys/mman.h>
#include <sys/stat.h>
#include <fcntl.h>
#include <unistd.h>
#include <stdatomic.h>
#include <string.h>
#include <stdio.h>

typedef struct {
    _Atomic size_t head, tail, cap;
    char data[];
} ring;

int main(int argc, char**argv){
    const char* path = "/tmp/ring.bin";
    int fd = open(path, O_CREAT|O_RDWR, 0600);
    size_t cap = 1<<20; // 1MB
    ftruncate(fd, sizeof(ring)+cap);
    ring* r = mmap(NULL, sizeof(ring)+cap, PROT_READ|PROT_WRITE, MAP_SHARED, fd, 0);
    close(fd);

    if (argc>1 && !strcmp(argv[1],"init")){
        r->head=r->tail=0; r->cap=cap; return 0;
    }
    if (argc>1 && !strcmp(argv[1],"w")){
        const char* m = "hello via mmap ring";
        size_t n=strlen(m);
        for(size_t i=0;i<n;i++){
            while(((r->head+1)%r->cap)==r->tail) ; // full → busy wait (학습용)
            r->data[r->head]=m[i];
            r->head=(r->head+1)%r->cap;
        }
        return 0;
    }
    if (argc>1 && !strcmp(argv[1],"r")){
        char out[256]; size_t k=0;
        while(k<20){
            while(r->head==r->tail) ; // empty
            out[k++]=r->data[r->tail];
            r->tail=(r->tail+1)%r->cap;
        }
        write(1,out,k); write(1,"\n",1);
        return 0;
    }
    fprintf(stderr,"usage: %s [init|w|r]\n", argv[0]);
    return 1;
}
```

```bash
gcc -O2 mmap_ring.c -o mmap_ring -pthread
./mmap_ring init
./mmap_ring r & ./mmap_ring w
```

**현업 개선 포인트**
- 바쁜 대기 대신 **futex**/세마포/조건변수 사용
- **헤더 + 데이터 일관성**을 위해 **메모리 배리어**(atomic, `__sync_synchronize`) 고려
- 장애 내성(크래시 시 재동기화) → **시퀀스 번호/저널링**

---

### 공유 메모리에서의 동시성 이슈와 해결

- **Race Condition**: 동시에 읽기/쓰기로 순서 의존 → 뮤텍스/세마포/lock-free 알고리즘
- **Deadlock**: 잠금 순환 → **고정된 락 순서**, 타임아웃/백오프
- **False Sharing**: 서로 다른 데이터가 같은 캐시 라인 → 패딩, alignas(64)
- **ABA 문제**(CAS 기반 구조) → 세대 카운터/태그

#### Cache line padding 예시

```c
typedef struct {
    _Atomic size_t head;
    char pad1[64 - sizeof(size_t)];
    _Atomic size_t tail;
    char pad2[64 - sizeof(size_t)];
    size_t cap;
    char data[];
} ring_padded;
```

---

## IPC in Message-Passing Systems

**핵심 아이디어**: 커널/네트워크를 통해 **메시지(바이트/프레임)** 를 주고받는다.
장점: 격리/안전(형태 정의), 프로세스/호스트 간 **확장성**.
단점: 보통 **복사**와 **경계 비용**이 수반됨.

### 파이프(익명/명명)

#### 익명 파이프: 부모–자식 단방향 스트림

```c
// pipe_demo.c
#include <unistd.h>
#include <string.h>
#include <sys/wait.h>

int main(){
    int p[2]; pipe(p);
    if(fork()==0){
        close(p[1]);
        char b[64]; int n=read(p[0], b, sizeof(b));
        write(1, b, n); _exit(0);
    }else{
        close(p[0]);
        const char* m="hello pipe\n";
        write(p[1], m, strlen(m));
        close(p[1]); wait(NULL);
    }
}
```

#### FIFO(명명 파이프): 경로 기반 다 프로세스 통신

```bash
mkfifo /tmp/myfifo
# 터미널1

cat /tmp/myfifo
# 터미널2

echo "via fifo" > /tmp/myfifo
```

---

### UNIX 도메인 소켓 (로컬 IPC / 파일 경로 기반)

**장점**: 파일 권한/SELinux로 접근 제어, **FD 전송**(ancillary data) 지원.

#### 서버/클라이언트 (스트림)

```c
// unix_srv.c
#define _GNU_SOURCE
#include <sys/socket.h>
#include <sys/un.h>
#include <unistd.h>
#include <string.h>
#include <stdio.h>

int main(){
    const char* path="/tmp/usock";
    unlink(path);
    int s=socket(AF_UNIX,SOCK_STREAM,0);
    struct sockaddr_un a={.sun_family=AF_UNIX};
    strncpy(a.sun_path,path,sizeof(a.sun_path)-1);
    bind(s,(struct sockaddr*)&a,sizeof(a));
    listen(s,16);
    int c=accept(s,NULL,NULL);
    char b[256]; int n=read(c,b,sizeof(b));
    write(c,b,n);
    return 0;
}
```

```c
// unix_cli.c
#include <sys/socket.h>
#include <sys/un.h>
#include <unistd.h>
#include <string.h>

int main(){
    const char* path="/tmp/usock";
    int s=socket(AF_UNIX,SOCK_STREAM,0);
    struct sockaddr_un a={.sun_family=AF_UNIX};
    strncpy(a.sun_path,path,sizeof(a.sun_path)-1);
    connect(s,(struct sockaddr*)&a,sizeof(a));
    write(s,"hello uds\n",11);
    char b[64]; int n=read(s,b,sizeof(b));
    write(1,b,n);
}
```

```bash
gcc -O2 unix_srv.c -o unix_srv && gcc -O2 unix_cli.c -o unix_cli
./unix_srv & ./unix_cli
```

#### 전송(요약: `sendmsg/recvmsg` + `SCM_RIGHTS`)

- 관리 프로세스가 **열린 소켓/파일**을 워커에게 넘겨 핸드오버

---

### TCP/UDP 소켓 (프로세스/호스트 간)

- **TCP**: 연결/신뢰/바이트 스트림, head-of-line blocking
- **UDP**: 비연결/비신뢰/메시지 경계 유지, 멀티캐스트 가능

#### TCP 에코 서버 (논블로킹 + epoll)

```c
// tcp_epoll_echo.c
#define _GNU_SOURCE
#include <sys/epoll.h>
#include <sys/socket.h>
#include <netinet/in.h>
#include <fcntl.h>
#include <unistd.h>
#include <errno.h>
#include <string.h>

static int nb(int fd){ int f=fcntl(fd,F_GETFL,0); return fcntl(fd,F_SETFL,f|O_NONBLOCK); }

int main(){
    int s=socket(AF_INET,SOCK_STREAM,0), one=1;
    setsockopt(s,SOL_SOCKET,SO_REUSEADDR,&one,sizeof(one));
    struct sockaddr_in a={.sin_family=AF_INET,.sin_port=htons(9090),.sin_addr={0}};
    bind(s,(struct sockaddr*)&a,sizeof(a)); listen(s,512); nb(s);

    int ep=epoll_create1(0);
    struct epoll_event ev={.events=EPOLLIN,.data.fd=s};
    epoll_ctl(ep,EPOLL_CTL_ADD,s,&ev);
    struct epoll_event evs[256]; char buf[4096];

    for(;;){
        int n=epoll_wait(ep,evs,256,-1);
        for(int i=0;i<n;i++){
            int fd=evs[i].data.fd;
            if(fd==s){
                for(;;){
                    int c=accept4(s,NULL,NULL,SOCK_NONBLOCK);
                    if(c<0){ if(errno==EAGAIN) break; else break; }
                    struct epoll_event ce={.events=EPOLLIN|EPOLLET,.data.fd=c};
                    epoll_ctl(ep,EPOLL_CTL_ADD,c,&ce);
                }
            }else{
                for(;;){
                    ssize_t r=read(fd,buf,sizeof(buf));
                    if(r>0){ (void)write(fd,buf,r); }
                    else if(r==0){ close(fd); break; }
                    else if(errno==EAGAIN) break; else { close(fd); break; }
                }
            }
        }
    }
}
```

```bash
gcc -O2 tcp_epoll_echo.c -o tcp_echo && ./tcp_echo
printf "hi\n" | nc 127.0.0.1 9090
```

#### UDP 요청/응답

```c
// udp_echo.c
#include <sys/socket.h>
#include <netinet/in.h>
#include <unistd.h>

int main(){
    int s=socket(AF_INET,SOCK_DGRAM,0);
    struct sockaddr_in a={.sin_family=AF_INET,.sin_port=htons(9091),.sin_addr={0}};
    bind(s,(struct sockaddr*)&a,sizeof(a));
    char b[1500]; struct sockaddr_in cli; socklen_t cl=sizeof(cli);
    for(;;){
        int n=recvfrom(s,b,sizeof(b),0,(struct sockaddr*)&cli,&cl);
        sendto(s,b,n,0,(struct sockaddr*)&cli,cl);
    }
}
```

---

### POSIX 메시지 큐

**장점**: 우선순위 지원, 커널 큐(영속X), 동기화 내장(블로킹/논블로킹).

```c
// mq_demo.c
#define _GNU_SOURCE
#include <mqueue.h>
#include <fcntl.h>
#include <sys/stat.h>
#include <stdio.h>
#include <string.h>
#include <unistd.h>

int main(int argc, char**argv){
    const char* q="/mq_demo";
    struct mq_attr at = {.mq_flags=0,.mq_maxmsg=10,.mq_msgsize=256,.mq_curmsgs=0};
    if(argc>1 && !strcmp(argv[1],"w")){
        mqd_t mq = mq_open(q, O_CREAT|O_WRONLY, 0600, &at);
        mq_send(mq, "hello", 5, 5); // prio=5
        mq_send(mq, "world", 5, 1); // prio=1
        mq_close(mq); return 0;
    }
    if(argc>1 && !strcmp(argv[1],"r")){
        mqd_t mq = mq_open(q, O_CREAT|O_RDONLY, 0600, &at);
        char buf[256]; unsigned pr;
        for(int i=0;i<2;i++){
            ssize_t n=mq_receive(mq, buf, sizeof(buf), &pr);
            write(1, buf, n); write(1,"\n",1);
        }
        mq_close(mq); mq_unlink(q); return 0;
    }
    fprintf(stderr,"usage: %s [w|r]\n", argv[0]);
    return 1;
}
```

```bash
gcc -O2 mq_demo.c -o mq_demo -lrt
./mq_demo r & ./mq_demo w
```

---

### Zero-Copy 메시징 기법 (고급)

- **`sendfile`**: 파일 → 소켓으로 **커널 내 복사 최소화**
- **`splice`/`tee`**: 파이프 ↔ 파일/소켓 간 **페이지 이동**으로 복사 줄이기
- **`io_uring`**: 커널과 **공유 큐**로 경계 비용 감소

```c
// sendfile_http.c (개념) — 소켓으로 정적 파일 전송
#include <sys/sendfile.h>

/* ... 소켓 accept 후 ... */
int fd = open("index.html", O_RDONLY);
off_t off=0; struct stat st; fstat(fd,&st);
sendfile(client_fd, fd, &off, st.st_size);
```

---

### 고수준 RPC (개념)

- **gRPC/HTTP+JSON**: 스키마/코드 생성, 스트리밍, 인증
- **ZeroMQ/nanomsg**: 패턴(pub/sub, req/rep) 내장, 브로커리스
- **성능/신뢰 트레이드오프**를 고려해 선택

---

## 3.4–3.6 실전 종합: “고속 로그 파이프라인” 설계

**목표**: 애플리케이션 프로세스들이 생성하는 로그를 **낮은 지연/낮은 오버헤드**로 수집/집계.

1) **프로듀서**(N개): 프로세스 로컬 **UNIX 도메인 datagram**으로 “소규모 로그 메시지” 송신
2) **로컬 에이전트**: 수신 즉시 **mmap 링버퍼(공유 메모리)**에 적재(Zero-copy)
3) **집계기**: 일정 배치마다 파일에 **`pwritev` + `fdatasync`**, 네트워크 전송은 **`sendfile`**
4) **관측**: `perf stat`/`bpftrace`로 시스템콜 비용 측정, **슬라이스/배치 크기**를 변수로 튜닝

**간단 모델**
배치 크기 $$B$$, 메시지당 고정 오버헤드 $$h$$, 시스템콜 비용 $$C_s$$, 복사 비용 $$C_c$$라 하면
$$
T_{\text{batch}} \approx C_s + B\cdot (h + C_c).
$$
- **공유 메모리**로 $$C_c\rightarrow 0$$,
- **배치**로 `C_s` amortization,
- **flush 주기**는 내구성 vs 지연의 절충.

---

## 디버깅/튜닝 체크리스트

- **파이프/소켓**: `strace -e send,recv,write,read`, `ss -tup`, `tcpdump`
- **공유 메모리**: `/proc/<pid>/maps`, `pmap`, `perf c2c`(캐시라인 충돌)
- **세마포/뮤텍스**: 잠금 경합 지표(`perf lock`, `bpftrace` kprobe on futex)
- **메시지 큐**: `mq_getattr`, 큐 길이/우선순위 분포
- **Zero-copy**: `perf record`로 경계 비용·복사 루프 확인

---

## 보안/안전 고려사항

- **권한**: POSIX shm/mq는 **네임스페이스/권한** 설정 필수
- **입력 검증**: 메시지 정형화(길이/헤더/체크섬) → **OOM/DoS** 방지
- **리소스 상한**: `RLIMIT_NOFILE`, `mq_maxmsg`/`mq_msgsize`, 공유 메모리 크기
- **셀프힐링**: 프로듀서 크래시 시 링버퍼 재동기화, **시퀀스 번호**/**헤더 CRC** 사용

---

## 추가 연습 과제

1) **다생산자/다소비자** 공유 메모리 큐를 **세마포어 + 조건변수**로 구현하고, **가변 길이 메시지**를 지원하라(헤더에 길이 포함).
2) **UNIX 도메인 소켓 + FD 전송**으로 “수락한 TCP 소켓”을 워커에게 넘기는 **핸드오프 서버**를 만들어라.
3) **POSIX 메시지 큐 우선순위**가 실제 처리 순서에 미치는 영향을 측정(동일 큐 길이 vs 다양한 prio).
4) `splice` 기반 **파일→TCP** 경로와 `read+write` 기반 경로의 CPU 사용량/처리량 차이를 비교하라.
5) 공유 메모리 링버퍼에 **futex** 기반 **대기/깨우기**를 붙여 바쁜 대기를 제거하라.

---

## 결론

- **Shared Memory**: 최고 성능(복사 없음), **동기화/일관성** 책임이 큼
- **Message Passing**: 격리/분산/신뢰성↑, 복사·경계 비용 관리 필요
- 올바른 선택은 **워크로드 특성**(메시지 크기, 지연 민감도, 장애 격리 요구)과 **운영 제약**(보안/관측/배포)에 달려 있다.
본 장의 예제들을 실행/변형하며 **지표**(지연·처리량·CPU·락 경합)를 수집하라. 그러면 어떤 IPC가 **언제** 더 적합한지 스스로 판단할 수 있다.
