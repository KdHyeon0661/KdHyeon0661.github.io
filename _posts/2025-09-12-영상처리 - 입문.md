---
layout: post
title: 영상처리 - 입문
date: 2025-09-12 19:25:23 +0900
category: 영상처리
---
# 영상 처리의 개요

## | 영상 처리의 개요

### 디지털 영상 처리란?

- **디지털 영상 처리(Digital Image Processing)**는 **이산화(discretization)**된 영상 데이터를 컴퓨터로 **분석·변환·측정**하는 전 과정을 말합니다.
- 영상은 **픽셀(pixel)**이라는 최소 단위의 격자(grid)로 표현되며, 각 픽셀은 밝기 또는 색 정보를 담습니다.
- 목표는 다양합니다.
  - **향상(Enhancement)**: 노이즈 제거, 선명화, 대비 보정 등 사람이 보기 좋게 만드는 처리
  - **복원(Restoration)**: 흐림/왜곡의 역과정(inverse) 추정으로 원래 신호 복원
  - **분할(Segmentation)**: 관심 영역/객체를 분리
  - **특징 추출(Feature Extraction)**: 에지, 코너, 텍스처, 키포인트 등
  - **인식/이해(Recognition/Understanding)**: 분류, 검출, 추적 등 상위 과제의 전처리 및 직접 해결
- 연산은 **공간 영역(spatial domain)** 또는 **주파수 영역(frequency domain)**에서 수행될 수 있습니다.

#### 핵심 수학 개념(압축 정리)

- **이산 신호**: 영상 $f[x, y]$는 $(x, y)\in\mathbb{Z}^2$에서 정의된 이산 함수
- **컨볼루션(Convolution)**:
  $$ g[x, y] \;=\; \sum_{m=-k}^{k}\sum_{n=-k}^{k} h[m, n]\; f[x-m,\, y-n] $$
  - 선형 필터의 기본. 블러, 샤프닝, 에지 검출 등 대부분의 고전 필터가 이 형태.
- **표본화/샘플링(Sampling)**: **나이퀴스트 조건**
  $$ f_s \ge 2 f_{\max} $$
  - 과소표본화는 **앨리어싱(aliasing)**을 발생 → 프리필터/안티앨리어싱 필요.
- **양자화(Quantization)**: 연속값을 유한한 비트로 근사. 8-bit 그레이스케일은 $\{0,\dots,255\}$ 범위.

> ✔️ **실무 요령**: 컨볼루션·보간 등은 성능 병목이 되기 쉽다. **메모리 접근 패턴**, **캐시 지역성**, **stride**, **SIMD**를 먼저 점검하자.

---

### 다양한 영상 처리 응용 분야

- **의료 영상**: MRI/CT/초음파의 잡음 억제, 조영 강조, 병변 영역 분할
- **산업 검사**: 반도체/PCB/제조 라인의 불량 검출, 측정 자동화(게이지)
- **자율주행/로보틱스**: 차선/보행자/신호등 검출, SLAM, 시각 오도메트리
- **위성/항공 영상**: 토지 피복 분류, 변화 탐지, 대기 보정
- **보안/CCTV**: 움직임 감지, 객체 추적, 군중 분석
- **멀티미디어**: 사진 보정, 영상 압축/스트리밍, AR 필터

응용은 계속 확장 중이며, **전통 영상 처리 + 딥러닝** 융합이 가속되고 있습니다. 전통 영상 처리의 정확한 이해는 **데이터 준비, 전처리, 후처리**에서 경쟁력이 됩니다.

---

## | 영상 처리 프로그래밍

이 절에서는 **영상 표현 방법**, **2차원 배열 처리**, **변형된 2차원 배열 동적 할당**을 실전 코드와 함께 설명합니다.
(코드는 **표준 C++17 이상**을 기준으로 하며, 필요 시 OpenCV로도 병행 예시를 보입니다.)

---

### 영상 표현 방법

#### 그레이스케일 vs 컬러

- **Grayscale**: 한 픽셀은 명도 **1채널** (보통 8-bit: 0~255)
- **Color**: 일반적으로 **3채널** (RGB/BGR). 픽셀 하나가 3개의 값으로 구성.

#### 채널 저장 방식

- **Interleaved(교차 저장)**: `RGBRGBRGB...` 픽셀 단위로 채널이 교차
  - OpenCV 기본 BGR interleaved (CV_8UC3)
- **Planar(평면 저장)**: `RRR... GGG... BBB...` 채널별로 독립 평면
  - 일부 영상 코덱/딥러닝 백엔드 선호

#### 픽셀 정밀도/비트 심도

- **정수형**: `uint8_t(8-bit)`, `uint16_t(10~12-bit 센서 저장에 사용)`, `uint32_t`
- **부동소수**: `float(32-bit)`, `double(64-bit)` — 정규화/필터링/변환에 유용

#### 색 공간(Color Space)

- **RGB ↔ YCbCr/YCbCr**: 전송/압축에서 널리 사용
- **sRGB 감마**: 디스플레이 표준. 선형 연산 전에는 **감마 역보정**을 고려:
  - 선형화(간략 모델): $$ C_{\text{lin}} = \left(\frac{C_{\text{sRGB}}}{255}\right)^\gamma, \quad \gamma \approx 2.2 $$
  - 다시 sRGB로: $$ C_{\text{sRGB}} = 255 \cdot C_{\text{lin}}^{1/\gamma} $$

#### 정렬과 stride(행 간 바이트 간격)

- 많은 라이브러리는 행을 **정렬(Alignment)**하여 SIMD/캐시 효율을 높입니다.
- 행의 실제 시작 바이트 간격을 **stride** 또는 **step**이라 하며, `stride >= width * channels * bytesPerChannel`.

```
메모리(1채널, 8-bit, width=6, stride=8, height=3)
row0: [p0 p1 p2 p3 p4 p5 __ __]
row1: [p0 p1 p2 p3 p4 p5 __ __]
row2: [p0 p1 p2 p3 p4 p5 __ __]
```

---

### 2차원 배열 처리 (순수 C++)

#### 연속(contiguous) 버퍼 + stride 인덱싱

- **장점**: 한 덩어리 메모리 → 캐시 친화적, 파일 I/O/라이브러리 호환이 쉬움
- **방법**: `std::vector<T>`에 `height * stride` 크기 할당 후, `(y*stride + x*channels + c)`로 접근

```cpp
#include <vector>
#include <cstdint>
#include <cassert>
#include <algorithm>

struct GrayImage8 {
    int width{};
    int height{};
    int stride{};                 // bytes per row
    std::vector<uint8_t> data;    // size = height * stride

    static int aligned_stride(int width, int alignBytes = 16) {
        int raw = width; // 1채널 8-bit
        int rem = raw % alignBytes;
        return rem ? (raw + (alignBytes - rem)) : raw;
    }

    GrayImage8(int w, int h, int alignBytes = 16)
        : width(w), height(h),
          stride(aligned_stride(w, alignBytes)),
          data(height * stride, 0) {}

    uint8_t& at(int x, int y) {
        assert(0 <= x && x < width);
        assert(0 <= y && y < height);
        return data[y * stride + x];
    }
};
```

> 팁: stride는 **픽셀 단위**가 아닌 **바이트 단위**로 관리하는 편이 실수가 적습니다(특히 다채널/고정밀 포맷).

#### 이중 포인터(행 포인터 테이블) 방식

- `std::vector<uint8_t*> rows(height)`를 만들어 **행 시작 포인터**를 캐시
- 내부 버퍼는 여전히 연속. 행 포인터로 인덱싱 간결화

```cpp
struct GrayView8 {
    int width{};
    int height{};
    int stride{};
    uint8_t* base{};
    std::vector<uint8_t*> rows; // 행 시작 포인터

    GrayView8(int w, int h, int s, uint8_t* ptr)
        : width(w), height(h), stride(s), base(ptr), rows(h, nullptr) {
        for (int y = 0; y < h; ++y) rows[y] = base + y * stride;
    }

    uint8_t& at(int x, int y) {
        return rows[y][x];
    }
};
```

#### ROI(sub-image) 뷰 만들기

- ROI는 **복사 없이** 포인터만 옮겨 **부분 영상**을 다룰 수 있어야 합니다.

```cpp
GrayView8 make_roi(GrayView8 src, int x, int y, int w, int h) {
    assert(x >= 0 && y >= 0 && x + w <= src.width && y + h <= src.height);
    GrayView8 roi = src;
    roi.width = w;
    roi.height = h;
    roi.base = src.base + y * src.stride + x;
    for (int r = 0; r < h; ++r) roi.rows[r] = roi.base + r * roi.stride;
    return roi;
}
```

---

### 변형된 2차원 배열 동적 할당

**“변형된”**이라는 표현은 보통 다음 상황을 가리킵니다.

- (1) **패딩/stride**가 있는 2D 버퍼(정렬 최적화)
- (2) **다채널 interleaved** 또는 **planar** 평면 구조
- (3) **부분 영상(ROI)** 뷰, **타일링**(tiling), **피치(pitch)** 개념
- (4) 고정 크기 행 포인터 배열 + 연속 픽셀 영역을 **하나의 블록**으로 동적 할당

#### 하나의 블록에 행 포인터 + 픽셀 버퍼를 통합 할당

- 메모리 해제 단순화 및 지역성 향상(행 포인터와 픽셀 데이터가 가깝다)

```cpp
#include <memory>
#include <cstring>

struct GrayImageOwned8 {
    int width{}, height{}, stride{};
    std::unique_ptr<uint8_t[]> block; // [row_ptrs | pixels]
    uint8_t** rows{};                  // block의 앞부분을 row 포인터 테이블로 사용
    uint8_t*  pixels{};                // block의 뒷부분을 실제 픽셀 데이터로 사용

    GrayImageOwned8(int w, int h, int alignBytes = 32)
        : width(w), height(h), stride(GrayImage8::aligned_stride(w, alignBytes))
    {
        size_t rowsBytes   = sizeof(uint8_t*) * h;
        size_t pixelBytes  = (size_t)stride * h;
        size_t total       = rowsBytes + pixelBytes;

        block = std::make_unique<uint8_t[]>(total);
        std::memset(block.get(), 0, total);

        rows   = reinterpret_cast<uint8_t**>(block.get());
        pixels = block.get() + rowsBytes;

        for (int y = 0; y < h; ++y) {
            rows[y] = pixels + (size_t)y * stride;
        }
    }

    uint8_t& at(int x, int y) { return rows[y][x]; }
};
```

#### 다채널 interleaved 이미지(예: 8-bit 3채널)

```cpp
struct BGRImage8 {
    int width{}, height{}, channels{3};
    int stride{}; // bytes per row
    std::vector<uint8_t> data;

    static int aligned_stride(int width, int channels, int alignBytes = 32) {
        int raw = width * channels;
        int rem = raw % alignBytes;
        return rem ? (raw + (alignBytes - rem)) : raw;
    }

    BGRImage8(int w, int h, int alignBytes = 32)
        : width(w), height(h),
          stride(aligned_stride(w, 3, alignBytes)),
          data((size_t)height * stride, 0) {}

    uint8_t* pixel_ptr(int x, int y) { return &data[(size_t)y * stride + x * 3]; }

    void set(int x, int y, uint8_t b, uint8_t g, uint8_t r) {
        auto* p = pixel_ptr(x, y);
        p[0] = b; p[1] = g; p[2] = r;
    }
};
```

#### Planar 3채널 (R/G/B 평면 분리)

```cpp
struct RGBPlanar8 {
    int width{}, height{};
    int stride{}; // bytes per row per plane
    std::vector<uint8_t> R, G, B;

    static int aligned_stride(int width, int alignBytes = 32) {
        int raw = width;
        int rem = raw % alignBytes;
        return rem ? (raw + (alignBytes - rem)) : raw;
    }

    RGBPlanar8(int w, int h, int alignBytes = 32)
        : width(w), height(h), stride(aligned_stride(w, alignBytes)),
          R((size_t)height * stride, 0),
          G((size_t)height * stride, 0),
          B((size_t)height * stride, 0) {}

    uint8_t& r(int x, int y) { return R[(size_t)y * stride + x]; }
    uint8_t& g(int x, int y) { return G[(size_t)y * stride + x]; }
    uint8_t& b(int x, int y) { return B[(size_t)y * stride + x]; }
};
```

> **선택 기준**
> - Interleaved: 일반 디스플레이/GUI/API 친화적, 한 픽셀의 3채널에 연속 접근이 쉬움
> - Planar: 채널별 컨볼루션/벡터화가 쉬움, 딥러닝 전처리(채널 정규화)에 종종 유리

---

## 실전: 가장 작은 파일 포맷으로 입출력(PGM/PPM)

BMP/PNG는 헤더와 압축/팔레트 등 보조 요소가 많아 **튜토리얼 초입**에는 부담입니다. **PGM/PPM(Netpbm)**은 텍스트 기반 헤더 + 원시 바이트로 단순합니다.

- **PGM(P5)**: 그레이스케일 1채널
  헤더 예시:
  ```
  P5
  640 480
  255
  <binary payload 640*480 bytes>
  ```
- **PPM(P6)**: 컬러 3채널(BGR/RGB 사용은 자유)
  ```
  P6
  640 480
  255
  <binary payload 640*480*3 bytes>
  ```

### 읽기/쓰기 — 안전한 최소 구현

```cpp
#include <fstream>
#include <string>
#include <sstream>
#include <stdexcept>
#include <cctype>

struct PGM {
    static GrayImage8 read(const std::string& path) {
        std::ifstream ifs(path, std::ios::binary);
        if (!ifs) throw std::runtime_error("PGM open failed");

        auto skip_comments = [&](std::istream& is) {
            int ch;
            while ((ch = is.peek()) == '#') {
                std::string dummy;
                std::getline(is, dummy);
            }
        };

        std::string magic;
        ifs >> magic;
        if (magic != "P5") throw std::runtime_error("Not P5");

        skip_comments(ifs);

        int w, h, maxv;
        ifs >> w; skip_comments(ifs);
        ifs >> h; skip_comments(ifs);
        ifs >> maxv;
        ifs.get(); // consume whitespace/newline after maxv

        if (maxv != 255) throw std::runtime_error("Only 8-bit PGM supported");

        GrayImage8 img(w, h, 16);
        for (int y = 0; y < h; ++y) {
            ifs.read(reinterpret_cast<char*>(&img.data[y * img.stride]), w);
            if (!ifs) throw std::runtime_error("PGM payload truncated");
        }
        return img;
    }

    static void write(const std::string& path, const GrayImage8& img) {
        std::ofstream ofs(path, std::ios::binary);
        if (!ofs) throw std::runtime_error("PGM write open failed");

        ofs << "P5\n" << img.width << " " << img.height << "\n255\n";
        for (int y = 0; y < img.height; ++y) {
            ofs.write(reinterpret_cast<const char*>(&img.data[y * img.stride]), img.width);
        }
    }
};
```

> **주의**: 헤더의 주석라인(`# ...`)이 중간중간 나타날 수 있으므로 **주석 스킵** 처리가 필요합니다.

---

## 기초 연산 — 픽셀 단위 루프 & 선형 변환

### 반전, 밝기/대비, 클램프

- **반전**: $g = 255 - f$
- **밝기/대비**: $g = \alpha f + \beta,\;\; g \in [0, 255]$로 **클램프**
- **정수 산술 주의**: 오버플로/언더플로 방지

```cpp
inline uint8_t clamp_u8(int v) { return (uint8_t)std::min(255, std::max(0, v)); }

void invert(GrayView8 img) {
    for (int y = 0; y < img.height; ++y) {
        uint8_t* row = img.rows[y];
        for (int x = 0; x < img.width; ++x) {
            row[x] = 255 - row[x];
        }
    }
}

void linear_contrast(GrayView8 img, float alpha, int beta) {
    for (int y = 0; y < img.height; ++y) {
        uint8_t* row = img.rows[y];
        for (int x = 0; x < img.width; ++x) {
            int v = int(alpha * row[x]) + beta;
            row[x] = clamp_u8(v);
        }
    }
}
```

---

## — 가장 작은 블러부터

$$
g[x,y] \;=\; \sum_{m=-1}^{1}\sum_{n=-1}^{1} h[m,n] \, f[x-m, y-n]
$$

### 경계 처리(Border Handling)

- **상수 패딩**(0 채움)
- **복제(Replicate)**: 경계 값을 반복
- **반사(Reflect)**: 배열 밖 인덱스를 반사 대칭

아래 코드는 **복제 경계**를 사용한 3×3 박스 블러 예시입니다.

```cpp
int clamp(int v, int lo, int hi) { return v < lo ? lo : (v > hi ? hi : v); }

void box_blur3x3(const GrayView8& src, GrayView8 dst) {
    static const int K[3][3] = {
        {1,1,1},
        {1,1,1},
        {1,1,1}
    };
    const int div = 9;

    for (int y = 0; y < src.height; ++y) {
        for (int x = 0; x < src.width; ++x) {
            int acc = 0;
            for (int j = -1; j <= 1; ++j) {
                int yy = clamp(y + j, 0, src.height - 1);
                const uint8_t* row = src.rows[yy];
                for (int i = -1; i <= 1; ++i) {
                    int xx = clamp(x + i, 0, src.width - 1);
                    acc += K[j+1][i+1] * row[xx];
                }
            }
            dst.rows[y][x] = uint8_t(acc / div);
        }
    }
}
```

> **테스트 팁**: 블러 후 히스토그램의 **첨두(peak)**가 낮아지고 분포가 넓어지는지 확인해 보세요.

---

## 컬러 → 그레이 변환(표준 계수)

**sRGB/BT.709** 근사:

$$ Y \;\approx\; 0.2126R + 0.7152G + 0.0722B $$

**BT.601** 근사:

$$ Y \;\approx\; 0.299R + 0.587G + 0.114B $$

```cpp
void bgr_to_gray(const BGRImage8& src, GrayView8 dst) {
    for (int y = 0; y < src.height; ++y) {
        const uint8_t* srow = &src.data[(size_t)y * src.stride];
        uint8_t* drow = dst.rows[y];
        for (int x = 0; x < src.width; ++x) {
            uint8_t b = srow[x*3 + 0];
            uint8_t g = srow[x*3 + 1];
            uint8_t r = srow[x*3 + 2];
            int yv = int(0.299f*r + 0.587f*g + 0.114f*b + 0.5f);
            drow[x] = clamp_u8(yv);
        }
    }
}
```

---

## — 최근접/선형 보간

해상도 변경, 회전/이동/스케일에서 핵심은 **소스 좌표 → 목적 좌표** 매핑과 **보간**입니다.

- 최근접(Nearest): 빠르지만 계단 현상
- 선형(Bilinear): 품질 향상, 비용 증가

**선형 보간** (그레이스케일):

$$
\begin{aligned}
x &= \lfloor u \rfloor,\;\; y = \lfloor v \rfloor \\
a &= u - x,\;\; b = v - y \\
g &= (1-a)(1-b)\,f[x,y] + a(1-b)\,f[x+1,y] \\
  &\quad + (1-a)b\,f[x,y+1] + ab\,f[x+1,y+1]
\end{aligned}
$$

```cpp
uint8_t bilinear(const GrayView8& src, float u, float v) {
    int x = (int)std::floor(u);
    int y = (int)std::floor(v);
    float a = u - x;
    float b = v - y;

    x = clamp(x, 0, src.width-2);
    y = clamp(y, 0, src.height-2);

    const uint8_t* r0 = src.rows[y];
    const uint8_t* r1 = src.rows[y+1];

    float f00 = r0[x],     f10 = r0[x+1];
    float f01 = r1[x],     f11 = r1[x+1];

    float g = (1-a)*(1-b)*f00 + a*(1-b)*f10 + (1-a)*b*f01 + a*b*f11;
    int gi = (int)std::round(g);
    return clamp_u8(gi);
}
```

---

## OpenCV와의 연결(Pure C++ ↔ cv::Mat)

**cv::Mat**은 `(height, width, type, data, step)`로 구성되며, 우리가 만든 버퍼를 **래핑**해 사용할 수 있습니다.

```cpp
#include <opencv2/opencv.hpp>

cv::Mat wrap_as_mat(GrayView8 v) {
    // CV_8UC1, 깊은 복사 없이 래핑. v.base의 라이프타임 유지 필수!
    return cv::Mat(v.height, v.width, CV_8UC1, v.base, v.stride);
}

cv::Mat wrap_as_mat(BGRImage8& c) {
    return cv::Mat(c.height, c.width, CV_8UC3, c.data.data(), c.stride);
}
```

OpenCV 필터를 **우리 버퍼**에 직접 적용:

```cpp
void gaussian_blur_inplace(GrayView8 img, int ksize = 3) {
    cv::Mat m = wrap_as_mat(img);
    cv::GaussianBlur(m, m, cv::Size(ksize, ksize), 0.0);
}
```

> **실무 메모**: 외부 라이브러리에 버퍼를 **래핑**할 때는 참조되는 동안 **소유 버퍼가 파괴되지 않도록** 수명 관리에 특히 유의하세요(RAII).

---

## 예제: PGM 읽고, 반전+블러 후 저장

```cpp
int main() {
    // 1) 입력 읽기
    GrayImage8 src = PGM::read("lenna.pgm");

    // 2) 뷰 준비
    GrayView8 srcv(src.width, src.height, src.stride, src.data.data());
    GrayImage8 dst(src.width, src.height);
    GrayView8 dstv(dst.width, dst.height, dst.stride, dst.data.data());

    // 3) 처리
    invert(srcv);
    box_blur3x3(srcv, dstv);

    // 4) 저장
    PGM::write("out.pgm", dst);
}
```

---

## 성능 팁 — 캐시/분기/SIMD/멀티스레딩

1. **접근 순서**: `y` 바깥, `x` 안쪽 루프(행 우선)로 캐시 지역성 극대화
2. **경계 분리**: 내부(패딩 필요 없음)와 경계(패딩/클램프 필요) 분리로 분기 최소화
3. **SIMD**: SSE/AVX/NEON으로 8~32 픽셀 동시 처리
4. **타일링**: 큰 영상은 L1/L2 캐시에 맞는 타일 단위로 처리
5. **스레딩**: `std::thread`, OpenMP, TBB 등을 통한 행 분할

*간단 AVX2 예시(개념 스니펫)*

```cpp
// g++ -mavx2 ...
#include <immintrin.h>

// 32바이트 정렬된 버퍼를 가정한 아주 단순한 반전(경계/정렬 예외 미처리)
void invert_avx2(uint8_t* ptr, size_t n) {
    __m256i v255 = _mm256_set1_epi8((char)0xFF);
    size_t i = 0;
    for (; i + 32 <= n; i += 32) {
        __m256i v = _mm256_loadu_si256((__m256i const*)(ptr + i));
        __m256i r = _mm256_sub_epi8(v255, v);
        _mm256_storeu_si256((__m256i*)(ptr + i), r);
    }
    for (; i < n; ++i) ptr[i] = 255 - ptr[i];
}
```

> **주의**: 실제 AVX 구현은 **정렬, stride, 경계**를 꼼꼼히 고려해야 합니다. 먼저 **정확한 scalar 버전**으로 검증 후 점진적으로 벡터화하세요.

---

## 히스토그램 계산 & 정규화

**히스토그램** $H[k] = |\{(x,y)\mid f[x,y] = k\}|,\; k\in[0,255]$

```cpp
#include <array>

std::array<uint32_t, 256> histogram(const GrayView8& img) {
    std::array<uint32_t, 256> H{}; H.fill(0);
    for (int y = 0; y < img.height; ++y) {
        const uint8_t* row = img.rows[y];
        for (int x = 0; x < img.width; ++x) ++H[row[x]];
    }
    return H;
}
```

**히스토그램 스트레칭**(min-max 정규화):

$$
g = \frac{f - f_{\min}}{f_{\max} - f_{\min}} \cdot 255
$$

```cpp
void hist_stretch(GrayView8 img) {
    int mn = 255, mx = 0;
    for (int y = 0; y < img.height; ++y) {
        const uint8_t* row = img.rows[y];
        for (int x = 0; x < img.width; ++x) {
            mn = std::min<int>(mn, row[x]);
            mx = std::max<int>(mx, row[x]);
        }
    }
    int denom = std::max(1, mx - mn);
    for (int y = 0; y < img.height; ++y) {
        uint8_t* row = img.rows[y];
        for (int x = 0; x < img.width; ++x) {
            int v = (row[x] - mn) * 255 / denom;
            row[x] = (uint8_t)v;
        }
    }
}
```

---

## 에지 검출(소벨)

수평/수직 마스크:

$$
G_x =
\begin{bmatrix}
-1 & 0 & 1\\
-2 & 0 & 2\\
-1 & 0 & 1
\end{bmatrix},\quad
G_y =
\begin{bmatrix}
-1 & -2 & -1\\
0  &  0 &  0\\
1  &  2 &  1
\end{bmatrix}
$$

크기 근사:

$$
M \approx |g_x| + |g_y|\quad\text{or}\quad M = \sqrt{g_x^2 + g_y^2}
$$

```cpp
void sobel_mag(const GrayView8& src, GrayView8 dst) {
    for (int y = 0; y < src.height; ++y) {
        for (int x = 0; x < src.width; ++x) {
            int xm1 = clamp(x-1, 0, src.width-1);
            int xp1 = clamp(x+1, 0, src.width-1);
            int ym1 = clamp(y-1, 0, src.height-1);
            int yp1 = clamp(y+1, 0, src.height-1);

            int tl = src.rows[ym1][xm1],  tc = src.rows[ym1][x],  tr = src.rows[ym1][xp1];
            int ml = src.rows[y][xm1],    mc = src.rows[y][x],    mr = src.rows[y][xp1];
            int bl = src.rows[yp1][xm1],  bc = src.rows[yp1][x],  br = src.rows[yp1][xp1];

            int gx = -tl + tr - 2*ml + 2*mr - bl + br;
            int gy = -tl - 2*tc - tr + bl + 2*bc + br;

            int mag = std::min(255, std::abs(gx) + std::abs(gy));
            dst.rows[y][x] = (uint8_t)mag;
        }
    }
}
```

---

## 메모리 안전 & 예외 대응 체크리스트

- [ ] 입력 크기/stride가 **오버플로**를 일으키지 않는지(곱셈 시 `size_t` 사용)
- [ ] 파일 헤더 **검증** (매직/치수/최대값)
- [ ] 경계 접근 시 **클램프** 또는 패딩 처리
- [ ] 래핑한 외부 포인터의 **수명 관리** (dangling 방지)
- [ ] 스레드 병렬 처리 시 **false sharing**과 **동기화 비용** 점검

---

## 미니 과제(Hands-on)

1) `PGM` 로더로 이미지를 읽고,
   - `invert` → `hist_stretch` → `box_blur3x3` 순서로 파이프라인 구성
   - 결과를 `out_stageX.pgm`으로 저장하고 단계별 차이를 확인

2) `bgr_to_gray` 구현을 **Planar** 구조 입력으로 바꾸어 보기

3) **ROI 기반** 처리:
   - 큰 이미지 가운데 512×512 ROI만 처리(복사 없는 뷰)
   - 전체 대비 ROI의 처리 시간이 어떻게 줄어드는지 측정

4) **경계 분리 최적화**:
   - 내부 영역(1~width-2, 1~height-2)은 분기 없는 핵심 루프
   - 나머지 경계만 별도 처리. 성능 차이를 측정

---

## 자주 묻는 질문(FAQ)

**Q. 왜 stride가 필요한가요? `width*channels`로 충분하지 않나요?**
A. 정렬/패딩으로 인해 **행의 실제 바이트 간격**이 `width*channels*bpp`보다 클 수 있습니다. 파일/라이브러리와 호환하려면 stride를 정확히 다뤄야 합니다.

**Q. Interleaved와 Planar 중 무엇을 선택해야 하나요?**
A. UI/렌더링/일반 API는 **Interleaved**가 편하고, 채널별 벡터화/딥러닝 전처리는 **Planar**가 유리합니다. 변환 비용을 감안해 파이프라인에 맞추세요.

**Q. float 영상이 필요한가요?**
A. 컨볼루션/정규화/감마 교정/기하 변환에서 **부동소수**가 수식 구현을 단순·정확하게 합니다. 최종 저장/표시 전 정수로 양자화하세요.

---

## 마무리 요약

- **영상 표현**: 픽셀/채널/색 공간/stride/정렬을 이해하면 대부분의 버그(왜곡, 색/단계 틀어짐)를 예방할 수 있습니다.
- **2D 배열 처리**: 연속 버퍼 + stride 인덱싱을 기본으로, ROI/포인터 테이블/planar 등 **실전 패턴**을 익히세요.
- **기본 연산**: 밝기/대비, 컨볼루션, 보간은 모든 상위 알고리즘의 **토대**입니다.
- **성능**: 메모리 접근이 왕. 루프 순서/경계 분리/SIMD/타일링/스레딩의 **순서 있는 최적화**가 중요합니다.
