---
layout: post
title: 소켓프로그래밍 - 멀티스레딩과 병렬성
date: 2025-09-25 15:25:23 +0900
category: 소켓프로그래밍
---
## 11. 멀티스레딩과 병렬성

> 목표: 서버 구조에서 **멀티스레딩 모델**을 비교(연결당 스레드 vs 스레드풀 vs 이벤트 루프 1개 + 워커),  
> `SO_REUSEPORT`로 **리스너 N개**를 분산하는 패턴을 익히고, **락 경합/false sharing/NUMA**의 병목을 피하는 법을 다룬다.  
> 마지막으로 **코어별 리스너 + epoll(ET)** 구성이 어떻게 스케일하는지 **실습 코드**와 **측정 지표**를 제시한다.  
> 기준: 리눅스 + C++23.

---

### 11.1 스레딩 모델, 언제 무엇을 쓰나

#### 11.1.1 연결당 스레드(one thread per connection)
- **설명**: `accept` 후 `std::jthread`(또는 `pthread`) 하나를 만들고 그 스레드가 해당 연결의 블로킹 I/O를 담당.
- **장점**
  - **프로그램 모델 단순**: 각 연결은 **직선적 로직**(프레이밍 → 핸들러 → 응답).
  - 디버깅이 쉬움, 레가시 코드와 궁합.
- **단점**
  - **스레드 수 = 동시 연결 수** → 수천~수만에서 **컨텍스트 스위치 폭증**, 스택 메모리(기본 1MB) 낭비.
  - **락 경합/캐시 압력**으로 성능 급락.
- **적합**
  - 동시 연결 **수백 이하**, I/O **대기**가 많은데 **CPU는 가벼운** 워크로드.

#### 11.1.2 스레드풀(thread pool)
- **설명**: 고정 개수의 워커 스레드에 작업을 분배. I/O는 보통 **논블로킹 + 멀티플렉서**와 조합하거나, 블로킹 I/O를 **작업 큐**로 위임.
- **장점**
  - 스레드 수를 **코어 수 근처**로 유지 → 스케일 안정.
  - CPU 바운드 로직(파싱/암호화/압축)에 워커 투입 가능.
- **단점**
  - **작업 큐**에서 락 경합 가능, **작은 작업**이면 큐잉 오버헤드가 의미 있게 됨.
  - I/O 이벤트와 워커 간 **핸드오프 비용**(캐시 로컬리티 손실).
- **적합**
  - I/O와 CPU 워크가 섞인 서비스. **중간 난이도**의 병렬성.

#### 11.1.3 이벤트 루프 1개 + 워커(offload)
- **설명**: **1개의 이벤트 루프(accept + epoll)** 가 모든 소켓 I/O를 처리, **무거운 작업만** 워커풀에 offload.  
- **장점**
  - 네트워크 I/O 경합이 최소화(단일 루프가 소유). 코어 친화적 캐시 히트.
- **단점**
  - **단일 루프가 병목** 가능(특히 수만 연결 + 대용량 송수신 시).
- **적합**
  - I/O는 가볍고, 가끔 **CPU-헤비**인 핸들러가 존재할 때.

#### 11.1.4 이벤트 루프 **N개** (코어별/샤딩: “어댑터-워커 일치”)
- **설명**: **코어 수(or NUMA 노드 수)** 만큼 **독립 epoll 루프**를 둠. 각 루프가 **자기 fd**만 처리(“소유권”).  
- **장점**
  - **락 프리**에 가깝다(공유 자료구조 제거).  
  - **L1/L2/L3 & NUMA** 로컬리티 최적.  
- **단점**
  - 연결을 어느 루프에 배정할지 결정(해시/REUSEPORT), **cross-thread handoff**가 어려움.
- **적합**
  - 고성능 서버(수만 연결, 대역폭 큼), **낮은 지연**이 중요한 서비스.

> 실무 결론: **“코어별 독립 이벤트 루프 + SO\_REUSEPORT”** 구성이 안전한 고성능 기본값이다.  
> CPU-헤비 작업이 눈에 띄면 **루프 내부 소형 워커풀** 또는 **비동기 job queue**를 같은 코어에 붙여 로컬리티를 유지하라.

---

### 11.2 `SO_REUSEPORT`로 리스너 N개 분산

- **목적**: 다수(코어 수만큼)의 프로세스/스레드가 동일 (IP,PORT)에 `bind/listen` 하여 **커널이 들어오는 연결을 분산**.
- **장점**
  - **accept 락 경합 제거**(전통적 “thundering herd” 문제 해소).
  - **코어별**로 독립 서버 루프 → 캐시/NUMA 로컬리티.
- **주의**
  - 모든 리스너에 **동일 옵션/백로그**를 설정.
  - 분배는 해시 기반(완전 균등 보장 X).  
  - 애플리케이션 레벨 **로드밸런스**(소켓 수/연결 수 관측하여 워커 수 동적 조정) 병행 권장.

**리스너 생성 요점(요지)**

```cpp
int lfd = ::socket(family, SOCK_STREAM, 0);
int on = 1;
::setsockopt(lfd, SOL_SOCKET, SO_REUSEADDR, &on, sizeof(on));
::setsockopt(lfd, SOL_SOCKET, SO_REUSEPORT, &on, sizeof(on));
::bind(lfd, addr, addrlen);
::listen(lfd, 1024);
```

---

### 11.3 락 경합, false sharing, NUMA

#### 11.3.1 락 경합(lock contention)
- **공유 큐/맵**에 여러 스레드가 빈번히 접근 → **CAS/뮤텍스 경합**, **cache-line ping-pong**.
- 대책:
  - **샤딩(sharding)**: 코어별 **분할 자료구조**(N배 복제).
  - **싱글 라이터 원칙**: fd/연결 소유권을 **단일 루프**에 고정.
  - **배치 처리**: 이벤트/작업을 모아서 처리(오버헤드 amortization).

#### 11.3.2 false sharing(가짜 공유)
- 서로 다른 변수지만 같은 **cache line(보통 64B)** 에 위치 → 한 스레드가 갱신하면 다른 스레드의 캐시 라인 **무효화**.  
- 대책:
  - **패딩**: `alignas(64)` + 패딩 필드로 라인 분리.
  - **코어별 구조**에 **hot counter** 를 분리.

```cpp
struct alignas(64) Counter {
    std::atomic<uint64_t> v{0};
    char pad[64 - sizeof(std::atomic<uint64_t>)]; // 단순 예시
};
```

#### 11.3.3 NUMA
- **메모리 접근 비용**이 노드 간 다름. 소켓/스레드는 **같은 NUMA 노드의 메모리**를 사용해야 유리.
- 대책:
  - **CPU affinity**로 스레드를 **코어/노드에 고정**.
  - **메모리 할당**을 첫 접근 노드에서 수행(“first touch”).
  - 리스너/epoll 루프/워크 메모리를 **노드별 분리**.

**CPU affinity 설정(간단 예)**

```cpp
#include <pthread.h>
#include <sched.h>

void pin_to_cpu(int cpu) {
    cpu_set_t set; CPU_ZERO(&set); CPU_SET(cpu, &set);
    ::pthread_setaffinity_np(pthread_self(), sizeof(set), &set);
}
```

---

### 11.4 코어별 리스너 + epoll(ET) 스케일링 — 설계

- **프로세스 1개** 내 **N개 워커 스레드**(N=코어 수 또는 노드별 * 코어수):
  1) 각 워커가 **자기 리스너**를 생성(`SO_REUSEPORT`), **자기 epoll**을 돌린다.
  2) 각 워커는 **accept/epoll/recv/send** 를 **전담**(fd 소유권 고정).
  3) **CPU affinity** 로 각 워커를 각 코어에 고정.
- **상호 공유 없음**: 공용 큐/락 제거(로그/통계는 **원자 per-thread 카운터**로 모아서 주기적 집계).

---

### 11.5 실습: 코어별 리스너 + epoll(ET) 에코 서버

> **특징**
> - 스레드 수 = 코어 수(옵션), 각 스레드는 **독립 리스너**(`SO_REUSEPORT`)와 **자기 epoll** 보유.
> - **길이-프리픽스** 프레이밍(4B, BE), **CAP** 방어.
> - **ET 드레인 루프** 정석.
> - **CPU affinity** 옵션.
> - **간단 벤치 지표**: per-thread 처리량 카운터.

```cpp
// reuseport_et_server.cpp
// 빌드: g++ -std=c++23 -O2 -pthread reuseport_et_server.cpp -o reuseport_server
// 사용: ./reuseport_server [bind_host] [port] [threads=N] [affinity=0|1]
//   예) ./reuseport_server :: 9000 8 1
//
// 참고: root 권한 없이도 동작. CPU pinning은 권한/컨테이너 제한에 따라 실패할 수 있음(무시 가능).

#include <arpa/inet.h>
#include <fcntl.h>
#include <netdb.h>
#include <sys/epoll.h>
#include <sys/socket.h>
#include <unistd.h>

#include <atomic>
#include <cerrno>
#include <csignal>
#include <cstdint>
#include <cstdio>
#include <cstring>
#include <expected>
#include <iostream>
#include <memory>
#include <print>
#include <span>
#include <string>
#include <string_view>
#include <thread>
#include <vector>

static std::error_code last_errno(){ return {errno, std::generic_category()}; }

static int set_nonblock(int fd) {
    int fl = ::fcntl(fd, F_GETFL, 0);
    if (fl == -1) return -1;
    return ::fcntl(fd, F_SETFL, fl | O_NONBLOCK);
}

struct addr_list { addrinfo* head{}; ~addr_list(){ if (head) ::freeaddrinfo(head); } };

static std::expected<addr_list, std::error_code>
resolve(std::string_view host, std::string_view serv, int family, int socktype, int flags) {
    addrinfo hints{}; hints.ai_family=family; hints.ai_socktype=socktype; hints.ai_flags=flags;
    addrinfo* res=nullptr;
    int rc = ::getaddrinfo(host.empty()?nullptr:std::string(host).c_str(),
                           std::string(serv).c_str(), &hints, &res);
    if (rc != 0) return std::unexpected(std::make_error_code(std::errc::invalid_argument));
    addr_list L; L.head = res; return L;
}

static std::string sa_to_string(const sockaddr* sa, socklen_t slen) {
    char h[NI_MAXHOST]{}, s[NI_MAXSERV]{};
    if (::getnameinfo(sa, slen, h, sizeof(h), s, sizeof(s), NI_NUMERICHOST|NI_NUMERICSERV)==0)
        return std::string(h)+":"+s;
    return "(unknown)";
}

static int make_reuseport_listener(std::string_view host, std::string_view port, int backlog=1024) {
    auto R = resolve(host, port, AF_UNSPEC, SOCK_STREAM, AI_PASSIVE|AI_ADDRCONFIG|AI_NUMERICSERV);
    if (!R) return -1;
    for (auto* ai=R->head; ai; ai=ai->ai_next) {
        int s = ::socket(ai->ai_family, ai->ai_socktype, ai->ai_protocol);
        if (s<0) continue;
        int on=1;
        ::setsockopt(s, SOL_SOCKET, SO_REUSEADDR, &on, sizeof(on));
        ::setsockopt(s, SOL_SOCKET, SO_REUSEPORT, &on, sizeof(on));
        if (ai->ai_family==AF_INET6) {
            int v6only=0; ::setsockopt(s, IPPROTO_IPV6, IPV6_V6ONLY, &v6only, sizeof(v6only));
        }
        if (::bind(s, ai->ai_addr, ai->ai_addrlen)==0 && ::listen(s, backlog)==0) {
            if (set_nonblock(s)!=0) { ::close(s); continue; }
            std::print("[listen] {}\n", sa_to_string(ai->ai_addr, ai->ai_addrlen));
            return s;
        }
        ::close(s);
    }
    return -1;
}

struct Conn {
    enum class St { READ_LEN, READ_BODY, WRITE_BODY };
    St st = St::READ_LEN;
    uint32_t be_len{0};
    uint32_t len{0};
    std::size_t have_len{0};
    std::size_t have_body{0};
    std::size_t out_sent{0};
    std::vector<std::byte> in;
    std::vector<std::byte> out; // [4B | body]
};

struct ThreadCtx {
    int id{};
    int lfd{-1};
    int ep{-1};
    std::vector<Conn*> table; // fd index
    std::atomic<uint64_t> frames{0}; // 처리 프레임 수(벤치 지표)
    std::atomic<uint64_t> bytes_in{0}, bytes_out{0};
};

static void pin_cpu_if(int tid, bool do_pin) {
#ifdef __linux__
    if (!do_pin) return;
    cpu_set_t set; CPU_ZERO(&set);
    // 간단하게: tid를 CPU로 맵. 실제는 NUMA/하이퍼스레딩 고려 필요.
    int cpu = tid % std::thread::hardware_concurrency();
    CPU_SET(cpu, &set);
    ::pthread_setaffinity_np(pthread_self(), sizeof(set), &set);
    std::print("[thread {}] pinned to cpu {}\n", tid, cpu);
#else
    (void)tid; (void)do_pin;
#endif
}

static inline void ep_add(int ep, int fd, uint32_t ev) {
    epoll_event e{}; e.data.fd=fd; e.events=ev;
    ::epoll_ctl(ep, EPOLL_CTL_ADD, fd, &e);
}
static inline void ep_mod(int ep, int fd, uint32_t ev) {
    epoll_event e{}; e.data.fd=fd; e.events=ev;
    ::epoll_ctl(ep, EPOLL_CTL_MOD, fd, &e);
}
static inline void ep_del(int ep, int fd) {
    ::epoll_ctl(ep, EPOLL_CTL_DEL, fd, nullptr);
}

static Conn* get_conn(ThreadCtx& C, int fd) {
    if ((size_t)fd >= C.table.size()) C.table.resize(fd+1, nullptr);
    if (!C.table[fd]) C.table[fd] = new Conn{};
    return C.table[fd];
}

static void free_conn(ThreadCtx& C, int fd) {
    if ((size_t)fd < C.table.size() && C.table[fd]) {
        delete C.table[fd];
        C.table[fd] = nullptr;
    }
}

static bool drain_read(ThreadCtx& T, int fd, Conn& C) {
    constexpr std::size_t CAP = 1<<20; // 1MiB
    for(;;){
        if (C.st == Conn::St::READ_LEN) {
            std::byte* dst = std::as_writable_bytes(std::span{&C.be_len,1}).data() + C.have_len;
            ssize_t n = ::recv(fd, dst, 4 - C.have_len, 0);
            if (n > 0) {
                C.have_len += (size_t)n;
                if (C.have_len == 4) {
                    C.len = ntohl(C.be_len);
                    if (C.len > CAP) return false;
                    C.in.assign(C.len, std::byte{0});
                    C.have_body = 0;
                    C.st = Conn::St::READ_BODY;
                }
                continue;
            }
            if (n == 0) return false;
            if (errno == EAGAIN || errno == EWOULDBLOCK) break;
            if (errno == EINTR) continue;
            return false;
        }
        if (C.st == Conn::St::READ_BODY) {
            std::byte* dst = C.in.data() + C.have_body;
            ssize_t need = (ssize_t)(C.len - C.have_body);
            ssize_t n = ::recv(fd, dst, need, 0);
            if (n > 0) {
                C.have_body += (size_t)n;
                T.bytes_in += (uint64_t)n;
                if (C.have_body == C.len) {
                    // echo
                    uint32_t be = htonl(C.len);
                    C.out.resize(4 + C.len);
                    std::memcpy(C.out.data(), &be, 4);
                    std::memcpy(C.out.data()+4, C.in.data(), C.len);
                    C.out_sent = 0;
                    C.st = Conn::St::WRITE_BODY;
                    ep_mod(T.ep, fd, EPOLLIN|EPOLLOUT|EPOLLRDHUP|EPOLLET);
                    break; // 쓰기 기회 주기
                }
                continue;
            }
            if (n == 0) return false;
            if (errno == EAGAIN || errno == EWOULDBLOCK) break;
            if (errno == EINTR) continue;
            return false;
        }
        break;
    }
    return true;
}

static bool drain_write(ThreadCtx& T, int fd, Conn& C) {
    if (C.st != Conn::St::WRITE_BODY) return true;
    for(;;){
        std::size_t sent = C.out_sent;
        std::size_t remain = C.out.size() - sent;
        if (remain == 0) break;
        ssize_t n = ::send(fd, C.out.data()+sent, remain, 0);
        if (n > 0) {
            C.out_sent += (size_t)n;
            T.bytes_out += (uint64_t)n;
            continue;
        }
        if (n == 0) break;
        if (errno == EAGAIN || errno == EWOULDBLOCK) break;
        if (errno == EINTR) continue;
        return false;
    }
    if (C.out_sent == C.out.size()) {
        // 완료 → 다음 프레임
        C.st = Conn::St::READ_LEN; C.have_len=0; C.have_body=0; C.out.clear(); C.in.clear();
        T.frames++;
        ep_mod(T.ep, fd, EPOLLIN|EPOLLRDHUP|EPOLLET);
    }
    return true;
}

static void thread_main(ThreadCtx T, std::string bind_host, std::string port, bool pin) {
    pin_cpu_if(T.id, pin);

    T.lfd = make_reuseport_listener(bind_host, port, 2048);
    if (T.lfd < 0) { std::print(stderr, "[t{}] listen fail\n", T.id); return; }

    T.ep = ::epoll_create1(EPOLL_CLOEXEC);
    if (T.ep < 0) { std::print(stderr, "[t{}] epoll_create1: {}\n", T.id, std::strerror(errno)); return; }

    ep_add(T.ep, T.lfd, EPOLLIN | EPOLLET);

    constexpr int MAX_EVENTS = 512;
    std::vector<epoll_event> evs(MAX_EVENTS);

    auto accept_drain = [&](){
        for(;;){
            sockaddr_storage ss{}; socklen_t sl=sizeof(ss);
            int cfd = ::accept4(T.lfd, (sockaddr*)&ss, &sl, SOCK_NONBLOCK|SOCK_CLOEXEC);
            if (cfd >= 0) {
                get_conn(T, cfd); // allocate slot
                ep_add(T.ep, cfd, EPOLLIN | EPOLLRDHUP | EPOLLET);
                continue;
            }
            if (errno==EAGAIN || errno==EWOULDBLOCK) break;
            if (errno==EINTR) continue;
            break;
        }
    };

    auto close_conn = [&](int fd){
        ep_del(T.ep, fd);
        ::close(fd);
        free_conn(T, fd);
    };

    // 메인 이벤트 루프
    for(;;){
        int n = ::epoll_wait(T.ep, evs.data(), (int)evs.size(), 10000);
        if (n < 0) {
            if (errno==EINTR) continue;
            break;
        }
        if (n == 0) continue;

        for (int i=0;i<n;++i) {
            int fd = evs[i].data.fd;
            uint32_t ev = evs[i].events;

            if (fd == T.lfd) { accept_drain(); continue; }

            Conn* C = (fd < (int)T.table.size()) ? T.table[fd] : nullptr;
            if (!C) { close_conn(fd); continue; }

            if (ev & (EPOLLERR|EPOLLHUP)) { close_conn(fd); continue; }
            if (ev & EPOLLRDHUP) { close_conn(fd); continue; }

            if (ev & EPOLLIN) {
                if (!drain_read(T, fd, *C)) { close_conn(fd); continue; }
            }
            if (ev & EPOLLOUT) {
                if (!drain_write(T, fd, *C)) { close_conn(fd); continue; }
            }
        }
    }

    ::close(T.ep);
    ::close(T.lfd);
}

static std::atomic<bool> stop_flag{false};
static void on_sigint(int){ stop_flag.store(true); }

int main(int argc, char** argv) {
    std::string host = (argc>1 ? argv[1] : "");
    std::string port = (argc>2 ? argv[2] : "9000");
    int threads = (argc>3 ? std::stoi(argv[3]) : (int)std::thread::hardware_concurrency());
    bool pin = (argc>4 ? std::stoi(argv[4])!=0 : false);

    std::print("[main] host='{}' port={} threads={} pin={}\n", host, port, threads, pin);

    std::signal(SIGINT, on_sigint);
    std::vector<std::jthread> ths;
    ths.reserve(threads);
    for (int i=0;i<threads;i++) {
        ThreadCtx t; t.id = i;
        ths.emplace_back(std::jthread([=]() mutable {
            thread_main(t, host, port, pin);
        }));
    }

    // 단순 상태 출력(표준 출력은 비용이 큼 → 실제 벤치 시에는 끄기)
    while (!stop_flag.load()) {
        std::this_thread::sleep_for(std::chrono::seconds(2));
        // 각 스레드 로컬 카운터를 main에서 접근할 수 있도록 공유메모리/pipe/metrics를 써야 하지만,
        // 여기서는 간소화(스레드 내부 로컬이므로 생략). 실무에선 /proc, eBPF, 외부 벤치로 관측 권장.
        std::print("[main] running... (press Ctrl-C to stop)\n");
    }
    std::print("[main] stopping\n");
    return 0;
}
```

> **확장 포인트**  
> - per-thread 통계를 **공유 메모리**(lock-free 링버퍼)로 main에 집계.  
> - **NUMA 노드별**로 스레드/리스너를 분리하고, 큰 버퍼 할당을 **first-touch**로 초기화.  
> - **TLS 오프로딩**이 필요하면 워커를 **같은 코어**에 배치(핸드오프 최소화).

---

### 11.6 간단 벤치마크 및 비교 항목

#### 11.6.1 벤치 도구
- 레이어-7: `wrk`, `h2load`, `bombardier`(HTTP 기반일 때).
- 레이어-4: `hping3`, `iperf3`(TCP 모드), 또는 **자체 TCP 에코 로더**(N 커넥션, M바이트 프레임).

#### 11.6.2 비교 실험 시나리오
1) **단일 스레드(epoll 1개)** vs **코어별 epoll + SO\_REUSEPORT**  
   - 동일 메시지 크기/연결수에서 **RPS/MB/s/지연 p95/p99** 비교.
2) **CPU affinity ON/OFF**  
   - 핀닝 시 **지연 분산**과 **캐시 미스** 감소 관찰.
3) **NUMA cross traffic**  
   - 한 노드의 스레드가 다른 노드 메모리를 쓰게 해 **지연 증가**를 확인.
4) **스레드풀/핸드오프**  
   - I/O 루프 → 워커큐(락) → 응답: **락 경합**과 **캐시 로컬리티 손실**로 지표 악화 여부 관찰.

#### 11.6.3 관측 포인트
- **CPU 사용률**(per-core), **컨텍스트 스위치**, **run queue length**  
- **TCP retrans**, **RTT**, **cwnd** (`TCP_INFO`), **socket snd/rcv-queue**(`ss -tinp`)  
- **perf**: L1/L2/L3 miss, LLC miss %, branch miss  
- **/proc/interrupts**: NIC 큐/IRQ가 특정 코어에 몰리는지

---

### 11.7 수학적 직관 — Amdahl & Gustafson

- **Amdahl’s Law**(직렬 비율 \(s\), 코어 수 \(N\)):
  $$
  \text{Speedup}_{\text{Amdahl}} = \frac{1}{s + \frac{1-s}{N}}
  $$
  → 직렬 구간(\(s\))이 크면 \(N\)을 늘려도 **한계**.
- **Gustafson’s Law**(문제 크기를 늘리면):
  $$
  \text{Speedup}_{\text{Gustafson}} = N - s \times (N - 1)
  $$
  → **스케일 아웃**에서 문제 크기를 키우면 병렬 이득이 더 현실적.
- **해석**: 공유 큐/락/전역 로그 등 **직렬 병목**을 줄여 \(s \downarrow\) 하는 것이 핵심.  
  `SO_REUSEPORT + per-core epoll`은 수신 경로의 직렬 병목을 **구조적으로 제거**한다.

---

### 11.8 체크리스트(현장용)

- [ ] **구조 선택**: 가능한 한 **코어별 독립 epoll**(fd 소유권 고정).  
- [ ] **REUSEPORT**: 동일 옵션/백로그로 리스너 N개.  
- [ ] **CPU affinity**: 스레드를 코어/NUMA 노드에 고정.  
- [ ] **락 회피**: 공유 맵/큐 제거. 필요한 경우 **샤딩 + 배치**.  
- [ ] **false sharing 방지**: 핫 카운터는 `alignas(64)` 패딩.  
- [ ] **메모리**: first-touch, 노드별 allocator(선택: `std::pmr`).  
- [ ] **ET 정석**: `accept/recv/send` 를 **EAGAIN까지 드레인**.  
- [ ] **CAP/백프레셔**: per-conn 송신 큐 상한, 초과 시 상위로 흐름 제어.  
- [ ] **벤치시 로그 OFF**: 표준 출력은 병목.  
- [ ] **지표**: p50/p95/p99 지연, RPS/MBps, CPU/LLC miss, retrans.

---

### 11.9 마무리

멀티스레딩에서 성능을 **결정**하는 것은 **모델**이다.  
작업 큐를 중심으로 한 전통적 스레드풀은 **단순**하지만 **락 경합/핸드오프**를 수반한다.  
반면, `SO_REUSEPORT` + **코어별 epoll(ET)** 은 **소유권 고정**과 **로컬리티**를 통해  
락을 없애고 캐시 친화적 경로를 만든다. **지표로 검증**하라: 동일 하드웨어에서 **지연 분포가 조여지고** **스루풋이 상승**할 것이다.  
그다음 단계는 **NUMA 튜닝**, **NIC 큐/IRQ affinity**, **TLS 오프로딩** 등 시스템 전반을 하나의 **병렬 파이프라인**으로 정렬하는 일이다.
