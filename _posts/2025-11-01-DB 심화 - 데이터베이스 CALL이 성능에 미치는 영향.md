---
layout: post
title: DB 심화 - 데이터베이스 CALL이 성능에 미치는 영향
date: 2025-11-01 18:25:23 +0900
category: DB 심화
---
# 데이터베이스 호출이 성능에 미치는 영향과 최적화 방법

> **핵심 요약**
> 데이터베이스 성능 문제의 상당수는 과도한 호출에서 비롯됩니다. 호출 자체의 횟수가 많거나, 각 호출이 내부적으로 수행하는 작업량이 과도할 때 응답 시간이 느려집니다. 네트워크 왕복 최소화, 커서 재사용, 실행 계획 안정화, 적절한 배치 처리 등을 통해 이러한 문제를 해결할 수 있습니다.

---

## 실습 환경 준비

```sql
-- 대용량 테이블 생성
DROP TABLE sales_rt PURGE;
CREATE TABLE sales_rt AS
SELECT level   AS sale_id,
       CASE MOD(level,4)
         WHEN 0 THEN 'APAC' WHEN 1 THEN 'EMEA'
         WHEN 2 THEN 'AMER' ELSE 'OTHER' END AS region,
       TRUNC(SYSDATE) - MOD(level, 365) AS order_dt,
       ROUND(DBMS_RANDOM.VALUE(10, 1000), 2) AS amount,
       CASE WHEN MOD(level,20)=0 THEN 'CANCEL' ELSE 'OK' END AS status
FROM dual CONNECT BY level <= 2e6;

-- 인덱스 생성
CREATE INDEX ix_sales_rt_region_dt ON sales_rt(region, order_dt);
CREATE INDEX ix_sales_rt_status    ON sales_rt(status);

-- 통계 정보 수집
BEGIN
  DBMS_STATS.GATHER_TABLE_STATS(USER,'SALES_RT',cascade=>TRUE,
    method_opt=>'FOR COLUMNS SIZE 75 region SIZE 75 status SIZE 1 order_dt');
END;
/
```

---

## 데이터베이스 호출의 개념 이해

### 사용자 호출과 재귀 호출
데이터베이스 호출은 크게 두 가지 유형으로 구분됩니다:

1. **사용자 호출(User Call)**: 애플리케이션이 데이터베이스 서버로 보내는 요청 횟수입니다. SQL 실행, 커밋, 페치 등 모든 클라이언트-서버 간 상호작용이 여기에 포함됩니다.
2. **재귀 호출(Recursive Call)**: 오라클이 사용자의 SQL을 처리하는 과정에서 내부적으로 추가로 실행하는 SQL입니다. 데이터 딕셔너리 조회, 시퀀스 값 획득, 공간 관리 등이 이에 해당합니다.

### 호출의 세 단계
SQL 실행은 세 단계로 구성되며, 각 단계마다 성능 특성이 다릅니다:

1. **파싱(Parsing)**: SQL 문장의 구문 분석, 권한 확인, 실행 계획 생성
2. **실행(Execution)**: 생성된 실행 계획에 따라 실제 데이터 처리
3. **페치(Fetching)**: 결과 집합을 클라이언트로 전송

---

## 데이터베이스 호출의 성능 영향 분석

### 응답 시간 구성 요소
단일 데이터베이스 호출의 응답 시간은 여러 요소로 구성됩니다:

1. **애플리케이션 처리 시간**: 객체-관계 매핑(ORM) 변환, 가비지 컬렉션 등
2. **네트워크 왕복 시간**: 패킷 전송 지연, TLS 암호화/복호화
3. **데이터베이스 CPU 시간**: SQL 파싱, 실행, 정렬, 해시 연산
4. **대기 시간**: 디스크 I/O, 락 경합, 로그 동기화 등

이 중에서 네트워크 왕복 시간은 호출 횟수에 비례하여 누적되며, 특히 지리적으로 멀리 떨어진 클라이언트와 서버 간 통신에서는 더욱 큰 영향을 미칩니다.

---

## 성능을 저하시키는 일반적인 패턴

### 작은 페치 크기로 인한 과도한 왕복
가장 흔한 문제 중 하나는 기본 페치 크기가 너무 작아 많은 네트워크 왕복이 발생하는 경우입니다.

**문제점:**
- `user calls` 수치가 비정상적으로 높음
- TKPROF에서 Fetch `count` 값이 매우 높게 나타남
- `elapsed` 시간 중 Fetch 비중이 과도하게 높음

**해결책:**
```java
// Java JDBC 예시
try (PreparedStatement ps = conn.prepareStatement(sql)) {
    ps.setFetchSize(1000); // 기본값(10-50)보다 크게 설정
    // ... 나머지 코드
}
```

```python
# Python 예시
cur.arraysize = 1000  # 기본값보다 크게 설정
cur.execute("SELECT ...")
```

### N+1 쿼리 문제
ORM을 사용할 때 흔히 발생하는 문제로, 메인 쿼리 결과의 각 행에 대해 추가 조회를 수행하는 패턴입니다.

**문제점:**
- 수백에서 수천 번의 추가 호출 발생
- 네트워크 오버헤드 누적
- 평균 응답 시간 급증

**해결책:**
```sql
-- 나쁜 예: 고객별로 주문 수를 개별 조회
-- 좋은 예: 조인과 집계를 한 번에 처리
SELECT c.customer_id, c.name, COUNT(o.order_id) AS order_cnt
FROM customers c 
LEFT JOIN orders o ON o.customer_id = c.customer_id
WHERE c.segment = :seg
GROUP BY c.customer_id, c.name;
```

### 문장 재파싱 문제
SQL 문장을 매번 새로 파싱하면 파싱 오버헤드가 누적됩니다.

**문제점:**
- Parse `count` 수치가 높음
- `library cache miss` 증가
- 하드 파싱 비율 상승

**해결책:**
```java
// ❌ 나쁜 예: 문자열 결합으로 SQL 생성
String sql = "SELECT * FROM users WHERE id = " + userId;

// ✅ 좋은 예: 바인드 변수 사용
String sql = "SELECT * FROM users WHERE id = ?";
PreparedStatement ps = conn.prepareStatement(sql);
ps.setInt(1, userId);
```

### 행 단위 커밋 문제
각 데이터 행마다 개별적으로 커밋을 수행하면 로그 파일 동기화 대기가 누적됩니다.

**문제점:**
- `log file sync` 대기 이벤트 증가
- 커밋 호출 횟수 과다
- 트랜잭션 오버헤드 누적

**해결책:**
```python
# ❌ 나쁜 예: 각 행마다 커밋
for row in data:
    cursor.execute(insert_sql, row)
    connection.commit()

# ✅ 좋은 예: 배치 커밋
batch_size = 1000
for i, row in enumerate(data, 1):
    cursor.execute(insert_sql, row)
    if i % batch_size == 0:
        connection.commit()
connection.commit()
```

---

## 최적화 기법 카탈로그

### 네트워크 왕복 최소화
1. **페치 크기 최적화**: 애플리케이션 특성에 맞는 적절한 페치 크기 설정
2. **배치 DML 사용**: 여러 개의 DML 작업을 한 번에 전송
3. **키셋 페이지네이션**: OFFSET 방식 대신 마지막 키를 기준으로 페이징

### 파싱 오버헤드 감소
1. **바인드 변수 일관적 사용**: SQL 문장 템플릿 고정
2. **커서 캐시 활용**: 드라이버 수준과 데이터베이스 세션 수준 캐시 모두 활용
3. **세션 상태 표준화**: NLS 설정, 역할 등의 일관성 유지

### 실행 효율성 향상
1. **인덱스 적절한 활용**: SARGable 조건 사용, 함수 기반 조건 회피
2. **실행 계획 안정화**: 히스토그램 통계, SQL Plan Baseline 활용
3. **재귀 호출 최소화**: 시퀀스 캐시 확대, 런타임 DDL 회피

---

## 실전 최적화 사례

### 사례 1: 페치 크기 조정 효과 측정

**테스트 쿼리:**
```sql
VAR r VARCHAR2(10); 
VAR d1 DATE; 
VAR d2 DATE;
EXEC :r := 'APAC'; 
EXEC :d1 := TRUNC(SYSDATE) - 90; 
EXEC :d2 := TRUNC(SYSDATE);

SELECT /* fetch-bench */ sale_id, amount
FROM sales_rt
WHERE region = :r AND order_dt >= :d1 AND order_dt < :d2;
```

**측정 방법:**
1. `fetchSize = 50`으로 실행 후 성능 측정
2. `fetchSize = 1000`으로 실행 후 성능 측정
3. TKPROF 리포트 비교 분석

**예상 결과:**
- 페치 크기가 작을 때: Fetch `count` 높음, `elapsed` 시간 중 Fetch 비중 높음
- 페치 크기가 클 때: Fetch `count` 낮음, 전체 실행 시간 감소

### 사례 2: 배치 DML 구현

**Java 구현:**
```java
String sql = "INSERT INTO orders (id, customer_id, amount) VALUES (?, ?, ?)";
try (PreparedStatement ps = connection.prepareStatement(sql)) {
    for (int i = 1; i <= 10000; i++) {
        ps.setInt(1, i);
        ps.setInt(2, i % 1000);
        ps.setBigDecimal(3, new BigDecimal("100.00"));
        ps.addBatch();
        
        if (i % 1000 == 0) {
            ps.executeBatch();  // 1000개 단위로 배치 실행
        }
    }
    ps.executeBatch();  // 남은 데이터 처리
    connection.commit();
}
```

**Python 구현:**
```python
# 대량 데이터 삽입
data = [(i, i % 1000, 100.00) for i in range(1, 10001)]
cursor.executemany(
    "INSERT INTO orders (id, customer_id, amount) VALUES (:1, :2, :3)",
    data
)
connection.commit()
```

---

## 진단 및 모니터링 방법

### 성능 문제 식별 절차
1. **증상 파악**: AWR/ASH 리포트에서 응답 시간이 긴 SQL 식별
2. **상세 분석**: TKPROF나 SQL Trace를 통해 실행 통계 분석
3. **병목 식별**: 
   - Parse 시간이 높은지 확인 (파싱 문제)
   - Fetch 시간이 높은지 확인 (네트워크/왕복 문제)
   - Execute 시간이 높은지 확인 (인덱스/실행 계획 문제)
4. **개선 및 검증**: 최적화 적용 후 성능 재측정

### 주요 모니터링 지표
1. **행당 사용자 호출 비율**: `총 페치 행 수 / 사용자 호출 수`
   - 값이 작을수록 네트워크 왕복이 많다는 의미
2. **재귀/사용자 호출 비율**: `재귀 호출 수 / 사용자 호출 수`
   - 급격한 증가 시 시퀀스, DDL, 공간 관리 문제 의심
3. **파싱/실행 비율**: `파싱 횟수 / 실행 횟수`
   - 1에 가까우거나 초과하면 커서 재사용 문제

---

## 실전 최적화 팁

### 자주 발생하는 문제와 해결책
1. **자동 커밋 모드**: 많은 프레임워크가 기본값으로 자동 커밋을 사용합니다. 명시적 트랜잭션 관리로 변경하세요.
2. **세션 상태 불일치**: NLS 설정, 역할 등이 달라지면 커서가 분화되어 파싱 증가를 유발합니다.
3. **동적 SQL 남용**: 문자열 결합으로 SQL 생성 시 매번 다른 SQL로 인식되어 파싱 증가합니다.
4. **과도한 IN-list**: 수백 개 이상의 값을 IN 조건으로 사용하면 성능이 저하됩니다. 임시 테이블 조인으로 대체하세요.
5. **비효율적인 페이지네이션**: 큰 OFFSET 값은 성능을 크게 저하시킵니다. 키셋 페이지네이션으로 전환하세요.

### 데이터베이스 링크 사용 시 주의사항
데이터베이스 링크를 통한 원격 조회는 추가적인 네트워크 지연을 발생시킵니다. 필요한 경우 로컬에 데이터를 복제하거나, 배치 작업으로 대량 처리를 수행하세요.

---

## 종합 최적화 사례: 느린 API 성능 개선

**초기 상태:**
- API 평균 응답 시간: 1.2초
- 95백분위 응답 시간: 3.5초
- 주요 문제: 과도한 페치 호출, 파싱 오버헤드

**진단 결과:**
- 페치 크기: 10 (기본값)
- 파싱 횟수: 실행 횟수의 80%
- 인덱스 미사용으로 인한 전체 테이블 스캔

**적용한 개선사항:**
1. 페치 크기를 1000으로 증가
2. 바인드 변수 사용으로 파싱 감소
3. Statement Cache 활성화
4. 누락된 인덱스 추가
5. 페이지네이션 방식을 키셋 방식으로 변경

**개선 결과:**
- API 평균 응답 시간: 180ms (85% 개선)
- 95백분위 응답 시간: 450ms (87% 개선)
- 사용자 호출 수: 95% 감소
- 파싱 오버헤드: 최소화

---

## 결론: 데이터베이스 호출 최적화의 핵심 원칙

데이터베이스 성능 최적화는 복잡해 보이지만 몇 가지 기본 원칙을 따르면 효과적으로 개선할 수 있습니다.

### 1. 호출 횟수 최소화
네트워크 왕복은 성능에 직접적인 영향을 미칩니다. 배치 처리, 적절한 페치 크기 설정, N+1 쿼리 패턴 제거 등을 통해 호출 횟수를 최소화하세요.

### 2. 각 호출의 효율성 극대화
단일 호출이 수행하는 작업을 최적화하세요. 인덱스 적절한 사용, 실행 계획 안정화, 불필요한 재귀 호출 제거 등이 여기에 포함됩니다.

### 3. 자원 재사용 최적화
파싱 오버헤드를 줄이기 위해 커서 재사용을 극대화하세요. 바인드 변수 사용, 세션 상태 일관성 유지, 적절한 캐시 설정이 중요합니다.

### 4. 측정 기반 접근
성능 최적화는 추측이 아니라 데이터에 기반해야 합니다. AWR, ASH, TKPROF 등의 도구를 활용하여 문제를 정확히 진단하고, 개선 후에는 반드시 성능을 재측정하세요.

### 5. 지속적인 모니터링과 튜닝
성능 최적화는 일회성 작업이 아닌 지속적인 과정입니다. 주요 성능 지표를 모니터링하고, 변화하는 워크로드에 맞춰 시스템을 조정하세요.

**최종 요약:**
효율적인 데이터베이스 성능 관리는 "적게 호출하고, 효율적으로 실행하며, 가능한 한 재사용하는" 접근 방식에서 시작됩니다. 이러한 기본 원칙을 적용하면 대부분의 성능 문제를 효과적으로 해결할 수 있으며, 더 나은 사용자 경험과 시스템 안정성을 제공할 수 있습니다.