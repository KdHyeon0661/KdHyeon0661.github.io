---
layout: post
title: DB 심화 - 데이터베이스 CALL이 성능에 미치는 영향
date: 2025-11-01 18:25:23 +0900
category: DB 심화
---
# 데이터베이스 CALL이 성능에 미치는 영향

> **핵심 요약**
> - **DB Call**은 클라이언트↔DB 사이 **왕복(Round Trip)** 과 DB 내부의 **작업(파싱/실행/페치/재귀 호출)** 의 합이다.
> - 느린 시스템의 80%는 **“호출이 많아서”** 느리거나(**user call 과다**), **“호출 1번당 내부 일이 과해서”** 느리다(**recursive call 과다**).
> - **배열/배치(페치/바인드)**, **커서 재사용(바인드/캐시)**, **플랜 안정/인덱스/SARGability**, **네트워크 왕복 축소**, **세션 상태 표준화**가 정석 해법.

---

## 0. 준비: 공통 실습 객체

```sql
-- 큰 테이블 생성
DROP TABLE sales_rt PURGE;
CREATE TABLE sales_rt AS
SELECT level   AS sale_id,
       CASE MOD(level,4)
         WHEN 0 THEN 'APAC' WHEN 1 THEN 'EMEA'
         WHEN 2 THEN 'AMER' ELSE 'OTHER' END AS region,
       TRUNC(SYSDATE) - MOD(level, 365) AS order_dt,
       ROUND(DBMS_RANDOM.VALUE(10, 1000), 2) AS amount,
       CASE WHEN MOD(level,20)=0 THEN 'CANCEL' ELSE 'OK' END AS status
FROM dual CONNECT BY level <= 2e6;

CREATE INDEX ix_sales_rt_region_dt ON sales_rt(region, order_dt);
CREATE INDEX ix_sales_rt_status    ON sales_rt(status);
BEGIN
  DBMS_STATS.GATHER_TABLE_STATS(USER,'SALES_RT',cascade=>TRUE,
    method_opt=>'FOR COLUMNS SIZE 75 region SIZE 75 status SIZE 1 order_dt');
END;
/
```

---

## 1. “DB Call”이란 무엇인가? (User vs Recursive, Parse/Execute/Fetch)

### 1.1 User Call
- **정의**: 애플리케이션(클라이언트)이 서버로 보낸 **OCI/드라이버 호출 횟수**.
- **예**: Prepare/Parse, Execute, Fetch, Commit, Describe, Logon/Off.
- **지표**: `V$SYSSTAT/V$SESSTAT`의 `user calls`, `bytes sent/received via SQL*Net …`.

### 1.2 Recursive Call
- **정의**: 사용자의 SQL을 수행하는 동안 **오라클 내부가 추가로 실행한 SQL**(사전 조회·공간 관리·시퀀스·트리거 등).
- **지표**: `recursive calls`, `recursive cpu usage`.

### 1.3 CALL 통계(세 단계)
TKPROF/SQL Trace의 **CALL 표**:

```
call     count  cpu   elapsed   disk   query current rows
Parse       10  0.03     0.08      0      30       0    0
Execute     10  0.25     0.60   2000   50000    1000  10
Fetch       20  0.12     0.30     50   20000      50  1000
```

- **Parse**: 하드/소프트 파싱, 권한, 최적화
- **Execute**: 계획 수행(SELECT 스캔 시작·DML 반영)
- **Fetch**: 결과 전송(왕복 횟수에 좌우)

---

## 2. 시간은 어디에서 쓰이는가? — **호출 1회 비용 모델**

DB Call 1회의 **응답시간**은 크게 4부분으로 나뉜다.

1) **클라이언트 측 지연**: 애플리케이션 스레드 스케줄링/GC/ORM 변환
2) **네트워크 왕복**: RTT × 왕복 횟수, 패킷 수, TLS, MTU/세그먼트화
3) **서버 CPU**: Parse/Execute/Fetch CPU + PL/SQL/함수/정렬/해시
4) **서버 대기(Waits)**: 디스크 I/O, 락, 래치/뮤텍스, 로깅, 네트워크 등

> **간이 식**
> $$ \text{RT} \approx \underbrace{\text{RTT} \times N_{\text{roundtrips}}}_{\text{user call 영향}} + \underbrace{(\text{CPU} + \text{Wait})}_{\text{recursive/row-source 영향}} $$
> - **user call**이 늘면 **RTT 누적**이 커진다.
> - **recursive call**/Row-Source가 무거우면 **CPU/Wait**이 커진다.

---

## 3. 성능을 망치는 전형 패턴 8가지

### 패턴 1) **작은 fetchSize**로 자잘하게 많이 가져오기
- **증상**: `user calls`↑, TKPROF에서 Fetch **count**↑, `elapsed`가 Fetch에 집중
- **해법**: fetch/arraysize 확대 → 왕복 감소

#### 예 (JDBC)
```java
String sql = "SELECT /* fetch-demo */ * FROM sales_rt WHERE region=? AND order_dt>=? AND order_dt<?";
try (PreparedStatement ps = conn.prepareStatement(sql)) {
  ps.setFetchSize(1000); // 기본 10~50 → 500~2000 권장
  ps.setString(1, "APAC");
  ps.setDate(2, Date.valueOf("2025-09-01"));
  ps.setDate(3, Date.valueOf("2025-11-01"));
  try (ResultSet rs = ps.executeQuery()) {
    while (rs.next()) { /* consume */ }
  }
}
```

#### 예 (Python oracledb)
```python
cur.arraysize = 1000
cur.execute("""
  SELECT /* fetch-demo */ * FROM sales_rt
  WHERE region=:r AND order_dt>=:d1 AND order_dt<:d2
""", r='APAC', d1=date(2025,9,1), d2=date(2025,11,1))
for row in cur:
    pass
```

---

### 패턴 2) **N+1 쿼리(ORM)** — 목록 조회 후 각 행마다 추가 조회
- **증상**: `user calls` 수백~수천, 네트워크 소음, 평균 RT 급증
- **해법**: **JOIN/IN-list(배열 바인드)** 로 **1~2회**로 합치기, **Batch Fetch**.

```sql
-- 나쁜 예: 각 customer에 대해 주문 COUNT를 별도 SELECT
-- 좋은 예: 집계 JOIN
SELECT c.customer_id, c.name, COUNT(o.order_id) AS order_cnt
FROM   customers c LEFT JOIN orders o ON o.customer_id = c.customer_id
WHERE  c.segment = :seg
GROUP  BY c.customer_id, c.name;
```

---

### 패턴 3) **Statement 재준비/하드파싱 남발**(리터럴/텍스트 변형)
- **증상**: TKPROF Parse `count`↑, `misses in library cache during parse`↑, `parse count (hard)`↑
- **해법**: **바인드 변수**, 텍스트 템플릿 고정, 드라이버 Statement Cache, `SESSION_CACHED_CURSORS`.

```java
// ❌ 나쁜 예: 값 문자열 삽입 → 매번 다른 SQL 텍스트
String sql = "SELECT * FROM sales_rt WHERE region='" + userInput + "'";
// ✅ 좋은 예: 바인드
String sql = "SELECT * FROM sales_rt WHERE region = ?";
```

---

### 패턴 4) **Auto-commit 또는 per-row commit**
- **증상**: `log file sync` 대기, `user calls`(COMMIT 호출)↑
- **해법**: **트랜잭션 배치**, 배치 DML, 커밋 간격 조정

```python
# ❌ 각 행마다 commit
for row in rows:
    cur.execute("INSERT INTO t VALUES (:1, :2)", row)
    conn.commit()
# ✅ 주기적 커밋
for i, row in enumerate(rows, 1):
    cur.execute("INSERT INTO t VALUES (:1, :2)", row)
    if i % 1000 == 0:
        conn.commit()
conn.commit()
```

---

### 패턴 5) **대량 IN-list를 문자열로 붙이기**
- **증상**: 동적 SQL 폭증(커서 공유 실패), Parse↑
- **해법**: **배열 바인드** 또는 **GTT 조인**(정적 SQL 유지)

```plsql
-- 스키마 타입 + 배열 바인드
CREATE OR REPLACE TYPE t_num_list AS TABLE OF NUMBER;
SELECT * FROM big_table
WHERE key IN (SELECT COLUMN_VALUE FROM TABLE(:keys)); -- 텍스트 고정, 커서 공유 OK
```

---

### 패턴 6) **스큐/히스토그램 부재로 인한 플랜 흔들림**
- **증상**: 같은 SQL인데 어떤 값은 번개, 어떤 값은 느림 → Execute `disk/query` 급증
- **해법**: **히스토그램/ACS**, 값대별 SQL 분리(예외적으로 리터럴), SPM

---

### 패턴 7) **재귀 호출 과다**(시퀀스/DDL/공간/트리거)
- **증상**: AWR `Recursive Calls/CPU`↑, TKPROF `recursive calls`↑
- **해법**: 시퀀스 **CACHE** 확대, 런타임 **DDL 금지**, **공간 사전 확보**, 트리거 슬림화, 딕셔너리/라이브러리 캐시 히트율 유지

```sql
-- 시퀀스 캐시 확대
CREATE SEQUENCE seq_big CACHE 1000;
```

---

### 패턴 8) **선택적 검색조건을 OR로 처리**(SARGability 저하)
- **증상**: Execute I/O 과다, 전체 스캔
- **해법**: **동적 WHERE(값은 바인드)** 또는 **UNION ALL 분기**로 불필요 조건 제거

```sql
-- ❌ (col=:p OR :p IS NULL) 패턴 남발
-- ✅ 가드된 UNION ALL(정적 SQL 유지)
SELECT SUM(amount) FROM (
  SELECT amount FROM sales_rt
   WHERE :use_r=1 AND region=:r AND order_dt>=:d1 AND order_dt<:d2
  UNION ALL
  SELECT amount FROM sales_rt
   WHERE :use_r=0 AND order_dt>=:d1 AND order_dt<:d2
);
```

---

## 4. DB Call 줄이기/가볍게 하기 **해법 카탈로그**

### 4.1 네트워크 왕복 최소화
- **Fetch/arraysize 확대** (JDBC `setFetchSize`, ODP.NET `FetchSize`, Python `arraysize`)
- **배치 DML** (JDBC `addBatch/executeBatch`, ODP.NET `ArrayBindCount`, Python `executemany`)
- **페이지네이션**: `OFFSET/FETCH`보다는 **Keyset Pagination**(> last_id)
- **SQL*Net 튜닝**: SDU/TDU(환경에 따라), MTS보다는 전용 세션 선호(요구에 따름)

### 4.2 파싱 비용 최소화(커서 재사용)
- **바인드 변수 / 텍스트 템플릿 고정**
- **Statement Cache**(드라이버) + **Session Cursor Cache**(서버)
- **세션 상태 표준화**(NLS/ROLE/Optimizer Env) — Child 폭증 방지

### 4.3 내부 작업(Recursive/Row-Source) 경감
- **인덱스/SARGability**: 함수 가공 금지, 범위 정규화(`[low, high)`), LIKE 접두사 → 범위로
- **히스토그램/ACS**: 스큐 대응, 플랜 안정
- **SPM**: 핵심 SQL 플랜 고정
- **시퀀스 CACHE**, **공간 사전 확보**, **DDL 런타임 금지**, **트리거 슬림화**

---

## 5. 실습: 같은 질의, **페치 사이즈만** 바꾸어 효과 보기

### 5.1 대상 쿼리
```sql
VAR r VARCHAR2(10); VAR d1 DATE; VAR d2 DATE;
EXEC :r := 'APAC'; EXEC :d1 := TRUNC(SYSDATE) - 90; EXEC :d2 := TRUNC(SYSDATE);

SELECT /* fetch-bench */ sale_id, amount
FROM   sales_rt
WHERE  region=:r AND order_dt>=:d1 AND order_dt<:d2;
```

### 5.2 트레이스 수집
```sql
ALTER SESSION SET statistics_level=ALL;
ALTER SESSION SET events '10046 trace name context forever, level 8';
-- 클라이언트에서 fetchSize=50 → 실행
-- 같은 질의를 fetchSize=1000 → 재실행
ALTER SESSION SET events '10046 trace name context off';
```

### 5.3 TKPROF 비교(요지)
- **작은 fetchSize**: `Fetch count`↑, `elapsed`(Fetch)↑, `bytes sent/received` 증가
- **큰 fetchSize**: `Fetch count`↓, `elapsed`↓, 동일 rows 대비 왕복 감소

---

## 6. 실습: **배치 DML**로 user call 줄이기

### 6.1 JDBC
```java
String sql = "INSERT INTO t_ins(id, amt) VALUES (?, ?)";
try (PreparedStatement ps = conn.prepareStatement(sql)) {
  for (int i=1;i<=10000;i++) {
    ps.setInt(1, i);
    ps.setBigDecimal(2, new BigDecimal("123.45"));
    ps.addBatch();
    if (i % 1000 == 0) ps.executeBatch(); // user calls 크게 감소
  }
  ps.executeBatch();
  conn.commit();
}
```

### 6.2 ODP.NET
```csharp
var cmd = conn.CreateCommand();
cmd.CommandText = "INSERT INTO t_ins(id, amt) VALUES (:1,:2)";
cmd.ArrayBindCount = rows;
cmd.Parameters.Add(":1", OracleDbType.Int32, ids, ParameterDirection.Input);
cmd.Parameters.Add(":2", OracleDbType.Decimal, amts, ParameterDirection.Input);
cmd.ExecuteNonQuery(); // 1회 호출로 대량 처리
conn.Commit();
```

### 6.3 Python
```python
cur.executemany("INSERT INTO t_ins(id, amt) VALUES (:1,:2)", rows)  # rows: list of tuples
conn.commit()
```

---

## 7. **user call vs recursive call** — “호출 수”와 “호출 1회당 내부 일”의 상관

- **user call**을 줄이면 **RTT 누적**이 줄고, CPU/Wait이 같은 조건이라도 **RT**가 감소한다.
- **recursive call**을 줄이면 **Execute CPU/Wait**이 줄어든다(시퀀스/DDL/공간/사전).
- 두 축을 함께 줄일 때 **선형 이상**의 체감 성능 상승.

---

## 8. 진단 루틴 — 어디서부터 볼 것인가?

1) **증상 포착**
   - AWR: SQL ordered by Elapsed/CPU/IO, Load Profile(Calls/sec), Instance Efficiency(캐시 히트), Top Events
   - ASH: Hot SQL, Wait Event, Time Model
2) **문제 SQL 선정 → TKPROF/SQL Trace**
   - **CALL 표**에서 Parse/Execute/Fetch의 **elapsed 비중** 확인
   - `disk/query/current/rows` 상관 확인
   - 하단 **Wait Events**로 경향 파악(I/O/락/뮤텍스/네트워크)
3) **user vs recursive**
   - `V$SESSTAT`: `user calls`, `recursive calls`, `bytes sent/received`, `parse count (hard)`
4) **가설 → 수정 → 재측정**
   - fetch/arraysize/배치/바인드/캐시/인덱스/히스토그램/ACS/SPM
   - 전후 CALL 통계 비교로 개선 수치화

---

## 9. 미세 팁 & 함정

- **Auto-Commit=ON**인 드라이버 기본값을 의심하라(많은 프레임워크가 기본 ON).
- **세션 상태(NLS_DATE_FORMAT, optimizer_features_enable 등)** 가 달라지면 **Child 분화** → Parse 증가.
- **주석/힌트 랜덤화**도 텍스트 변경 → 커서 공유 실패.
- **DB Link**: Fetch에서 `SQL*Net message from dblink` 대기 — **원격 RTT/네트워크** 영향.
- **LIKE '%abc'**: 앞와일드카드 → 인덱스 무력화(행 수↑ → I/O↑ → Execute `elapsed`↑).
- **IN-list “값이 아주 많음”**: 배열 바인드/GTT로 전환(동적 문자열 IN 금지).
- **페이지네이션**: `OFFSET N FETCH M` 는 큰 N에서 느려짐. **Keyset** 방식(`WHERE id > :last`)으로 변경.

---

## 10. 간단한 수치 지표로 운영 감시

- **Rows per User Call**
  $$ \text{RPUC} = \frac{\text{총 페치 Rows}}{\text{user calls}} $$
  값이 **작으면** 채팅성 가능성↑ → fetch/배치 확대.

- **Recursive/User Ratio**
  $$ \text{RUratio} = \frac{\text{recursive calls}}{\text{user calls}} $$
  평시 대비 급등 → 시퀀스/DDL/공간/사전 접근 확인.

- **Parse per Exec**
  $$ \text{P/E} = \frac{\text{parse count (total)}}{\text{execute count}} $$
  **1 근처/초과** → 커서 재사용 실패(바인드/캐시/세션 상태).

> 수치는 절대값보다 **전후/동시간대 비교**가 중요.

---

## 11. “끝장” 예제 — 느린 API를 3단계로 개선

**상황**: `/orders/search` API가 평균 1.2s, p95 3.5s

1) **진단**
   - TKPROF: Fetch count=1500(배열 10), Parse count 높고 `misses … during parse` 다수
   - AWR: `SQL*Net more data to client`, `db file sequential read` 상위

2) **조치**
   - 클라이언트 `fetchSize=1000`, `executemany`/배치 도입
   - 바인드 변수 전환 + Statement Cache 활성, `SESSION_CACHED_CURSORS=100`
   - `region,status` 히스토그램 수집, 인덱스 `(region, order_dt)` 정비
   - 페이지네이션을 Keyset으로 변경

3) **결과**
   - `user calls` 95%↓, Parse 시간 미미, Fetch `elapsed` 90%↓
   - 평균 180ms, p95 450ms로 안정

---

## 12. 체크리스트(실전 적용용)

- [ ] **fetch/arraysize** 확대 (왕복↓)
- [ ] **배치 DML/벌크 바인드** (user call↓, log sync↓)
- [ ] **바인드 변수**, **Statement/Session Cursor Cache**, 텍스트 템플릿 고정
- [ ] **SARGability** 확보(함수 제거/범위 정규화/LIKE→범위)
- [ ] **인덱스/히스토그램/ACS/SPM** 로 플랜 안정
- [ ] **시퀀스 CACHE**, **DDL 런타임 금지**, **공간 사전 확보**, **트리거 슬림화**
- [ ] **ORM N+1 제거**, 보고서는 **집계/조인으로 합치기**
- [ ] AWR/ASH/TKPROF로 **전/후** CALL 통계 수치화

---

## 13. 결론

- **DB Call**은 성능의 1차 단위다.
  - **user call**은 *왕복 횟수*를,
  - **recursive call**은 *호출 1회당 DB 내부 일감*을 뜻한다.
- **왕복을 줄이고**(배열/배치/페이지네이션/캐시), **내부 일을 덜 만들면**(바인드/인덱스/플랜/시퀀스/공간)
  대부분의 시스템에서 응답시간은 즉시 줄어든다.
- 언제나 **CALL 통계**와 **대기 이벤트**를 함께 보며, **전후 비교**로 개선을 수치로 증명하라.

> **한 줄 요약**
> “**적게, 크게, 재사용**” — 적은 호출 수로, 큰 덩어리로, 커서/플랜을 재사용하면 DB는 빨라진다.
