---
layout: post
title: 확률과 통계 - 비모수 & 재표본화
date: 2025-09-20 15:25:23 +0900
category: 확률과 통계
---
# 11) 비모수 & 재표본화

> **목표**  
> - **순위검정**: **맨–휘트니 U**(독립 2표본), **윌코슨 부호순위**(대응·전후 비교), **크루스칼–왈리스 H**(독립 k표본)의 **아이디어·공식·가정·효과크기**를 익힌다.  
> - **재표본화**: **부트스트랩(Percentile/BCa/Studentized)**, **퍼뮤테이션(랜덤화) 검정**을 KPI(체류시간·ARPU·CVR)에 적용하는 **절차와 리포팅**을 배운다.  
> - **체크 포인트**: **랜덤화 단위(사용자/세션)** 를 **절대 혼동하지 말 것**—모든 검정/재표본화는 **무작위화 단위 = 분석 단위**에 맞춰야 한다.

---

## 0) Hook — “정규성도, 등분산도… 몰라도 된다?”
- **체류시간**·**ARPU**는 **한쪽 꼬리가 길고**(heavy-tailed), **이상값**이 많아 **평균의 정규근사**가 느리거나 불안정.  
- **비모수 순위검정**과 **재표본화**는 **가정 완화**와 **강건한 결론**을 준다. 단, **올바른 단위**로 표본을 섞고(퍼뮤테이션) **올바른 단위**로 다시 뽑아야(부트스트랩) 한다.

---

## 1) 언제 비모수/재표본화를 쓰나?

- **분포 가정 불확실**: 비대칭·이질분산·이상값이 많은 **체류시간/ARPU**.  
- **척도가 서열(순위) 수준**: 점수/만족도(리커트).  
- **표본이 작거나**(정규 근사 불안) **큰데도 꼬리**가 지배.  
- **전후(대응) 비교**: 같은 사용자의 패널 데이터(개선 전·후).  
- **정확한 유의성**이 필요한 경우: **랜덤화 설계** 기반 **퍼뮤테이션**.

> **원칙**: 비모수 = “모양(정규성 등)을 모른다”가 아니라 **“합리적 최약 가정”** 하에서 **중앙위치/순위 차**를 본다.

---

## 2) 맨–휘트니 U (Mann–Whitney U, Wilcoxon rank-sum) — 독립 2표본

### 2.1 상황·가정
- **독립** 두 집단 A, B(예: 버튼 **A/B**)의 **분포 위치 차** 비교.  
- 가정: **독립**(사용자 단위), **연속형**(동점은 보정 가능), “같은 모양 + 위치만 차이”일 때 **중위수 차** 해석이 깔끔.

### 2.2 정의
- 두 집단 데이터 \( \{x_i\}_{i=1}^{n_A},\ \{y_j\}_{j=1}^{n_B} \)를 **합쳐 순위화**(작을수록 순위 낮음).  
- A 집단 순위합 \( R_A=\sum \text{rank}(x_i) \).  
- **U 통계량**:
$$
U_A = R_A - \frac{n_A(n_A+1)}{2},\qquad U_B = n_A n_B - U_A.
$$
- **크기 해석**: \( U / (n_A n_B) = P(X<Y) + \tfrac12 P(X=Y) \) — 임의 추출 \(X\in A, Y\in B\)가 “A가 더 작다”일 확률.

### 2.3 귀무/대립·근사
- \( H_0:\) 두 분포 동일(위치 차 없음).  
- 큰 표본에서 **정규근사**:
$$
Z=\frac{U - \mu_U}{\sigma_U},\quad \mu_U=\frac{n_A n_B}{2},\quad
\sigma_U=\sqrt{\frac{n_A n_B (n_A+n_B+1)}{12} - \text{tie correction}}.
$$
- **동점 보정**(tie correction): 같은 값 묶음 \(t_g\)마다 \( \sum(t_g^3-t_g)/(12(N)(N-1)) \) 항을 빼준다.

### 2.4 효과크기
- **Rank-biserial r**:
$$
r = 1 - \frac{2U}{n_A n_B} \quad (\text{부호는 대립 방향})
$$
- **Cliff’s delta** \( \delta = P(X>Y)-P(X<Y) = 2\cdot U/(n_A n_B) - 1 \) (−1~+1).

### 2.5 위치 차의 추정 — **Hodges–Lehmann**(HL) 추정량
- 모든 쌍 차 \( \{x_i - y_j\} \)의 **중앙값** → “**전형적 위치 차**”  
- **신뢰구간**: 순위기반(부호검정식) 또는 **부트스트랩**으로 계산.

> **리포트 예**  
> “체류시간(초): 맨–휘트니 \(U=1.82\times 10^8\), \(Z=4.1\), \(p<0.0001\). HL 추정치 \(+6.3\)초 [95% BCa: +3.1, +9.7]. Cliff’s \(\delta=0.08\) (작은 효과).”

---

## 3) 윌코슨 부호순위 (Wilcoxon signed-rank) — **대응(전후·쌍체)**

### 3.1 상황·가정
- 같은 사용자 **전후 비교**, 혹은 **짝지은** 쌍.  
- 차이 \( d_i = \text{after}_i - \text{before}_i \)의 **중앙값=0** 검정.  
- 가정: 차이의 **분포가 대칭**이면 강력.

### 3.2 절차
1) \( d_i=0 \) 제거, 나머지의 **절댓값**을 순위화.  
2) 원부호(+/−)를 순위에 부여 → **양의 순위합 \(W^+\)**, 음의 \(W^-\)**.  
3) 통계량 \( W=\min(W^+, W^-) \) (또는 \(T=W^+\)). 대수 근사로 p값.

### 3.3 효과크기 & 추정
- **matched rank-biserial** \( r = \frac{W^+ - W^-}{\binom{n}{2}} \) (정의 다양).  
- **HL 추정**: 쌍 차이의 **중앙값**과 CI(부트스트랩 권장).

> **리포트 예**  
> “같은 사용자 기준 ARPU 전후 변화: 윌코슨 \(V=1.12\times 10^6\), \(p=0.002\). HL(중앙 차) \(+210\)원 [BCa: +80, +360].”

---

## 4) 크루스칼–왈리스 H — **독립 k표본(≥3)**

### 4.1 정의
- \(k\)개 집단을 합쳐 순위화, 집단별 순위합 \(R_i\).  
- 통계량:
$$
H = \frac{12}{N(N+1)}\sum_{i=1}^k \frac{R_i^2}{n_i} - 3(N+1),\quad (N=\sum n_i)
$$
- 큰 표본에서 \( H \sim \chi^2_{k-1} \) 근사(동점 보정 필수).

### 4.2 사후검정
- **Dunn** (쌍 비교, Bonferroni/Holm/BH 보정), **Conover**, **Nemenyi**.  
- **효과크기**: \( \epsilon^2 = \frac{H- (k-1)}{N-1} \) 또는 \( \eta^2_H = \frac{H}{N-1} \).

> **리포트 예**  
> “요일 7수준의 체류시간 차이: \(H(6)=52.3, p<0.001\), \(\epsilon^2=0.04\) (작음). Dunn(이질분산 보정)에서 금요일 > 수요일(+4.2s, q<0.05).”

---

## 5) 퍼뮤테이션(랜덤화) 검정 — 설계에 충실한 p값

### 5.1 아이디어
- **귀무 \(H_0\)**: **처리 레이블은 결과에 무관**(교환 가능성).  
- 실제 실험의 **무작위화 방식**을 모사하여 **레이블을 섞고**, 관심 통계량(평균/중앙/HL/회귀계수 등)을 다시 계산 → **분포** 형성 → **순위 p값**.

### 5.2 절차(독립 2표본; 사용자 단위)
1) 실제 차이 \( T_{\text{obs}} = \text{stat}(A,B) \).  
2) **사용자 ID**의 처리 레이블을 **랜덤 셔플**(세션이 아님!).  
3) \( B \)회 반복하여 \( \{T_b\}_{b=1}^B \) 수집.  
4) 양측 p: \( p=\frac{1+\#\{|T_b|\ge |T_{\text{obs}}|\}}{1+B} \).

### 5.3 변형
- **블록/층화 퍼뮤테이션**: 요일·국가 **블록 내부**에서만 레이블 교환.  
- **클러스터 퍼뮤테이션**: **사용자 단위** 무작위화였다면, **사용자별 세션 묶음**을 통째로 이동.  
- **회귀 기반**: 잔차를 섞는 **Freedman–Lane**(공변량 통제).

> **장점**: 정규성·등분산 **불요**, **설계 일치 p값**.  
> **주의**: **랜덤화 단위**를 틀리면 p값이 **과소**(거짓 양성↑).

---

## 6) 부트스트랩(bootstrap) — CI와 표준오차를 데이터에서

### 6.1 기본(비모수, IID)
- 표본 \( \{x_i\}_{i=1}^n \)에서 **복원추출** 크기 \(n\) 샘플 \( \{x_i^\*(b)\} \)을 \(B\)회 생성.  
- 관심 통계량 \( \hat\theta^\*(b)=g(\{x_i^\*(b)\}) \) 값들의 분포로 **SE/CI** 추정.

### 6.2 CI 방식
- **Percentile**: \([q_{\alpha/2}, q_{1-\alpha/2}]\). 직관적·간단.  
- **BCa**(Bias-Corrected and Accelerated): **편향·비대칭** 보정 — **체류시간/ARPU** 추천.  
- **Studentized(bootstrap–t)**: 통계량을 표준화하여 신뢰성↑(비용↑).

### 6.3 두 표본·차이/비율
- **차이** \( \hat\theta=\bar x-\bar y \) 또는 **중앙값 차**(HL).  
- 각 집단을 **독립 부트스트랩** → 차이의 분포로 CI.  
- **비율의 비율** 등 복합 통계량은 **델타법** 또는 **부트스트랩** 병행.

### 6.4 클러스터/블록 부트스트랩
- **사용자 단위**로 **묶음 복원추출**(사용자의 모든 세션 포함) → **독립성** 가정을 반영.  
- 시간 의존(일/주)에는 **블록 부트스트랩**(연속 블록 추출)로 자기상관 보존.

> **리포트 예**  
> “ARPU 평균: 3,420원, **BCa 95% CI** [3,150, 3,780] (사용자 클러스터 부트스트랩, B=10,000). **중앙값** 1,030원 [970, 1,090].”

---

## 7) 예제 A — **비대칭 체류시간**: A/B 중앙값 비교

### 7.1 데이터·목표
- Variant A(사용자 \(n_A\)), B(\(n_B\))의 **세션당 체류시간(초)**. **헤비테일**.  
- **문제**: 평균 비교 t-검정은 극단값 민감. 중앙값·순위 기반이 안정.

### 7.2 분석
1) **맨–휘트니 U**로 위치 차 검정 → p값.  
2) **HL 추정치**(쌍 차의 중앙값)와 **BCa 95% CI**(부트스트랩, 사용자 단위).  
3) **효과크기**: Cliff’s \(\delta\), rank-biserial r.  
4) **보고**: 중앙값/분위(25/50/75)/95p도 함께(꼬리 노출).

### 7.3 코드 스케치
```python
# 개념용(실행 예시); 부트스트랩은 사용자 단위 리스트로 복원추출
import random, math
def mann_whitney_u(a, b):
    # 단순 구현: 병합 순위 -> U 계산 (동점 보정 생략 버전)
    arr = [(x,0) for x in a] + [(y,1) for y in b]
    arr.sort(key=lambda z: z[0])
    # 평균 순위로 ties 처리하려면 블록평균 필요(지면상 생략)
    rank = 1
    RA = 0
    for v,g in arr:
        if g==0: RA += rank
        rank += 1
    nA, nB = len(a), len(b)
    UA = RA - nA*(nA+1)/2
    return UA

def hl_shift(a, b):
    # 모든 쌍 차의 중앙값 (O(n^2), 큰 데이터는 표본쌍)
    diffs = []
    for x in a:
        for y in b:
            diffs.append(x - y)
    diffs.sort()
    m = len(diffs)
    return diffs[m//2] if m%2 else 0.5*(diffs[m//2-1]+diffs[m//2])

def cluster_boot_ci(a, b, stat_fn, B=5000, alpha=0.05):
    # a,b는 사용자별 대표(예: 사용자별 평균 체류) 또는 사용자 한 관측치
    import numpy as np
    nA, nB = len(a), len(b)
    vals = []
    for _ in range(B):
        Ab = [a[random.randrange(nA)] for _ in range(nA)]
        Bb = [b[random.randrange(nB)] for _ in range(nB)]
        vals.append(stat_fn(Ab, Bb))
    vals.sort()
    lo = vals[int((alpha/2)*B)]
    hi = vals[int((1-alpha/2)*B)]
    return lo, hi

# stat_fn 예: HL shift 또는 중앙값 차
```

---

## 8) 예제 B — **ARPU**: 부트스트랩 CI (평균 & 중앙값)

### 8.1 왜 부트스트랩?
- **ARPU**는 **0**이 많고 드물게 **매우 큰 값** → 평균의 표준오차를 **정규근사**로 잡으면 **과소**.  
- **BCa** 혹은 **bootstrap–t**로 **신뢰구간**을 잡는 편이 안전.  
- 사용자 수준 **클러스터 부트스트랩**(사용자 뽑기 → 그 사용자의 전체 구매 합).

### 8.2 절차
1) 사용자별 ARPU 벡터 \( \{u_i\} \).  
2) \(B\)회 복원추출 → 각 부트스트랩 표본의 **평균**과 **중앙값** 계산.  
3) **BCa**(가능하면) 또는 **Percentile**로 CI.  
4) A/B 비교면 **두 집단 독립 부트스트랩** 후 차이의 CI.

> **리포트 템플릿**  
> “ARPU(원): 평균 3,420 [BCa 95%: 3,150–3,780], 중앙값 1,030 [970–1,090]. **A–B 평균 차** +160 [BCa: +40, +310].”

---

## 9) 랜덤화 단위(사용자/세션) **혼동 금지** — 치명적 함정

### 9.1 왜 위험한가?
- 실험은 **사용자 ID** 기반 무작위화인데, 분석은 **세션** 단위로 퍼뮤테이션/부트스트랩을 하면  
  - **독립성 위반**(동일 사용자 반복 관측),  
  - **표본 크기 과대**(실제 유효 샘플은 사용자 수인데 세션 수로 취급),  
  - p값 **과소**(거짓 양성↑).  

### 9.2 올바른 방법
- **퍼뮤테이션**: **사용자 레이블**만 섞는다(세션 묶음 유지).  
- **부트스트랩**: **사용자**를 복원추출(그 사용자의 모든 세션/구매 포함).  
- **회귀/순위검정**도 **사용자 요약**(예: 사용자별 평균 체류/ARPU)로 실시하거나, **군집-강건 SE**로 보정.

> **체크**: *내가 섞거나 다시 뽑는 단위가 실제 **랜덤화 단위**와 같은가?* — 다르면 **다시 설계**.

---

## 10) 실무 레시피 — 어떤 문제에 무엇을?

| 문제 | 추천 1 | 보완/대안 |
|---|---|---|
| **체류시간(heavy-tail), 2그룹** | 맨–휘트니 + HL + BCa CI | 로그척도 평균 비교(참고), 퍼뮤테이션 p |
| **전후(같은 사용자)** | 윌코슨 + HL(쌍 차 중앙) | 퍼뮤테이션(부호 보존) |
| **요일 7수준(연속화 KPI)** | 크루스칼–왈리스 + Dunn | GLM(로지스틱/포아송) + Deviance ANOVA |
| **ARPU 평균** | 사용자 클러스터 부트스트랩 BCa | 중앙값·분위 병기, bootstrap–t |
| **A/B 평균 차 p** | 퍼뮤테이션(사용자 레이블) | 이질분산 t + 부트스트랩 CI |
| **세그먼트 혼재** | 층화 퍼뮤테이션/부트 | EMMeans(가중 평균), 회귀+FL 퍼뮤테이션 |

---

## 11) 리포팅 템플릿

- **검정**: “맨–휘트니 \(U=\dots\), \(Z=\dots\), \(p=\dots\) (동점 보정).”  
- **효과크기**: “Cliff’s \(\delta=0.09\) (작음), rank-biserial \(r=0.18\).”  
- **점·구간추정**: “HL 위치차 \(+6.3s\) [BCa 95%: +3.1, +9.7].”  
- **단위**: “모든 퍼뮤테이션/부트스트랩은 **사용자 단위**로 수행.”  
- **보조**: “중앙값/분위수, 95p 병기. 이상치 민감도 분석(상위 0.5% 윈저) 결과 동일.”

---

## 12) 자주 겪는 함정 & 해결

1) **동점 다수**(0 체류 등) → 동점 보정, 필요시 **부호검정**(중앙값만)으로 대체.  
2) **극단 꼬리** → **BCa**·**bootstrap–t**, **로그척도** 병기.  
3) **자기상관**(일/주 패널) → **블록 부트스트랩**, 층화 퍼뮤테이션.  
4) **표본이 매우 큼** → p는 쉽게 작아진다. **효과크기·실질 의미**를 앞세워 보고.  
5) **다중비교**(여러 지표/요일/배너) → Dunn/Tukey 또는 **BH-FDR**.  
6) **누락값·절단(상한)** → 순위검정은 견고하지만 **기술통계**(분위·상위p) 병행.  
7) **퍼뮤테이션 통계량 선택** → 평균·중앙·HL·KS 등 **가설에 맞는** 지표로.

---

## 13) 수학 메모 & 참고 공식

- **Cliff’s δ 추정량**:
$$
\hat\delta = \frac{1}{n_A n_B}\sum_{i,j}\operatorname{sgn}(x_i - y_j),\quad \operatorname{sgn}(t)=\begin{cases}1,&t>0\\0,&t=0\\-1,&t<0\end{cases}
$$

- **부호검정(대응)의 p**: \( \#\{d_i>0\} \sim \mathrm{Bin}(m, 0.5) \) (0 제거 후 \(m\)개).  
- **BCa** 보정 파라미터 \(z_0, a\) 추정(잭나이프 기반) — 구현 시 라이브러리 권장.

---

## 14) 퍼뮤테이션 & 부트스트랩 — 구현 스니펫(개념)

```python
# 퍼뮤테이션(사용자 단위) — 평균/중앙/HL 등 임의 통계량 지원
import random, numpy as np

def permutation_p(groupA, groupB, stat_fn, B=20000, two_sided=True, seed=0):
    rng = random.Random(seed)
    pooled = [(v,0) for v in groupA] + [(v,1) for v in groupB]
    T_obs = stat_fn([v for v,g in pooled if g==0], [v for v,g in pooled if g==1])
    cnt = 0
    for _ in range(B):
        rng.shuffle(pooled)  # 사용자 레이블 셔플
        A = [v for v,g in pooled[:len(groupA)]]
        B_ = [v for v,g in pooled[len(groupA):]]
        T = stat_fn(A, B_)
        if two_sided:
            cnt += (abs(T) >= abs(T_obs))
        else:
            cnt += (T >= T_obs)
    p = (cnt + 1) / (B + 1)
    return T_obs, p

# 부트스트랩(클러스터=사용자) — 차이의 BCa는 패키지 권장, 여기선 Percentile
def bootstrap_ci_diff(A, B, stat_fn, Bn=10000, alpha=0.05, seed=1):
    rng = np.random.default_rng(seed)
    nA, nB = len(A), len(B)
    vals = []
    for _ in range(Bn):
        Ab = A[rng.integers(0,nA,nA)]
        Bb = B[rng.integers(0,nB,nB)]
        vals.append(stat_fn(Ab, Bb))
    vals = np.sort(vals)
    lo = vals[int(alpha/2*Bn)]
    hi = vals[int((1-alpha/2)*Bn)-1]
    return lo, hi

# 예시 통계량: 중앙값 차
def med_diff(A,B): return float(np.median(A) - np.median(B))
```

> **주의**: 실제 배포는 **검증된 라이브러리**(SciPy/statsmodels/R) 사용. **BCa/다중비교**는 직접 구현보다 라이브러리 신뢰.

---

## 15) 미니 연습문제 (정답 스케치)

1) **맨–휘트니 해석**: \(U/(n_A n_B)=0.62\). 무엇을 뜻하는가?  
   → 임의 \(X\in A, Y\in B\)에서 \(P(X<Y)\approx 0.62\) (A가 작다) — 위치 차 존재 신호.

2) **윌코슨 vs 부호검정**: 언제 부호검정이 낫나?  
   → **대칭성 가정**이 의심되거나 동점(0)이 많을 때. 윌코슨은 대칭이면 더 강력.

3) **크루스칼–왈리스 사후**: \(H\) 유의. 어떤 사후?  
   → **Dunn**(Holm/BH 보정)로 쌍 비교. 이질분산·불균형에도 견고.

4) **랜덤화 단위**: 사용자 무작위화 실험을 **세션**으로 퍼뮤테이션하면?  
   → 독립 위반·유효 표본 과대 → p값 과소, 거짓 양성↑. **사용자 단위**로 교정.

5) **ARPU CI**: 왜 BCa를 권장?  
   → **편향·비대칭** 보정. 헤비테일·제로 인플레에서 **퍼센타일**보다 커버리지 안정.

---

## 16) TL;DR
- **순위검정**: 맨–휘트니(독립), 윌코슨(대응), 크루스칼–왈리스(k표본). **효과크기**(Cliff’s δ, rank-biserial, \(\epsilon^2\))를 함께.  
- **퍼뮤테이션**: 실험 **무작위화 절차를 재현**해 p값 계산—**블록/클러스터** 버전 필수.  
- **부트스트랩**: **BCa/Studentized**로 **ARPU·체류시간** CI; **클러스터/블록** 재표본화로 **현실적 의존성** 반영.  
- **항상**: **랜덤화 단위 = 분석/재표본화 단위**. 틀리면 결론도 틀린다.