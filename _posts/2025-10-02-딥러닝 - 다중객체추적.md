---
layout: post
title: 딥러닝 - 다중객체추적
date: 2025-10-02 22:25:23 +0900
category: 딥러닝
---
# 다중객체추적(MOT) 총정리
**DeepSORT · ByteTrack 아이디어 완전정복 — 파이프라인·수학·디자인 선택·실전 코드**

> 목표: **Tracking-by-Detection** 계열의 대표 알고리즘 **DeepSORT**와 **ByteTrack**을,  
> “왜 이렇게 설계됐는가?”에서 시작해 **코드 레벨**까지 한 번에 이해합니다.  
> 프레임워크는 **Python + PyTorch(특징 추출)**, 연산/할당은 **NumPy/Scipy** 개념 코드로 제시합니다.  
> 수식은 `$$ ... $$` 로 감싸며, 코드는 ``` 로 감쌉니다.

---

## 0) MOT 문제 정식화와 메트릭

### 0.1 정의
비디오 프레임 시퀀스 \(\{\mathcal{I}_t\}_{t=1}^T\) 와 **객체 검출기**가 제공하는 프레임별 박스 집합  
\(\mathcal{D}_t=\{(b_i^t, s_i^t, c_i^t)\}\) 가 있을 때, 각 객체의 **영속 ID**를 부여하여  
트랙 \(\tau_k=\{(t, b_k^t)\}\) 를 복원하는 문제.

- \(b=(x_1,y_1,x_2,y_2)\) or \((x,y,w,h)\)
- \(s\): confidence, \(c\): class

### 0.2 핵심 과제
- **데이터 연관(Data Association)**: 프레임 \(t\)의 검출들을 \(t-1\)의 트랙과 매칭  
- **모션 모델**: 칼만 필터(상태 예측)로 탐색공간 축소  
- **가림/재출현**: 잠시 사라졌다 다시 보이는 객체의 **ID 유지**  
- **검출기 노이즈**: FP/FN, 스코어 바운스

### 0.3 메트릭 (MOTChallenge, BDD100K 등)
- **MOTA**(Multiple Object Tracking Accuracy):
  $$
  \mathrm{MOTA}=1-\frac{\sum_t(\mathrm{FN}_t+\mathrm{FP}_t+\mathrm{IDS}_t)}{\sum_t \mathrm{GT}_t}
  $$
- **IDF1**(ID 정합 기반 F1): ID 유지 품질(스위치/Fragmentation 민감)  
- **HOTA**: 탐지 정확도(DetA)와 연관 정확도(AssA)의 조화 평균

> 실무: **IDF1**이 실제 사용감과 상관이 높습니다(특히 추적 ID 유지가 중요한 경우).

---

## 1) 파이프라인 큰 그림

### 1.1 Tracking-by-Detection 공통 흐름
1) **검출**: DNN Detector(YOLO/CenterNet/RT-DETR/…)
2) **예측**: 각 트랙의 **모션 예측**(Kalman Filter)
3) **연관**: 트랙 ↔ 검출 **비용 행렬** 계산 → 헝가리안 최소화
4) **갱신**: 매칭된 트랙은 **필터 업데이트**, 미매칭은 **Lost 증가**
5) **탄생/소멸**: 새 검출로 **트랙 생성**, 오래 Lost면 **삭제**

### 1.2 DeepSORT vs ByteTrack 초간단 비교

| 항목 | DeepSORT | ByteTrack |
|---|---|---|
| 핵심 | **Appearance ReID**(임베딩) + IoU + Kalman | **고신뢰/저신뢰 2단 매칭** + IoU + Kalman |
| 매칭 전략 | **Matching Cascade**(age 작은 트랙 우선), **gating**(Mahalanobis) | **High-Conf 매칭 → Low-Conf 매칭**(미매칭만) |
| ReID 네트 | **필수**(cosine 거리) | **없음**(디폴트) — 단순 IoU로도 강함 |
| 튜닝 포인트 | 임베딩 품질, \(\lambda\)(모션/외관 가중), 임계/gate | conf_high / conf_low / IoU 임계 / TTL |
| 장점 | 가림·근접 객체 분리에 강함 | 검출기 스코어 **낮은 박스도 활용**해 **ID 유지**↑, 구현 단순·빠름 |
| 단점 | ReID 준비/추론 비용 | 근접·동일 외형 다수 시 ID 스위치↑ (필요시 ReID 추가해 하이브리드) |

---

## 2) 칼만 필터와 거리 게이팅

### 2.1 상태공간(상대적 널리 쓰는 SORT/DeepSORT형)
상태 \(\mathbf{x}=[x, y, a, h, \dot{x}, \dot{y}, \dot{a}, \dot{h}]^\top\)  
여기서 \(a=w/h\) (종횡비), \(h\)는 높이. 측정 \(\mathbf{z}=[x,y,a,h]\).

- **이동 모델**: 상시 속도(정지 가정도 무난)  
- **전이행렬** \( \mathbf{F}\), **관측행렬** \( \mathbf{H}\) 는 선형.  
- 공분산 \(\mathbf{P}\) 를 유지, 예측/갱신 반복.

### 2.2 Mahalanobis Gating
예측 분포 \( \mathcal{N}(\hat{\mathbf{z}}, \mathbf{S}) \) 에 대해 측정 \(\mathbf{z}\)의 **대수거리**:  
$$
d^2=(\mathbf{z}-\hat{\mathbf{z}})^\top \mathbf{S}^{-1} (\mathbf{z}-\hat{\mathbf{z}})
$$
카이제곱 분포 임계 \(\chi^2\) 로 **gate** 하여 원천적으로 불가능한 매칭 제거 → 비용 행렬 희소화.

---

## 3) DeepSORT 핵심: Appearance + Motion 융합

### 3.1 비용 함수
- 모션 기반(칼만 예측 vs 측정) **Mahalanobis distance** \(d^\mathrm{m}\)
- 외관 기반(ReID 임베딩 cosine) **appearance distance** \(d^\mathrm{a}\)
- 결합:
$$
\mathrm{cost} = \lambda\, d^\mathrm{m} + (1-\lambda)\, d^\mathrm{a}
$$
- 보통 \( \lambda \in [0.2,0.6] \). 외관이 좋을수록 \((1-\lambda)\) 비중↑.

### 3.2 Matching Cascade
- **최근에 갱신된(track age 작은)** 트랙부터 순차적으로 매칭 → 신선한 트랙의 유지 우선.  
- 각 단계에서 헝가리안으로 부분 매칭.

### 3.3 트랙 라이프사이클
- **Tentative**: 연속 \(n\)프레임(예: 3) 매칭 성공 시 **Confirmed**  
- **Confirmed**: 정상 추적  
- **Deleted**: Lost \(> \text{max\_age}\) 이면 삭제

---

## 4) ByteTrack 핵심: 스코어 두 구간 매칭

### 4.1 아이디어
- 고신뢰 검출만 쓰면 **리콜↓ → ID 단절**.  
- 반대로 낮은 스코어까지 다 쓰면 **FP 증가**.  
- **해결**:  
  1) **High-Conf**(예: \(s \ge \theta_\mathrm{high}\))로 1차 IoU 매칭  
  2) **Unmatched track** 과 **Low-Conf**( \(\theta_\mathrm{low} \le s < \theta_\mathrm{high}\) )로 2차 IoU 매칭  
  → 검출기 스코어가 흔들려도 **연속성 보존**.

### 4.2 상태머신(일반적 구현)
- `Tracked` ↔ `Lost` ↔ `Removed`  
- 2차 매칭에서 붙은 **Low-Conf** 박스는 트랙 갱신은 하지만 **출력/평가엔 반영 제한**(옵션).  
- **점수 누적/평활**: 트랙 score = EMA(최근 검출 score), 너무 낮아지면 `Lost`.

---

## 5) 최소 구현을 위한 데이터 구조

```python
# 공통 자료형(개념)
class Detection:
    def __init__(self, tlbr, score, feat=None, cls_id=0):
        self.tlbr = tlbr  # [x1,y1,x2,y2], float
        self.score = score
        self.feat = feat  # ReID embedding (DeepSORT)
        self.cls_id = cls_id

class TrackState:
    Tentative, Confirmed, Lost, Removed = range(4)

class Track:
    def __init__(self, mean, cov, track_id, n_init=3, max_age=30, feat=None):
        self.mean = mean      # 칼만 상태 평균
        self.cov  = cov       # 칼만 공분산
        self.track_id = track_id
        self.state = TrackState.Tentative
        self.time_since_update = 0
        self.hits = 1
        self.n_init = n_init
        self.max_age = max_age
        self.features = []    # DeepSORT: 임베딩 히스토리(큐)
        if feat is not None: self.features.append(feat)

    def mark_missed(self):
        if self.state == TrackState.Tentative:
            self.state = TrackState.Removed
        elif self.time_since_update > self.max_age:
            self.state = TrackState.Removed
        else:
            self.state = TrackState.Lost

    def is_confirmed(self): return self.state == TrackState.Confirmed
    def is_lost(self):      return self.state == TrackState.Lost
    def is_removed(self):   return self.state == TrackState.Removed
```

---

## 6) 칼만 필터(상시속도 박스 상태) — Numpy 개념 코드

```python
import numpy as np

class KalmanBox:
    def __init__(self):
        ndim, dt = 4, 1.0
        # 상태: [x,y,a,h, vx,vy,va,vh]
        self._motion_mat  = np.eye(2*ndim)
        for i in range(ndim):
            self._motion_mat[i, ndim+i] = dt
        self._update_mat  = np.eye(ndim, 2*ndim)

        # 노이즈(튜닝)
        self._std_pos = 1.0
        self._std_vel = 0.5

    def initiate(self, measurement):
        mean_pos = measurement
        mean_vel = np.zeros_like(mean_pos)
        mean = np.r_[mean_pos, mean_vel]
        std = [2, 2, 1e-1, 2, 10, 10, 1e-1, 10]
        cov = np.diag(np.square(std))
        return mean, cov

    def predict(self, mean, cov):
        std_pos = [self._std_pos, self._std_pos, 1e-1, self._std_pos]
        std_vel = [self._std_vel, self._std_vel, 1e-2, self._std_vel]
        Q = np.diag(np.square(np.r_[std_pos, std_vel]))
        mean = self._motion_mat.dot(mean)
        cov  = self._motion_mat.dot(cov).dot(self._motion_mat.T) + Q
        return mean, cov

    def project(self, mean, cov):
        std = [self._std_pos, self._std_pos, 1e-1, self._std_pos]
        R = np.diag(np.square(std))
        mean = self._update_mat.dot(mean)
        cov  = self._update_mat.dot(cov).dot(self._update_mat.T) + R
        return mean, cov

    def update(self, mean, cov, measurement):
        proj_mean, proj_cov = self.project(mean, cov)
        K = cov.dot(self._update_mat.T).dot(np.linalg.inv(proj_cov))
        inn = measurement - proj_mean
        mean = mean + K.dot(inn)
        cov  = cov - K.dot(proj_cov).dot(K.T)
        return mean, cov

def tlbr_to_xyah(tlbr):
    x1,y1,x2,y2 = tlbr
    w, h = x2-x1, y2-y1
    x = x1 + w/2.; y = y1 + h/2.
    a = w/float(max(h,1e-6))
    return np.array([x,y,a,h], dtype=float)
```

**Mahalanobis 게이팅**:

```python
def gating_distance(kf, mean, cov, measurements, gating_threshold=9.4877):  # chi2 df=4, p=0.05
    proj_mean, proj_cov = kf.project(mean, cov)
    L = np.linalg.cholesky(proj_cov)
    dists = []
    for z in measurements:
        y = z - proj_mean
        z_ = np.linalg.solve(L, y)
        d = np.sum(z_**2)  # Mahalanobis^2
        dists.append(d)
    mask = np.array(dists) < gating_threshold
    return np.array(dists), mask
```

---

## 7) 유틸: IoU/코사인/헝가리안

```python
import numpy as np
from scipy.optimize import linear_sum_assignment

def iou(a, b):  # a:(N,4), b:(M,4) in tlbr
    N,M = len(a), len(b)
    iou = np.zeros((N,M))
    for i in range(N):
        x1 = np.maximum(a[i,0], b[:,0]); y1=np.maximum(a[i,1], b[:,1])
        x2 = np.minimum(a[i,2], b[:,2]); y2=np.minimum(a[i,3], b[:,3])
        inter = np.maximum(0, x2-x1)*np.maximum(0, y2-y1)
        area1 = (a[i,2]-a[i,0])*(a[i,3]-a[i,1])
        area2 = (b[:,2]-b[:,0])*(b[:,3]-b[:,1])
        iou[i] = inter / (area1 + area2 - inter + 1e-9)
    return iou

def cosine_dist(A, B, eps=1e-12):  # A:(N,D), B:(M,D)
    An = A / (np.linalg.norm(A, axis=1, keepdims=True) + eps)
    Bn = B / (np.linalg.norm(B, axis=1, keepdims=True) + eps)
    return 1.0 - An.dot(Bn.T)  # distance

def hungarian(cost, cost_limit=None):
    row, col = linear_sum_assignment(cost)
    matches, um_rows, um_cols = [], [], []
    for r in range(cost.shape[0]):
        if r not in row: um_rows.append(r)
    for c in range(cost.shape[1]):
        if c not in col: um_cols.append(c)
    for r,c in zip(row, col):
        if cost_limit is None or cost[r,c] <= cost_limit:
            matches.append((r,c))
        else:
            um_rows.append(r); um_cols.append(c)
    return matches, um_rows, um_cols
```

---

## 8) DeepSORT 스타일 매칭(모션+외관) — 핵심 루틴

```python
def deepsort_match(tracks, detections, kf, lambda_=0.5, max_cosine=0.2, gating_th=9.4877):
    """
    tracks: list[Track] (confirmed)
    detections: list[Detection] with .tlbr and .feat
    1) Mahalanobis gating
    2) Appearance distance(average/min over track feature gallery)
    3) Weighted cost -> Hungarian
    """
    if len(tracks)==0 or len(detections)==0:
        return [], list(range(len(tracks))), list(range(len(detections)))

    # measurement list
    meas = np.array([tlbr_to_xyah(d.tlbr) for d in detections])
    # build motion cost with gating
    motion_cost = np.zeros((len(tracks), len(detections))) + 1e5
    for ti, tr in enumerate(tracks):
        d2, mask = gating_distance(kf, tr.mean, tr.cov, meas, gating_th)
        motion_cost[ti, mask] = d2[mask]

    # appearance cost (cosine)
    app_cost = np.zeros((len(tracks), len(detections))) + 1.0
    for ti, tr in enumerate(tracks):
        if len(tr.features)==0:
            app_cost[ti,:] = 1.0
            continue
        track_feat = np.array(tr.features)  # (K,D)
        det_feat   = np.array([d.feat for d in detections])  # (M,D)
        cd = cosine_dist(track_feat, det_feat)  # (K,M)
        app_cost[ti,:] = cd.min(axis=0)  # best-of gallery
    app_cost = np.clip(app_cost, 0.0, max_cosine)

    # normalize motion cost
    if np.isfinite(motion_cost).any():
        mc = motion_cost.copy()
        mc[~np.isfinite(mc)] = mc[ np.isfinite(mc) ].max()
        mc = mc / (mc.max()+1e-9)
    else:
        mc = np.ones_like(motion_cost)

    cost = lambda_*mc + (1-lambda_)*app_cost
    matches, um_tr, um_det = hungarian(cost, cost_limit=1.0)
    return matches, um_tr, um_det
```

**Matching Cascade** 는 `tracks` 를 `age`(time_since_update 오름차순) 그룹으로 나눠 위 매칭을 단계적으로 수행하면 됩니다.

---

## 9) ByteTrack 스타일 매칭 — 두 단계(High→Low)

```python
def bytetrack_match(tracks, dets_high, dets_low, iou_th_high=0.5, iou_th_low=0.1):
    """
    tracks: list[Track] (Tracked or Lost→candidate)
    dets_high: [Detection] with score>=th_high
    dets_low : [Detection] with th_low<=score<th_high
    step1: IoU match with high
    step2: unmatched tracks with low
    """
    tlbr_tr = np.array([t.to_tlbr() for t in tracks]) if len(tracks)>0 else np.zeros((0,4))
    tlbr_hi = np.array([d.tlbr for d in dets_high])   if len(dets_high)>0 else np.zeros((0,4))
    tlbr_lo = np.array([d.tlbr for d in dets_low])    if len(dets_low)>0 else np.zeros((0,4))

    matches, um_tr, um_hi = [], list(range(len(tracks))), list(range(len(dets_high)))
    if len(tracks)>0 and len(dets_high)>0:
        iou_mat = 1 - iou(tlbr_tr, tlbr_hi)  # cost = 1 - IoU
        m, ut, uh = hungarian(iou_mat, cost_limit=1 - iou_th_high)
        matches = m; um_tr = ut; um_hi = uh

    # 2nd stage with low
    matches2 = []
    if len(um_tr)>0 and len(dets_low)>0:
        iou_mat2 = 1 - iou(tlbr_tr[um_tr], tlbr_lo)
        m2, ut2, ul2 = hungarian(iou_mat2, cost_limit=1 - iou_th_low)
        # map local indices to global
        matches2 = [(um_tr[r], c) for (r,c) in m2]
        um_tr = [um_tr[r] for r in ut2]  # unmatched after step2

    return matches, um_tr, um_hi, matches2
```

- 트랙 객체에 `to_tlbr()`(현재 상태의 박스 복원) 메서드가 있다고 가정.  
- 실제 ByteTrack은 트랙을 **Tracked / Lost** 풀로 나눠 서로 다른 IoU 임계/우선순위를 적용합니다.

---

## 10) 트랙 갱신/관리 공통 루틴

```python
def update_tracks_with_matches(tracks, detections, matches, kf):
    for ti, di in matches:
        det = detections[di]
        z = tlbr_to_xyah(det.tlbr)
        tr = tracks[ti]
        tr.mean, tr.cov = kf.update(tr.mean, tr.cov, z)
        tr.time_since_update = 0
        tr.hits += 1
        if tr.state == TrackState.Tentative and tr.hits >= tr.n_init:
            tr.state = TrackState.Confirmed
        if det.feat is not None:
            # DeepSORT: feature gallery 관리(EMA/큐)
            tr.features.append(det.feat)
            if len(tr.features) > 50: tr.features = tr.features[-50:]

def mark_unmatched(tracks, unmatched_indices):
    for i in unmatched_indices:
        tr = tracks[i]
        tr.time_since_update += 1
        tr.mark_missed()

def birth_tracks(tracks, dets, unmatched_det_indices, kf, next_id, min_score=0.4, use_reid=False):
    for di in unmatched_det_indices:
        d = dets[di]
        if d.score < min_score: 
            continue
        mean, cov = kf.initiate(tlbr_to_xyah(d.tlbr))
        tr = Track(mean, cov, next_id)
        tr.state = TrackState.Tentative
        if use_reid and d.feat is not None:
            tr.features.append(d.feat)
        tracks.append(tr)
        next_id += 1
    return next_id

def purge_tracks(tracks):
    # 실제 출력용: Confirmed & 최근 업데이트된 트랙만
    alive, outputs = [], []
    for tr in tracks:
        if tr.state == TrackState.Removed:
            continue
        alive.append(tr)
        if tr.is_confirmed() and tr.time_since_update == 0:
            outputs.append(tr)
    return alive, outputs
```

---

## 11) 하나의 프레임 처리(DeepSORT 버전) — 예시

```python
def process_frame_deepsort(tracks, detections, kf, next_id,
                           lambda_=0.5, max_age=30, n_init=3,
                           gate_th=9.4877, min_birth_score=0.4):
    # 1) 칼만 예측
    for tr in tracks:
        tr.mean, tr.cov = kf.predict(tr.mean, tr.cov)

    # 2) confirmed / tentative 분리해 cascade 가능
    confirmed_idx = [i for i,t in enumerate(tracks) if t.is_confirmed()]
    tentative_idx = [i for i,t in enumerate(tracks) if t.state==TrackState.Tentative]

    # 3) confirmed 먼저 매칭
    conf_tracks = [tracks[i] for i in confirmed_idx]
    m1, um_tr1, um_det1 = deepsort_match(conf_tracks, detections, kf, lambda_, gating_th=gate_th)
    # index 보정
    matches_conf = [(confirmed_idx[ti], di) for (ti, di) in m1]
    um_tr_conf   = [confirmed_idx[i] for i in um_tr1]
    um_det_conf  = um_det1

    # 4) tentative 매칭(외관은 약함 → IoU나 완화된 gate 사용)
    tent_tracks = [tracks[i] for i in tentative_idx]
    meas = np.array([tlbr_to_xyah(d.tlbr) for d in detections])
    # 간단히 IoU 기반
    if len(tent_tracks)>0 and len(detections)>0:
        cost = 1 - iou(np.array([t.to_tlbr() for t in tent_tracks]),
                       np.array([d.tlbr for d in detections]))
        m2, ut2, ud2 = hungarian(cost, cost_limit=1-0.3)
        matches_tent = [(tentative_idx[ti], di) for (ti,di) in m2]
        um_tr_tent   = [tentative_idx[i] for i in ut2]
        um_det_tent  = ud2
    else:
        matches_tent, um_tr_tent, um_det_tent = [], tentative_idx, list(range(len(detections)))

    # 5) 갱신/미매칭 처리
    matched_all = matches_conf + matches_tent
    update_tracks_with_matches(tracks, detections, matched_all, kf)

    unmatched_tracks = list(set(um_tr_conf + um_tr_tent))
    mark_unmatched(tracks, unmatched_tracks)

    unmatched_dets = list(set(um_det_conf).intersection(set(um_det_tent)))
    next_id = birth_tracks(tracks, detections, unmatched_dets, kf, next_id, min_score=min_birth_score, use_reid=True)

    # 6) 삭제/출력
    tracks, outputs = purge_tracks(tracks)
    return tracks, outputs, next_id
```

> `Track.to_tlbr()` 는 칼만 상태의 \([x,y,a,h]\) 를 \([x1,y1,x2,y2]\) 로 변환하는 메서드라고 가정합니다.

---

## 12) 하나의 프레임 처리(ByteTrack 버전) — 예시

```python
def process_frame_bytetrack(tracks, detections, kf, next_id,
                            conf_high=0.6, conf_low=0.1,
                            iou_th_high=0.5, iou_th_low=0.1,
                            max_age=30):

    # 0) 분리
    dets_high = [d for d in detections if d.score >= conf_high]
    dets_low  = [d for d in detections if conf_low <= d.score < conf_high]

    # 1) 예측
    for tr in tracks:
        tr.mean, tr.cov = kf.predict(tr.mean, tr.cov)

    # 2) 1차 매칭(high)
    m1, um_tr, um_hi, m2 = bytetrack_match(tracks, dets_high, dets_low, iou_th_high, iou_th_low)
    # m1: tracks ↔ high, m2: leftover tracks ↔ low

    # 3) 갱신
    def upd(matches, det_list):
        for ti, di in matches:
            z = tlbr_to_xyah(det_list[di].tlbr)
            tracks[ti].mean, tracks[ti].cov = kf.update(tracks[ti].mean, tracks[ti].cov, z)
            tracks[ti].time_since_update = 0
            tracks[ti].hits += 1
            if tracks[ti].state == TrackState.Tentative and tracks[ti].hits >= tracks[ti].n_init:
                tracks[ti].state = TrackState.Confirmed

    upd(m1, dets_high)
    upd(m2, dets_low)

    # 4) 미매칭 트랙 처리
    unmatched_after = set(um_tr)  # 미매칭으로 남은 트랙 index
    # high에서 남은 dets는 birth 후보
    um_dets_for_birth = um_hi

    for ti in unmatched_after:
        tr = tracks[ti]
        tr.time_since_update += 1
        if tr.time_since_update > tr.max_age:
            tr.state = TrackState.Removed
        else:
            tr.state = TrackState.Lost

    # 5) 탄생: high 만으로 생성(보통)
    next_id = birth_tracks(tracks, dets_high, um_dets_for_birth, kf, next_id, min_score=conf_high, use_reid=False)

    # 6) purge & outputs
    tracks, outputs = purge_tracks(tracks)
    return tracks, outputs, next_id
```

---

## 13) ReID 임베딩 네트(DeepSORT용) — 경량 예시

> 실전은 ImageNet 백본 + **ID Classification(CE)** + **Triplet Loss** 조합(“학습은 분류, 사용은 임베딩”).  
> 샘플링: **PK 샘플링**(P개 ID × K개 이미지), **Random Erasing** 증강.

```python
import torch, torch.nn as nn, torch.nn.functional as F

class SmallReID(nn.Module):
    def __init__(self, feat_dim=128, num_classes=1000):
        super().__init__()
        self.backbone = nn.Sequential(
            nn.Conv2d(3,32,3,2,1), nn.BatchNorm2d(32), nn.ReLU(True),
            nn.Conv2d(32,64,3,2,1), nn.BatchNorm2d(64), nn.ReLU(True),
            nn.Conv2d(64,128,3,2,1), nn.BatchNorm2d(128), nn.ReLU(True),
            nn.AdaptiveAvgPool2d(1))
        self.fc = nn.Linear(128, feat_dim)
        self.classifier = nn.Linear(feat_dim, num_classes)

    def forward(self, x, return_feat=False):
        x = self.backbone(x).flatten(1)
        feat = F.normalize(self.fc(x))
        if return_feat: return feat
        logits = self.classifier(feat)
        return logits, feat

def triplet_loss(anchor, pos, neg, margin=0.3):
    d_ap = (anchor - pos).pow(2).sum(1)
    d_an = (anchor - neg).pow(2).sum(1)
    return F.relu(margin + d_ap - d_an).mean()
```

- DeepSORT 추론 시: 검출 박스로부터 **크롭 → 정규화 → 임베딩 추출 → 트랙 갤러리와 코사인 거리**.

---

## 14) 간단 엔드투엔드 시뮬레이터(의사코드)

```python
# detector_outputs[t] = list of Detection (tlbr, score, cls_id, feat(optional))
tracks = []
next_id = 1
kf = KalmanBox()

for t in range(1, T+1):
    detections = detector_outputs[t]  # ex. YOLO 결과 파싱
    # DeepSORT 예:
    tracks, outputs, next_id = process_frame_deepsort(tracks, detections, kf, next_id)

    # 결과 사용: outputs 는 방금 업데이트된 confirmed tracks
    for tr in outputs:
        tlbr = tr.to_tlbr()
        tid  = tr.track_id
        # 시각화/로그/저장 ...
```

---

## 15) 튜닝·현업 체크리스트

### 15.1 공통
- **검출 임계**: Precision–Recall tradeoff를 추적과 **함께** 최적화 (단독 mAP 최적이 아님).  
- **max_age(TTL)**: 프레임 누락 허용치(occlusion 길이)를 데이터 특성에 맞춤.  
- **클래스별 추적**: `person`만/모든 클래스/클래스별 파라미터.

### 15.2 DeepSORT
- 임베딩 품질이 열악하면 오히려 **ID 스위치↑** → 백본/학습 개선  
- **\(\lambda\)**: 겹침 많으면 **appearance↑**, 단조로운 장면이면 **motion↑**  
- **gallery 관리**: 최근 N개 EMA or queue; 오래된 특징 제거

### 15.3 ByteTrack
- \(\theta_\mathrm{high}\) / \(\theta_\mathrm{low}\): 데이터/검출기 스케일별 조정  
  - 흔한 시작: `high=0.6~0.7`, `low=0.1~0.3`  
- **low 매칭 후 출력 여부**: 시각 결과는 high만, 상태 갱신은 low도 허용(권장)

### 15.4 속도
- 벡터화된 IoU/거리 계산, 배치 ReID 추론  
- CPU가 병목이면 **칼만/헝가리안**은 C++/Numba, ReID는 GPU  
- 리얼타임: Detector 1개 + Tracker 1개를 **파이프라인**(스레드/스트림)으로

---

## 16) 배포(실시간/온디바이스) 이슈

- **정확도 회귀 테스트**: 파라미터 변경/정밀도(FP16/INT8)/엔진 교체 시 **IDF1/MOTA** 비교 자동화  
- **동적 입력/레터박스**: 박스 좌표 역변환 일치  
- **멀티카메라**: 카메라 간 ReID(도메인 쉬프트 주의), 시간 동기화  
- **INT8 양자화**: ReID 임베딩 코사인 민감 → QAT 권장, 또는 float로 유지

---

## 17) 평가 루틴(간단 Pseudo; IDF1 근사)

```python
# 실제 MOTChallenge 포맷은 별도 툴 사용 권장(TrackEval 등)
# 여기서는 개념을 위해 단순 근사 ID 매칭 후 F1 출력
def simple_idf1(gt_tracks, pred_tracks, iou_thr=0.5):
    """
    gt_tracks/pred_tracks: 딕셔너리 {frame_id: [(id, tlbr), ...]}
    1) 프레임별 IoU 매칭으로 ID pair 누적
    2) Global optimal mapping 근사(빈도수 가장 높은 pair 채택)
    3) Precision/Recall 계산
    """
    from collections import Counter
    pair_cnt = Counter(); tp=0; fp=0; fn=0
    for t in gt_tracks.keys():
        gts = gt_tracks[t]; prs = pred_tracks.get(t, [])
        if len(gts)==0 and len(prs)==0: continue
        if len(gts)==0: fp += len(prs); continue
        if len(prs)==0: fn += len(gts); continue
        g_box = np.array([g[1] for g in gts])
        p_box = np.array([p[1] for p in prs])
        M = iou(g_box, p_box)
        used_g, used_p = set(), set()
        # 그리디
        while True:
            idx = np.unravel_index(np.argmax(M), M.shape)
            if M[idx] < iou_thr: break
            gi, pi = idx
            if gi in used_g or pi in used_p: 
                M[gi,pi] = -1; continue
            pair_cnt[(gts[gi][0], prs[pi][0])] += 1
            used_g.add(gi); used_p.add(pi)
            M[gi,:] = -1; M[:,pi] = -1
        tp += len(used_p)
        fp += (len(prs) - len(used_p))
        fn += (len(gts) - len(used_g))
    # 단순 근사: 최빈 pair 수가 크면 ID 일관성↑ -> 여기선 F1만 반환
    prec = tp / max(tp+fp,1); rec = tp / max(tp+fn,1)
    f1 = 2*prec*rec / max(prec+rec,1e-9)
    return f1
```

---

## 18) 실전 레시피

- **사람 추적, 혼잡한 상업 매장**: DeepSORT(또는 ByteTrack+ReID 하이브리드)  
  - ReID는 상점 도메인 재학습(유니폼/조명 반영), \(\lambda=0.4\)부터 탐색  
  - TTL↑(occlusion 많음), detector conf_low 낮춰 recall 확보  
- **도로 차량 추적, 고속**: ByteTrack  
  - 검출기 강함(YOLO/RT-DETR) 가정, `high=0.6, low=0.2` 시작  
  - IoU_th_high 0.5~0.6, low 0.1~0.2, max_age 작게(빠른 이동)  
- **엣지 카메라**: ByteTrack 단독(간결/저비용), 필요 시 소형 ReID(옵션)

---

## 19) 자주 겪는 에러 & 디버깅

- **ID 스위치 많음**  
  - DeepSORT: 임베딩 품질/증강/학습(Triplet mining) 개선, \(\lambda\)↑  
  - ByteTrack: IoU_th_low↑(가짜 연결 줄임), conf_low↑  
- **놓침(FN) 많음**  
  - detector conf_low↓, max_age↑, ByteTrack 단계2 활성  
- **근접 객체 합쳐짐**  
  - NMS/IoU 임계 재조정, DeepSORT로 전환(appearance)  
- **프레임 드랍 시 추적 끊김**  
  - dt 반영 또는 max_age↑, 속도 기반 예측(카메라 FPS 변동 고려)  
- **클래스 섞임**  
  - 클래스별로 별도 트래커 or 비용 행렬에서 cross-class 불허

---

## 20) 요약(한 장)

- **DeepSORT**:  
  - 칼만 + **Matching Cascade** + **Appearance(ReID)**  
  - 복잡/가림/근접 분리에 강함  
- **ByteTrack**:  
  - 칼만 + **2단 IoU 매칭(High→Low)**  
  - 간결/리얼타임·리콜↑, 스코어 흔들림에 강함  
- 공통:  
  - **TTL(max_age)**, **임계(conf/iou)**, **좌표/전처리 일치**, **지표(IDF1)** 를 시스템 차원에서 함께 튜닝

제공한 코드 스니펫을 이어 붙이면 **작동하는 베이스라인 트래커**를 빠르게 만들 수 있습니다.  
검출기는 이미 확보되었다고 가정하고, **DeepSORT/ByteTrack** 중 도메인에 맞는 전략을 선택해  
**임계값/TTL/속도–정확도**를 체계적으로 탐색하세요.  
현업에서는 **정량 지표(특히 IDF1)** 를 자동 회귀 테스트에 넣어, 모델/엔진/설정 변경 시 **ID 안정성**을 항상 확인하는 것이 핵심입니다.