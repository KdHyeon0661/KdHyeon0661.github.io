---
layout: post
title: 알고리즘 - 알고리즘이란
date: 2024-12-27 19:20:23 +0900
category: 알고리즘
---
# 알고리즘이란? — 정의, 성질, 성능평가, 그리고 핵심 유형별 “완전” 실전 가이드

> **알고리즘(Algorithm)**은 주어진 입력을 받아 **유한한 단계**의 명확한 절차를 통해 **출력**을 산출하는 방법이다.
> 본 글은 당신이 제공한 초안(정의·특징·성능평가·유형 분류)을 **핵심만 압축해 재정리**하고, 그 위에 **증명 아이디어·코드·실전 체크리스트**를 **빠짐없이** 덧붙여 **확장**한 버전이다.
> 모든 코드는 ```로, 수학식은 반드시 $$로 감싼다.

---

## 형식적 관점과 전제(RAM/Word-RAM/비트복잡도)

- **계산 모델**을 정해야 성능 비교가 의미 있다.
  - **Word-RAM**: 단어 크기(보통 64비트) 안에 들어가는 정수 연산은 모두 O(1)로 본다.
  - **비트 복잡도 모델**: 입력 길이를 비트 단위로 보고, 큰 정수 연산 비용을 비트 길이에 따라 측정.
- **문제 인스턴스**: 입력 \(x \in \Sigma^*\) 와 명시적/암묵적 **제약**(정렬돼 있음, 그래프가 DAG 등).
- **정확성**: 사양(명세) 충족.
  - **부분/전체 정당성**: 전제(전제조건)를 만족하는 모든 입력에서 알고리즘이 **멈추고** 올바른 출력을 내면 전체 정당성, 멈추는 가정이 빠지면 부분 정당성.
- **명세 예**: 이진탐색 명세
  $$
  \text{Given sorted } A[0..n-1],\ x\in \mathbb{Z},\ \exists i\ \text{s.t. }A[i]=x?
  $$
  전제조건: \(A\)가 **오름차순 정렬**.

---

## 알고리즘의 5가지 특징 — 핵심을 뽑아 더 단단히

1) **입력(Input)**: 0개 이상.
2) **출력(Output)**: 1개 이상. 명세가 출력 형식을 고정한다.
3) **명확성(Definiteness)**: 각 단계가 기계적으로 해석 가능해야 한다.
4) **유한성(Finiteness)**: 종료 보장.
5) **효율성(Effectiveness)**: 각 단계가 현실적(수행 가능). Word-RAM 가정에서 덧셈, 비교는 O(1).

**보강**: 올바름을 보이기 위한 **루프 불변식(loop invariant)**, **귀납법**, **교환 논증(exchange argument)** 등 정당화 도구를 본문 각 섹션에서 실전 예와 함께 사용한다.

---

## 성능 평가 — Big-O의 정확한 뜻과 실전 비용 모델

### Big-O, Big-Ω, Big-Θ

- 정의(점근적 상계):
  $$
  f(n) \in O(g(n)) \iff \exists c>0,\ \exists n_0,\ \forall n\ge n_0:\ 0 \le f(n) \le c\cdot g(n).
  $$
- **Big-Ω**(점근적 하계), **Big-Θ**(상하계 동치).

### 시간·공간·I/O·캐시

- **시간복잡도**: 연산 횟수.
- **공간복잡도**: 추가 메모리(입력 제외).
- **I/O 모델**: 외부메모리(디스크, 네트워크) 병목 시 I/O 횟수 최소화가 지배적.
- **캐시 인식/우호**: 지역성(locality)·연속 메모리 레이아웃·분지 예측 감소.

### 상수·실전 함정

- 이론상 \(O(n)\)이라도 상수·메모리 패턴·브랜치 미스·가비지 컬렉션 등으로 실제 느릴 수 있다.
- **입력 분포**(거의 정렬·중복 많음 등)에 따른 최적화(삽입정렬·버킷 등) 고려.

---

## 알고리즘 ↔ 자료구조 시너지, 선택이 성능을 만든다

| 문제 | 자료구조 선택 | 복잡도(대표) |
|---|---|---|
| 최단경로(비음수) | 인접 리스트 + 이진힙 | Dijkstra: \(O((V+E)\log V)\) |
| 동적 순위통계 | 균형 BST(레드블랙/AVL) | 삽입/삭제/검색 \(O(\log n)\) |
| Disjoint Set | Union-Find(경로압축+랭크) | 거의 \(O(1)\) (아커만 역함수) |
| 빈도 상위 k | 해시맵 + 최소힙(k) | \(O(n\log k)\) |
| 스트림 카운팅 | Count-Min Sketch | 확률적 근사, \(O(1)\) 업데이트 |

---

## 탐색(Search)

### 선형 탐색

- 정렬 불필요, 단순.
- 최악 \(O(n)\), 최선 \(O(1)\).

```python
def linear_search(a, x):
    for i, v in enumerate(a):
        if v == x:
            return i
    return -1
```

**불변식**: 루프 k번째 반복 직전, \(a[0..k-1]\)엔 \(x\)가 없음.

### 이진 탐색 — 정렬 전제의 위력

- 전제: 배열 정렬 오름차순.
- 시간복잡도: \(O(\log n)\).

```python
def binary_search(a, x):
    lo, hi = 0, len(a)-1
    while lo <= hi:
        mid = (lo + hi) // 2
        if a[mid] == x:
            return mid
        if a[mid] < x:
            lo = mid + 1
        else:
            hi = mid - 1
    return -1
```

**정당성 개요**: 루프 불변식
- 매 반복: 답이 존재하면 구간 \([lo, hi]\) 안에 있다.
- 종료 시 \(lo>hi\)면 부재.

**경계 케이스**:
- 중복값에서 **첫/마지막 발생 위치**를 찾는 변형(하한/상한).
- 오버플로우: `mid = lo + (hi-lo)//2` 선호.

---

## 정렬(Sort)

### 비교 기반 정렬 하한(결정트리)

- 모든 순열 수 \(n!\) 구분 필요 → 결정트리 높이 \(\Omega(\log(n!)) = \Omega(n\log n)\).
  따라서 **어떤 비교 기반 정렬도** 최악 시간 \(\Omega(n\log n)\)보다 빠를 수 없다.

### 핵심 알고리즘

#### 삽입 정렬 — 작은 n/거의 정렬에 강함

- 평균/최악 \(O(n^2)\), 최선(이미 정렬) \(O(n)\).
- **안정적**이고 **제자리**.

```python
def insertion_sort(a):
    for i in range(1, len(a)):
        key = a[i]
        j = i-1
        while j >= 0 and a[j] > key:
            a[j+1] = a[j]
            j -= 1
        a[j+1] = key
```

#### 병합 정렬 — 안정·확정적 \(O(n\log n)\)

- 추가 메모리 \(O(n)\). 안정 정렬이 필요할 때 채택.

```python
def merge_sort(a):
    if len(a) <= 1:
        return a
    mid = len(a)//2
    left = merge_sort(a[:mid])
    right = merge_sort(a[mid:])
    return merge(left, right)

def merge(L, R):
    i=j=0; out=[]
    while i<len(L) and j<len(R):
        if L[i] <= R[j]:
            out.append(L[i]); i+=1
        else:
            out.append(R[j]); j+=1
    out.extend(L[i:]); out.extend(R[j:])
    return out
```

#### 퀵 정렬 — 평균 \(O(n\log n)\), 최악 \(O(n^2)\)

- **피벗 선택** 중요(랜덤/median-of-three). 제자리, 빠른 실제 성능.

```python
import random
def quicksort(a, lo=0, hi=None):
    if hi is None: hi = len(a)-1
    if lo >= hi: return
    p = partition(a, lo, hi)
    quicksort(a, lo, p-1)
    quicksort(a, p+1, hi)

def partition(a, lo, hi):
    pivot_idx = random.randint(lo, hi)
    a[pivot_idx], a[hi] = a[hi], a[pivot_idx]
    pivot = a[hi]
    i = lo
    for j in range(lo, hi):
        if a[j] <= pivot:
            a[i], a[j] = a[j], a[i]; i+=1
    a[i], a[hi] = a[hi], a[i]
    return i
```

#### 힙 정렬 — 확정적 \(O(n\log n)\), 제자리

- 안정적이지 않다. 추가 메모리 거의 없음.

```python
def heapsort(a):
    import heapq
    h = []
    for v in a: heapq.heappush(h, v)
    for i in range(len(a)):
        a[i] = heapq.heappop(h)
```

**실전 선택 요약**
- 안정성 필요/외부정렬: 병합.
- 메모리 아낌/최악 보장: 힙.
- 평균적으로 매우 빠름: 퀵(피벗 주의).

---

## 재귀(Recursion)와 점화식

### 마스터 정리

- 형태:
  $$
  T(n) = a\,T\!\left(\frac{n}{b}\right) + f(n),\ \ a\ge1,\ b>1
  $$
  - \(f(n) = O(n^{\log_b a-\epsilon}) \Rightarrow T(n)=\Theta(n^{\log_b a})\)
  - \(f(n) = \Theta(n^{\log_b a}\log^k n) \Rightarrow T(n)=\Theta(n^{\log_b a}\log^{k+1} n)\)
  - \(f(n) = \Omega(n^{\log_b a+\epsilon})\) + 규칙성 → \(T(n) = \Theta(f(n))\)

### 꼬리재귀 → 반복 변환

```python
def fact(n, acc=1):
    if n==0: return acc
    return fact(n-1, acc*n)  # 꼬리재귀
```

언어/컴파일러가 TCO 미지원이면 반복으로 변환:

```python
def fact_iter(n):
    acc=1
    while n>0:
        acc*=n
        n-=1
    return acc
```

---

## 분할 정복(Divide & Conquer)

### 이분 탐색, 병합정렬, 퀵정렬 — 앞서 다룸

### — 평균 \(O(n)\)

```python
import random
def quickselect(a, k):
    lo, hi = 0, len(a)-1
    while True:
        pivot = partition(a, lo, hi)
        if pivot == k: return a[pivot]
        if pivot < k: lo = pivot+1
        else: hi = pivot-1
```

### — \(O(n^{\log_2 3})\approx O(n^{1.585})\)

아이디어: 큰 정수를 절반으로 나눈 뒤 3번의 재귀 곱과 합성으로 덧셈/시프트를 줄인다.

---

## — 교환 논증으로 정당화

### 인터벌 스케줄링(최대 비겹침 개수)

- 전략: **종료 시간이 가장 이른** 활동부터 선택.

```python
def interval_scheduling(intervals):
    # intervals: [(s,e), ...]
    intervals.sort(key=lambda x: x[1])
    res=[]
    cur_end=-10**18
    for s,e in intervals:
        if s>=cur_end:
            res.append((s,e))
            cur_end=e
    return res
```

**정당성(스케치)**: 가장 빨리 끝나는 활동을 포함하는 최적해가 존재함을 교환 논증으로 보인다.

### 허프만 코딩 — 최적 접두코드

- 항상 **가장 빈도 낮은 두 노드**를 합쳐 나무를 만든다.

```python
import heapq

def huffman(freqs):  # freqs: dict{symbol: count}
    heap = [[w, s] for s, w in freqs.items()]
    heapq.heapify(heap)
    while len(heap)>1:
        w1, t1 = heapq.heappop(heap)
        w2, t2 = heapq.heappop(heap)
        heapq.heappush(heap, [w1+w2, [t1, t2]])
    return heap[0]
```

---

## 동적 계획법(DP)

### 탑다운 vs 보텀업

- **메모이제이션(탑다운)**: 재귀 + 캐시.
- **테이블(보텀업)**: 작은 문제부터 순서대로.

#### 피보나치

```python
# 탑다운

from functools import lru_cache
@lru_cache(None)
def fib(n):
    if n<2: return n
    return fib(n-1)+fib(n-2)

# 보텀업

def fib_bottom(n):
    if n<2: return n
    a,b=0,1
    for _ in range(2,n+1):
        a,b=b,a+b
    return b
```

### — 레벤슈타인

- 상태: \(dp[i][j]\) = a[0..i), b[0..j) 최소 편집 비용.

```python
def edit_distance(a, b):
    n, m = len(a), len(b)
    dp = [[0]*(m+1) for _ in range(n+1)]
    for i in range(n+1): dp[i][0]=i
    for j in range(m+1): dp[0][j]=j
    for i in range(1, n+1):
        for j in range(1, m+1):
            cost = 0 if a[i-1]==b[j-1] else 1
            dp[i][j] = min(dp[i-1][j]+1, dp[i][j-1]+1, dp[i-1][j-1]+cost)
    return dp[n][m]
```

### 0/1 배낭

```python
def knapsack_01(W, wt, val):
    n=len(wt)
    dp=[0]*(W+1)
    for i in range(n):
        for w in range(W, wt[i]-1, -1):
            dp[w]=max(dp[w], dp[w-wt[i]]+val[i])
    return dp[W]
```

### — DP + 이분탐색

```python
import bisect
def lis(a):
    d=[]
    for x in a:
        i=bisect.bisect_left(d, x)
        if i==len(d): d.append(x)
        else: d[i]=x
    return len(d)
```

### DP 최적화 힌트

- **Convex Hull Trick, Divide & Conquer, Knuth** 최적화 등 전개(명세 생략 없이 키워드만 제시).

---

## 백트래킹(Backtracking)과 가지치기

### N-Queen

```python
def nqueen(n):
    cols=set(); diag1=set(); diag2=set()
    board=[-1]*n; sol=[]
    def dfs(r):
        if r==n:
            sol.append(board.copy()); return
        for c in range(n):
            if (c in cols) or (r-c in diag1) or (r+c in diag2):
                continue
            cols.add(c); diag1.add(r-c); diag2.add(r+c)
            board[r]=c
            dfs(r+1)
            cols.remove(c); diag1.remove(r-c); diag2.remove(r+c)
    dfs(0)
    return sol
```

- **가지치기**로 비유효 분기 제거 → 실전 성능 비약적 향상.
- **Branch & Bound**: 상한/하한으로 탐색 순서와 가지치기 결정.

---

## 그래프 알고리즘

### 표현

- 희소 그래프: **인접 리스트**, 조밀: **인접 행렬**.
- 방향성, 가중치 유무에 따른 선택.

### BFS/DFS

- BFS: 최단 간선 수.
- DFS: 위상정렬(방향 비순환 그래프), 사이클 탐지, 연결요소.

```python
from collections import deque
def bfs(adj, s):
    n=len(adj); dist=[-1]*n
    q=deque([s]); dist[s]=0
    while q:
        u=q.popleft()
        for v in adj[u]:
            if dist[v]==-1:
                dist[v]=dist[u]+1; q.append(v)
    return dist
```

### 위상정렬(Kahn)

```python
from collections import deque
def topo_kahn(n, edges):
    indeg=[0]*n; adj=[[] for _ in range(n)]
    for u,v in edges: adj[u].append(v); indeg[v]+=1
    q=deque([i for i in range(n) if indeg[i]==0])
    order=[]
    while q:
        u=q.popleft(); order.append(u)
        for v in adj[u]:
            indeg[v]-=1
            if indeg[v]==0: q.append(v)
    if len(order)<n: raise ValueError("cycle")
    return order
```

### SCC (Tarjan)

- 한 번의 DFS로 모든 **강연결요소**.

```python
def scc_tarjan(adj):
    n=len(adj); idx=0
    ids=[-1]*n; low=[0]*n; on=[False]*n; st=[]
    res=[]
    def dfs(u):
        nonlocal idx
        ids[u]=low[u]=idx; idx+=1
        st.append(u); on[u]=True
        for v in adj[u]:
            if ids[v]==-1:
                dfs(v); low[u]=min(low[u], low[v])
            elif on[v]:
                low[u]=min(low[u], ids[v])
        if low[u]==ids[u]:
            comp=[]
            while True:
                w=st.pop(); on[w]=False
                comp.append(w)
                if w==u: break
            res.append(comp)
    for i in range(n):
        if ids[i]==-1: dfs(i)
    return res
```

### 최단경로

- **Dijkstra(비음수 가중치)**: 힙 사용.
```python
import heapq
def dijkstra(adj, s):
    # adj: list of list[(v, w)]
    n=len(adj); INF=10**18
    dist=[INF]*n; dist[s]=0
    pq=[(0,s)]
    while pq:
        d,u=heapq.heappop(pq)
        if d!=dist[u]: continue
        for v,w in adj[u]:
            nd=d+w
            if nd<dist[v]:
                dist[v]=nd
                heapq.heappush(pq, (nd,v))
    return dist
```

- **Bellman-Ford**: 음수 가중치 허용, 음수 사이클 탐지.
- **Floyd-Warshall**: 모든 쌍 최단경로 \(O(n^3)\).

### 최소신장트리(MST)

- **Kruskal**: 간선 가중치 오름차순 + Union-Find.
```python
def kruskal(n, edges):
    # edges: (w,u,v)
    parent=list(range(n)); rank=[0]*n
    def find(x):
        if parent[x]!=x: parent[x]=find(parent[x])
        return parent[x]
    def unite(a,b):
        a,b=find(a),find(b)
        if a==b: return False
        if rank[a]<rank[b]: a,b=b,a
        parent[b]=a
        if rank[a]==rank[b]: rank[a]+=1
        return True
    edges.sort()
    total=0; cnt=0
    for w,u,v in edges:
        if unite(u,v):
            total+=w; cnt+=1
            if cnt==n-1: break
    return total
```

- **Prim**: 힙으로 인접 정점 확장. 희소/밀집에 따라 선택.

### 최대 유량/매칭 — 고급 개요

- **Edmonds–Karp**(BFS on residual): \(O(VE^2)\).
- **Dinic**: 레벨 그래프 + 블로킹 플로우, 빠름.
- **Bipartite Matching**: Hopcroft–Karp \(O(E\sqrt{V})\).

---

## 확률·무작위화(Randomization)

### 랜덤 퀵정렬 기대 시간

- 기대 \(O(n\log n)\). 모든 입력에서 동일 기대 성능.

### 해싱

- 균등 분포 가정 시 평균 \(O(1)\) 검색/삽입.
- 충돌 해소: 체이닝/개방 주소법.

```python
# 파이썬 dict는 체인/오픈해싱의 하이브리드가 아님(구현특화).

freq={}
for x in [1,2,1,3,2,1]:
    freq[x]=freq.get(x,0)+1
```

### 몬테카를로 vs 라스베가스

- **몬테카를로**: 항상 빠름, 오답 확률 \(\epsilon\).
- **라스베가스**: 항상 정답, 기대 시간 상계.

---

## 복잡도 이론 개요

- **P**: 다항시간 결정 문제.
- **NP**: **검증**이 다항시간.
- **NP-완전**: NP에 속하고, NP의 모든 문제로부터 다항환원 가능.
- 최소 컷–최대 유량, 매칭은 다항; **SAT, 3-SAT, TSP(의사결정형)**는 NP-완전.

---

## 정확성 증명 도구 — 실전 템플릿

### 루프 불변식 체크리스트

1) 초기화: 진입 전 참
2) 유지: 반복 중 보존
3) 종료: 더 이상 반복 불가 → 목표 성립

예: 삽입 정렬 내부 while의 불변식
- “배열 \(a[0..j]\)는 항상 정렬돼 있고, 모든 원소는 `key`보다 작거나 같음.”

### 교환 논증(탐욕 정당화)

- 최적해를 “탐욕선택을 포함하는 최적해”로 교환 가능함을 보인다.

### 귀납(재귀 정당화)

- 작은 문제에서 성립한다고 가정 → 합치면 큰 문제에서도 성립.

---

## 캐시·데이터 지역성·실전 속도

- **연속 메모리**(배열) 선호, **Strided Access** 피하기.
- **분기 예측**: 데이터 의존 분기 최소화(예: 분할 시 branchless 비교 기법).
- **배치/벡터화**: NumPy/BLAS 활용, CPU SIMD.

---

## 각 유형별 “현업” 체크리스트

- **탐색**: 정렬 여부? 중복 처리? 상·하한 필요?
- **정렬**: 안정성/제자리/최악 보장/외부정렬 여부?
- **분할정복**: 입력이 매우 크면 재귀 깊이/스택 제한?
- **탐욕**: 교환 논증·매트로이드 조건 확인?
- **DP**: 상태 정의, 전이, 초기값, 순서, 메모리 축소.
- **백트래킹**: 가지치기 함수, 상·하한, 순서 휴리스틱.
- **그래프**: 표현(리스트/행렬), 음수 간선, 사이클, DAG 여부, 연결성.
- **확률화**: 실패 확률 허용? 시드/재현성 필요?

---

## 종합 예제 시나리오 — “작업 스케줄러” 설계

**요구**:
- n개의 작업, 각 작업은 (시작, 종료, 보상), 겹치면 안 됨.
- 최대 총 보상을 구하라.

### 접근 탐색

- **탐욕**: 종료 시간 기준 선택은 “개수 최대화”엔 최적이지만, **보상 합** 최대엔 실패.
- **DP (Weighted Interval Scheduling)**가 정답.

### DP 설계

- 작업을 종료시간 오름차순으로 정렬.
- \(p(j)\): j번째 작업과 **겹치지 않는** 마지막 작업의 인덱스(이분탐색).
- 점화:
  $$
  opt(j) = \max\{ opt(j-1),\ w_j + opt(p(j)) \}
  $$
- 전체 답: \(opt(n)\).

```python
import bisect

def max_reward_nonoverlap(jobs):
    # jobs: [(s,e,w)]
    jobs = sorted(jobs, key=lambda x: x[1])
    starts=[s for s,_,_ in jobs]
    ends  =[e for _,e,_ in jobs]
    w     =[w for _,_,w in jobs]
    n=len(jobs)
    p=[-1]*n
    for j in range(n):
        i = bisect.bisect_right(ends, jobs[j][0]-1)-1
        p[j]=i
    dp=[0]*(n+1)
    for j in range(1, n+1):
        dp[j]=max(dp[j-1], w[j-1] + (dp[p[j-1]+1] if p[j-1]>=0 else 0))
    return dp[n]
```

**설명**:
- \(p(j)\)는 \(O(\log n)\) 이분탐색으로 전처리. 전체 \(O(n\log n)\).
- 루프 불변식: `dp[j]`는 jobs[0..j-1]까지 고려한 최적 값.

---

## 추가 실전 예제 묶음

### 문자열: KMP(부분일치 테이블)

- 전처리 \(O(m)\), 검색 \(O(n)\).

```python
def kmp_table(p):
    m=len(p); lps=[0]*m
    k=0
    for i in range(1,m):
        while k>0 and p[k]!=p[i]:
            k=lps[k-1]
        if p[k]==p[i]: k+=1; lps[i]=k
    return lps

def kmp_search(s, p):
    lps=kmp_table(p)
    i=j=0; res=[]
    while i<len(s):
        if s[i]==p[j]:
            i+=1; j+=1
            if j==len(p):
                res.append(i-j); j=lps[j-1]
        elif j>0:
            j=lps[j-1]
        else:
            i+=1
    return res
```

### 트라이(Trie)와 해시

- 접두검색/사전 매칭 → 트라이.
- 키-값 빈도/중복 처리 → 해시맵.

```python
class Trie:
    def __init__(self): self.n={}
    def insert(self, w):
        cur=self.n
        for ch in w: cur=cur.setdefault(ch,{})
        cur['$']=True
    def search(self, w):
        cur=self.n
        for ch in w:
            if ch not in cur: return False
            cur=cur[ch]
        return '$' in cur
```

### 슬라이딩 윈도우(투 포인터)

- 고정/가변 길이 구간 최적화에 강력.

```python
def min_subarray_len(target, a):
    import math
    n=len(a); s=0; ans=math.inf
    left=0
    for right,x in enumerate(a):
        s+=x
        while s>=target:
            ans=min(ans, right-left+1)
            s-=a[left]; left+=1
    return 0 if ans==math.inf else ans
```

---

## 테스트·검증·벤치마크

- 단위 테스트: 경계·빈 입력·중복·음수·극값.
- **어설션/불변식**을 코드에 주석으로라도 기록.
- 입력 크기 늘려가며 **성능 곡선** 관찰.
- 난수·적대적 입력(퀵정렬 피벗 고정) 포함.

---

## 요약 및 다음 학습 경로

- **정의·특징·성능**의 기본을 명확히: Big-O의 수학적 뜻, 모델 전제.
- **유형별 핵심 아이디어와 정당성 도구**(불변식·교환 논증·귀납)가 실전 품질을 좌우.
- **자료구조 선택**이 복잡도를 바꾼다.
- 다음: 고급 그래프(최대유량/매칭/스펙트럴), DP 최적화, 근사/온라인/분산 알고리즘, 외부메모리 모델.

---

# 부록 A. 경계/실전 체크리스트(요약판)

- 정렬 전제? 중복 처리? overflow?
- 음수 간선? DAG 여부? 그래프 표현 선택?
- DP 상태 차원 축소 여지? 전이 순서? 초기화?
- 탐욕 정당화 완료? 반례 없음?
- 캐시 지역성, 메모리 할당/해제 비용, GC 영향?
- 난수 시드·재현성, 최악 입력 보호(랜덤 피벗 등)?

---

# 부록 B. 수식 예시와 증명 스케치

## B.1 비교 정렬 하한

$$
\text{결정트리 높이} \ge \log_2(n!) = \Theta(n\log n)
$$

스털링 근사:
$$
\log(n!) = n\log n - n + \Theta(\log n)
$$

따라서 최악 시간은 \(\Omega(n\log n)\).

## B.2 이진 탐색 정확성

귀납적 구간 축소: 각 단계에서 탐색 구간이 절반 이하로 감소. 종료 시 구간 공집합이면 부재.

---

# 부록 C. 추가 코드 스니펫 모음

## — 이진 탐색 변형

```python
def lower_bound(a, x):
    lo, hi = 0, len(a)
    while lo < hi:
        mid = (lo+hi)//2
        if a[mid] < x: lo = mid+1
        else: hi = mid
    return lo

def upper_bound(a, x):
    lo, hi = 0, len(a)
    while lo < hi:
        mid = (lo+hi)//2
        if a[mid] <= x: lo = mid+1
        else: hi = mid
    return lo
```

## C.2 Prim MST (힙)

```python
import heapq

def prim(n, adj):
    # adj[u] = [(v,w), ...]
    used=[False]*n
    pq=[(0,0)]; total=0; cnt=0
    while pq and cnt<n:
        w,u=heapq.heappop(pq)
        if used[u]: continue
        used[u]=True; total+=w; cnt+=1
        for v,ww in adj[u]:
            if not used[v]:
                heapq.heappush(pq, (ww, v))
    if cnt<n: raise ValueError("disconnected")
    return total
```

## C.3 Dinic 골격(의사코드)

```text
while BFS level graph exists:
    while blocking flow augmentable:
        send flow along DFS with ptr[] optimization
```
