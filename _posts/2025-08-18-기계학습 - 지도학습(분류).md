---
layout: post
title: 기계학습 - 지도학습(분류)
date: 2025-08-18 19:25:23 +0900
category: 기계학습
---
# 지도학습(분류, Classification)

## 분류 문제 정식화

### 정의와 표기

- 입력 특징 벡터 \( \mathbf{x}\in\mathbb{R}^d \), 레이블 \( y\in\{C_1,\dots,C_K\} \).
- 학습의 목표:
$$
\hat{f}=\arg\min_{f\in\mathcal{F}}\; \mathbb{E}_{(\mathbf{x},y)\sim \mathcal{D}} \big[\ell\big(y, f(\mathbf{x})\big)\big]
$$
경험적 위험 최소화(ERM)로 훈련 셋 \( \{(\mathbf{x}_i,y_i)\}_{i=1}^n \)에서
$$
\hat{f}=\arg\min_{f\in\mathcal{F}}\; \frac{1}{n}\sum_{i=1}^{n}\ell\big(y_i,f(\mathbf{x}_i)\big) + \lambda\Omega(f)
$$
- \(\ell\): 손실 함수(예: 크로스 엔트로피, 힌지).
- \(\Omega\): 정규화(예: \(L_1,L_2\)).

### 회귀 vs 분류 (요약 표)

| 구분 | 회귀 | 분류 |
|---|---|---|
| 출력 | 연속값 | 이산 클래스(이진/다중/다중레이블) |
| 대표 손실 | MSE, MAE | 크로스 엔트로피, 힌지, 포컬 |
| 대표 지표 | RMSE, \(R^2\) | Accuracy, Precision/Recall/F1, ROC-AUC, PR-AUC |
| 임계값 | 불필요 | **필요**(점수→클래스 매핑) |

---

## 점수(score)·확률(probability)·결정(decision)

### 점수와 확률

많은 분류기는 **점수 함수** \( s_k(\mathbf{x}) \)를 산출하고, softmax로 확률화:
$$
P(y=k\mid \mathbf{x})=\frac{e^{s_k(\mathbf{x})}}{\sum_{j=1}^{K}e^{s_j(\mathbf{x})}}
$$
이진( \(K=2\) )이면 시그모이드:
$$
\sigma(z)=\frac{1}{1+e^{-z}},\quad P(y=1\mid \mathbf{x})=\sigma\big(\mathbf{w}^\top\mathbf{x}+b\big)
$$

### 임계값 기반 의사결정

- 기본 임계값 \(t=0.5\) (균등 비용/사전확률 가정).
- 비용민감/불균형이면 \(t\neq0.5\) 로 조정(§7).

---

## 손실 함수(이진·다중)와 학습

### 크로스 엔트로피(CE)

- 이진:
$$
\mathcal{L}_{\text{BCE}} = -\frac{1}{n}\sum_{i=1}^{n}\Big[y_i\log \hat{p}_i + (1-y_i)\log(1-\hat{p}_i)\Big]
$$
- 다중(원-핫 \( \mathbf{y}_i\)):
$$
\mathcal{L}_{\text{CE}} = -\frac{1}{n}\sum_{i=1}^{n}\sum_{k=1}^{K} y_{i,k}\log \hat{p}_{i,k}
$$

### 힌지 손실(SVM)

$$
\mathcal{L}_{\text{hinge}}=\frac{1}{n}\sum_{i=1}^n \max\big(0,1-y_i\cdot \hat{g}_i\big)
$$
- \(\hat{g}_i\): 마진 점수(선형 분류기 \( \mathbf{w}^\top\mathbf{x}+b\)).

### 포컬 손실(불균형/난샘플 가중)

$$
\mathcal{L}_{\text{focal}} = -\frac{1}{n}\sum_i (1-\hat{p}_{i,y_i})^\gamma \log \hat{p}_{i,y_i},\ \ \gamma>0
$$

### 정규화(릿지/라쏘/엘라스틱넷)

$$
\min_\theta \ \mathcal{L}(\theta) + \lambda\underbrace{\big(\alpha\|\theta\|_1+(1-\alpha)\|\theta\|_2^2\big)}_{\text{Elastic Net}}
$$

---

## 대표 분류 알고리즘 한눈에

| 알고리즘 | 핵심 아이디어 | 장점 | 단점 | 주요 하이퍼파라미터 |
|---|---|---|---|---|
| 로지스틱 회귀 | 선형 결정경계 + CE | 단순/해석 용이 | 비선형 한계 | \(C\), penalty(L1/L2) |
| KNN | 근접 이웃 다수결/평균 | 비모수/직관 | 예측 느림/스케일 민감 | \(K\), 거리척도 |
| SVM | 마진 최대화(+커널) | 고차원 강함 | 대규모 느림 | \(C\), \(\gamma\), 커널 |
| 결정트리 | 지니/엔트로피로 분할 | 해석 용이 | 과적합 | 깊이, min_samples_* |
| 랜덤 포레스트 | 배깅+무작위특징 | 성능/안정 | 큰 모델 | n_estimators, max_features |
| GBDT(Gradient Boosting) | 순차적 잔차 보정 | 고성능 | 파라미터 많음 | learning_rate, depth, n_estimators |
| 나이브 베이즈 | 조건부 독립 가정 | 빠름/희소텍스트 강함 | 강한 가정 | 스무딩 \(\alpha\) |
| 신경망(MLP) | 비선형 표현 | 유연 | 데이터/자원 요구 | 층/뉴런, 활성, 정규화 |

---

## 성능평가: 혼동행렬·정밀도/재현율·ROC/PR

### 혼동행렬(이진)

| | 예측:양성 | 예측:음성 |
|---|---:|---:|
| 실제:양성 | \(TP\) | \(FN\) |
| 실제:음성 | \(FP\) | \(TN\) |

- Accuracy: \( \frac{TP+TN}{TP+FP+TN+FN} \)
- Precision: \( \frac{TP}{TP+FP} \)
- Recall: \( \frac{TP}{TP+FN} \)
- F1: \( 2\cdot \frac{PR}{P+R} \)

### ROC vs PR

- ROC-AUC: TPR vs FPR 면적, 클래스 비율 변화에 비교적 둔감.
- PR-AUC: 양성희소/불균형에서 **더 정보량 큼**.

### 다중분류 평균 방식

- **Macro**: 클래스별 지표 평균(클래스 균등 가중).
- **Micro**: 전 샘플 집계(빈도 가중).
- **Weighted**: 클래스별 샘플수 가중 평균.

---

## 임계값 조정·확률 보정·비용민감 결정

### 임계값 최적화

- F1, Youden’s J(ROC), 특정 비용 행렬 최소화 기준으로 \(t\) 탐색.

### 비용민감 결정

- 양성 예측 임계값:
$$
t^\star = \frac{C_{\text{FP}}\,P(y=0)}{C_{\text{FN}}\,P(y=1)+C_{\text{FP}}\,P(y=0)}
$$

### 확률 보정(calibration)

- Platt scaling(시그모이드), Isotonic regression.
- 교정 전/후 Brier score, Reliability curve 점검.

---

## 클래스 불균형 대응

- **데이터 측면**: Random Under/Over-sampling, SMOTE류.
- **모델 측면**: `class_weight='balanced'`, 비용가중, 포컬 손실.
- **지표**: PR-AUC, G-mean, Balanced Accuracy \(=\frac{TPR+TNR}{2}\).

---

## 다중분류 & 다중레이블

### 다중분류

- OvR(One-vs-Rest), OvO(One-vs-One), 본질적 다중(softmax).
- 지표: macro/micro/weighted F1, Top-k accuracy.

### 다중레이블

- 각 레이블 독립 시그모이드(이진화): Binary Relevance(OneVsRest).
- 지표: Subset accuracy(엄격), Hamming loss, micro/macro F1.

---

## 전처리·스케일링·파이프라인·교차검증

- **스케일링**: SVM/KNN/로지스틱/NN 필수(표준화 권장).
- **파이프라인**: 누수 방지(훈련 폴드에서만 fit→전 구간 transform).
- **교차검증**: StratifiedKFold(층화), 시계열은 TimeSeriesSplit.
- **특징공학**: 다항특징, 카테고리 인코딩(one-hot/target), TF-IDF.

---

## 해석가능성 & 오류분석

- 선형계수/정규화경로(L1)로 변수선택 해석.
- 트리기반: Gini importance, Permutation importance 권장.
- SHAP/LIME로 국소 설명.
- **오류분석**: 혼동행렬 상의 체계적 오분류, Partial Dependence/ICE로 경향 파악.

---

## 실전 코드 모음 (scikit-learn)

### 기본 이진 분류 파이프라인 + 층화 CV + 지표

```python
import numpy as np
from sklearn.datasets import make_classification
from sklearn.model_selection import StratifiedKFold, cross_validate
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import make_scorer, f1_score, roc_auc_score, average_precision_score

X, y = make_classification(n_samples=4000, n_features=30, n_informative=8,
                           class_sep=1.2, weights=[0.8, 0.2], random_state=7)

pipe = Pipeline([
    ("scaler", StandardScaler()),
    ("clf", LogisticRegression(max_iter=200, class_weight="balanced"))
])

scoring = {
    "f1": make_scorer(f1_score),
    "roc_auc": make_scorer(roc_auc_score, needs_threshold=True),
    "pr_auc": make_scorer(average_precision_score, needs_threshold=True)
}

cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=7)
res = cross_validate(pipe, X, y, scoring=scoring, cv=cv, return_train_score=False)
print({k: np.mean(v) for k, v in res.items() if k.startswith("test_")})
```

### RBF-SVM 그리드서치 + 임계값 튜닝 + 혼동행렬

```python
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.svm import SVC
from sklearn.metrics import confusion_matrix, classification_report, precision_recall_curve

Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=0.25, stratify=y, random_state=7)

pipe = Pipeline([
    ("scaler", StandardScaler()),
    ("svc", SVC(kernel="rbf", probability=True))  # 확률 필요시
])

param = {
    "svc__C": [0.5, 1, 5, 10],
    "svc__gamma": ["scale", 0.1, 0.5, 1.0]
}
gs = GridSearchCV(pipe, param, cv=5, scoring="average_precision", n_jobs=-1)
gs.fit(Xtr, ytr)
print("Best:", gs.best_params_)

# 임계값 조정(최대 F1)

proba = gs.predict_proba(Xte)[:, 1]
prec, rec, thr = precision_recall_curve(yte, proba)
f1 = 2 * (prec * rec) / (prec + rec + 1e-12)
t_star = thr[np.argmax(f1[:-1])]
yp = (proba >= t_star).astype(int)

print("Threshold*", t_star)
print(confusion_matrix(yte, yp))
print(classification_report(yte, yp, digits=4))
```

### 확률 보정(Platt vs Isotonic) 비교

```python
from sklearn.calibration import CalibratedClassifierCV, calibration_curve
from sklearn.metrics import brier_score_loss, log_loss

base = Pipeline([("scaler", StandardScaler()), ("svc", SVC(kernel="rbf", C=5, gamma="scale"))])
platt = Pipeline([("scaler", StandardScaler()), ("svc", SVC(kernel="rbf", C=5, gamma="scale", probability=True))])
isot = CalibratedClassifierCV(base, method="isotonic", cv=5)

isot.fit(Xtr, ytr)
platt.fit(Xtr, ytr)

p_is = isot.predict_proba(Xte)[:, 1]
p_pl = platt.predict_proba(Xte)[:, 1]
print("Brier (Isotonic, Platt):", brier_score_loss(yte, p_is), brier_score_loss(yte, p_pl))
print("LogLoss (Isotonic, Platt):", log_loss(yte, p_is), log_loss(yte, p_pl))
```

### 불균형: class_weight vs SMOTE (파이프라인)

```python
from sklearn.metrics import balanced_accuracy_score
from imblearn.pipeline import Pipeline as ImbPipeline
from imblearn.over_sampling import SMOTE
from sklearn.ensemble import RandomForestClassifier

Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=0.3, stratify=y, random_state=7)

# 방법1: class_weight

rf1 = RandomForestClassifier(n_estimators=400, class_weight="balanced_subsample", random_state=7)
rf1.fit(Xtr, ytr)
yp1 = rf1.predict(Xte)
print("Balanced Acc (cw):", balanced_accuracy_score(yte, yp1))

# 방법2: SMOTE + RF (훈련 폴드 내합성)

pipe = ImbPipeline([
    ("scaler", StandardScaler(with_mean=False)),  # 트리에선 불필요, 선형/커널용 예시
    ("smote", SMOTE(random_state=7)),
    ("rf", RandomForestClassifier(n_estimators=400, random_state=7))
])
pipe.fit(Xtr, ytr)
yp2 = pipe.predict(Xte)
print("Balanced Acc (SMOTE):", balanced_accuracy_score(yte, yp2))
```

### 다중분류와 평균 방식

```python
from sklearn.datasets import load_digits
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import f1_score

digits = load_digits()
Xd, yd = digits.data, digits.target
Xd_tr, Xd_te, yd_tr, yd_te = train_test_split(Xd, yd, test_size=0.25, stratify=yd, random_state=0)

clf = Pipeline([("scaler", StandardScaler()), ("lr", LogisticRegression(max_iter=500, multi_class="ovr"))])
clf.fit(Xd_tr, yd_tr)
yp = clf.predict(Xd_te)

print("Macro-F1:", f1_score(yd_te, yp, average="macro"))
print("Micro-F1:", f1_score(yd_te, yp, average="micro"))
```

### 다중레이블(One-vs-Rest) 예시

```python
from sklearn.datasets import make_multilabel_classification
from sklearn.multiclass import OneVsRestClassifier
from sklearn.metrics import f1_score
from sklearn.naive_bayes import GaussianNB

Xm, ym = make_multilabel_classification(n_samples=2000, n_features=50, n_classes=6,
                                        n_labels=2, allow_unlabeled=False, random_state=0)
Xm_tr, Xm_te, ym_tr, ym_te = train_test_split(Xm, ym, test_size=0.25, random_state=0)

ovr = OneVsRestClassifier(GaussianNB())
ovr.fit(Xm_tr, ym_tr)
yph = ovr.predict(Xm_te)
print("Micro-F1 (multilabel):", f1_score(ym_te, yph, average="micro"))
```

### 텍스트 분류 파이프라인(TF-IDF + 로지스틱)

```python
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.pipeline import Pipeline
from sklearn.model_selection import cross_val_score

texts = [
    "무료 쿠폰 지금 수령하세요", "할인 행사 진행 중", "회의록 공유드립니다",
    "점심미팅 일정 확인", "대출 한도 안내", "스팸 의심 메일"
]
labels = [1,1,0,0,1,1]  # 1=스팸(예시)

pipe = Pipeline([
    ("tfidf", TfidfVectorizer(ngram_range=(1,2), min_df=1)),
    ("clf", LogisticRegression(max_iter=500, class_weight="balanced"))
])
print("CV F1:", cross_val_score(pipe, texts, labels, cv=3, scoring="f1").mean())
```

> 주의: 외부 패키지 설치가 어려운 환경이면 SMOTE 등 imblearn 예제는 제외 가능.
> 그림/차트가 필요하면 ROC/PR 커브는 `matplotlib`로 한 장씩 단색 기본 스타일로 그릴 것.

---

## 체크리스트(실무 집중)

1. **데이터 분할**: Train/Valid/Test, 층화, 누수 방지.
2. **전처리**: 스케일링, 인코딩, 결측/이상치, 누수 방지 파이프라인.
3. **알고리즘/하이퍼파라미터**: 단순→복잡 순서, 그리드/랜덤/베이즈탐색.
4. **지표 설정**: 비즈니스 비용에 맞는 지표(예: PR-AUC, Recall@t).
5. **임계값/보정**: 목적 지표 최대화 임계값, 확률 보정(Brier/리라이어빌리티).
6. **불균형**: class_weight/샘플링/포컬/데이터 수집.
7. **해석**: 중요도/SHAP, 편향 여부, 데이터 드리프트 모니터링.
8. **오류분석**: 혼동행렬, 에지케이스 수집, 능동학습 루프.

---

## 요약

- 분류는 **점수/확률→임계값**을 통해 클래스로 매핑하는 문제이며, 손실(CE/힌지) 최소화와 정규화로 학습한다.
- 알고리즘 간 성능 차이는 **데이터 특성/전처리/지표/튜닝**에 크게 좌우된다.
- **불균형·비용민감·확률보정·임계값 최적화**가 실전 성능의 핵심 레버다.
- 파이프라인/층화CV/적합한 지표/오류분석/해석가능성을 반드시 포함하라.
