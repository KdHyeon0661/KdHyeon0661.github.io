---
layout: post
title: 기계학습 - 통계와 확률 기초
date: 2025-08-14 17:20:23 +0900
category: 기계학습
---
# 통계와 확률 기초

머신 러닝의 핵심은 **데이터에서 패턴을 찾아내고, 이를 바탕으로 예측을 수행하는 것**입니다.  
이 과정에서 **통계와 확률**은 데이터 해석, 모델 설계, 결과 평가의 기초가 됩니다.

---

## 1. 통계학(Statistics) 기초

통계학은 **데이터를 수집, 정리, 분석, 해석하는 학문**입니다.  
머신 러닝에서는 통계 지식이 다음과 같이 활용됩니다.

### (1) 기술 통계(Descriptive Statistics)
- 데이터의 주요 특성을 **요약·설명**하는 방법
- **중심 경향성(Central Tendency)**
  - **평균(Mean)**:
    $$
    \bar{x} = \frac{\sum_{i=1}^{n} x_i}{n}
    $$
  - **중앙값(Median)**: 데이터를 크기순으로 나열했을 때 중앙에 위치하는 값
  - **최빈값(Mode)**: 가장 자주 등장하는 값
- **산포도(Dispersion)** — 데이터의 흩어짐 정도
  - 분산(Variance):
    $$
    s^2 = \frac{\sum_{i=1}^{n} (x_i - \bar{x})^2}{n}
    $$
  - 표준편차(Standard Deviation):
    $$
    s = \sqrt{s^2}
    $$
  - 범위(Range) = 최대값 − 최소값
  - 사분위 범위(IQR) = Q3 − Q1

---

### (2) 추론 통계(Inferential Statistics)
- **표본(sample)**에서 얻은 정보를 바탕으로 **모집단(population)**을 추정하거나 가설 검정
- 예시:
  - 평균 키를 표본으로 측정 → 모집단 평균 추정
  - A/B 테스트: 두 버전의 전환율 차이가 유의미한지 검증

---

### (3) 상관관계(Correlation)
- 두 변수 간의 선형 관계를 측정
- 피어슨 상관계수(Pearson Correlation Coefficient):
  $$
  r = \frac{\sum_{i=1}^n (x_i - \bar{x})(y_i - \bar{y})}{\sqrt{\sum_{i=1}^n (x_i - \bar{x})^2} \cdot \sqrt{\sum_{i=1}^n (y_i - \bar{y})^2}}
  $$
- **r 해석**:
  - \( r \approx 1 \): 강한 양의 상관
  - \( r \approx -1 \): 강한 음의 상관
  - \( r \approx 0 \): 상관 없음
- 주의: 상관관계 ≠ 인과관계

---

## 2. 확률(Probability) 기초

확률은 **어떤 사건이 일어날 가능성을 0~1 사이의 값으로 표현**한 것입니다.

### (1) 기본 용어
- **시행(Trial)**: 실험 또는 관찰 1회
- **표본공간(Sample Space, \( S \))**: 가능한 모든 결과의 집합
- **사건(Event)**: 표본공간의 부분집합
- **확률(Probability)**:
  $$
  P(A) = \frac{\text{사건 A가 일어나는 경우의 수}}{\text{모든 경우의 수}}
  $$

---

### (2) 확률의 성질
1. \( 0 \le P(A) \le 1 \)
2. \( P(S) = 1 \)  (전체 사건 확률은 1)
3. 여사건(Complement):
   $$
   P(A^c) = 1 - P(A)
   $$
4. 서로 배반(Disjoint) 사건:
   $$
   P(A \cup B) = P(A) + P(B) \quad \text{if } A \cap B = \emptyset
   $$

---

### (3) 조건부 확률(Conditional Probability)
- 사건 B가 일어났다는 조건에서 사건 A가 일어날 확률
  $$
  P(A|B) = \frac{P(A \cap B)}{P(B)}
  $$

---

### (4) 독립 사건(Independence)
- 사건 A와 B가 독립이면:
  $$
  P(A \cap B) = P(A) \cdot P(B)
  $$

---

### (5) 베이즈 정리(Bayes' Theorem)
- 사후 확률을 구하는 데 사용
  $$
  P(A|B) = \frac{P(B|A) \cdot P(A)}{P(B)}
  $$
- 예시: 의료 진단, 스팸 필터

---

## 3. 확률 분포(Probability Distribution)

확률 분포는 데이터의 발생 패턴을 수학적으로 모델링합니다.

### (1) 이산형 확률 분포
- **베르누이 분포(Bernoulli)**:
  - 성공(1) 또는 실패(0) 확률
  - \( P(X=1) = p, \quad P(X=0) = 1-p \)
- **이항 분포(Binomial)**:
  - n번의 독립 시행에서 성공 횟수
  - \( P(X=k) = {n \choose k} p^k (1-p)^{n-k} \)
- **포아송 분포(Poisson)**:
  - 일정 시간/공간 내 발생 횟수

### (2) 연속형 확률 분포
- **정규분포(Normal Distribution)**:
  - 평균 \(\mu\), 표준편차 \(\sigma\)
  - 확률밀도함수:
    $$
    f(x) = \frac{1}{\sigma \sqrt{2\pi}} e^{ -\frac{(x - \mu)^2}{2\sigma^2} }
    $$
- **균등분포(Uniform)**:
  - 모든 값이 같은 확률
- **지수분포(Exponential)**:
  - 사건 간 시간 모델링

---

## 4. 머신 러닝에서 통계·확률이 중요한 이유

1. **데이터 이해**
   - 평균, 분산, 분포 형태를 파악하면 데이터 전처리 전략 수립 가능
2. **모델 가정 이해**
   - 예: 선형 회귀는 오차가 정규분포를 따른다고 가정
3. **평가 지표 해석**
   - ROC-AUC, p-value 등 확률 기반 해석 필요
4. **베이즈 추론**
   - 스팸 메일 분류, 의학 진단에서 조건부 확률 활용
5. **불확실성 추정**
   - 모델 예측의 신뢰 구간 계산

---

## 📌 정리
- **통계학**: 데이터를 요약(기술 통계)하고, 표본에서 모집단을 추론(추론 통계)
- **확률**: 사건이 발생할 가능성을 수치로 표현
- **머신 러닝**: 데이터의 확률적 성질과 통계적 분석을 기반으로 패턴을 학습

통계와 확률은 머신 러닝의 **언어**이자 **도구**로, 이를 깊이 이해하면 데이터 해석과 모델링 능력이 크게 향상됩니다.