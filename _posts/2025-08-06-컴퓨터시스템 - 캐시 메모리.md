---
layout: post
title: 컴퓨터시스템 - 캐시 메모리
date: 2025-08-06 20:20:23 +0900
category: 컴퓨터시스템
---
# 캐시 메모리(Cache Memory)

## 왜 캐시인가 — 메모리 벽과 지연/대역의 괴리

- **CPU vs DRAM**
  - CPU 파이프라인은 나노초(수 사이클)로 전진하지만 DRAM 왕복은 **수백 ns**.
  - DRAM 접근이 잦으면 파이프라인이 **memory stall**로 멈춰 **IPC**가 급락한다.
- **해법: 다단 캐시**
  - **L1**(코어 전용, 수십 KB, 1~몇 사이클), **L2**(수백 KB~MB), **L3/LLC**(소켓 공유, 수 MB~수십 MB)로
    **자주 쓰는 데이터는 가까이** 두고, 덜 쓰는 데이터는 멀리 둔다(지역성 가정).

---

## 캐시 구조 — 라인·세트·연관도·태그/인덱스/오프셋

### 캐시 라인(Cache line)

- 캐시는 **라인(블록)** 단위(관례적으로 **64바이트**)로 운반한다.
- 한 원소만 필요해도 같은 라인의 나머지가 함께 올라오므로 **공간 지역성**을 얻는 대신 **오염**(불필요 데이터)도 생길 수 있다.

### 주소 분해(Tag/Index/Offset)

```
물리주소: [........ TAG ........][ INDEX ][ OFFSET ]
                                  ↑세트 선택   ↑라인 내 바이트
세트 수 S = 캐시용량 / (라인크기 × 연관도)
```

- **INDEX**: 접근할 세트(집합)를 고른다.
- **TAG**: 세트의 각 way에 저장된 라인의 태그와 비교해 **히트/미스**를 판정.
- **OFFSET**: 라인 내부 바이트 위치.

### 연관도(associativity)와 매핑

- **직접 매핑**(1-way): 세트당 라인 1개. 단순·빠르지만 **충돌(conflict)**에 취약.
- **집합 연관**(N-way): 세트당 N개 way. 보편적 절충(예: 8-way).
- **완전 연관**: 어떤 세트에도 저장 가능(비용↑, 주로 TLB/작은 캐시에 사용).

### 교체 정책(Replacement)

- **LRU 근사(PLRU)**, **Random**, **RRIP**, **DIP** 등.
- 충돌 패턴에 민감할 수 있어 **세트 듀얼링** 등 **적응형**을 쓰기도 한다.

### 쓰기 정책(Write policy)

- **Write-back + Write-allocate**(보편): 캐시에 쓰고 **더티**로 표시, 축출 시 메모리 반영.
- **Write-through**: 매 쓰기마다 메모리에도 반영(단순/신뢰↑, 대역 소모↑).
- **No-write-allocate**: 미스에서 라인을 끌어오지 않고 바로 메모리에 씀(스트리밍에 유리).
- **비휘발(Non-temporal) 저장**: “한 번 쓰고 다시 안 볼” 데이터를 **캐시 오염 없이** DRAM으로 내보내는 힌트.

### 인클루시브(inclusive)와 배타적(exclusive)

- **Inclusive**: L3 ⊇ L2 ⊇ L1 (디버깅·일관성 용이, 용량 중복).
- **Non-inclusive/Exclusive**: 용량 효율↑, 정책 유연성↑(플랫폼별 상이).

### VIPT 인덱싱과 페이지 컬러링

- L1D는 흔히 **VIPT**(Virtually Indexed, Physically Tagged): 인덱스는 가상주소 **페이지 오프셋** 비트로, 태그는 물리주소로.
- 페이지 오프셋은 변환되지 않으므로 **TLB 의존 없이 동작**.
- 다만 **동의어(aliasing)** 문제를 피하려면 “**세트 수 × 라인크기 ≤ 페이지 크기**”가 유리하다.
- OS는 **페이지 컬러링**으로 세트 충돌을 완화할 수 있다.

---

## 캐시 동작 — 히트/미스·MSHR·프리패처

### 읽기/쓰기 히트·미스

1) 세트 선택(인덱스) → 2) way들의 **TAG 비교** → 3) 히트면 즉시 데이터 반환.
미스면 **MSHR(Line Fill Buffer)**에 요청을 발행, 하위 레벨(L2/L3/DRAM)에서 라인을 당겨와 **리필**한다.

### MLP(메모리 레벨 병렬성)와 MSHR

- MSHR 수만큼 **동시에 여러 미스**를 outstanding 가능.
- **독립 로드**를 많이 만들면(언롤·벡터화) **스톨이 겹쳐** 체감 지연 완화.

### 하드웨어 프리패처

- **스트림/스트라이드/다중 스트림** 프리패처가 선제 로드.
- 과도하면 **오염**·대역 낭비 → 플랫폼별 **Prefetch degree/거리**가 다르므로 실측 필요.

---

## 캐시 미스 분류(3C+1C)와 AMAT

### 3C(+1C) 미스

- **Compulsory**: 최초 접근(콜드).
- **Capacity**: 용량 부족으로 교체.
- **Conflict**: 특정 세트로 몰려 충돌.
- **Coherence(+1C)**: 다른 코어의 쓰기로 무효화(폴스 셰어링 포함).

### 평균 접근 시간(AMAT)

$$
\text{AMAT} = T_{L1} + m_1\Big(T_{L2} + m_2\big(T_{L3} + m_3 T_\text{Mem}\big)\Big)
$$
- 목표는 **상층 미스율 \(m_1,m_2\)**을 줄여 **기하급수적** 효과를 얻는 것.

---

## 충돌 미스의 정체 — 세트/스트라이드/색

### “같은 세트에 몰리는” 나쁜 예

- 배열 길이·스트라이드가 **세트 수의 배수**면 같은 세트에 반복 매핑 → **스래싱**.

```c
// 'stride'가 특정 세트만 두드리도록 만들면 LLC miss 폭증 가능
size_t bad_stride_sum(int *a, size_t n, size_t stride){
  size_t s=0;
  for(size_t i=0;i<n;i+=stride) s += a[i];
  return s;
}
```

**처방**:
- **패딩/오프셋** 추가, 배열 크기를 **소수/비2의 거듭제곱**으로,
- OS **페이지 컬러링** 또는 **데이터 구조 색칠**(bucket 분산).

---

## 캐시 친화적 코드 패턴 — 지역성/타일링/레이아웃

### 행-주도 vs 열-주도

```c
// 행-주도(좋음)
for (int i=0;i<N;i++)
  for (int j=0;j<N;j++)
    sum += A[i][j];

// 열-주도(스트라이드 N → 미스↑ 가능)
for (int j=0;j<N;j++)
  for (int i=0;i<N;i++)
    sum += A[i][j];
```

### 타일링(블로킹) — 재사용 극대화

```c
void saxpy_block(float *restrict y, const float *restrict x, float a, int n, int B){
  for(int ii=0; ii<n; ii+=B){
    int im = (ii+B<n)? ii+B : n;
    for(int i=ii;i<im;i++){
      float xi = x[i];              // 스칼라 치환: 한 번만 로드
      y[i] = y[i] + a * xi;
    }
  }
}
```

- 블록 크기 \(B\)는 **L1/L2 용량**과 **라인크기/연관도**를 고려해 실측으로 맞춘다.

### AoS → SoA(열지향) 전환

```c
typedef struct { float *x, *y, *z; } Vec3SoA;
void norm2_soa(Vec3SoA v, int n){
  #pragma omp simd
  for(int i=0;i<n;i++){
    float dx=v.x[i], dy=v.y[i], dz=v.z[i];
    v.x[i] = dx*dx + dy*dy + dz*dz; // 열 단위 연속 접근 → 히트율/벡터화↑
  }
}
```

### 프리패칭과 스트리밍 저장

```c
void sum_prefetch(const float *a, int n){
  float s=0;
  for (int i=0;i<n;i+=64){
    __builtin_prefetch(&a[i+256], 0, 1); // 읽기 프리패치 힌트
    for (int k=0;k<64 && i+k<n; ++k) s += a[i+k];
  }
  (void)s;
}
```
- **거리**는 DRAM 지연/루프당 사이클을 감안해 조정(플랫폼별 실측 필수).
- 큰 결과 버퍼는 **non-temporal store**(플랫폼/컴파일러 힌트)로 **오염**을 줄인다.

---

## 멀티코어 — 코히어런시와 폴스 셰어링

### MESI/MOESI 한 줄 요약

- 코어 간 같은 라인을 **공유/수정**할 때 상태 전이와 **무효화/업데이트** 트래픽 발생.

### 폴스 셰어링 방지

- 다른 스레드의 **서로 다른 변수**라도 **같은 라인**에 있으면 **무효화 폭주**.

```c
typedef struct { _Alignas(64) long v; } pad64;
static pad64 cnt[64];

void add(int tid, long x){ cnt[tid].v += x; } // 스레드별 라인 분리
long total(){ long s=0; for(int t=0;t<64;t++) s += cnt[t].v; return s; }
```

**처방**:
- **라인 패딩/정렬**, **스레드별 샤딩**, **배치 업데이트 후 머지**,
- **락 범위 축소**·읽기 다수면 **RW락**.

---

## NUMA/LLC와의 상호작용

- 멀티소켓/칩렛: **로컬 노드** 접근이 빠르고, **원격 노드**는 지연/대역 페널티.
- **First-touch**로 페이지를 스레드의 노드에 배치, 스레드/메모리 **바인딩**.

```c
#pragma omp parallel for

for (long i=0;i<n;i++) a[i]=0; // 초기화도 병렬: 각 스레드가 자기 노드에 할당
```

---

## 성능 모델과 상한 — AMAT·Roofline·MLP

### AMAT 재확인

$$
\text{AMAT} = T_{L1} + m_1\Big(T_{L2} + m_2\big(T_{L3} + m_3 T_\text{Mem}\big)\Big)
$$

### Roofline(대역 상한)

$$
\text{Perf} \le \min(\text{Peak FLOPs},\ \text{AI}\cdot \text{Peak BW}),\quad
\text{AI} = \frac{\text{FLOPs}}{\text{Bytes moved}}
$$
- **SAXPY** 예: 2 FLOP/요소, 24B 이동(8+8 read, 8 write) →
  \(\text{AI}\approx 0.083\ \text{FLOP/B}\) → **메모리 바운드**, 캐시/대역 최적화가 핵심.

### MLP(미스의 중첩)

- 독립 로드를 늘려 **동시에 outstanding**하게 만들면 체감 지연 완화.
- 포인터 추적처럼 직렬 의존이 크면 **MLP≈1**.

---

## 도구와 계측 — 무엇을 어떻게 볼 것인가

### 하드웨어 카운터(리눅스 perf 예)

```bash
# 요약 지표

perf stat -e cycles,instructions,branches,branch-misses,IPC,\
L1-dcache-loads,L1-dcache-load-misses,\
LLC-loads,LLC-load-misses,\
dTLB-loads,dTLB-load-misses,\
stalled-cycles-frontend,stalled-cycles-backend \
./app
```
- **IPC** 낮고 **LLC/dTLB miss** 높으면 **메모리 바운드**.
- **branch-misses** 높으면 **분기 병목**.
- **frontend/back-end stalled**로 파이프라인 병목 위치 감.

### 캐시 시뮬/프로파일

- `valgrind --tool=cachegrind`(라인·세트·미스 비교),
- VTune/Advisor(캐시·대역·벡터화 분석), 플레임그래프(핫패스 가시화).

---

## 사례/스니펫 — 전/후 비교

### 행렬 곱 타일링(블록 GEMM)

```c
void gemm_blocked(int n, float *restrict A, float *restrict B, float *restrict C, int Bsz){
  for(int ii=0; ii<n; ii+=Bsz)
    for(int jj=0; jj<n; jj+=Bsz)
      for(int kk=0; kk<n; kk+=Bsz){
        int im=(ii+Bsz<n)?ii+Bsz:n, jm=(jj+Bsz<n)?jj+Bsz:n, km=(kk+Bsz<n)?kk+Bsz:n;
        for(int i=ii;i<im;i++)
          for(int j=jj;j<jm;j++){
            float acc=C[i*n+j];                 // 레지스터 누적
            for(int k=kk;k<km;k++) acc+=A[i*n+k]*B[k*n+j];
            C[i*n+j]=acc;
          }
      }
}
```
- **효과**: **L1/L2 재사용 극대화**, **LLC/dTLB miss** 감소, **IPC**↑.

### SoA + 벡터화 + 스칼라 치환

```c
typedef struct { float *x,*y,*z; } V3;
float l2_sum(V3 v, int n){
  __builtin_assume_aligned(v.x,64);
  float s=0.0f;
  #pragma omp simd reduction(+:s)
  for(int i=0;i<n;i++){
    float dx=v.x[i], dy=v.y[i], dz=v.z[i];
    s += dx*dx + dy*dy + dz*dz;
  }
  return s;
}
```
- **효과**: **연속 접근 + 벡터화**로 대역 효율↑, **메모리 통과 횟수↓**.

### 함수 호출/분기 오버헤드 제거(핫루프)

```c
// before
static inline int relu(int x){ return x>0?x:0; }
for(int i=0;i<n;i++) y[i]=relu(x[i]);

// after (branchless)
for(int i=0;i<n;i++){ int m=x[i]>>31; y[i]=(x[i]^m)-m; }
```
- **효과**: 분기 예측 실패·front-end 압박 감소(컴파일러 최적화 확인 필수).

---

## 마이크로벤치 템플릿 — 측정은 이렇게

```c
#include <time.h>

double now_sec(){ struct timespec t; clock_gettime(CLOCK_MONOTONIC,&t);
                  return t.tv_sec + t.tv_nsec*1e-9; }
```

- **프로토콜**: 워밍업 → N회 반복 → **중앙값 + 95% CI**.
- **환경 고정**: CPU governor **performance**, 스레드 **핀 고정**, 동일 입력/크기.
- **보고**: `T_old → T_new (−X%)`, **IPC/미스율 변화**, 플레임그래프 전/후.

---

## 체크리스트 — 바로 적용

- [ ] **행-주도/스트라이드 1**? (언어 레이아웃과 일치)
- [ ] **타일링**으로 L1/L2에 **붙여두기**(블록 크기 실측)
- [ ] **AoS→SoA**, **정렬/패딩**(세트 충돌·폴스 셰어링 방지)
- [ ] **스칼라 치환/불변 호이스팅**으로 **중복 로드 제거**
- [ ] **프리패치/스트리밍 저장**의 **거리/정책** 검증
- [ ] **TLB/NUMA**: Huge Page, first-touch, 스레드·메모리 바인딩
- [ ] **분기 단순화/브랜치리스**, 핫루프의 **함수 호출 최소화**
- [ ] `perf`로 **IPC/LLC·dTLB miss/스톨**을 **숫자**로 확인

---

## 부록 — 수식·모델·주소 비트 직관

### AMAT

$$
\text{AMAT} = T_{L1} + m_1\Big(T_{L2} + m_2\big(T_{L3} + m_3 T_\text{Mem}\big)\Big)
$$

### 미스율 변화에 따른 시간 절감 근사

$$
\Delta T \approx \Delta m_1\!\cdot\!T_{L2\downarrow}
+ m_1\Delta m_2\!\cdot\!T_{L3\downarrow}
+ m_1 m_2\Delta m_3\!\cdot\!T_{\text{Mem}\downarrow}
$$

### 세트/인덱스 직관

- 세트 수 \(S = \frac{\text{용량}}{\text{라인} \times \text{연관도}}\).
- **INDEX 비트**가 스트라이드의 배수와 맞물리면 특정 세트로 몰림 → **패딩/오프셋**으로 분산.

---

## 맺음말

캐시는 **지역성**을 전제로 **지연을 가리고 대역을 끌어내는** 계층이다.
성능을 결정짓는 것은 대개 **데이터 이동**:
1) **접근 순서**를 바꾸고(행-주도/타일링/SoA),
2) **불필요한 로드/분기/호출**을 줄이며,
3) **TLB/NUMA/코히어런시**를 함께 관리하라.
그리고 **측정→개선→재측정**의 루프를 습관화하면, 워크로드에 맞는 **캐시 활용 전략**을 체계적으로 찾을 수 있다.
