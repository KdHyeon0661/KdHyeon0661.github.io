---
layout: post
title: 운영체제 - 가상 메모리 (1)
date: 2025-10-25 16:30:23 +0900
category: 운영체제
---
# Chapter 10 — Virtual Memory

## Background

### 가상 메모리(Virtual Memory)의 목적

- **큰 논리 주소 공간**: 프로세스는 실제 RAM보다 **훨씬 큰** 주소 공간을 가진다.
- **보호(Protection)**: 프로세스 간 메모리 격리. 커널/사용자 모드 구분.
- **공유(Sharing)**: 코드(텍스트), 라이브러리, 메모리 매핑 파일을 **페이지 단위**로 공유.
- **투명성(Transparency)**: 프로그래머는 **연속적인 바이트 배열**처럼 접근 → MMU가 **가상주소→물리주소** 변환.

### 주소 변환 & 페이징 복습 요약

- **페이지(Page)**: 가상 공간의 고정 크기 블록 (4KiB/16KiB/64KiB 등).
- **프레임(Frame)**: 물리 메모리 블록 (페이지와 동일 크기).
- **페이지 테이블(PTE)**: VPN→PFN 매핑 + 접근권한(R/W/X), 존재 비트(Present), 더티/참조 등 상태.
- **TLB**: 최근 변환 캐시. 히트율 \(h\) 이 높을수록 유리.
- **유효 접근 시간(EAT)** 근사(단일 레벨 PT 가정):
  $$
  EAT \approx h\cdot (t+m) + (1-h)\cdot (t+2m)
  $$
  여기서 \(t\): TLB 접근, \(m\): DRAM 접근. (멀티레벨 PT면 미스 시 접근 수가 더 늘어난다.)

### 가상 메모리의 운영 목표

- **워크셋(Working Set)** 을 RAM에 유지해 **페이지 폴트**를 낮춘다.
- **교체(Replacement)**: LRU 이상형에 근사(Clock/Second-Chance 등).
- **I/O 비용 최소화**: 지연 큰 디스크 I/O를 줄이도록 **프리페치/히트 힌트** 활용.

---

## Demand Paging

> **Demand paging**: 실제로 **접근하는 순간**에만 페이지를 메모리로 가져오는 방식. 초기 실행 시 페이지 대부분이 RAM에 없고, 접근 시 **페이지 폴트**가 발생하여 적재된다.

### 페이지 폴트 흐름(커널 관점)

1) CPU가 VA를 접근 → **TLB 미스** → 페이지 테이블 조회.
2) PTE의 **Present=0** 또는 **권한 위반** → **페이지 폴트 예외** 발생.
3) 커널의 폴트 핸들러가 아래를 수행:
   - 이 접근이 **합법**인지 확인(매핑 존재/권한 체크).
   - 필요 프레임을 **교체 정책**으로 확보(필요하면 희생 프레임 스왑아웃).
   - 백업 저장소(실행파일/공유 라이브러리/스왑/파일)에서 **페이지 읽기**.
   - PTE 업데이트(프레임 번호, Present=1, 권한), TLB 갱신/무효화.
   - 폴트 발생 명령을 **재시작**.

### 유효 접근 시간(EAT) with 페이지 폴트

페이지 폴트 확률을 \(p\), 디스크 I/O 지연을 \(D\)라 하면,
$$
EAT \approx h(t+m) + (1-h)(t+2m) + p\cdot D.
$$
보통 \(D\)는 \(\text{ms}\) 단위로 매우 커서 \(pD\) 항이 전체를 지배 → **폴트율 최소화**가 중요.

### 소프트(미너) vs 하드(메이저) 폴트

- **Minor fault**: PTE는 유효하거나 페이지가 **페이지 캐시**에 있어 **디스크 I/O 없이** 처리.
- **Major fault**: 실제 디스크에서 **읽어와야** 하는 경우 → 지연이 큼.

### 폴트 유형 & 권한

- 접근 권한 위반(R/X/W) → **보호 오류**(Segmentation fault).
- COW(10.3) 상황에서 **쓰기**는 의도적 **폴트 유발 이벤트** → 커널이 **사본 생성** 후 권한 부여.

### 단순 교체 시뮬레이터 (FIFO/Clock 비교)

```python
# demand_paging_sim.py — 간단 페이지 교체 시뮬(학습용)

from collections import deque

def fifo_faults(seq, frames):
    q, inmem, faults = deque(), set(), 0
    for p in seq:
        if p not in inmem:
            faults += 1
            if len(q) == frames:
                out = q.popleft()
                inmem.remove(out)
            q.append(p); inmem.add(p)
    return faults

def clock_faults(seq, frames):
    frame = [-1]*frames
    used  = [0]*frames
    hand = 0; faults=0
    for p in seq:
        if p in frame:
            used[frame.index(p)] = 1
            continue
        faults += 1
        while True:
            if used[hand] == 0:
                frame[hand] = p
                used[hand]  = 1
                hand = (hand+1)%frames
                break
            used[hand] = 0
            hand = (hand+1)%frames
    return faults

if __name__ == "__main__":
    seq = [0,1,2,3,0,1,4,0,1,2,3,4]
    for f in (3,4):
        print(f"FIFO f={f}: {fifo_faults(seq,f)}  CLOCK f={f}: {clock_faults(seq,f)}")
```

### 메모리 매핑 파일 & 지연 적재

`mmap`으로 파일을 매핑하면, 접근 시 **해당 페이지만** 가져온다(지연 적재). 순차 스캔/랜덤 접근에 대해 힌트를 줄 수 있다.

```c
// mmap_demand.c — 파일을 mmap하여 demand paging 관찰
#define _GNU_SOURCE
#include <sys/mman.h>
#include <sys/stat.h>
#include <fcntl.h>
#include <unistd.h>
#include <stdio.h>

int main(int argc, char** argv){
  if(argc<2){ fprintf(stderr,"usage: %s <file>\n", argv[0]); return 1; }
  int fd = open(argv[1], O_RDONLY);
  struct stat st; fstat(fd, &st);
  char* p = mmap(NULL, st.st_size, PROT_READ, MAP_PRIVATE, fd, 0);

  // 순차 접근: 커널이 리드어헤드를 통해 폴트 횟수를 줄일 수 있음
  for(off_t i=0;i<st.st_size;i+=4096){
    volatile char x = p[i]; (void)x;
  }

  // 접근 패턴 힌트
  posix_fadvise(fd, 0, st.st_size, POSIX_FADV_SEQUENTIAL);
  madvise(p, st.st_size, MADV_SEQUENTIAL);

  munmap(p, st.st_size); close(fd);
}
```

### 스로싱(Thrashing) 방지

- **프레임 수**가 **워크셋**보다 작으면, 계속 폴트 → CPU가 I/O 대기만 함.
- 해결: **멀티프로그래밍 정도**(동시 프로세스 수)를 조절, 작업별 **min/max 프레임** 할당, **NUMA 바인딩**.

---

## Copy-on-Write (COW)

> **COW**: 페이지를 **읽기 전용으로 공유**하다가 **쓰기가 발생하면** 그 시점에 **개별 사본을 복사**하는 최적화 기법. `fork()`/`mmap(MAP_PRIVATE)` 등에서 핵심적으로 사용된다.

### 동작 원리

- 초기 상태: 부모와 자식(혹은 여러 프로세스)이 같은 물리 페이지를 **읽기 전용 공유**. PTE의 **W 비트 off** + **COW 표시(소프트웨어 비트)**.
- 쓰기 발생: **보호 폴트** 트랩 → 커널이 **새 프레임**을 할당하고 **원본 내용을 복사** → 쓰기 가능한 PTE로 교체 → 명령 재시작.

### COW의 장점

- `fork()` 직후 즉시 **메모리 두 배**가 되지 않는다. 실제로 **쓰는 페이지만** 복제.
- 프로세스 시작 시 **초기화 비용** 절감(예: 큰 힙을 가진 서버를 복제해 워커 생성).
- **스냅샷**/버전 관리(파일시스템, VM, DB)에도 응용 가능.

### `fork()` + COW 동작 예 (리눅스)

```c
// cow_fork.c — fork 후 부모/자식이 같은 페이지를 공유하다, 자식이 쓸 때만 복제
#define _GNU_SOURCE
#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include <sys/mman.h>
#include <unistd.h>

int main(){
  size_t sz = 4*1024*1024;            // 4MiB
  char* buf = mmap(NULL, sz, PROT_READ|PROT_WRITE,
                   MAP_ANONYMOUS|MAP_PRIVATE, -1, 0);
  memset(buf, 'A', sz);               // 초기화(여전히 private, dirty)
  pid_t pid = fork();
  if(pid==0){
    // 자식: 첫 쓰기 시 해당 페이지에서 COW 발생(커널이 새 프레임 할당 후 복제)
    for(size_t i=0;i<sz;i+=4096) buf[i] = 'B';
    // 자식만의 프레임으로 변경됨
    _exit(0);
  } else {
    // 부모: 여전히 'A'를 유지
    wait(NULL);
    printf("parent sees: %c %c %c\n", buf[0], buf[4096], buf[8192]);
    munmap(buf, sz);
  }
}
```

> 관찰 팁: `perf stat -e page-faults,major-faults` / `cat /proc/<pid>/smaps` 로 **Private_Dirty** 증가 확인.

### `mmap(MAP_PRIVATE)`의 COW

- `MAP_PRIVATE` 매핑은 파일과 **COW 관계**: 읽기는 공유, 쓰면 **익명(anonymous) 사본**으로 갈라진다.

```c
// cow_mmap.c — 파일 MAP_PRIVATE + 쓰기 → 익명 사본으로 COW
#define _GNU_SOURCE
#include <sys/mman.h>
#include <sys/stat.h>
#include <fcntl.h>
#include <stdio.h>
#include <unistd.h>
#include <string.h>

int main(int argc,char** argv){
  if(argc<2){ fprintf(stderr,"usage: %s file\n", argv[0]); return 1; }
  int fd = open(argv[1], O_RDONLY);
  struct stat st; fstat(fd,&st);
  char* p = mmap(NULL, st.st_size, PROT_READ|PROT_WRITE, MAP_PRIVATE, fd, 0);
  // 파일 내용 읽기 — 페이지는 파일백드, 공유 읽기
  char before = p[0];
  // 쓰기 — 이 순간 해당 페이지가 익명 사본으로 COW 되어 파일에는 영향 없음
  p[0] = (before=='A'?'Z':'A');
  msync(p, 4096, MS_SYNC); // MAP_PRIVATE에선 파일로 쓰여지지 않음(무의미). 테스트용 호출.
  printf("before=%c after=%c\n", before, p[0]);
  munmap(p, st.st_size); close(fd);
}
```

### 사용자 공간에서 COW를 흉내 낸 데이터 구조(개념 확장)

운영체제의 페이지 단위 COW와 별개로, **데이터 구조 레벨**에서도 COW 패턴을 사용한다(멀티스레드/스냅샷 친화).

- 예: **CopyOnWriteArrayList**(Java) — 쓰기 시 전체 배열 복사(페이지가 아닌 자료구조 단위).
- 예: **영구(Persistent) 자료구조** — 노드 공유 + 변경 경로만 복사(구조적 공유).

```java
// cow_list_demo.java — 개념 데모 (OS 레벨 COW와 목적은 유사하나 단위가 다름)
import java.util.concurrent.CopyOnWriteArrayList;
public class Demo {
  public static void main(String[] args){
    CopyOnWriteArrayList<Integer> list = new CopyOnWriteArrayList<>();
    for(int i=0;i<5;i++) list.add(i);
    for(Integer x: list) { // 이터레이션 중에도 안전 — 쓰기는 사본에
      if(x==2) list.add(99);
      System.out.print(x+" ");
    }
    System.out.println("\n"+list);
  }
}
```

### COW의 주의점

- **첫 쓰기 비용**: 복사 오버헤드 + 페이지 폴트 처리.
- **공유/참조 카운트** 관리 필요(커널: 페이지의 map count, 소프트웨어: ref-count).
- **NUMA**: COW 후 생성된 사본의 **노드 배치**가 성능에 영향.

---

## 종합 실습 & 튜닝 체크리스트

### 실습 A — Demand vs Pre-Fault

1) `mmap_demand.c` 로 큰 파일을 매핑 후 **랜덤/순차** 접근에서 폴트/지연 비교.
2) `madvise(MADV_WILLNEED)` → **선제 로드** 효과 관찰.
3) `vmstat 1`, `perf stat -e page-faults,major-faults` 로 측정.

### 실습 B — COW 관찰

1) `cow_fork.c` 실행 전후 `smaps` 의 **Private_Dirty** 변화를 확인.
2) `fork()` 후 자식이 **읽기만** 할 때와 **쓰기** 할 때의 **폴트 수** 비교.

### 실습 C — 교체 알고리즘 실험

1) `demand_paging_sim.py`에서 시퀀스/프레임 수를 바꿔 **fault 수** 비교.
2) 실제 시스템에서는 **Clock(Second-Chance)** 가 LRU 근사로 흔히 쓰임 — 참조 비트/AF(Accessed Flag) 연계 확인.

### 운영 체크리스트

- **폴트율**과 **p95/p99 지연** 상관관계 모니터링.
- **NUMA**: 바인딩/퍼스트-터치 정책으로 COW 후 사본의 노드 배치 최적화.
- **THP/HugeTLB**: TLB 커버리지 증가 ↔ 내부 단편화/복사 비용 트레이드오프.
- **힌트**: `madvise`, `mlock`(핫 데이터), `posix_fadvise`(파일 워크로드).

---

## 핵심 요약

- **10.1 가상 메모리 배경**: 큰 논리 공간, 보호/공유, MMU 변환. 성능 핵심은 **TLB 히트**와 **폴트율**.
- **10.2 지연 적재(Demand Paging)**: 접근 시점에만 불러오기. **페이지 폴트 비용**이 지배적이므로 워크셋을 RAM에 유지하고 교체·프리페치 전략을 통해 폴트를 줄여야 한다.
- **10.3 Copy-on-Write**: `fork()`/`MAP_PRIVATE`의 핵심 최적화. **처음 쓰기** 때만 복사하여 메모리·I/O를 절약한다. 다만 첫 쓰기 지연, NUMA 배치, ref-count 관리에 주의.
