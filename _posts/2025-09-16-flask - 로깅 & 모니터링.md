---
layout: post
title: flask - 로깅 & 모니터링
date: 2025-09-16 23:25:23 +0900
category: flask
---
# 로깅 & 모니터링

## 운영 관점에서의 로깅 & 모니터링 큰 그림

현대적인 웹 애플리케이션 운영에서는 체계적인 관측 가능성(Observability)이 필수적입니다. 이를 위해 다음과 같은 요소들을 통합적으로 고려해야 합니다:

- **구조화 로깅(JSON)**: 사람이 읽기 쉬운 텍스트 로그 대신 **기계가 파싱하기 쉬운 JSON 형식**으로 로그를 기록합니다. 각 로그 항목에는 레벨, 타임스탬프, 요청ID, 경로, 사용자, 라우트, 응답 시간, 응답 크기, 에러 코드, 호스트, 버전 등의 구조화된 필드가 포함됩니다.

- **코릴레이션**: 하나의 요청이 내부 함수 호출, 외부 API 호출, 백그라운드 작업까지 이어지는 전체 흐름을 추적할 수 있도록 **request_id / correlation_id**를 모든 레이어에 전파합니다.

- **에러 수집**: Sentry나 Rollbar 같은 도구를 활용하여 **스택 트레이스, 태그, 사용자 컨텍스트**를 자동으로 수집하고 집계합니다.

- **메트릭**: Prometheus의 Counter/Gauge/Histogram이나 StatsD를 사용하여 요청률, 응답 지연, 오류율, 큐 길이, 캐시 적중률 등의 시스템 지표를 추적합니다.

- **헬스체크**: Kubernetes나 로드밸런서를 위한 **liveness/readiness 엔드포인트**를 제공하고, 데이터베이스, 캐시, 외부 API 같은 내부 의존성의 상태를 점검합니다.

> 핵심 원칙은 **표준화, 일관성, 자동화**입니다. "로그는 JSON 형식, 메트릭은 라벨 기반, 트레이싱과 코릴레이션은 필수, 헬스 엔드포인트는 빠르고 결정적"이라는 기본 원칙을 준수해야 합니다.

---

## 구조화 로깅(JSON)

### 로그 수집 파이프라인 전제

- 컨테이너나 Kubernetes 환경에서는 애플리케이션이 **STDOUT으로 로그 출력** → **Fluent Bit, Vector, Filebeat 같은 수집기**가 로그를 수집하여 중앙 집중식 저장소로 전송합니다.
- 로그 보관과 검색을 위해 Elasticsearch/OpenSearch, Loki, CloudWatch, Datadog 등을 사용합니다.

### Python 로거 구성(기본)

```python
# app/logging.py

import logging, sys
from pythonjsonlogger import jsonlogger

def setup_json_logging(app, level=logging.INFO):
    handler = logging.StreamHandler(sys.stdout)
    fmt = jsonlogger.JsonFormatter(
        "%(asctime)s %(levelname)s %(name)s %(message)s "
        "%(pathname)s %(lineno)s %(process)d %(thread)d"
    )
    handler.setFormatter(fmt)

    root = logging.getLogger()
    root.handlers[:] = [handler]
    root.setLevel(level)

    # Flask 자체 로거도 루트 로거로 전파
    app.logger.handlers[:] = []
    app.logger.propagate = True

    # 과도한 로그를 생성하는 외부 라이브러리 제어
    for noisy in ("werkzeug", "urllib3", "botocore", "boto3"):
        logging.getLogger(noisy).setLevel(logging.WARNING)
```

### 요청과 코릴레이션 ID 주입

```python
# app/middleware.py

import uuid, time
from flask import g, request

def setup_request_context(app):
    @app.before_request
    def start_timer():
        g.start_ts = time.time()
        # 클라이언트가 보낸 요청 ID 우선 사용(X-Request-ID 또는 x-correlation-id)
        rid = request.headers.get("X-Request-ID") or request.headers.get("X-Correlation-ID")
        g.request_id = rid or uuid.uuid4().hex

    @app.after_request
    def add_log_and_headers(resp):
        elapsed_ms = int((time.time() - g.get("start_ts", time.time())) * 1000)
        resp.headers["X-Request-ID"] = g.request_id
        # 구조화된 액세스 로그 기록
        app.logger.info(
            "access",
            extra={
                "event": "http_access",
                "request_id": g.request_id,
                "method": request.method,
                "path": request.full_path.split("?")[0],
                "query": request.query_string.decode("utf-8"),
                "status": resp.status_code,
                "size": resp.calculate_content_length() or 0,
                "remote_addr": request.headers.get("X-Forwarded-For", request.remote_addr),
                "user_agent": request.headers.get("User-Agent"),
                "elapsed_ms": elapsed_ms,
            },
        )
        return resp
```

**사용자/세션 컨텍스트 추가** (로그인 사용자 정보 포함):

```python
# app/middleware.py (after_request 내부 또는 before_request에서 current_user 활용)

from flask_login import current_user

user_id = getattr(current_user, "id", None)
app.logger.info("access", extra={"user_id": user_id, ...})
```

### 보안: 민감정보 마스킹

```python
# app/log_filters.py

import logging, re

REDACT_KEYS = {"password", "secret", "token", "authorization", "api_key"}

class RedactFilter(logging.Filter):
    def filter(self, record):
        if isinstance(record.args, dict):
            record.args = {k: ("***" if k.lower() in REDACT_KEYS else v) for k, v in record.args.items()}
        if hasattr(record, "message") and isinstance(record.message, str):
            record.message = re.sub(r"(password|secret|token)=[^&\s]+", r"\1=***", record.message, flags=re.I)
        return True
```

핸들러에 필터 추가:

```python
handler.addFilter(RedactFilter())
```

### Gunicorn 액세스 로그를 JSON 형식으로 출력

```bash
# gunicorn.conf.py

import json, sys, time

def post_worker_init(worker):
    pass

accesslog = "-"
errorlog = "-"
loglevel = "info"

def access_log_format(environ, resp, request_time):
    # Gunicorn의 기본 액세스 로그 형식 대신 직접 JSON 출력
    ts = time.strftime("%Y-%m-%dT%H:%M:%S%z", time.localtime())
    rec = {
        "asctime": ts,
        "levelname": "INFO",
        "name": "gunicorn.access",
        "event": "http_access",
        "method": environ.get("REQUEST_METHOD"),
        "path": environ.get("RAW_URI") or environ.get("PATH_INFO"),
        "status": resp.status,
        "length": resp.response_length,
        "remote": environ.get("HTTP_X_FORWARDED_FOR") or environ.get("REMOTE_ADDR"),
        "ua": environ.get("HTTP_USER_AGENT"),
        "request_id": environ.get("HTTP_X_REQUEST_ID"),
        "elapsed_ms": int(request_time * 1000),
    }
    print(json.dumps(rec), file=sys.stdout)
    return ""
```

> 환경과 조직의 요구사항에 맞게 **하나의 포맷으로 통일**하고, 로깅 파이프라인의 필드 매핑을 명확히 문서화하는 것이 중요합니다.

---

## 에러 수집: Sentry

### 설치와 초기화

```bash
pip install sentry-sdk
```

```python
# app/observability/sentry.py

import os, sentry_sdk
from sentry_sdk.integrations.flask import FlaskIntegration
from sentry_sdk.integrations.celery import CeleryIntegration
from sentry_sdk.integrations.redis import RedisIntegration
from sentry_sdk.integrations.sqlalchemy import SqlalchemyIntegration

def init_sentry(app):
    dsn = os.getenv("SENTRY_DSN")
    if not dsn:
        return
    sentry_sdk.init(
        dsn=dsn,
        integrations=[FlaskIntegration(), CeleryIntegration(), RedisIntegration(), SqlalchemyIntegration()],
        traces_sample_rate=float(os.getenv("SENTRY_TRACES_SAMPLE_RATE", "0.0")),  # APM(선택사항)
        profiles_sample_rate=float(os.getenv("SENTRY_PROFILES_SAMPLE_RATE", "0.0")),  # 프로파일링(선택사항)
        environment=os.getenv("APP_ENV", "development"),
        release=os.getenv("RELEASE", "dev"),
        send_default_pii=False,  # 개인정보 자동 포함 비활성화(사용자 컨텍스트는 선택적으로 추가)
        max_breadcrumbs=200,
    )
```

애플리케이션 초기화:

```python
# app/__init__.py

from .observability.sentry import init_sentry
def create_app(config=None):
    app = Flask(__name__)
    ...
    init_sentry(app)
    return app
```

### 수동 에러 보고와 부가정보 추가

```python
import sentry_sdk
from flask_login import current_user

def capture_business_error(msg: str, **kvs):
    with sentry_sdk.push_scope() as scope:
        scope.set_tag("component", "billing")
        if getattr(current_user, "id", None):
            scope.user = {"id": current_user.id, "email": getattr(current_user, "email", None)}
        for k, v in kvs.items():
            scope.set_extra(k, v)
        sentry_sdk.capture_message(msg, level="error")
```

예외 포착:

```python
try:
    risky()
except Exception:
    sentry_sdk.capture_exception()
    raise
```

### 샘플링, PII, 보안 모범사례

- **샘플링**: 트래픽이 많은 서비스는 **에러 이벤트는 100% 수집**, 트랜잭션(APM)은 **샘플링(예: 5%)** 합니다.
- **PII**: `send_default_pii=False`를 유지하고, 사용자 정보는 **명시적으로만** 추가합니다.
- **출시 버전과 환경**: `release`와 `environment` 태그로 배포 추적을 용이하게 합니다.
- **Ignore/Grouping**: 클라이언트 연결 중단, 봇 트래픽 같은 알려진 예외는 무시 규칙을 설정합니다.

---

## 메트릭: StatsD / Prometheus

### 무엇을 측정할 것인가

- **트래픽/오류/지연**: 초당 요청수(RPS), 2xx/4xx/5xx 상태 코드 분포, p50/p90/p99 지연 시간, 타임아웃/재시도 횟수
- **리소스 사용량**: 워커 프로세스 수, 큐 길이, 데이터베이스 연결 수, 캐시 적중률, 파일 핸들 수, CPU/메모리 사용량
- **비즈니스 지표**: 주문 수, 결제 성공률, 신규 가입자 수, 로그인 실패율

### StatsD 예시

```bash
pip install datadog
```

```python
# app/metrics/statsd.py

import os
from datadog import initialize, statsd

def init_statsd():
    # 환경에 따라 로컬 에이전트(8125/UDS)로 메트릭 전송
    initialize(statsd_host=os.getenv("STATSD_HOST", "127.0.0.1"),
               statsd_port=int(os.getenv("STATSD_PORT", "8125")),
               statsd_socket_path=os.getenv("STATSD_SOCKET", None))
```

HTTP 메트릭을 위한 미들웨어:

```python
# app/middleware_metrics.py

import time
from flask import request
from datadog import statsd

def setup_http_metrics(app):
    @app.before_request
    def _start():
        request._t0 = time.time()

    @app.after_request
    def _end(resp):
        t = time.time() - getattr(request, "_t0", time.time())
        route = (request.url_rule.rule if request.url_rule else request.path)
        method = request.method
        code = resp.status_code
        tags = [f"route:{route}", f"method:{method}", f"status:{code}"]
        statsd.increment("http.requests", tags=tags)
        statsd.histogram("http.latency_ms", t * 1000, tags=tags)
        return resp
```

비즈니스 지표:

```python
statsd.increment("signup.completed", tags=["plan:pro", "channel:web"])
statsd.gauge("queue.length", length, tags=["name:media"])
```

### Prometheus 클라이언트

```bash
pip install prometheus-client
```

지표 등록:

```python
# app/metrics/prom.py

from prometheus_client import Counter, Histogram, Gauge, generate_latest, CONTENT_TYPE_LATEST
from flask import Blueprint, Response

REQUESTS = Counter("http_requests_total", "Total HTTP requests", ["route", "method", "status"])
LATENCY = Histogram("http_request_duration_seconds", "Latency", ["route", "method"], buckets=(.005,.01,.025,.05,.1,.25,.5,1,2,5))
INPROG = Gauge("http_inprogress", "In-progress requests")

metrics_bp = Blueprint("metrics", __name__)

@metrics_bp.get("/metrics")
def metrics():
    return Response(generate_latest(), mimetype=CONTENT_TYPE_LATEST)
```

미들웨어 구현:

```python
# app/middleware_prom.py

import time
from flask import request
from .metrics.prom import REQUESTS, LATENCY, INPROG

def setup_prom_middleware(app):
    @app.before_request
    def _start():
        request._t0 = time.time()
        INPROG.inc()

    @app.after_request
    def _end(resp):
        t = time.time() - getattr(request, "_t0", time.time())
        route = (request.url_rule.rule if request.url_rule else request.path)
        REQUESTS.labels(route=route, method=request.method, status=resp.status_code).inc()
        LATENCY.labels(route=route, method=request.method).observe(t)
        INPROG.dec()
        return resp
```

> 배포 시 Prometheus 서버가 `/metrics` 엔드포인트를 스크랩합니다. Kubernetes 환경에서는 `PodMonitor`나 `ServiceMonitor`를 사용하여 라벨링된 포드/서비스를 자동으로 스크랩합니다.

### 지표 네이밍과 라벨 가이드라인

- **snake_case 영어 사용**, 단위 포함(`_seconds`, `_bytes`, `_total`)
- **라벨 카디널리티 관리**: `user_id`처럼 값이 무제한으로 늘어날 수 있는 **폭발적인 라벨**은 피합니다.
- 경로 라벨은 **정규화된 라우트 패턴** 사용(`/users/<id>`), **원본 URL이나 쿼리스트링은 포함하지 않습니다**.

---

## 헬스체크 / 레디니스 / 라이브니스

### 개념 이해

- **라이브니스(liveness)**: 프로세스가 **정상적으로 실행 중인지** 확인합니다. (하드락, 데드락, GC 정지 등 감지) → 실패 시 컨테이너 재시작
- **레디니스(readiness)**: **요청을 처리할 준비가 된 상태인지** 확인합니다. (데이터베이스 연결, 캐시, 외부 의존성 준비 상태) → 실패 시 트래픽에서 제외
- **헬스(health)**: 운영자나 상태 페이지를 위한 상세한 시스템 진단 정보

### 구현 예제

```python
# app/health.py

from flask import Blueprint, jsonify
from app.extensions import db
import time

health_bp = Blueprint("health", __name__)

@health_bp.get("/healthz/live")
def live():
    # 매우 가볍고 빠르게 응답해야 함. 논리적으로 True면 200 응답
    return jsonify(status="ok", ts=int(time.time()))

@health_bp.get("/healthz/ready")
def ready():
    # 내부 의존성 체크: 짧은 타임아웃으로 성공/실패만 판단
    ok_db = _check_db()
    ok_cache = _check_cache()
    ok_ext = _check_external()
    ok = ok_db and ok_cache and ok_ext
    code = 200 if ok else 503
    return jsonify(
        status="ok" if ok else "fail",
        deps={"db": ok_db, "cache": ok_cache, "external": ok_ext},
        ts=int(time.time())
    ), code

def _check_db(timeout=0.2) -> bool:
    try:
        with db.engine.connect() as conn:
            conn.exec_driver_sql("SELECT 1")
        return True
    except Exception:
        return False

def _check_cache() -> bool:
    try:
        from app.extensions import cache
        cache.set("health:ping", "1", timeout=5)
        return cache.get("health:ping") == "1"
    except Exception:
        return False

def _check_external() -> bool:
    # 외부 API 핑(선택사항, 타임아웃 매우 짧게 설정)
    return True
```

Kubernetes 프로브 설정 예시:

```yaml
livenessProbe:
  httpGet:
    path: /healthz/live
    port: 8000
  initialDelaySeconds: 10
  periodSeconds: 10
readinessProbe:
  httpGet:
    path: /healthz/ready
    port: 8000
  initialDelaySeconds: 5
  periodSeconds: 5
  timeoutSeconds: 1
```

> **규칙**: `live` 엔드포인트는 **항상 가볍고 빠르게**, `ready` 엔드포인트는 **의존성 상태를 점검**합니다. 준비되지 않은 상태에서는 503 응답을 반환합니다.

### 상세 헬스 정보(내부 관리용)

```python
@health_bp.get("/health")
def health():
    # 내부 관리자/운영자를 위한 상세 시스템 상태 정보
    return jsonify({
        "uptime_s": _uptime(),
        "version": {"release": os.getenv("RELEASE","dev"), "env": os.getenv("APP_ENV","dev")},
        "limits": {"max_fds": _get_fd_limit()},
        "threads": _thread_count(),
        "queue": {"default_len": _rq_len("default")},
    })
```

> 이 엔드포인트는 인증과 권한 검사를 필수로 적용해야 하며, 공개적으로 접근 가능해서는 안 됩니다. 민감한 정보 노출에 주의하세요.

---

## 코릴레이션: 외부 호출, 백그라운드 작업, 실시간 통신까지

### 외부 HTTP 요청에 헤더 전파

```python
# app/http/client.py

import requests
from flask import g

session = requests.Session()

def get_json(url, timeout=3):
    headers = {}
    rid = getattr(g, "request_id", None)
    if rid:
        headers["X-Request-ID"] = rid
        headers["X-Correlation-ID"] = rid
    r = session.get(url, timeout=timeout, headers=headers)
    r.raise_for_status()
    return r.json()
```

### Celery 태스크로 코릴레이션 ID 전파

```python
# 태스크 제출 측

task = do_stuff.apply_async(args=[...], headers={"X-Request-ID": g.request_id})

# 태스크 측 구현

@celery.task(bind=True)
def do_stuff(self, ...):
    rid = self.request.get("headers", {}).get("X-Request-ID")
    # 로거에 코릴레이션 ID 바인딩
    logger = logging.getLogger("worker")
    logger = logging.LoggerAdapter(logger, extra={"request_id": rid})
    logger.info("worker started")
```

### SocketIO 이벤트 전파

```python
socketio.emit("evt", {...}, to=room, headers={"X-Request-ID": g.request_id})
```

> **일관된 키**(`X-Request-ID`를 코릴레이션 기준으로 사용)를 정하고 이를 문서화하는 것이 중요합니다.

---

## 로그 레벨, 샘플링, 레이트 리미팅

### 로그 레벨 가이드라인

- `DEBUG`: 개발/디버깅용, 운영 환경에서는 **샘플링** 또는 비활성화
- `INFO`: 정상적인 상태 변경 기록(시작/중지/주요 비즈니스 이벤트)
- `WARNING`: 복구 가능한 오류 상황(재시도/대체 경로 사용)
- `ERROR`: 요청 실패/사용자에게 영향을 주는 오류
- `CRITICAL`: 시스템 전체 위험/즉시 조치 필요 상황

### 샘플링과 레이트 리미팅 필터

```python
# app/log_filters.py (추가)

import random, time

class SamplingFilter(logging.Filter):
    def __init__(self, rate=0.1):  # 10%
        super().__init__()
        self.rate = rate
    def filter(self, record):
        if record.levelno == logging.DEBUG:
            return random.random() < self.rate
        return True

class RateLimitFilter(logging.Filter):
    last = {}
    def __init__(self, key="message", interval=5):
        super().__init__()
        self.key = key; self.interval = interval
    def filter(self, record):
        k = getattr(record, self.key, record.getMessage())
        now = time.time()
        last = self.last.get(k, 0)
        if (now - last) < self.interval and record.levelno <= logging.INFO:
            return False
        self.last[k] = now
        return True
```

핸들러에 필터 적용:

```python
handler.addFilter(SamplingFilter(rate=0.05))
handler.addFilter(RateLimitFilter(interval=2))
```

---

## 테스트: 로그 검증과 메트릭 검증

### 로그 단언(Pytest caplog 활용)

```python
def test_access_log(client, caplog):
    caplog.set_level(logging.INFO)
    r = client.get("/ping")
    assert r.status_code == 200
    assert any("access" in rec.message for rec in caplog.records)
```

### Prometheus 메트릭 테스트

```python
from prometheus_client import REGISTRY

def test_metric_exposed(client):
    r = client.get("/metrics")
    assert r.status_code == 200
    assert b"http_requests_total" in r.data
```

---

## 실전 통합: 애플리케이션 부트스트랩

### 통합 설정

```python
# app/__init__.py

from flask import Flask
from .logging import setup_json_logging
from .middleware import setup_request_context
from .observability.sentry import init_sentry
from .metrics.prom import metrics_bp
from .middleware_prom import setup_prom_middleware
from .health import health_bp

def create_app(config=None):
    app = Flask(__name__)
    setup_json_logging(app)
    init_sentry(app)
    setup_request_context(app)
    setup_prom_middleware(app)

    app.register_blueprint(metrics_bp)     # /metrics 엔드포인트
    app.register_blueprint(health_bp)      # /healthz/live, /healthz/ready 엔드포인트

    @app.get("/ping")
    def ping():
        app.logger.info("pong", extra={"event":"ping"})
        return {"pong": True}
    return app
```

### Docker Compose 예시(관측 스택)

```yaml
version: "3.9"
services:
  web:
    build: .
    ports: ["8000:8000"]
    environment:
      - APP_ENV=production
      - SENTRY_DSN=${SENTRY_DSN}
      - RELEASE=${GIT_SHA}
    command: >
      gunicorn "wsgi:app" -k gthread --threads 8 -w 2
      --bind :8000 --access-logfile - --error-logfile -
  prometheus:
    image: prom/prometheus
    volumes:
      - ./ops/prometheus.yml:/etc/prometheus/prometheus.yml
    ports: ["9090:9090"]
  loki:
    image: grafana/loki:2.9.0
  promtail:
    image: grafana/promtail:2.9.0
    volumes:
      - /var/log:/var/log
```

---

## 확장: OpenTelemetry 통합(로그-트레이스 상관관계)

OpenTelemetry를 사용하면 **로그에 trace_id와 span_id를 포함**하여 **단일 클릭으로 로그와 트레이스를 상관관계** 지을 수 있습니다.

```python
# app/logging_otlp.py

from opentelemetry.trace import get_current_span

class OTelContextFilter(logging.Filter):
    def filter(self, record):
        span = get_current_span()
        ctx = span.get_span_context() if span is not None else None
        if ctx and ctx.is_valid:
            record.trace_id = format(ctx.trace_id, "032x")
            record.span_id = format(ctx.span_id, "016x")
        else:
            record.trace_id = None
            record.span_id = None
        return True

handler.addFilter(OTelContextFilter())
```

로그 포맷에 필드 추가:

```python
fmt = jsonlogger.JsonFormatter("%(asctime)s %(levelname)s %(name)s %(message)s %(trace_id)s %(span_id)s")
```

---

## 보안과 규정 준수 고려사항

- **개인정보(PII)와 금융/건강 정보**: 로그에 절대 남기지 않도록 마스킹/삭제 정책을 수립합니다.
- **보존 기간**: 최소화 원칙을 따르고(예: 14~30일), 백업과 보관 체계를 분리합니다.
- **접근 제어**: 관측 시스템(로그/메트릭/트레이스/대시보드)에 대한 접근 권한을 엄격히 관리합니다.
- **알람과 시그널링**: 비상 호출 정책을 수립하고, 에러 예산 기반으로 알람을 구성합니다.

---

## 결론

이번 장에서는 프로덕션 환경에서 Flask 애플리케이션을 효과적으로 운영하기 위한 관측 가능성 체계를 구축하는 방법을 심도 있게 살펴보았습니다. JSON 구조화 로깅과 요청/코릴레이션 ID 전파를 통해 시스템 전반의 흐름을 추적할 수 있는 기반을 마련하고, Sentry를 활용한 에러 수집, StatsD/Prometheus를 통한 메트릭 수집, Kubernetes 운용을 고려한 liveness/readiness 헬스 체크 엔드포인트 설계까지 실제 프로덕션 환경에서 필요한 모든 요소를 다루었습니다.

여기에 로그 샘플링과 레이트 리미팅, 민감정보 마스킹, OpenTelemetry를 통한 트레이스-로그 상관관계 구축까지 추가하면 완전한 관측 가능성 스택을 갖출 수 있습니다. 이러한 체계를 구축함으로써 개발자는 문제 발생 시 빠르게 근본 원인을 파악할 수 있고, 운영자는 시스템의 건강 상태를 실시간으로 모니터링할 수 있으며, 비즈니스 이해관계자는 서비스 품질을 정량적으로 평가할 수 있게 됩니다.

최종적으로는 이러한 관측 가능성 인프라가 단순히 기술적 요구사항을 넘어, 서비스의 신뢰성과 운영 효율성을 지속적으로 개선하는 핵심 도구로 자리 잡을 수 있도록 체계적으로 관리하고 발전시켜 나가야 합니다.