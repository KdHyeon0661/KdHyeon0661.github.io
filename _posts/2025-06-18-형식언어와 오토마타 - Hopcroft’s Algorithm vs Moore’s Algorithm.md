---
layout: post
title: 형식언어와 오토마타 - Hopcroft’s Algorithm vs Moore’s Algorithm
date: 2025-06-18 23:20:23 +0900
category: 형식언어와 오토마타
---
# DFA 최소화를 위한 알고리즘: Hopcroft’s Algorithm vs Moore’s Algorithm

---

## 개요

DFA(Deterministic Finite Automaton)는 같은 언어를 인식하면서도 여러 구조를 가질 수 있습니다. DFA 최소화 알고리즘은 **상태 수를 최소로 줄이면서도 인식 언어는 동일한 DFA**를 생성하는 과정입니다.

이 과정에서 가장 많이 사용되는 두 가지 알고리즘은 다음과 같습니다:

- **Hopcroft’s Algorithm**: 효율적이며 시간 복잡도가 낮다 (\\( O(n \log n) \\))
- **Moore’s Algorithm**: 직관적이며 구현이 간단하지만 느리다 (\\( O(n^2) \\))

---

## 1. Hopcroft’s Algorithm

### 핵심 아이디어

> “가능한 많은 상태를 한꺼번에 분리해서 최소화”

Hopcroft는 초기 파티션을 세밀하게 유지하며, 분리 가능한 상태 집합을 작은 파티션부터 반복적으로 **효율적으로 분할(refinement)**하는 전략을 사용한다.

### 알고리즘 절차

1. **초기 파티션 설정**  
   \\( P = \{F, Q \setminus F\} \\)  
   종료 상태와 비종료 상태를 분리

2. **분할 리스트(worklist) 초기화**  
   \\( W = \{F, Q \setminus F\} \\)

3. **반복문 실행**  
   반복하면서 분할 리스트에서 집합 \\( A \\)를 꺼내고, 모든 입력 심볼 \\( a \in \Sigma \\)에 대해 아래 연산 수행:

   - \\( \text{Pre}(A, a) = \{ q \in Q \mid \delta(q, a) \in A \} \\)
   - 이 집합이 다른 파티션을 분리하면, 해당 파티션을 두 개로 나눈다.
   - 나눠진 파티션은 다시 worklist에 추가

4. **모든 파티션이 안정화되면 종료**

### 시간 복잡도

- 최악의 경우 시간 복잡도:  
  \\( O(n \log n) \\)  
  (n: 상태 수, Σ: 입력 알파벳 수)

### 장점

- 매우 빠르고 효율적 (특히 상태 수가 클 때)
- 이론적으로 최적의 DFA 최소화 알고리즘 중 하나

---

## 2. Moore’s Algorithm

### 핵심 아이디어

> “모든 상태 쌍에 대해 구별 가능성을 반복적으로 체크”

Moore 알고리즘은 **모든 상태 쌍을 검사**하면서 점진적으로 구별되는 상태를 찾아나간다. 구조가 단순하고 직관적이지만, 반복 횟수가 많아질 수 있다.

### 알고리즘 절차

1. **초기 파티션 설정**  
   종료 상태와 비종료 상태로 구분 (\\( F, Q \setminus F \\))

2. **상태 레이블 부여**  
   각 상태에 현재 속한 파티션 번호를 할당

3. **각 상태 쌍에 대해 반복적으로 비교**  
   상태 \\( p, q \\)가 현재 같은 파티션에 속해 있을 때:
   - 모든 입력 심볼 \\( a \\)에 대해 \\( \delta(p, a), \delta(q, a) \\)의 파티션이 같지 않으면, \\( p, q \\)는 구별됨 → 분할 수행

4. **분할이 더 이상 발생하지 않을 때까지 반복**

5. **각 파티션을 새로운 DFA 상태로 구성**

### 시간 복잡도

- \\( O(n^2) \\) 또는 더 느릴 수 있음  
  (특히 반복 횟수가 많은 경우)

### 장점

- 구현이 매우 간단하고 직관적
- 상태 수가 적을 경우 오히려 효율적일 수 있음

---

## 3. 예제 비교

다음 DFA를 고려:

- 상태 집합: \\( Q = \{A, B, C, D, E\} \\)
- 입력: \\( \Sigma = \{0, 1\} \\)
- 종료 상태: \\( \{C, E\} \\)

| 상태 | 0 → | 1 → |
|------|-----|-----|
| A    | B   | C   |
| B    | A   | D   |
| C    | E   | C   |
| D    | E   | D   |
| E    | E   | E   |

### Moore’s 방식

1. P₀ = { {C, E}, {A, B, D} }  
2. 반복적으로 상태 쌍 비교 후 분할
   - 예: A와 B는 다른 전이 결과로 인해 분할됨
3. 최종 파티션 = 최소 DFA 상태

### Hopcroft’s 방식

1. 시작 파티션 = { {C, E}, {A, B, D} }  
2. 작은 파티션({C, E})부터 Pre 연산 수행  
3. 각 전이와 대응 파티션에 따라 반복 분리  
4. 최소 상태 파티션 구성

→ **동일한 결과 DFA**를 도출하지만, Hopcroft 방식은 불필요한 비교를 줄여 속도가 빠름

---

## 4. 두 알고리즘 비교 요약

| 항목 | Hopcroft’s Algorithm | Moore’s Algorithm |
|------|------------------------|--------------------|
| 시간복잡도 | \\( O(n \log n) \\) | \\( O(n^2) \\) |
| 구현 난이도 | 복잡함 | 간단함 |
| 성능 | 빠름 (대규모 DFA) | 느림 (복잡한 DFA) |
| 직관성 | 낮음 | 높음 |
| 실제 사용 | 정규식 엔진, 컴파일러 등 | 교육용, 간단 DFA 분석용 |

---

## 5. 결론

- **Hopcroft**는 성능에 최적화된 알고리즘
- **Moore**는 구조가 단순하고 소형 DFA에 적합
- 둘 다 DFA를 최소화하며, 결과는 언어적으로 **항상 동치**

---

## 6. 참고 코드 구조 (Python 의사코드)

### Hopcroft’s Algorithm 요약

```python
def hopcroft_minimize(DFA):
    P = {F, Q - F}
    W = {F}

    while W:
        A = W.pop()
        for a in Sigma:
            X = {q for q in Q if delta[q][a] in A}
            for Y in P:
                inter, diff = X & Y, Y - X
                if inter and diff:
                    P.remove(Y)
                    P.add(inter)
                    P.add(diff)
                    if Y in W:
                        W.remove(Y)
                        W.add(inter)
                        W.add(diff)
                    else:
                        W.add(min(inter, diff))
    return P
```
