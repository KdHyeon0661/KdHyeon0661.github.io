---
layout: post
title: C# - 파일 입출력과 비동기 처리
date: 2024-10-21 19:20:23 +0900
category: Csharp
---
# C# 파일 입출력과 비동기 처리

## .NET I/O 시스템의 전체 구조

C#의 파일 입출력 시스템은 다양한 추상화 레벨을 제공하여 단순한 파일 조작부터 복잡한 데이터 처리까지 다양한 시나리오를 지원합니다. 핵심은 **스트림(Stream)** 개념으로, 데이터의 흐름을 추상화하여 파일, 메모리, 네트워크 등 다양한 원본을 일관된 방식으로 처리할 수 있습니다. 동기와 비동기 I/O는 각각의 사용 사례가 있으며, 특히 비동기 처리와 `async/await`의 조합은 현대 애플리케이션의 필수 요소가 되었습니다.

---

## 텍스트 파일 작업: 단순성에서 시작하기

### 기본적인 텍스트 파일 처리

가장 단순한 수준에서 텍스트 파일을 다루는 방법은 `File` 클래스의 정적 메서드를 사용하는 것입니다:

```csharp
using System.IO;

// 간단한 텍스트 파일 쓰기
File.WriteAllText("document.txt", "안녕하세요, C# 파일 입출력입니다.");

// 텍스트 파일 읽기
string content = File.ReadAllText("document.txt");
Console.WriteLine(content);

// 여러 줄 쓰기
var lines = new[] { "첫 번째 줄", "두 번째 줄", "세 번째 줄" };
File.WriteAllLines("multiline.txt", lines);

// 여러 줄 읽기
foreach (string line in File.ReadLines("multiline.txt"))
{
    Console.WriteLine(line);
}
```

### 인코딩의 중요성

텍스트 파일을 처리할 때 인코딩은 핵심 고려사항입니다:

```csharp
using System.Text;

// UTF-8로 파일 쓰기 (BOM 없음)
File.WriteAllText("utf8.txt", "유니코드 텍스트", Encoding.UTF8);

// 특정 인코딩으로 읽기
string eucKrText = File.ReadAllText("euckr.txt", Encoding.GetEncoding(51949));

// StreamWriter로 세밀한 제어
using var writer = new StreamWriter("log.txt", true, Encoding.UTF8, 16384);
writer.WriteLine($"[{DateTime.Now:yyyy-MM-dd HH:mm:ss}] 작업 시작");
```

UTF-8은 현대 시스템의 표준 인코딩으로, 국제화와 상호운용성 측면에서 가장 권장되는 선택입니다. 특별한 이유가 없는 한 UTF-8을 기본 인코딩으로 사용하세요.

---

## 스트림 기반 접근: 유연성과 제어

### StreamReader와 StreamWriter 활용

대용량 파일이나 실시간 스트리밍 처리가 필요할 때는 `StreamReader`와 `StreamWriter`를 사용합니다:

```csharp
// 효율적인 파일 읽기
using var reader = new StreamReader("largefile.txt");
string? line;
while ((line = await reader.ReadLineAsync()) != null)
{
    // 라인 단위 처리
    ProcessLine(line);
}

// 효율적인 파일 쓰기
using var writer = new StreamWriter("output.txt", append: true, Encoding.UTF8, bufferSize: 8192);
for (int i = 0; i < 1000; i++)
{
    await writer.WriteLineAsync($"데이터 {i}: {DateTime.Now}");
}
```

### FileStream: 바이너리 데이터의 핵심

바이너리 파일을 처리할 때는 `FileStream`이 기본 도구입니다:

```csharp
// 바이너리 파일 쓰기
using var writeStream = new FileStream("data.bin", FileMode.Create, FileAccess.Write);
byte[] data = { 0x01, 0x02, 0x03, 0x04 };
await writeStream.WriteAsync(data, 0, data.Length);
await writeStream.FlushAsync();

// 바이너리 파일 읽기
using var readStream = new FileStream("data.bin", FileMode.Open, FileAccess.Read);
var buffer = new byte[1024];
int bytesRead = await readStream.ReadAsync(buffer, 0, buffer.Length);
```

### 성능 최적화 옵션

`FileStream`은 다양한 옵션을 통해 성능을 최적화할 수 있습니다:

```csharp
using var optimizedStream = new FileStream(
    path: "performance.dat",
    mode: FileMode.OpenOrCreate,
    access: FileAccess.ReadWrite,
    share: FileShare.Read,
    bufferSize: 65536, // 64KB 버퍼
    options: FileOptions.Asynchronous | FileOptions.SequentialScan | FileOptions.WriteThrough
);
```

- **Asynchronous**: 비동기 I/O 활성화
- **SequentialScan**: 순차적 접근에 대한 힌트 (OS 레벨 프리페칭)
- **WriteThrough**: 캐시 우회 (데이터 손실 방지, 성능은 낮음)

---

## 비동기 I/O: 현대 애플리케이션의 필수 요소

### 왜 비동기 I/O인가?

동기 I/O는 작업이 완료될 때까지 스레드를 차지하지만, 비동기 I/O는 I/O 작업이 진행되는 동안 스레드를 다른 작업에 사용할 수 있습니다. 이는 특히 서버 애플리케이션에서 중요한 성능 향상을 제공합니다.

### 비동기 파일 처리 패턴

```csharp
public async Task ProcessLargeFileAsync(string inputPath, string outputPath)
{
    const int bufferSize = 8192; // 8KB 버퍼
    
    await using var inputStream = new FileStream(
        inputPath, FileMode.Open, FileAccess.Read, FileShare.Read,
        bufferSize, FileOptions.Asynchronous | FileOptions.SequentialScan
    );
    
    await using var outputStream = new FileStream(
        outputPath, FileMode.Create, FileAccess.Write, FileShare.None,
        bufferSize, FileOptions.Asynchronous
    );
    
    var buffer = new byte[bufferSize];
    int bytesRead;
    long totalBytes = inputStream.Length;
    long processedBytes = 0;
    
    while ((bytesRead = await inputStream.ReadAsync(buffer, 0, buffer.Length)) > 0)
    {
        await outputStream.WriteAsync(buffer, 0, bytesRead);
        processedBytes += bytesRead;
        
        // 진행률 보고 (옵션)
        double progress = (double)processedBytes / totalBytes * 100;
        Console.WriteLine($"처리 진행률: {progress:F2}%");
    }
}
```

### 진행률 표시와 취소 지원

사용자 경험을 개선하기 위해 진행률 표시와 취소 기능을 추가할 수 있습니다:

```csharp
public async Task CopyFileWithProgressAsync(
    string sourcePath, 
    string destinationPath,
    IProgress<double> progress = null,
    CancellationToken cancellationToken = default
)
{
    var sourceInfo = new FileInfo(sourcePath);
    long fileSize = sourceInfo.Length;
    long totalBytesRead = 0;
    
    await using var sourceStream = new FileStream(
        sourcePath, FileMode.Open, FileAccess.Read, FileShare.Read,
        65536, FileOptions.Asynchronous
    );
    
    await using var destStream = new FileStream(
        destinationPath, FileMode.Create, FileAccess.Write, FileShare.None,
        65536, FileOptions.Asynchronous
    );
    
    var buffer = new byte[65536];
    int bytesRead;
    
    while ((bytesRead = await sourceStream.ReadAsync(buffer, 0, buffer.Length, cancellationToken)) > 0)
    {
        cancellationToken.ThrowIfCancellationRequested();
        
        await destStream.WriteAsync(buffer, 0, bytesRead, cancellationToken);
        totalBytesRead += bytesRead;
        
        progress?.Report((double)totalBytesRead / fileSize);
    }
}
```

---

## 파일 시스템 작업: 경로와 디렉터리 관리

### 안전한 경로 처리

플랫폼 간 호환성을 유지하기 위해 경로 처리는 항상 `Path` 클래스를 사용해야 합니다:

```csharp
// 올바른 경로 결합
string basePath = Environment.GetFolderPath(Environment.SpecialFolder.MyDocuments);
string fileName = "data.txt";
string fullPath = Path.Combine(basePath, "MyApp", fileName);

// 경로 구성 요소 추출
string directory = Path.GetDirectoryName(fullPath);
string name = Path.GetFileNameWithoutExtension(fullPath);
string extension = Path.GetExtension(fullPath);

// 임시 파일 생성
string tempFile = Path.GetTempFileName();
string tempDirectory = Path.Combine(Path.GetTempPath(), Guid.NewGuid().ToString());
Directory.CreateDirectory(tempDirectory);

// 작업 후 정리
try
{
    // 임시 파일 사용
    await File.WriteAllTextAsync(tempFile, "임시 데이터");
}
finally
{
    // 리소스 정리
    File.Delete(tempFile);
    Directory.Delete(tempDirectory, recursive: true);
}
```

### 디렉터리 작업

```csharp
// 디렉터리 생성 (존재해도 안전)
Directory.CreateDirectory("logs/2024/01");

// 디렉터리 내용 조회
var files = Directory.EnumerateFiles("source", "*.txt", SearchOption.AllDirectories);
foreach (string file in files)
{
    Console.WriteLine($"파일: {file}");
}

// 디렉터리 트리 순회
void TraverseDirectory(string path, int depth = 0)
{
    var indent = new string(' ', depth * 2);
    
    foreach (var file in Directory.GetFiles(path))
    {
        Console.WriteLine($"{indent}📄 {Path.GetFileName(file)}");
    }
    
    foreach (var dir in Directory.GetDirectories(path))
    {
        Console.WriteLine($"{indent}📁 {Path.GetFileName(dir)}");
        TraverseDirectory(dir, depth + 1);
    }
}
```

---

## 실전 패턴과 고급 기법

### 원자적 파일 업데이트

파일 업데이트 중 시스템 장애가 발생해도 데이터가 손상되지 않도록 원자적 업데이트를 구현해야 합니다:

```csharp
public async Task AtomicWriteAsync(string filePath, string content)
{
    string tempPath = filePath + ".tmp";
    
    try
    {
        // 임시 파일에 완전히 쓰기
        await File.WriteAllTextAsync(tempPath, content, Encoding.UTF8);
        
        // 원자적으로 교체
        if (OperatingSystem.IsWindows())
        {
            File.Replace(tempPath, filePath, filePath + ".backup", true);
        }
        else
        {
            // Unix 계열: 이동 작업이 일반적으로 원자적
            File.Move(tempPath, filePath, overwrite: true);
        }
    }
    finally
    {
        // 임시 파일 정리 (실패 시)
        if (File.Exists(tempPath))
        {
            File.Delete(tempPath);
        }
    }
}
```

### 로그 파일 회전(Rolling) 시스템

대규모 애플리케이션에서 로그 관리는 중요한 과제입니다:

```csharp
public class RollingFileLogger
{
    private readonly string _logDirectory;
    private readonly string _baseFileName;
    private readonly long _maxFileSize;
    private readonly int _maxBackupFiles;
    private StreamWriter _currentWriter;
    private long _currentFileSize;

    public RollingFileLogger(string logDirectory, string baseFileName, long maxFileSize = 10 * 1024 * 1024, int maxBackupFiles = 5)
    {
        _logDirectory = logDirectory;
        _baseFileName = baseFileName;
        _maxFileSize = maxFileSize;
        _maxBackupFiles = maxBackupFiles;
        
        Directory.CreateDirectory(logDirectory);
        InitializeCurrentWriter();
    }

    private void InitializeCurrentWriter()
    {
        string currentFilePath = Path.Combine(_logDirectory, $"{_baseFileName}.current.log");
        _currentWriter = new StreamWriter(currentFilePath, true, Encoding.UTF8);
        _currentFileSize = new FileInfo(currentFilePath).Length;
    }

    public async Task LogAsync(string message)
    {
        string logLine = $"[{DateTime.Now:yyyy-MM-dd HH:mm:ss.fff}] {message}";
        long lineSize = Encoding.UTF8.GetByteCount(logLine + Environment.NewLine);
        
        // 파일 크기 체크 및 회전
        if (_currentFileSize + lineSize > _maxFileSize)
        {
            await RotateLogFileAsync();
        }
        
        await _currentWriter.WriteLineAsync(logLine);
        await _currentWriter.FlushAsync();
        _currentFileSize += lineSize;
    }

    private async Task RotateLogFileAsync()
    {
        await _currentWriter.FlushAsync();
        _currentWriter.Dispose();
        
        string currentFilePath = Path.Combine(_logDirectory, $"{_baseFileName}.current.log");
        string timestamp = DateTime.Now.ToString("yyyyMMdd_HHmmss");
        string archivedFilePath = Path.Combine(_logDirectory, $"{_baseFileName}_{timestamp}.log");
        
        // 현재 파일을 아카이브로 이동
        File.Move(currentFilePath, archivedFilePath);
        
        // 압축 (선택적)
        await CompressLogFileAsync(archivedFilePath);
        
        // 오래된 백업 파일 정리
        CleanupOldBackups();
        
        // 새 로그 파일 시작
        InitializeCurrentWriter();
    }

    private async Task CompressLogFileAsync(string filePath)
    {
        string compressedPath = filePath + ".gz";
        
        await using var sourceStream = File.OpenRead(filePath);
        await using var compressedStream = File.Create(compressedPath);
        await using var gzipStream = new GZipStream(compressedStream, CompressionMode.Compress);
        
        await sourceStream.CopyToAsync(gzipStream);
        
        // 원본 파일 삭제
        File.Delete(filePath);
    }

    private void CleanupOldBackups()
    {
        var backupFiles = Directory.GetFiles(_logDirectory, $"{_baseFileName}_*.log.gz")
            .Select(f => new FileInfo(f))
            .OrderByDescending(f => f.CreationTime)
            .ToList();
        
        for (int i = _maxBackupFiles; i < backupFiles.Count; i++)
        {
            backupFiles[i].Delete();
        }
    }

    public async ValueTask DisposeAsync()
    {
        if (_currentWriter != null)
        {
            await _currentWriter.FlushAsync();
            _currentWriter.Dispose();
        }
    }
}
```

### 스트리밍 JSON 처리

대용량 JSON 파일을 메모리 효율적으로 처리하는 방법:

```csharp
using System.Text.Json;

public async IAsyncEnumerable<T> ReadJsonArrayAsync<T>(string filePath)
{
    await using var fileStream = File.OpenRead(filePath);
    
    using var jsonDocument = await JsonDocument.ParseAsync(fileStream);
    var root = jsonDocument.RootElement;
    
    if (root.ValueKind == JsonValueKind.Array)
    {
        foreach (var element in root.EnumerateArray())
        {
            yield return element.Deserialize<T>();
        }
    }
}

// 사용 예
await foreach (var item in ReadJsonArrayAsync<Product>("products.json"))
{
    Console.WriteLine($"상품: {item.Name}, 가격: {item.Price}");
}
```

---

## 예외 처리와 오류 관리

파일 I/O는 다양한 예외 상황에 직면할 수 있으므로 견고한 예외 처리가 필수적입니다:

```csharp
public async Task<string> SafeReadFileAsync(string filePath)
{
    const int maxRetries = 3;
    int retryCount = 0;
    
    while (retryCount < maxRetries)
    {
        try
        {
            return await File.ReadAllTextAsync(filePath, Encoding.UTF8);
        }
        catch (FileNotFoundException ex)
        {
            // 파일이 없는 경우
            Console.WriteLine($"파일을 찾을 수 없습니다: {filePath}");
            throw; // 상위 호출자에게 예외 전파
        }
        catch (DirectoryNotFoundException ex)
        {
            // 디렉터리가 없는 경우
            Console.WriteLine($"디렉터리를 찾을 수 없습니다: {Path.GetDirectoryName(filePath)}");
            throw;
        }
        catch (UnauthorizedAccessException ex)
        {
            // 권한 문제
            Console.WriteLine($"파일에 접근할 권한이 없습니다: {filePath}");
            throw;
        }
        catch (IOException ex) when (ex.HResult == 32) // 공유 위반
        {
            // 다른 프로세스가 파일을 사용 중
            retryCount++;
            Console.WriteLine($"파일이 잠겨 있습니다. 재시도 {retryCount}/{maxRetries}");
            await Task.Delay(100 * retryCount); // 지수 백오프
        }
        catch (IOException ex)
        {
            // 기타 I/O 오류
            Console.WriteLine($"I/O 오류 발생: {ex.Message}");
            throw;
        }
    }
    
    throw new IOException($"파일을 읽을 수 없습니다: {filePath} (최대 재시도 횟수 초과)");
}
```

---

## 성능 고려사항과 모범 사례

### 버퍼 크기 최적화

적절한 버퍼 크기 선택은 I/O 성능에 큰 영향을 미칩니다:

```csharp
public class BufferSizeBenchmark
{
    // 다양한 버퍼 크기로 파일 복사 성능 테스트
    public async Task TestBufferSizesAsync(string sourcePath, string destPath)
    {
        var bufferSizes = new[] { 4096, 8192, 16384, 32768, 65536, 131072, 262144 };
        
        foreach (int bufferSize in bufferSizes)
        {
            var stopwatch = Stopwatch.StartNew();
            await CopyFileWithBufferAsync(sourcePath, destPath, bufferSize);
            stopwatch.Stop();
            
            Console.WriteLine($"버퍼 크기 {bufferSize}바이트: {stopwatch.ElapsedMilliseconds}ms");
        }
    }
    
    private async Task CopyFileWithBufferAsync(string source, string dest, int bufferSize)
    {
        await using var sourceStream = new FileStream(source, FileMode.Open, FileAccess.Read);
        await using var destStream = new FileStream(dest, FileMode.Create, FileAccess.Write);
        
        var buffer = new byte[bufferSize];
        int bytesRead;
        
        while ((bytesRead = await sourceStream.ReadAsync(buffer, 0, buffer.Length)) > 0)
        {
            await destStream.WriteAsync(buffer, 0, bytesRead);
        }
    }
}
```

### 메모리 스트림 활용

작은 파일이나 임시 데이터의 경우 `MemoryStream`을 사용할 수 있습니다:

```csharp
public async Task<byte[]> ProcessInMemoryAsync(string filePath)
{
    // 파일을 메모리로 읽기
    await using var fileStream = File.OpenRead(filePath);
    using var memoryStream = new MemoryStream();
    
    await fileStream.CopyToAsync(memoryStream);
    
    // 메모리에서 처리
    memoryStream.Position = 0;
    byte[] processedData = await ProcessStreamAsync(memoryStream);
    
    return processedData;
}

private async Task<byte[]> ProcessStreamAsync(Stream stream)
{
    // 스트림 처리 로직
    var buffer = new byte[stream.Length];
    await stream.ReadAsync(buffer, 0, buffer.Length);
    return buffer;
}
```

---

## 결론

C#의 파일 I/O 시스템은 단순한 파일 조작부터 복잡한 데이터 처리 파이프라인까지 다양한 요구사항을 충족할 수 있는 강력한 도구들을 제공합니다. 효과적인 파일 I/O 구현을 위한 핵심 원칙은 다음과 같습니다:

1. **추상화 수준 선택**: 작업의 복잡도에 맞는 적절한 추상화 수준을 선택하세요. 간단한 작업에는 `File` 클래스의 정적 메서드를, 복잡한 처리는 스트림 기반 API를 사용하세요.

2. **비동기 패턴 채택**: 현대 애플리케이션에서는 응답성과 확장성을 위해 비동기 I/O를 기본으로 사용하세요. `async/await` 패턴은 코드 가독성을 유지하면서 비동기 작업을 쉽게 구현할 수 있게 해줍니다.

3. **리소스 관리**: 파일 핸들과 스트림은 한정된 시스템 리소스입니다. `using` 문과 `IAsyncDisposable`을 사용하여 적시에 리소스를 해제하세요.

4. **오류 처리 강화**: 파일 시스템은 다양한 예외 상황(파일 없음, 권한 부족, 디스크 공간 부족 등)에 노출됩니다. 견고한 예외 처리와 재시도 메커니즘을 구현하세요.

5. **성능 고려**: 버퍼 크기, 파일 옵션, 압축, 스트리밍 처리 등을 고려하여 성능을 최적화하세요. 특히 대용량 파일 처리는 메모리 사용량을 신중하게 관리해야 합니다.

6. **플랫폼 호환성**: 경로 구분자, 파일 시스템 권한, 원자적 작업 등을 플랫폼 독립적으로 처리하세요. `Path` 클래스와 환경 검사를 활용하세요.

7. **데이터 무결성 보장**: 중요한 데이터의 경우 원자적 쓰기, 트랜잭션 로깅, 체크섬 검증 등을 통해 데이터 무결성을 보장하세요.

파일 I/O는 많은 애플리케이션의 핵심 기능이지만, 동시에 성능 병목과 오류의 주요 원인이 될 수 있습니다. 이러한 도구들과 패턴들을 이해하고 적절히 적용하면 안정적이고 효율적인 파일 기반 애플리케이션을 구축할 수 있습니다.