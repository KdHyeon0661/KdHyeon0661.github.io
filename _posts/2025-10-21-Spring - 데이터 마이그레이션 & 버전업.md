---
layout: post
title: Spring - 데이터 마이그레이션 & 버전업
date: 2025-10-21 21:25:23 +0900
category: Spring
---
# 25. 데이터 마이그레이션 & 버전업 — 스키마 관리(Flyway/Liquibase), 레거시→부트 이전, 롤링 마이그레이션/이중 쓰기

> 목표: **무중단(또는 최소 다운타임)**으로 스키마/데이터를 진화시키고, **레거시 시스템**을 **Spring Boot** 기준으로 이전하며, **롤링 마이그레이션/이중 쓰기**로 안전하게 전환한다.
> 기준: Spring Boot 3.3+, Java 21, RDB(PostgreSQL 예시), GitOps/Helm, CI/CD는 GitHub Actions·Argo CD 가정.

---

## A. 스키마 관리 개론 — 원칙과 흐름

### A-1. 기본 원칙(Expand → Migrate → Contract)
1) **Expand**: 뒤 호환 추가(새 컬럼/인덱스/테이블). 기존 코드와 **동시 호환**.
2) **Migrate**: 데이터 백필/전환 작업(일괄 또는 점진).
3) **Contract**: 더는 쓰지 않는 컬럼/인덱스/코드 제거(충분한 관찰 기간 이후).

→ 항상 **두 버전 코드가 공존** 가능한 스키마부터 만들고, **배포는 작고 자주**.

### A-2. “스키마 변경 = 코드 변경”을 같은 PR로 묶지 않기
- 보통 2~3 단계 PR/릴리스:
  - PR1: Expand(스키마만) → 배포
  - PR2: 애플리케이션이 새 스키마 사용(읽기/쓰기 전환) → 배포
  - PR3: Contract(구스키마 제거) → 배포

### A-3. 마이그레이션 유형
- **DDL**: 테이블/컬럼/인덱스/제약.
- **DML**: 백필(Backfill), 정규화/분할, ID 재부여.
- **데이터 이동**: 레거시 DB → 신규 DB, 혹은 모놀리식 테이블 → 컨텍스트별 테이블.
- **운영 도구**: Flyway/Liquibase, Spring Batch, 외부 ETL/CDC(Debezium), 온라인 DDL(PG CONCURRENTLY, MySQL PT-OSC/gh-ost).

---

## B. Flyway로 스키마 버전 관리

### B-1. 의존 & 설정
```kotlin
dependencies {
  implementation("org.flywaydb:flyway-core")
  runtimeOnly("org.postgresql:postgresql")
}
```
```yaml
spring:
  flyway:
    enabled: true
    locations: classpath:db/migration
    baseline-on-migrate: true   # 기존 DB에 도입 시
    out-of-order: false
    connect-retries: 3
```

### B-2. 버전 파일 네이밍
- `V<버전>__<설명>.sql` 또는 자바 마이그레이션.
- 예: `V1__init.sql`, `V2__add_orders_table.sql`, `V3__add_index_orders_created_at.sql`

### B-3. Expand 예시(SQL)
```sql
-- db/migration/V2__add_orders_table.sql
CREATE TABLE orders (
  id           varchar(26) PRIMARY KEY,
  customer_id  varchar(26) NOT NULL,
  status       varchar(20) NOT NULL,
  total_amount numeric(18,2) NOT NULL DEFAULT 0,
  created_at   timestamp with time zone NOT NULL DEFAULT now(),
  updated_at   timestamp with time zone NOT NULL DEFAULT now()
);
-- 뒤 호환: 새 코드가 오기 전, 기존 기능에 영향없도록 별도 테이블 생성
```

### B-4. 인덱스/락 최소화(동시성 인덱스)
```sql
-- db/migration/V3__idx_orders_created_at.sql
CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_orders_created_at ON orders (created_at);
-- Liquibase면 <createIndex concurrent="true">
```

> **주의**: `CREATE INDEX CONCURRENTLY`는 트랜잭션 블록 내에서 실행 불가.
> Flyway는 `repeatable sql migrate` 또는 `mixed` 모드 없이도 실행할 수 있도록 파일 단위로 운용(스키마락과 충돌 주의).

### B-5. DML 백필(Chunking)
```sql
-- db/migration/V4__add_slug_and_backfill.sql
ALTER TABLE products ADD COLUMN slug text;
-- 백필은 대용량이면 SQL만으로는 위험 → 배치(아래) 권장. 소량이면 아래와 같이 구간 나눠 수행.
UPDATE products SET slug = lower(regexp_replace(name, '[^a-zA-Z0-9]+','-','g'))
WHERE slug IS NULL AND id BETWEEN 1 AND 100000;
```

### B-6. Java 기반(MigrationRunner) — 점진 백필
```java
@Component
@RequiredArgsConstructor
public class ProductSlugBackfill implements ApplicationRunner {
  private final JdbcTemplate jdbc;
  @Value("${backfill.product-slug.enabled:false}") boolean enabled;

  @Override public void run(ApplicationArguments args) {
    if (!enabled) return;
    int batch = 5000;
    Long last = 0L;
    while (true) {
      var rows = jdbc.queryForList("""
         SELECT id, name FROM products WHERE slug IS NULL AND id > ? ORDER BY id LIMIT ?
      """, last, batch);
      if (rows.isEmpty()) break;
      rows.forEach(r -> {
        var id = ((Number) r.get("id")).longValue();
        var slug = ((String) r.get("name")).toLowerCase().replaceAll("[^a-z0-9]+", "-");
        jdbc.update("UPDATE products SET slug=? WHERE id=?", slug, id);
        last = id;
      });
      try { Thread.sleep(50); } catch (InterruptedException ignored) {}
    }
  }
}
```
> **스위치 플래그**로 활성화/비활성 제어(배포 중 점진 실행).
> 더 규모가 크면 **Spring Batch**(아래 G절).

### B-7. Contract(제거)
```sql
-- db/migration/V10__drop_legacy_columns.sql
ALTER TABLE orders DROP COLUMN old_status;  -- 전환 후 충분히 안정화된 다음
```

---

## C. Liquibase로 스키마 관리(대안)

### C-1. 의존 & 기본 changelog
```kotlin
dependencies { implementation("org.liquibase:liquibase-core") }
```
`src/main/resources/db/changelog/db.changelog-master.yaml`
```yaml
databaseChangeLog:
  - changeSet:
      id: 001-init
      author: you
      changes:
        - createTable:
            tableName: orders
            columns:
              - column: { name: id, type: varchar(26), constraints: { primaryKey: true } }
              - column: { name: customer_id, type: varchar(26), constraints: { nullable: false } }
              - column: { name: status, type: varchar(20), constraints: { nullable: false } }
              - column: { name: total_amount, type: numeric(18,2), defaultValueNumeric: 0, constraints: { nullable: false } }
              - column: { name: created_at, type: timestamp with time zone, defaultValueComputed: now() }
              - column: { name: updated_at, type: timestamp with time zone, defaultValueComputed: now() }
  - changeSet:
      id: 002-idx-created
      author: you
      changes:
        - createIndex:
            tableName: orders
            indexName: idx_orders_created_at
            columns: [ { column: { name: created_at } } ]
            concurrent: true
```

### C-2. Rollback 명세(있으면 모범)
```yaml
  - changeSet:
      id: 003-add-slug
      author: you
      changes:
        - addColumn:
            tableName: products
            columns:
              - column: { name: slug, type: text }
      rollback:
        - dropColumn:
            columnName: slug
            tableName: products
```

> Liquibase 장점: **명시적 rollback**, **preconditions**(조건부 실행).
> 단점: 팀 선호/러닝커브, PR diff 가독성(대규모 YAML).

---

## D. 레거시 → Spring Boot 이전 전략(데이터 & 트래픽)

### D-1. 전환 모델: Strangler Fig(덩굴무화과) 패턴
1) **프런트 도메인/엔드포인트**를 **게이트웨이**로 집결.
2) 하나씩 **신규(부트) 모듈**로 라우팅, 나머지는 레거시에 남김.
3) 점진적으로 라우팅을 바꿔 **레거시 수축 → 제거**.

### D-2. 데이터 이전 Topology
- **단발성 이관**(downtime): 스냅샷 → 검증 → 컷오버(소규모/사내툴).
- **점진 이관(무중단)**:
  - **Shadow Read**: 신규 서비스가 **레거시 DB**에서 읽기만(검증).
  - **Dual-Write**: 레거시/신규 DB 동시 기록 → 신규에서 읽기 스위치.
  - **CDC**: 레거시 DB 변경 로그를 구독(Debezium) → 신규 DB에 반영.

### D-3. 리스크/결정표
| 방법 | 다운타임 | 복잡도 | 검증 난이도 | 주의 |
|---|---|---|---|---|
| 스냅샷 + 컷오버 | 짧거나 가끔 길다 | 낮음 | 중간 | 트래픽 정지/재시작 시나리오 필요 |
| Dual-Write | 없음 | 중간~높음 | 높음 | 멱등성/순서/에러처리 |
| CDC | 없음 | 높음 | 중간 | Debezium/로그 접근/스키마 진화 |

---

## E. 롤링 마이그레이션(Zero/Low Downtime) 패턴

### E-1. API 레벨 롤링
- **읽기 전환**: `GET`/조회부터 신규 서비스로 라우팅(Shadow 검증 후).
- **쓰기 전환**: Dual-Write로 안전판을 두고, 검증 후 **single-write**로 절체.
- **Contract** 단계에서 레거시 쓰기 중단 → 최종 제거.

### E-2. DB 레벨 롤링
- 스키마 변경은 **뒤 호환**으로 먼저.
- 인덱스/제약 추가는 **온라인**(PG CONCURRENTLY / MySQL PT-OSC).
- 컬럼 타입 변경은 **새 컬럼 추가 + 백필 + 코드 전환 + 구컬럼 삭제**.

### E-3. 읽기/쓰기 스위치 — 피처 플래그/환경변수
```yaml
migration:
  readSource: LEGACY         # LEGACY | NEW | MIRROR(검증용)
  writeMode: DUAL            # LEGACY_ONLY | DUAL | NEW_ONLY
```

```java
@Service
@RequiredArgsConstructor
class OrderGateway {
  private final LegacyRepo legacy;
  private final NewRepo neo;
  private final MigrationProps props;

  public OrderView get(String id){
    return switch (props.readSource()) {
      case LEGACY -> legacy.findView(id);
      case NEW    -> neo.findView(id);
      case MIRROR -> { // Shadow Read 비교 로그
         var a = legacy.findView(id); var b = neo.findView(id);
         if (!a.equals(b)) log.warn("shadow-mismatch id={}", id);
         yield a; // 고객 영향 최소화
      }
    };
  }

  @Transactional
  public void create(OrderCreate cmd){
    switch (props.writeMode()) {
      case LEGACY_ONLY -> legacy.create(cmd);
      case DUAL -> {
        try { legacy.create(cmd); } finally { // 실패 전파 전략 선택
          try { neo.create(cmd); } catch (Exception e){ log.error("dual-write new failed", e); }
        }
      }
      case NEW_ONLY -> neo.create(cmd);
    }
  }
}
```

> Dual-Write는 **정합성** 이슈(부분 실패, 순서, 중복)에 취약 → 되도록 **Outbox/CDC** 기반 이벤트 전파로 대체.

---

## F. 이중 쓰기 구현 패턴

### F-1. Outbox + Consumer(권장)
1) 쓰기 트랜잭션에서 **도메인 이벤트**를 Outbox 테이블에 함께 기록.
2) **Outbox Consumer**(배치/스트리머)가 읽어 **신규 DB/서비스**에 반영(멱등).
3) 성공 시 Outbox 레코드 **확정/삭제**.

**Outbox 테이블**
```sql
CREATE TABLE outbox (
  id bigserial primary key,
  aggregate_type text not null,
  aggregate_id text not null,
  type text not null,         -- event type
  payload jsonb not null,
  created_at timestamptz not null default now(),
  sent_at timestamptz
);
CREATE INDEX CONCURRENTLY idx_outbox_unsent ON outbox (sent_at) WHERE sent_at IS NULL;
```

**Publish (쓰기 트랜잭션 안)**
```java
@Transactional
public void placeOrder(PlaceOrder cmd){
  var order = createOrder(cmd);
  repo.save(order);
  outbox.save(new Outbox("Order", order.id(), "OrderPlaced", toJson(order)));
}
```

**Consumer(스케줄러/카프카/직접 호출)**
```java
@Scheduled(fixedDelayString = "PT2S")
void flush() {
  var batch = outbox.findUnsent(500);
  for (var e : batch) {
    try {
      neo.apply(e);                  // 신규 DB/서비스 반영(멱등 키 사용)
      outbox.markSent(e.id());
    } catch (Exception ex) {
      log.error("outbox deliver failed {}", e.id(), ex); // 재시도/보류 큐
    }
  }
}
```

**멱등 키**
- 신규 시스템에 **Idempotency-Key**(예: Outbox id) 헤더/컬럼으로 중복 차단.

### F-2. Debezium(CDC) 기반
- 레거시 DB binlog/WRITE-AHEAD LOG를 구독 → 신규 DB로 ETL.
- 장점: 애플리케이션 변경 최소.
- 단점: 인프라/보안/로그 접근, 스키마 진화 매핑 필요.

---

## G. 대규모 백필 — Spring Batch 예제

### G-1. 의존
```kotlin
dependencies {
  implementation("org.springframework.boot:spring-boot-starter-batch")
  runtimeOnly("org.postgresql:postgresql")
}
```

### G-2. 잡/스텝(청크) 구성
```java
@Configuration
@EnableBatchProcessing
@RequiredArgsConstructor
class BackfillJobConfig {

  private final JobRepository repo;
  private final PlatformTransactionManager tx;

  @Bean
  Job backfillProductSlugJob(Step step) {
    return new JobBuilder("backfillProductSlugJob", repo)
      .start(step).build();
  }

  @Bean
  Step step(ItemReader<Product> reader, ItemProcessor<Product, Product> proc, ItemWriter<Product> writer) {
    return new StepBuilder("slugStep", repo)
      .<Product, Product>chunk(1000, tx)
      .reader(reader)
      .processor(proc)
      .writer(writer)
      .faultTolerant().retryLimit(3).retry(Exception.class)
      .build();
  }

  @Bean
  JdbcPagingItemReader<Product> reader(DataSource ds) {
    var r = new JdbcPagingItemReader<Product>();
    r.setDataSource(ds);
    r.setFetchSize(1000);
    r.setRowMapper((rs,i)-> new Product(rs.getLong("id"), rs.getString("name")));
    var q = new PostgresPagingQueryProvider();
    q.setSelectClause("id, name");
    q.setFromClause("from products");
    q.setWhereClause("where slug is null");
    q.setSortKeys(Map.of("id", Order.ASCENDING));
    r.setQueryProvider(q);
    return r;
  }

  @Bean
  ItemProcessor<Product, Product> processor() {
    return p -> p.withSlug(slugify(p.name()));
  }

  @Bean
  JdbcBatchItemWriter<Product> writer(DataSource ds) {
    var w = new JdbcBatchItemWriter<Product>();
    w.setDataSource(ds);
    w.setSql("update products set slug=:slug where id=:id");
    w.setItemSqlParameterSourceProvider(new BeanPropertyItemSqlParameterSourceProvider<>());
    return w;
  }
}
```

> 운영 팁: **분할 실행**(파티셔닝), **스로틀/백오프**, **야간 윈도우**, **락/IO 스파이크** 감시.

---

## H. 데이터 품질 검증 & 검수(리허설)

### H-1. 샘플/전수 검증 전략
- **Row count 매칭**(테이블/조건별).
- **해시/체크섬**: 중요 열을 연결해 SHA-256 비교.
- **도메인 제약**: not null/범위/유일성/참조 무결성.
- **샘플링**: PPP(Percent-Percent-Percent) 샘플(1%, 5%, 10%) 비교.

**검증 SQL 예**
```sql
-- count
SELECT (SELECT count(*) FROM legacy.orders) AS legacy_cnt,
       (SELECT count(*) FROM new.orders)    AS new_cnt;

-- 해시
SELECT md5(string_agg(id || '|' || total_amount || '|' || status, ',' ORDER BY id))
FROM legacy.orders WHERE created_at >= now() - interval '1 day';
```

### H-2. 리허설(드라이런)
- **Stage DB**에 실제 크기와 유사한 샘플/복제 데이터 → 마이그 잡/DDL을 **같은 스크립트**로 반복.
- 수행 시간, 락/CPU/IO를 측정 → 본 이관의 **윈도우/스루풋** 가늠.

---

## I. 무중단 배포와 스키마 버전 호환성

### I-1. 규칙(요약)
- **서버는 구·신 스키마 모두 이해**해야 한다(읽기/쓰기 중간단계).
- **NOT NULL 추가**는 **DEFAULT**와 함께, 혹은 **3단계**(컬럼 추가→백필→NOT NULL).
- **열 타입 변경**은 새 열로 복사(캐리/캐리), 뷰/동의어로 호환.
- **PK 변경**은 **새 키 생성 + 레퍼런스 업데이트 + 전환**(난이도 높음 → 피함).

### I-2. API 계약 버전
- **v1/v2 병행** + 게이트웨이 라우팅.
- DB 스키마 변경을 API 버전과 **강결합하지 않기**(DTO/DAO 매핑에서 흡수).

---

## J. 운영 체크리스트(마이그레이션 당일)

1) **준비**
   - [ ] 최신 백업/스냅샷, 롤백 계획(스위치 되돌림/DB 스냅샷 복원)
   - [ ] 모니터링 대시(에러율/p95/DB 잠금/CPU/IO)
   - [ ] **커뮤니케이션 채널**(War Room/슬랙/줌)
   - [ ] 플래그 기본값/토글 스크립트 준비

2) **실행**
   - [ ] Expand DDL 적용
   - [ ] Shadow Read on → mismatch 로그/지표 수집
   - [ ] Backfill 시작(청크/스로틀)
   - [ ] Dual-Write on(혹은 CDC 연결)
   - [ ] 읽기 소스 NEW로 스위치
   - [ ] 일정 시간 관찰(30~120분)

3) **사후**
   - [ ] Dual-Write off, Legacy write 차단
   - [ ] Contract DDL(제거) 예약(며칠~몇 주 후)
   - [ ] Postmortem & 성능/비용 평가

---

## K. 실패·롤백 시나리오

- **지연 급증**: Backfill Throttle↑(청크/슬립), 야간으로 이동, 인덱스 추가.
- **정합성 이슈**: Dual-Write 중 신규 DB 반영 실패 → **Idempotency**로 재처리, Outbox 재전송.
- **CDC 지연**: 슬롯/오프셋 점검, 큐 적재율 한도.
- **컷오버 실패**: **즉시 스위치 복구**(읽기/쓰기 플래그 원복), 최근 변경분 재동기화 스크립트 실행.
- **DDL 롤백**: Liquibase rollback 명세 또는 역 DDL(주의: 데이터 소실 방지).

---

## L. 성능·잠금 최소화 팁(포스트그레스 기준)

- 대형 테이블 인덱스: **`CREATE INDEX CONCURRENTLY`**
- 컬럼 추가는 빠르나 **기본값 기록**은 테이블 전체 재쓰기 → **DEFAULT 없이 추가** 후 **백필** → **DEFAULT+NOT NULL**.
- 대량 업데이트는 **배치 크기**(예: 5k~20k) & **작은 트랜잭션**.
- 빈번 조회 칼럼에 **파셜 인덱스**(WHERE 조건).
- 아카이브/히스토리는 **파티션 테이블**.
- Autovacuum 튜닝: `autovacuum_vacuum_cost_limit`, `naptime` 조절, 대량 삭제 후 `VACUUM (FULL)`은 오프피크에.

---

## M. 예제: “회원 테이블 이메일 정규화” (완전체 흐름)

### M-1. 요구
- 기존 `members(email text)`가 대소문자/공백 혼재.
- 목표: **정규화 컬럼 `email_norm`** 추가, **유니크** 제약.

### M-2. 단계

1) **Expand**
```sql
-- V101__add_email_norm.sql
ALTER TABLE members ADD COLUMN email_norm citext;   -- citext(대소문 구분 없이 비교)
-- 인덱스는 당장 유니크 걸지 않고 보조 인덱스만
CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_members_email_norm ON members (email_norm);
```

2) **Backfill (Batch)**
```java
// 청크 10k, lower(trim(email)) -> email_norm
```

3) **Code switch**
- 쓰기 시 `email_norm = normalize(email)` 저장.
- 조회/로그인 시 `WHERE email_norm = normalize(input)`.

4) **유니크 제약 추가(검증 후)**
```sql
-- V104__unique_email_norm.sql
ALTER TABLE members ADD CONSTRAINT uq_members_email_norm UNIQUE USING INDEX idx_members_email_norm;
```

5) **Contract**
```sql
-- V110__drop_email.sql
ALTER TABLE members DROP COLUMN email;
```

---

## N. 예제: “모놀리식 orders → 주문/결제 분리” (MSA 전환)

1) **신규 스키마 설계**: `orders(id, customer_id, total, ...)`, `payments(id, order_id, status, amount, ...)`
2) **Outbox 이벤트**: `OrderPlaced`, `PaymentCaptured`
3) **Neo 서비스(주문)**는 자체 DB 소유.
4) **CDC/Outbox Consumer**가 레거시 주문 변경을 신규 주문 DB로 반영(멱등).
5) **게이트웨이**는 `GET /orders`를 신규로 라우팅(Shadow → NEW), `POST /orders`는 Dual-Write.
6) 관찰/정합성 검증 후 레거시 경로 차단 → **완전 전환**.

---

## O. CI/CD에 녹이는 법

- **스키마 린트**: `sqlfluff`/`schemacrawler`로 DDL 규칙(이름 규약/NOT NULL 등).
- **마이그 테스트**: CI에서 **깨끗한 DB**에 Flyway/Liquibase 적용 → 통합 테스트 실행.
- **DB 마이그 전용 워크플로**: prod 배포 전 **DDL만 선적용**(승인 필요), 애플리케이션 배포는 그 이후.
- **메트릭/알람**: 마이그레이션 잡 동안 DB CPU/IO/락/슬로우쿼리 알람 레벨 하향/특수 대시 사용.

---

## P. 문서화 & 거버넌스

- **Change Record**: 각 ChangeSet에 “이유/리스크/롤백/모니터링 지표”를 기록.
- **데이터 분류**(PII/민감정보)와 **마스킹 전략**(백필/로그/검증).
- **소유권**: 테이블/스키마마다 **DRI(책임자)** 명시.
- **데이터 계약**: 서비스 간 **스키마/이벤트 스키마(AsyncAPI/Schema Registry)** 버저닝.

---

## Q. 한 페이지 요약

- 스키마 진화는 **Expand → Migrate → Contract**의 3박자.
- **Flyway/Liquibase**로 버전 추적·재현 가능성을 확보하고, 대용량 백필은 **Spring Batch/CDC**로 안전하게.
- 레거시 이전은 **게이트웨이 + Shadow Read + Dual-Write(혹은 CDC)**로 **무중단** 전환.
- 이중 쓰기는 **Outbox + 멱등 키**로 견고하게 만들고, 컷오버는 **플래그/PR**로 되돌릴 수 있어야 한다.
- 모든 단계에서 **관측/검증/런북/롤백 계획**이 먼저 준비되어야 한다.
