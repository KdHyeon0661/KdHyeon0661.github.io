---
layout: post
title: 딥러닝 - 실시간 최적화
date: 2025-10-02 23:25:23 +0900
category: 딥러닝
---
# 실시간 최적화 총정리
**TensorRT 적용 개론 · 입력 해상도 전략 · 타일링 · NMS 가속**

> 목표: “초당 X 프레임” 또는 “P95 지연 Y ms” 목표를 **엔드투엔드**로 달성하기 위한  
> 1) **TensorRT 변환**(ONNX/PTQ/QAT/프로파일링) →  
> 2) **입력 해상도/마이크로배치** →  
> 3) **타일링(대해상도/멀티스트림)** →  
> 4) **NMS·후처리 GPU 가속**까지  
> 개념+코드+실무 체크리스트를 한 번에 제공합니다.  
> 프레임워크: PyTorch → ONNX → TensorRT (Python API), 필요 시 Triton 배포를 간단 언급합니다.

---

## 0) 성능 목표를 수치로 정의하기
실시간(Real-time)은 맥락에 따라 다릅니다. 지표를 먼저 고정하세요.

- **지연(latency)**: P50/P95/P99 _(단위: ms)_  
  - 온라인 서비스는 **P95 이하**를 KPI로 삼는 일이 많습니다.
- **스루풋(throughput)**: FPS 또는 RPS  
- **비용**: GPU·CPU 점유율, 전력, 메모리 상한
- **품질**: mAP/mIoU/OKS 같은 정확도 회귀(수치 검증)

**레이턴시 예산 분해**
```
디코드/입력 → 전처리 → 추론 → 후처리(NMS 등) → 포맷/전송
```
각 구간의 시간과 변동 폭(표준편차)을 측정하고, 큰 구간부터 최적화합니다.

---

## 1) TensorRT 개론

### 1.1 무엇을 해주는가?
- **그래프 최적화**: Conv+BN+Act **레이어 융합**, 상수 폴딩, 커널 선택(tactic)  
- **정밀도 축소**: FP32 → **FP16/BF16** → **INT8**(PTQ/QAT)  
- **메모리/스케줄링**: 텐서 생명주기 최적화, 스트림/커널 배치  
- **다이내믹 셰이프** 최적화 프로파일(최소/최적/최대)  
- **플러그인**: NonMaxSuppression, EfficientNMS, ROIAlign, DeformConv 등

### 1.2 빌딩 블록
- `NetworkDefinition`(ONNX에서 파싱)  
- `BuilderConfig`(정밀도/워크스페이스/플래그)  
- `OptimizationProfile`(다이내믹 입력 범위)  
- `Engine(Plan)`(직렬화, 런타임 로딩)  
- `ExecutionContext`(실행 핸들, 바인딩 셰이프 설정)

### 1.3 정확도 전략
- **FP16/BF16**: 대부분 안전, 정확도 손실 극히 미미.  
- **INT8**: 
  - **PTQ**(사후 양자화): 대표 샘플로 통계 **캘리브레이션** → 쉽고 빠름.  
  - **QAT**(학습 중 양자화): 정확도 **최상**. (FakeQuant + ONNX Export + TRT 빌드)

---

## 2) PyTorch → ONNX → TensorRT: 미니 레시피

### 2.1 PyTorch → ONNX 내보내기
```python
import torch
from pathlib import Path

def export_onnx(model, onnx_path="model.onnx", opset=17, dynamic=True):
    model.eval()
    dummy = torch.randn(1, 3, 640, 640)  # 예: detector
    input_names  = ["images"]
    output_names = ["cls", "bbox"]  # 또는 ["logits"] 등 모델에 맞게
    dynamic_axes = {"images": {0: "batch", 2: "h", 3: "w"}}
    with torch.no_grad():
        torch.onnx.export(model, dummy, onnx_path, opset_version=opset,
                          input_names=input_names, output_names=output_names,
                          dynamic_axes=dynamic_axes if dynamic else None,
                          do_constant_folding=True)
    print("Saved:", Path(onnx_path).resolve())
```
> 팁  
> - **ONNX opset**은 17 이상 권장(최근 NMS/정규화 등 지원 풍부).  
> - **동적 축**(B/H/W) 지정 시 TRT에서 **Optimization Profile**을 만들어야 합니다.

### 2.2 TensorRT 엔진 빌드(Python API)
```python
import tensorrt as trt

def build_engine_from_onnx(onnx_path, plan_path, 
                           fp16=True, int8=False, calibrator=None,
                           max_workspace=(1<<30),  # 1GB
                           min_shape=(1,3,320,320),
                           opt_shape=(1,3,640,640),
                           max_shape=(4,3,1280,1280)):
    logger = trt.Logger(trt.Logger.WARNING)
    builder = trt.Builder(logger)
    network_flags = (1<<int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH))
    network = builder.create_network(flags=network_flags)
    parser = trt.OnnxParser(network, logger)

    with open(onnx_path, "rb") as f:
        assert parser.parse(f.read()), f"ONNX parse failed: {parser.get_error(0)}"

    config = builder.create_builder_config()
    config.set_memory_pool_limit(trt.MemoryPoolType.WORKSPACE, max_workspace)

    profile = builder.create_optimization_profile()
    inp = network.get_input(0)  # "images"
    profile.set_shape(inp.name, min_shape, opt_shape, max_shape)
    config.add_optimization_profile(profile)

    if fp16 and builder.platform_has_fast_fp16:
        config.set_flag(trt.BuilderFlag.FP16)
    if int8 and builder.platform_has_fast_int8:
        config.set_flag(trt.BuilderFlag.INT8)
        assert calibrator is not None, "INT8 needs calibrator (PTQ)"
        config.int8_calibrator = calibrator

    engine = builder.build_engine(network, config)
    with open(plan_path, "wb") as f:
        f.write(engine.serialize())
    print("Built TRT plan:", plan_path)
```

### 2.3 INT8 캘리브레이터(Entropy/MinMax)
```python
import numpy as np, tensorrt as trt, pycuda.driver as cuda

class ImageBatchStream:
    def __init__(self, paths, batch, shape):
        self.batch = batch; self.shape = shape
        self.ptr = 0
        self.data = [self.preprocess(p) for p in paths]
    def preprocess(self, path):
        # 사용자 전처리(리사이즈/정규화) 적용 후 NCHW float32
        import cv2
        img = cv2.imread(path)[:,:,::-1]  # BGR->RGB
        img = cv2.resize(img, (self.shape[3], self.shape[2]))
        arr = (img.astype(np.float32)/255.).transpose(2,0,1)
        return arr
    def next_batch(self):
        if self.ptr >= len(self.data): return None
        batch = self.data[self.ptr:self.ptr+self.batch]
        self.ptr += self.batch
        if len(batch) < self.batch:
            # pad
            batch += [batch[-1]]*(self.batch-len(batch))
        return np.ascontiguousarray(batch, dtype=np.float32)

class EntropyCalibrator(trt.IInt8EntropyCalibrator2):
    def __init__(self, stream, cache="calib.cache"):
        super().__init__()
        self.stream = stream; self.cache = cache
        self.d_input = cuda.mem_alloc(np.prod(self.stream.shape)*4*self.stream.batch)
    def get_batch_size(self): return self.stream.batch
    def get_batch(self, names):
        batch = self.stream.next_batch()
        if batch is None: return None
        cuda.memcpy_htod(self.d_input, batch)  # host->device
        return [int(self.d_input)]
    def read_calibration_cache(self):
        try: return open(self.cache, "rb").read()
        except: return None
    def write_calibration_cache(self, cache):
        open(self.cache, "wb").write(cache)
```

---

## 3) 런타임 추론: 바인딩/스트림/비동기

```python
import numpy as np, tensorrt as trt, pycuda.driver as cuda, pycuda.autoinit

class TRTModule:
    def __init__(self, plan_path):
        logger = trt.Logger(trt.Logger.ERROR)
        with open(plan_path, "rb") as f, trt.Runtime(logger) as rt:
            self.engine = rt.deserialize_cuda_engine(f.read())
        self.ctx = self.engine.create_execution_context()
        self.stream = cuda.Stream()
        self.bindings = [None]*self.engine.num_io_tensors

    def infer(self, input_np):
        # 1) shapes
        b, c, h, w = input_np.shape
        self.ctx.set_input_shape("images", (b,c,h,w))
        # 2) allocate
        d_in  = cuda.mem_alloc(input_np.nbytes)
        cuda.memcpy_htod_async(d_in, input_np, self.stream)
        self.bindings[self.engine.get_binding_index("images")] = int(d_in)
        # 3) outputs (예: "cls","bbox")
        outs = {}
        for name in self.engine.get_output_names():
            shape = tuple(self.ctx.get_tensor_shape(name))
            nbytes = np.dtype(np.float32).itemsize * int(np.prod(shape))
            d_out = cuda.mem_alloc(nbytes)
            self.bindings[self.engine.get_binding_index(name)] = int(d_out)
            outs[name] = (d_out, shape)
        # 4) enqueue
        self.ctx.execute_async_v3(self.stream.handle)
        # 5) D2H
        host_out = {}
        for name,(d_out,shape) in outs.items():
            buf = np.empty(shape, dtype=np.float32)
            cuda.memcpy_dtoh_async(buf, d_out, self.stream)
            host_out[name] = buf
        self.stream.synchronize()
        return host_out
```

> 팁  
> - **Pinned Memory** 사용으로 H2D/D2H 속도 개선.  
> - **CUDA Graphs**는 반복 추론에서 런치 오버헤드 감소(고정 shape에 특히 유리).  
> - `execute_async_v3` + 이름 기반 바인딩으로 가독성↑.

---

## 4) NMS 가속: ONNX NMS vs TRT EfficientNMS 플러그인

### 4.1 선택지
- **애플리케이션 레벨(PyTorch/NumPy)**: 구현 쉬움, **CPU 병목** 위험.  
- **ONNX `NonMaxSuppression` 노드**: TRT가 변환/플러그인으로 실행.  
- **TRT EfficientNMS 플러그인**: 수천 후보 박스도 **GPU**에서 고속 처리, **멀티클래스/배치** 지원.

### 4.2 ONNX 그래프에 NMS를 넣는 이유
- **엔진 내부에서 후처리** → D2H 트래픽 감소(전체 박스 대신 **최종 K개**만 호스트로).  
- 파이프라인 단순화, 일관된 수치.

### 4.3 EfficientNMS 사용(네트워크 구성 예)
```python
# 네트워크가 [B, num_boxes, 4] boxes 와 [B, num_boxes, num_classes] scores 를 내놓는다고 가정
# Python API에서 플러그인 추가 (TensorRT >= 8.x)
import tensorrt as trt

def add_efficientnms(network, boxes_tensor, scores_tensor, 
                     score_thresh=0.25, iou_thresh=0.6,
                     max_output=300, background_class=-1, 
                     score_activation=False, box_coding=0):
    creator = trt.get_plugin_registry().get_plugin_creator("EfficientNMS_TRT", "1")
    fields = [
        trt.PluginField("score_threshold", np.float32(score_thresh), trt.PluginFieldType.FLOAT32),
        trt.PluginField("iou_threshold",   np.float32(iou_thresh),   trt.PluginFieldType.FLOAT32),
        trt.PluginField("background_class", np.int32(background_class), trt.PluginFieldType.INT32),
        trt.PluginField("max_output_boxes", np.int32(max_output), trt.PluginFieldType.INT32),
        trt.PluginField("score_activation", np.int32(int(score_activation)), trt.PluginFieldType.INT32),
        trt.PluginField("box_coding", np.int32(box_coding), trt.PluginFieldType.INT32),
    ]
    plugin = creator.create_plugin("effnms", trt.PluginFieldCollection(fields))
    layer = network.add_plugin_v2([boxes_tensor, scores_tensor], plugin)
    # layer outputs: nmsed_boxes[B, max_output, 4], scores[B, max_output], classes[B, max_output], num_dets[B]
    return layer
```
> **주의**: 모델 헤드의 **박스/스코어 텐서 형식**이 플러그인 요구와 맞아야 합니다(배치 차원 포함, 좌표 형식 xyxy 등).

---

## 5) 입력 해상도 전략(속도↔정확도)

### 5.1 왜 해상도가 핵심인가?
- 추론 복잡도는 대개 **O(H·W)** 에 가깝습니다.  
- 해상도를 640→512로 낮추면 **연산량 ≈ (512/640)^2 ≈ 0.64배** (속도 ↑).  
- 반대로 **작은 객체** 탐지 리콜이 저하될 수 있음 → **타일링** 또는 **멀티스케일**로 보완.

### 5.2 다이내믹 해상도 & 최적화 프로파일
- TRT에서 **프로파일별 성능 편차**가 큽니다.  
  - 최소·최적·최대=(320,640,1280) 같은 범위를 **벤치마크 후** 확정.  
- **해상도별 임계/후처리 튜닝**(score/NMS 임계)도 함께 해야 P95 안정.

### 5.3 해상도-지연-정확도 스윕 코드
```python
def benchmark_resolutions(engine, images, sizes=[320, 480, 640, 960], warmup=10, iters=100):
    # images: list of np.ndarray(H,W,3) RGB
    import time, cv2
    lat = {}
    rt = TRTModule(engine)
    for sz in sizes:
        # 간단 전처리
        batch = []
        for img in images:
            im = cv2.resize(img, (sz, sz))
            arr = (im.astype(np.float32)/255.).transpose(2,0,1)[None]
            batch.append(arr)
        x = np.concatenate(batch, 0)
        for _ in range(warmup): rt.infer(x)
        t0 = time.time()
        for _ in range(iters): rt.infer(x)
        t1 = time.time()
        lat[sz] = 1000*(t1-t0)/iters
    return lat
```

---

## 6) 타일링(대해상도/초광각/원격탐사)

### 6.1 언제 필요한가?
- 입력이 4K/8K, 또는 작은 객체가 많아 **해상도를 낮추기 어려울 때**  
- **한 장**을 축소하면 정확도 급락 → **오버랩 타일**로 분할 추론

### 6.2 설계 포인트
- **타일 크기**: 엔진 **최적 프로파일**에 맞추기(예: 640×640)  
- **오버랩**: NMS 누락 방지(예: 타일 경계 10~20% 겹치기)  
- **좌표 복원**: 타일 offset + letterbox 보정  
- **메모리**: 폴딩 배치(타일을 batch로), **스트림 병렬**  
- **멀티-엔진**: 레이턴시 분할(스루풋 ↑)

### 6.3 타일 추론(개념 코드)
```python
import math, numpy as np

def sliding_window_infer(img, trt, tile=640, overlap=0.2):
    H, W, _ = img.shape
    stride = int(tile * (1-overlap))
    dets_all = []
    for y in range(0, max(H - tile + 1, 1), stride):
        for x in range(0, max(W - tile + 1, 1), stride):
            y2 = min(y + tile, H); x2 = min(x + tile, W)
            y = y2 - tile; x = x2 - tile
            crop = img[y:y2, x:x2]
            # 전처리 → TRT → (boxes_xyxy_local, scores, cls)
            out = trt.infer(preprocess(crop))  # 사용자 정의
            boxes, scores, cls = decode(out)   # 사용자 정의
            # 로컬→글로벌
            boxes[:, [0,2]] += x; boxes[:, [1,3]] += y
            dets_all.append(np.c_[boxes, scores, cls])
    dets_all = np.concatenate(dets_all, 0) if dets_all else np.zeros((0,6))
    # 글로벌 NMS(클래스별 또는 class-agnostic)
    keep = nms_gpu_or_trt(dets_all)  # EfficientNMS를 한 번 더 사용 가능
    return dets_all[keep]
```
> 팁  
> - **전처리/후처리 모두 GPU**로 보내면 왕복을 줄임. (CUDA/torch/TensorRT 플러그인)  
> - **멀티 스트림**으로 타일 간 오버랩 실행 → Throughput 향상.

---

## 7) 전처리·후처리 GPU 올리기

### 7.1 전처리
- **리사이즈/정규화/패딩(letterbox)** 를 OpenCV CPU 대신  
  - `cv::cuda`, **NPP**, **CUDA 커널**, **DALI**, 혹은 **torchvision.ops**(텐서형)로.  
- **Pinned Memory** + **비동기 H2D**(스트림)로 겹치기.

### 7.2 후처리
- **디코딩/시그모이드/조합/좌표 변환**을 GPU로.  
- **NMS를 엔진 내**로(ONNX/플러그인) 넣는 게 가장 강력.

---

## 8) Triton Inference Server로 동시성/배칭

- **모델 리포지터리**: `model.plan` + `config.pbtxt`  
- **동적 배칭**: 짧은 지연 허용 범위 내에서 자동 배치(스루풋 ↑)  
- **인스턴스 그룹**: GPU마다 엔진 복수 인스턴스 → 병렬 처리  
- **모니터링**: Prometheus/Grafana로 **레이턴시 히스토그램** 확인

예시 `config.pbtxt` (일부):
```text
name: "detector_trt"
platform: "tensorrt_plan"
max_batch_size: 4
input [
  { name: "images" data_type: TYPE_FP32 dims: [3, -1, -1] }
]
output [
  { name: "nmsed_boxes" data_type: TYPE_FP32 dims: [ -1, 4 ] },
  { name: "nmsed_scores" data_type: TYPE_FP32 dims: [ -1 ] },
  { name: "nmsed_classes" data_type: TYPE_FP32 dims: [ -1 ] },
  { name: "num_dets" data_type: TYPE_INT32 dims: [ 1 ] }
]
dynamic_batching { preferred_batch_size: [ 1, 2, 4 ] }
instance_group [{ kind: KIND_GPU, count: 2 }]
```

---

## 9) 정확도 회귀(수치 검증) 자동화

### 9.1 왜 필요한가?
- FP16/INT8/엔진 교체/전처리 변경마다 **정확도 드리프트**가 발생할 수 있습니다.  
- **AP/mIoU/IDF1** 뿐 아니라 **로짓/박스 코사인/Top-1 일치율**을 **샘플셋**에서 비교하세요.

### 9.2 회귀 스크립트(개념)
```python
def numeric_regression(ref_logits, new_logits, atol=1e-2, rtol=1e-2):
    import numpy as np
    same = np.allclose(ref_logits, new_logits, atol=atol, rtol=rtol)
    cos = (ref_logits*new_logits).sum() / (np.linalg.norm(ref_logits)*np.linalg.norm(new_logits)+1e-9)
    return {"allclose": bool(same), "cos_sim": float(cos)}

def det_regression(ref, new, iou_thr=0.5):
    # ref/new: [N,6] (x1,y1,x2,y2,score,cls)
    # 간단 매칭 → 평균 iou/score 차
    pass  # 실제 구현은 데이터셋 메트릭 사용(코코 api/pycocotools)
```

---

## 10) 실전 체크리스트(우선순위 순)

1) **NMS 엔진 내 삽입**(EfficientNMS 플러그인/ONNX NMS)  
2) **FP16**(기본 켜기) → 가능하면 **INT8(PTQ/QAT)**  
3) **해상도 스윕**으로 **최적 프로파일** 고정 & 임계 튜닝  
4) **전처리/후처리 GPU** & **비동기 파이프라인**(스트림/스레드)  
5) **타일링**(해상도 큰 도메인) + **전역 NMS**  
6) **메모리/오버헤드**: Pinned, Pre-alloc, CUDA Graphs  
7) **프로파일링**: `trtexec`/Nsight로 병목 식별  
8) **수치 회귀** 자동화로 정확도 보호

---

## 11) `trtexec` 빠른 실험 레시피

- **FP16 엔진 생성 & 벤치**
```bash
trtexec --onnx=model.onnx --saveEngine=model_fp16.plan --fp16 \
        --minShapes=images:1x3x320x320 --optShapes=images:1x3x640x640 --maxShapes=images:4x3x1280x1280 \
        --workspace=2048 --avgRuns=200 --shapes=images:1x3x640x640
```

- **INT8 PTQ(캘리브레이터)**  
  - 먼저 Python으로 `calib.cache` 생성 후:
```bash
trtexec --onnx=model.onnx --saveEngine=model_int8.plan --int8 --calib=calib.cache \
        --minShapes=images:1x3x320x320 --optShapes=images:1x3x640x640 --maxShapes=images:4x3x1280x1280
```

- **프로파일 로그/탐색**: `--verbose`, `--dumpProfile`

---

## 12) YOLO류 예: 디코딩+NMS를 TRT로 옮기기

### 12.1 헤드 출력 정규화
- 보통 **[B, A, H, W, (cx,cy,w,h,obj,cls…)]** 형태 → **[B, N, 4] boxes & [B, N, C] scores** 로 변환 필요.
- **디코드(그리드 오프셋·스트라이드·exp/log)** 를 **네트워크 내**로 옮기는 두 가지 방법:
  1) PyTorch에서 **연산 노드로 모델에 포함** → ONNX에 내보내기  
  2) TRT **플러그인**(custom layer)로 변환

**(개념) PyTorch 내 디코드 포함 예시**
```python
class YoloDecodeHead(torch.nn.Module):
    def __init__(self, strides=(8,16,32), num_classes=80):
        super().__init__()
        self.strides = strides; self.num_classes = num_classes
    def forward(self, preds):
        # preds: list of [B, A* (5+C), H, W] → concat → decode to boxes/scores
        # 여기서 그리드 생성/시그모이드/exp/w,h 보정 등 모두 텐서 연산으로 구현
        # boxes: [B, N, 4] (xyxy), scores: [B, N, C]
        return boxes, scores
```
이렇게 **디코드까지 ONNX**에 들어가면 TRT에서 바로 **EfficientNMS**를 연결할 수 있어,  
**후처리 전체가 엔진 내부**로 들어갑니다.

---

## 13) 멀티스트림/멀티스레드 파이프라인(실시간 카메라)

1) **캡처/디코드 스레드**: GStreamer/NVDEC(하드웨어 디코드)  
2) **전처리 스레드**: 리사이즈/패딩 GPU  
3) **추론 스레드(복수 Context)**: **동시성** 확보(스트림 분리, 동적 배칭)  
4) **후처리/렌더링 스레드**: NMS 결과 오버레이

**파이썬 개념 스케치**
```python
from queue import Queue
import threading

q_in, q_out = Queue(maxsize=4), Queue(maxsize=4)
trt = TRTModule("model.plan")

def reader():
    while True:
        frame = read_frame()  # HW decode
        q_in.put(frame)

def worker():
    while True:
        frame = q_in.get()
        x = preprocess_gpu(frame)  # torch/cv2.cuda
        out = trt.infer(x)
        q_out.put(out)

def writer():
    while True:
        out = q_out.get()
        render(out)

for fn in [reader, worker, writer]:
    threading.Thread(target=fn, daemon=True).start()
```
> **주의**: 파이썬 GIL/스레드 컨텍스트 제약 → **멀티프로세스**나 C++ 경로가 더 탄탄합니다.  
> **CUDA 스트림**을 각 워커에 고정하여 겹치기를 유지하세요.

---

## 14) 문제해결(FAQ)

- **엔진 빌드 느림/불안정** → `tacticSources` 제한, workspace 확대, ONNX 단순화  
- **동적 입력에서 성능 급락** → 프로파일의 **opt shape**에 맞춰 입력을 정규화(패딩/리사이즈)  
- **INT8 정확도 하락** → Calib 샘플 다양화, QAT 고려, 특정 레이어 FP16 강제(플래그)  
- **NMS 결과가 다름** → class-agnostic vs per-class, 좌표형식(xyxy/xywh), 임계/TopK 동일화  
- **CPU 병목** → 전처리/후처리 GPU, D2H 최소화(엔진 내 합치기), 비동기 파이프라인  
- **메모리 부족** → batch/프로파일 축소, 레이어 fusion 확인, 텐서 재사용 버퍼

---

## 15) 종합 예제: FP16 엔진 + EfficientNMS + 타일링 + 벤치

> 아래 코드는 “개념용”으로 이어 붙일 수 있는 형태입니다. 실제로는 모델 구조에 맞춘 `decode()`/`preprocess()` 조정이 필요합니다.

```python
# 1) ONNX export (모델 내부에 디코드까지 포함했다고 가정)
export_onnx(model, "det.onnx", opset=17, dynamic=True)

# 2) TRT 빌드 (FP16)
build_engine_from_onnx("det.onnx", "det_fp16.plan",
                       fp16=True, int8=False,
                       min_shape=(1,3,320,320), opt_shape=(1,3,640,640), max_shape=(4,3,1280,1280))

# 3) 런타임 모듈
trt_mod = TRTModule("det_fp16.plan")

# 4) 타일링 기반 추론 함수(전처리/후처리는 사용처에 맞게 구현)
dets = sliding_window_infer(image_rgb, trt_mod, tile=640, overlap=0.2)

# 5) 벤치: 해상도-레이턴시 곡선
lat = benchmark_resolutions("det_fp16.plan", images=[image_rgb]*4, sizes=[320,480,640,960])
print(lat)
```

---

## 16) 요약(체크리스트 카드)

- **TensorRT**  
  - ONNX 파싱 → **FP16** 기본, 필요 시 **INT8(PTQ/QAT)**  
  - **Optimization Profile**: min/opt/max = **벤치 후 확정**  
  - **EfficientNMS** 플러그인으로 **후처리 내장**  
- **입력 해상도**  
  - 목표 P95 지연/정확도 곡선 스윕 → 프로파일/임계 고정  
- **타일링**  
  - 오버랩 10–20%, 글로벌 NMS, 멀티 스트림  
- **전/후처리 GPU**  
  - D2H/H2D 최소화, 비동기 파이프라인  
- **배포**  
  - Triton: 동적 배칭·인스턴스 그룹, 지표/로그 표준화  
- **수치 회귀**  
  - FP16/INT8/엔진 교체 시 정확도 자동 비교(메트릭+로짓/박스 유사도)

위 절차를 그대로 적용하면, “단순 FP16 변환만”으로도 **2–3배** 가속이 흔하고,  
**EfficientNMS + 전처리/후처리 GPU 이관**까지 하면 **엔드투엔드 P95**가 눈에 띄게 안정됩니다.  
해상도/타일/임계값을 수도꼭지처럼 조절하며 **서비스 목표 지연**을 정확히 맞추는 것이 실전의 승부처입니다.