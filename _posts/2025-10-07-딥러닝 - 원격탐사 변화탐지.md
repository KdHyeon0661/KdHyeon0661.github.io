---
layout: post
title: 딥러닝 - 원격탐사 변화탐지
date: 2025-10-07 14:25:23 +0900
category: 딥러닝
---
# 원격탐사 변화탐지(타일링·전처리·클라우드 마스킹)

## 0) 변화탐지 문제와 전형적 함정

### 0.1 문제 정의
두 시점 \(t_1,t_2\) 영상 \(I_{t_1}, I_{t_2}\) (동일 센서·해상도·투영, 구름/그림자 제거)로부터  
**변화 마스크** \(\mathcal{C}\subset\Omega\) (픽셀/객체 단위)를 추정.

- **스펙트럴 변화**: 식생 감소(벌채/산불), 수역 확장(홍수), 인공구조물 증가(도시화) 등  
- **레이블 수준**: 이진(변화/무변화) 또는 다중 클래스(산불, 수해, 도시화 유형 등)

### 0.2 함정 (반드시 회피할 것)
- **정합(코레지스트레이션) 불량**: 1~2픽셀만 어긋나도 가장자리 전체가 “변화”로 뜸  
- **기상/계절·태양 고도**: 조도/그늘/BRDF 차이 → radiometric normalization 필요  
- **구름·구름 그림자·박무**: 오검출의 주범 → **클라우드 마스킹+버퍼/합성**  
- **수역/설경의 계절성**: NDWI/NDVI 기준 변동이 큼 → 지역별/시기별 임계 보정

---

## 1) 전처리 파이프라인(정합·리샘플·정규화)

### 1.1 동일 좌표계/해상도/정렬
- **투영/해상도 일치**: 둘 중 하나에 맞추어 **reproject+resample**(bilinear; 클래식 분류면 nearest)  
- **그리드 정렬**: 픽셀 그리드 **origin과 pixel size가 동일**해야 타일 경계가 정확히 맞음  
- **밴드 정렬/마스크 정렬**: SCL/QA 밴드도 동일 변환으로 맞추기

### 1.2 Radiometric Normalization(간단 버전)
다른 날씨·태양고도 차를 줄이기 위해 **밴드별 선형 보정**:
- **PIF(불변특성 픽셀)** 추출(도로/암석/건물 등, 식생·수역 제외)  
- 각 밴드 \(b\)에 대해
  $$ I_{t_2}^{(b)} \approx \alpha_b \, I_{t_1}^{(b)} + \beta_b $$
  최소제곱으로 \(\alpha_b,\beta_b\) 산출 후 \(I_{t_2}^{(b)}\)를 보정(또는 반대)

> 실전은 회귀를 **타일별** 또는 **군집별**로 나누어 지역 편차를 줄이면 더 안정적.

### 1.3 지수(예: NDVI/NDWI/SAVI) 표준화
- **NDVI**:  
  $$ \mathrm{NDVI} = \frac{\mathrm{NIR} - \mathrm{RED}}{\mathrm{NIR} + \mathrm{RED} + \varepsilon} $$
- **NDWI(물)**:  
  $$ \mathrm{NDWI} = \frac{\mathrm{GREEN} - \mathrm{NIR}}{\mathrm{GREEN} + \mathrm{NIR} + \varepsilon} $$
- **SAVI(토양보정)**:  
  $$ \mathrm{SAVI} = \frac{(1+L)(\mathrm{NIR}-\mathrm{RED})}{\mathrm{NIR}+\mathrm{RED}+L+\varepsilon} $$
  (보통 \(L=0.5\))

---

## 2) 클라우드/그림자 마스킹 개론

### 2.1 Sentinel-2 L2A (SCL 기반)
**SCL(Scene Classification Layer)** 클래스(대표값):
- 0: No data, 1: Saturated/defective, 2: Dark area, **3: Cloud shadow**, 4: Vegetation, 5: Bare soils, 6: Water, 7: Unclassified, **8: Cloud medium prob**, **9: Cloud high prob**, **10: Thin cirrus**, **11: Snow/ice**  
→ 보통 마스크 = {3, 8, 9, 10, 11} (+ 1, 0 옵션)

**버퍼링**: 구름/그림자 경계 dilate(픽셀 1~3)로 누수 방지.

### 2.2 Landsat L2 (QA_PIXEL/FMask)
- QA_PIXEL 비트 조합(Cloud, Dilated Cloud, Cloud Shadow, Snow, Water 등).  
- 정확한 비트맵은 **제품 문서** 확인 후 적용(센서/컬렉션마다 차이).  
- 간단 대안: **FMask/CFMask** 결과 밴드(클라우드/그림자) 사용.

### 2.3 합성(Temporal Compositing)
- 동일 시즌에서 **구름 없는 픽셀 우선**으로 **median** 또는 **percentile** 합성  
- **클라우드-쉐도우 보간**: 시간적으로 가까운 이웃에서 대체(갭필)

---

## 3) 타일링(슬라이딩 윈도) 설계

### 3.1 왜 필요한가?
- 전국/광역 모자이크는 수 만 × 수 만 픽셀 → **RAM 불가**  
- **타일 크기**(예: 512/1024/2048)와 **오버랩**(예: 32~64 픽셀)을 정해 **슬라이딩 인퍼런스**  
- **오버랩 이유**: 필터/합성/디코딩 시 경계 인공물 완화, **NMS/라벨** 손실 방지

### 3.2 실무 팁
- **윈도우 좌표 == 지리 좌표** 동등성 유지(한 번만 reproject)  
- **IO 최적화**: `rasterio`의 window read, **메모리 매핑**(GTiff with internal tiling, overviews)  
- **병렬**: 타일 단위로 멀티프로세스(디스크 IO 병목에 유의)

---

## 4) 변화탐지 기법 요약

### 4.1 지수 차분(Image Differencing)
- NDVI/NDWI/알베도 등 단일 지수의 **차분**:
  $$ D = I_{t_2}^{\mathrm{NDVI}} - I_{t_1}^{\mathrm{NDVI}} $$
- **임계화**: Otsu, Percentile(상하위 1~5%), 혼합가우시안(GMM)  
- 장점: 간단·빠름, 특정 목적(식생/수역)엔 강력

### 4.2 CVA(Change Vector Analysis, 다밴드 벡터 크기)
- 다밴드 스택 \(\mathbf{x}_{t_1}, \mathbf{x}_{t_2}\)에 대해  
  $$ \Delta \mathbf{x} = \mathbf{x}_{t_2} - \mathbf{x}_{t_1}, \quad 
     \|\Delta \mathbf{x}\|_2 = \sqrt{\sum_b (x_{t_2}^{(b)}-x_{t_1}^{(b)})^2} $$
- 방향성 분석(어느 밴드에서 변했는가) 가능

### 4.3 MAD(Multivariate Alteration Detection)
- **정준상관분석(CCA)** 로 두 시점의 상관 최대/최소 조합을 찾아 **변화성**을 측정(통계적 고급 기법)  
- 구현 난이도는 ↑, 잡음에 robust

### 4.4 SAR(Log-ratio)
- 레이더(예: Sentinel-1)에서 감마0/시그마0 로그 차:  
  $$ D = \left| \log(I_{t_2}+\varepsilon) - \log(I_{t_1}+\varepsilon) \right| $$
- 스펙클 필터(Lee/Frost)와 **동일 궤도/각** 매칭 중요

### 4.5 학습형(지도/약지도)
- **Siamese U-Net/UNet++**: 입력을 \([t_1,t_2]\) 채널 결합(예: 6ch/8ch) 또는 두 경로 공유가중치  
- 손실: **BCE + Dice**(불균형 데이터 안정), 또는 Focal  
- 약지도: 지수차분/클러스터 기반 **준라벨** → 수작업 정제 → 점진적 개선

---

## 5) 코드 – I/O·정렬·마스킹·타일러(실전 재사용형)

> 실무에서 바로 붙여 쓰기 좋도록 **모듈러** 코드를 제공합니다.  
> (경로/밴드 인덱스는 사용자 데이터에 맞게 수정)

```python
# pip install rasterio numpy scipy scikit-image torch torchvision
import rasterio as rio
from rasterio.windows import Window
from rasterio.warp import reproject, Resampling
import numpy as np
from scipy.ndimage import binary_dilation, binary_opening

EPS = 1e-6

def read_bands(path, band_indices):  # 1-based -> numpy(0-based) 변환 유의
    with rio.open(path) as ds:
        bands = []
        for b in band_indices:
            bands.append(ds.read(b).astype(np.float32))
        arr = np.stack(bands, axis=0)  # (C, H, W)
        profile = ds.profile
    return arr, profile

def align_to_reference(src_path, ref_profile, band_indices, resampling=Resampling.bilinear):
    arr, _ = read_bands(src_path, band_indices)
    C = arr.shape[0]
    out = np.zeros((C, ref_profile['height'], ref_profile['width']), dtype=np.float32)
    # 같은 transform/shape/CRS로 맞추기
    with rio.open(src_path) as src:
        for i in range(C):
            reproject(
                source=arr[i],
                destination=out[i],
                src_transform=src.transform,
                src_crs=src.crs,
                dst_transform=ref_profile['transform'],
                dst_crs=ref_profile['crs'],
                resampling=resampling
            )
    return out

def ndvi(nir, red):
    return (nir - red) / (nir + red + EPS)

def ndwi(green, nir):
    return (green - nir) / (green + nir + EPS)

# Sentinel-2 SCL 기반 마스크
SCL_CLOUDLIKE = {3, 8, 9, 10, 11}  # shadow, cloud(M/H), cirrus, snow/ice
def scl_mask(scl, dilate_px=2, add_nodata=True):
    mask = np.isin(scl, list(SCL_CLOUDLIKE))
    if add_nodata:
        mask |= (scl == 0) | (scl == 1)
    # 작은 점 제거/가장자리 확장
    mask = binary_opening(mask, structure=np.ones((3,3)))
    if dilate_px > 0:
        mask = binary_dilation(mask, structure=np.ones((2*dilate_px+1, 2*dilate_px+1)))
    return mask

# Landsat QA_PIXEL (사용자 비트맵 지정)
def qa_mask_bits(qa, bits_to_mask, dilate_px=2):
    """
    qa: uint16/32 QA band, bits_to_mask: [bit_index,...]
    """
    mask = np.zeros_like(qa, dtype=bool)
    for b in bits_to_mask:
        mask |= ((qa >> b) & 1).astype(bool)
    mask = binary_opening(mask, structure=np.ones((3,3)))
    if dilate_px > 0:
        mask = binary_dilation(mask, structure=np.ones((2*dilate_px+1, 2*dilate_px+1)))
    return mask

# 타일 반복자
def tile_windows(H, W, tile=1024, overlap=64):
    stride = tile - overlap
    ys = list(range(0, max(H - tile + 1, 1), stride))
    xs = list(range(0, max(W - tile + 1, 1), stride))
    # 마지막 테두리 정렬
    if ys[-1] + tile < H: ys.append(H - tile)
    if xs[-1] + tile < W: xs.append(W - tile)
    for y in ys:
        for x in xs:
            yield Window(x, y, tile, tile), (y, x)
```

---

## 6) 예제 시나리오 A — **NDVI 차분 + Otsu 임계 변화맵**

**상황**: 숲 지역의 벌채/산불 탐지. Sentinel-2 L2A 두 날짜(가급적 같은 계절).  
**단계**: 정렬 → SCL 마스크 → NDVI → 차분 → Otsu 임계.

```python
import rasterio as rio
from skimage.filters import threshold_otsu

# (1) 참조 영상 읽기 (t1)
# Sentinel-2: RED=B4, NIR=B8 (10m) / SCL=Scene Classification
B_RED, B_NIR = 4, 8
t1_bands, prof = read_bands("S2_t1.tif", [B_RED, B_NIR])     # (2,H,W)
t1_scl, _      = read_bands("S2_t1_SCL.tif", [1])            # (1,H,W)
t1_ndvi = ndvi(t1_bands[1], t1_bands[0])
t1_mask = scl_mask(t1_scl[0])  # True=mask(무효)

# (2) t2를 t1 그리드로 정렬
t2_bands = align_to_reference("S2_t2.tif", prof, [B_RED, B_NIR])
t2_scl   = align_to_reference("S2_t2_SCL.tif", prof, [1])[0]
t2_ndvi  = ndvi(t2_bands[1], t2_bands[0])
t2_mask  = scl_mask(t2_scl)

valid = ~(t1_mask | t2_mask)

# (3) NDVI 차분
d_ndvi = np.zeros_like(t1_ndvi, dtype=np.float32)
d_ndvi[valid] = t2_ndvi[valid] - t1_ndvi[valid]

# (4) 임계화 (음수 방향=식생 감소)
vals = d_ndvi[valid]
th = threshold_otsu(vals)  # 전체 변화 임계
change = (d_ndvi < min(th, -0.1)) & valid  # 안전을 위해 -0.1 하한

# (5) GeoTIFF 저장
out_profile = prof.copy()
out_profile.update(count=1, dtype="uint8", nodata=0, compress='lzw')
with rio.open("change_ndvi_otsu.tif", "w", **out_profile) as dst:
    dst.write(change.astype(np.uint8)*1, 1)
```

**해설/팁**
- **계절성**이 다르면 Otsu가 양/음 변화를 섞어 결정 → 관심 방향(식생 감소)에 맞게 **부호 조건** 추가  
- **마스크 버퍼링**으로 구름경계 false change 감소  
- **소구역 잡음**은 `binary_opening`으로 후정제

---

## 7) 예제 시나리오 B — **CVA(다밴드) + K-means 이진화**

**상황**: 도시 확장(콘크리트/포장) + 식생/수역 복합 변화. Sentinel-2 (B2,B3,B4,B8).  
**단계**: 4밴드 스택 정규화 → 벡터 차 크기 → K-means(2클러스터)로 변화/무변화 분리.

```python
from sklearn.cluster import KMeans

# t1_stack: (4,H,W)  B2,B3,B4,B8
# t2_stack: (4,H,W)  동일 정렬/정규화 전제
t1_stack, prof = read_bands("S2_t1.tif", [2,3,4,8])
t2_stack       = align_to_reference("S2_t2.tif", prof, [2,3,4,8])

# 마스크 (SCL 있으면 적용)
scl1,_ = read_bands("S2_t1_SCL.tif",[1]); scl2 = align_to_reference("S2_t2_SCL.tif",prof,[1])[0]
valid = ~(scl_mask(scl1[0]) | scl_mask(scl2))

# 간단 표준화(밴드별 z-score)
def zscore(x, m=None, s=None):
    if m is None: m = np.nanmean(x, axis=(1,2), keepdims=True)
    if s is None: s = np.nanstd(x,  axis=(1,2), keepdims=True) + 1e-6
    return (x - m)/s, (m, s)
t1z,(m,s) = zscore(t1_stack)
t2z,_     = zscore(t2_stack, m, s)

# CVA magnitude
d = np.linalg.norm((t2z - t1z).transpose(1,2,0), axis=-1)  # (H,W)

# K-means 이진화(유효픽셀만)
vals = d[valid].reshape(-1,1)
km = KMeans(n_clusters=2, n_init=10, random_state=42).fit(vals)
labs = np.zeros_like(d, dtype=np.uint8)
labs[valid] = (km.predict(vals)).astype(np.uint8) + 1  # {1,2}
# 변화 클래스=평균값 큰 쪽
c1 = d[(labs==1)&valid].mean(); c2 = d[(labs==2)&valid].mean()
change = (labs == (1 if c1>c2 else 2))

with rio.open("change_cva_kmeans.tif", "w", **prof|{'count':1,'dtype':'uint8','nodata':0}) as dst:
    dst.write(change.astype(np.uint8), 1)
```

---

## 8) 정규화 고도화 — **PIF 기반 밴드 회귀**

```python
def pseudo_invariant_mask(t1, t2, valid, ndvi1=None, ndvi2=None, thr=0.05):
    """
    t1,t2: (C,H,W) reflectance z-scored 전
    간단 규칙: |NDVI 변화|<thr, 수역/설경 제외, 음영 과도 제외(밝기 하한)
    """
    if ndvi1 is None: ndvi1 = (t1[3]-t1[2])/(t1[3]+t1[2]+EPS)  # NIR-RED / NIR+RED
    if ndvi2 is None: ndvi2 = (t2[3]-t2[2])/(t2[3]+t2[2]+EPS)
    dndvi = np.abs(ndvi2 - ndvi1)
    bright = np.mean(t1,0); bright2 = np.mean(t2,0)
    mask = valid & (dndvi < thr) & (bright>0.05) & (bright2>0.05)
    return mask

def linear_band_match(t1, t2, valid_pif):
    """
    t1,t2:(C,H,W) -> t2를 t1에 맞춤(밴드별 회귀)
    """
    C,H,W = t1.shape
    t2_adj = t2.copy()
    for b in range(C):
        x = t2[b][valid_pif].reshape(-1,1)
        y = t1[b][valid_pif]
        if len(x)<1000: continue
        # y ≈ a x + b
        A = np.c_[x, np.ones_like(x)]
        coef,_,_,_ = np.linalg.lstsq(A, y, rcond=None)
        a,b = coef[0], coef[1]
        t2_adj[b] = a*t2[b] + b
    return t2_adj
```

---

## 9) 슬라이딩 윈도(타일) 기반 **빠른 NDVI 변화지도**(전국 규모)

```python
def write_geotiff(path, array, profile, dtype="float32", nodata=None, compress='lzw'):
    p = profile.copy()
    p.update(count=1, dtype=dtype, nodata=nodata, compress=compress)
    with rio.open(path, "w", **p) as dst:
        dst.write(array.astype(p['dtype']), 1)

def ndvi_change_large(s2_t1_path, s2_t1_scl_path, s2_t2_path, s2_t2_scl_path,
                      out_path, tile=2048, overlap=64):
    # 참조 열기
    with rio.open(s2_t1_path) as ds:
        prof = ds.profile
        H,W = ds.height, ds.width
    # 결과 버퍼
    out = np.zeros((H,W), dtype=np.float32); out[:]=np.nan

    # 타일 순회
    for win, (y,x) in tile_windows(H,W,tile,overlap):
        # t1 읽기
        with rio.open(s2_t1_path) as ds1, rio.open(s2_t1_scl_path) as scl1:
            r1 = ds1.read(4, window=win).astype(np.float32)
            n1 = ds1.read(8, window=win).astype(np.float32)
            s1 = scl1.read(1, window=win)
        # t2 정렬 읽기(동일 그리드라고 가정) — 다르면 align_to_reference(window 크롭) 필요
        with rio.open(s2_t2_path) as ds2, rio.open(s2_t2_scl_path) as scl2:
            r2 = ds2.read(4, window=win).astype(np.float32)
            n2 = ds2.read(8, window=win).astype(np.float32)
            s2 = scl2.read(1, window=win)
        m = ~(scl_mask(s1) | scl_mask(s2))
        if m.sum()==0: continue
        nd1 = (n1 - r1)/(n1 + r1 + EPS); nd2 = (n2 - r2)/(n2 + r2 + EPS)
        d = np.full_like(nd1, np.nan, dtype=np.float32)
        d[m] = nd2[m] - nd1[m]
        out[y:y+win.height, x:x+win.width] = np.where(np.isnan(out[y:y+win.height, x:x+win.width]), d,
                                                      np.nanmean(np.stack([out[y:y+win.height, x:x+win.width], d]),0))
    write_geotiff(out_path, out, prof, dtype="float32", nodata=np.nan)

# 사용
# ndvi_change_large("S2_t1.tif","S2_t1_SCL.tif","S2_t2.tif","S2_t2_SCL.tif","ndvi_diff.tif")
```

---

## 10) 학습형: **Siamese U-Net**(2시점 입력→변화마스크)

### 10.1 구조·입력
- 입력: \([t_1, t_2]\) 6채널(예: RGB×2) 또는 8채널(예: (B2,B3,B4,B8)×2)  
- 출력: 1채널(변화 확률)  
- 손실:  
  $$ \mathcal{L} = \mathrm{BCE} + \lambda \,(1-\mathrm{Dice}) $$
  $$ \mathrm{Dice} = \frac{2\sum p\,g + \epsilon}{\sum p + \sum g + \epsilon} $$

### 10.2 PyTorch 스켈레톤

```python
import torch, torch.nn as nn, torch.nn.functional as F

class DoubleConv(nn.Module):
    def __init__(self, cin, cout):
        super().__init__()
        self.net = nn.Sequential(
            nn.Conv2d(cin, cout, 3, padding=1), nn.BatchNorm2d(cout), nn.ReLU(True),
            nn.Conv2d(cout, cout, 3, padding=1), nn.BatchNorm2d(cout), nn.ReLU(True),
        )
    def forward(self, x): return self.net(x)

class UNetSiamese(nn.Module):
    def __init__(self, in_ch=6, base=32):
        super().__init__()
        self.down1 = DoubleConv(in_ch, base)
        self.pool1 = nn.MaxPool2d(2)
        self.down2 = DoubleConv(base, base*2); self.pool2=nn.MaxPool2d(2)
        self.down3 = DoubleConv(base*2, base*4); self.pool3=nn.MaxPool2d(2)
        self.mid   = DoubleConv(base*4, base*8)
        self.up3   = nn.ConvTranspose2d(base*8, base*4, 2, 2)
        self.dec3  = DoubleConv(base*8, base*4)
        self.up2   = nn.ConvTranspose2d(base*4, base*2, 2, 2)
        self.dec2  = DoubleConv(base*4, base*2)
        self.up1   = nn.ConvTranspose2d(base*2, base, 2, 2)
        self.dec1  = DoubleConv(base*2, base)
        self.out   = nn.Conv2d(base, 1, 1)

    def forward(self, x1, x2):
        # 입력 두 장을 채널 결합: [B,C1+C2,H,W]
        x = torch.cat([x1,x2], dim=1)
        d1 = self.down1(x)
        d2 = self.down2(self.pool1(d1))
        d3 = self.down3(self.pool2(d2))
        m  = self.mid(self.pool3(d3))
        u3 = self.up3(m);  u3 = torch.cat([u3,d3],1); u3 = self.dec3(u3)
        u2 = self.up2(u3); u2 = torch.cat([u2,d2],1); u2 = self.dec2(u2)
        u1 = self.up1(u2); u1 = torch.cat([u1,d1],1); u1 = self.dec1(u1)
        return self.out(u1)

def dice_loss(pred, target, eps=1e-6):
    pred = torch.sigmoid(pred)
    num = 2*(pred*target).sum() + eps
    den = pred.sum() + target.sum() + eps
    return 1 - num/den
```

### 10.3 데이터로더(타일+마스크)
- 입력: 정렬된 \(t_1,t_2\) 스택과 GT 변화마스크(없다면 준라벨)  
- **클라우드 마스크**를 **loss mask**로 적용(무효픽셀 무시)

```python
from torch.utils.data import Dataset
import random

class ChangeTileDataset(Dataset):
    def __init__(self, t1_path, t2_path, scl1_path, scl2_path, label_path,
                 bands=(2,3,4,8), tile=512, overlap=0, augment=True):
        self.t1, self.p = read_bands(t1_path, list(bands))
        self.t2, _      = align_to_reference(t2_path, self.p, list(bands))
        self.scl1,_     = read_bands(scl1_path,[1])
        self.scl2       = align_to_reference(scl2_path, self.p, [1])[0]
        with rio.open(label_path) as ds: self.lab = ds.read(1).astype(np.uint8)
        self.valid = ~(scl_mask(self.scl1[0]) | scl_mask(self.scl2))
        self.tile, self.overlap = tile, overlap
        self.tiles = list(tile_windows(self.p['height'], self.p['width'], tile, overlap))
        self.augment = augment

    def __len__(self): return len(self.tiles)
    def __getitem__(self, i):
        win,_ = self.tiles[i]
        def crop(arr): return arr[(..., slice(win.row_off, win.row_off+win.height),
                                        slice(win.col_off, win.col_off+win.width))]
        t1 = crop(self.t1); t2=crop(self.t2)
        m  = crop(self.valid); y = crop(self.lab)

        # 정규화(0~1)
        t1 = np.clip(t1,0,1); t2 = np.clip(t2,0,1)
        # 간단 증강(좌우/상하 flip)
        if self.augment and random.random()<0.5:
            t1 = t1[:,:,::-1]; t2 = t2[:,:,::-1]; y = y[:,::-1]; m=m[:,::-1]
        if self.augment and random.random()<0.5:
            t1 = t1[:,::-1,:]; t2 = t2[:,::-1,:]; y = y[::-1,:]; m=m[::-1,:]

        # 마스크 무효 영역을 255로 둬서 loss ignore 하거나, 샘플에서 제외
        return (torch.from_numpy(t1), torch.from_numpy(t2),
                torch.from_numpy(y[None].astype(np.float32)),
                torch.from_numpy(m[None].astype(np.float32)))
```

### 10.4 학습 루프(무효영역 무시)
```python
def train_one_epoch(model, loader, opt, device="cuda"):
    model.train(); tot=0
    for t1, t2, y, valid in loader:
        t1,t2,y,valid = t1.to(device),t2.to(device),y.to(device),valid.to(device)
        opt.zero_grad(set_to_none=True)
        logits = model(t1, t2)
        # 무효영역 마스크(0=무효) → 유효만 손실
        bce = F.binary_cross_entropy_with_logits(logits, y, reduction='none')
        dl  = dice_loss(logits*valid + (-20)*(1-valid), y*valid)  # 무효영역은 음의 큰 로짓으로 무시 비슷한 효과
        loss = (bce*valid).sum() / (valid.sum()+1e-6) + 0.5*dl
        loss.backward(); torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)
        opt.step(); tot += loss.item()
    return tot/len(loader)
```

---

## 11) 검증/평가(픽셀 IoU·F1, 영역 후처리)

- **IoU**:  
  $$ \mathrm{IoU} = \frac{|P \cap G|}{|P \cup G|} $$
- **F1**:  
  $$ \mathrm{F1} = \frac{2\,\mathrm{Prec}\cdot \mathrm{Rec}}{\mathrm{Prec}+\mathrm{Rec}} $$
- **소영역 제거**: 연결요소에서 면적 < \(K\) 픽셀 제거  
- **벡터화**: `rasterio.features.shapes` → GeoJSON/GeoPackage로 내보내어 면적/행정구역 통계

---

## 12) 고급: **구름 그림자 추정(투영)** & **시간 합성**

- 그림자 투영: 구름 높이 \(h_c\)와 태양천정각/방위각 \((\theta,\phi)\)로 그림자 이동 벡터 \(\vec{d}\) 추정  
  $$ \vec{d} \approx \frac{h_c}{\tan(\theta)} \,[\cos(\phi), \sin(\phi)] $$
  구름 마스크를 \(\vec{d}\)만큼 이동시키고 dilate → 그림자 후보  
- **계절 합성**: 동일 분기/월 내에서 **cloud-free median composite**로 단일 기준영상 생성  
- **Haze 보정**: Dark Object Subtraction(DOS) 등 단순기법으로 박무 영향 완화

---

## 13) SAR 변화탐지(보너스)

- 평균/중간 필터로 스펙클 완화 후 **로그차**  
- 수해: 로그차 + 수역 보정(평상시 수역 마스크)  
- 바람/거칠기 변화에 민감 → 의사결정시 **다중 자료**(광학+SAR) 융합 권장

---

## 14) 품질·운영 체크리스트

1) **정합 오프셋**: 특징기반 또는 위상상관으로 미세정합(1픽셀 이하)  
2) **정규화**: PIF 회귀로 밴드별 밝기·대기 차 완화  
3) **클라우드/그림자**: SCL/QA + 버퍼 + 합성(가능하면)  
4) **타일링**: 오버랩 32~64, IO 병목 고려, 멀티프로세스  
5) **임계 튜닝**: 지역/계절별 percentile 규칙(예: NDVI diff < −0.15)  
6) **검증 루프**: 표본 지역 GT로 IoU/F1, 변화량 통계(면적, 위치)  
7) **로그/감사**: 사용 데이터(씬 ID·날짜·태양각), 파라미터 버전 고정  
8) **배포**: 슬라이딩 인퍼런스 + 스트림 파이프라인; 대규모는 Dask/Rasterio 병행

---

## 15) 요약(한 장)

- **전처리**가 80%: **정합·정규화·마스킹**이 제대로 되면 간단한 NDVI 차분만으로도 놀랄 만큼 잘 맞습니다.  
- **타일링**으로 메모리/속도를 통제하고, **오버랩**으로 경계 아티팩트를 막으세요.  
- **지수 차분 → CVA/MAD → 학습형** 순으로 복잡성을 올리며, 매 단계에서 **정확도 회귀**를 측정하세요.  
- **클라우드 마스킹**은 SCL/QA + 버퍼 + 시간합성(가능하면) 조합이 가장 안정적입니다.

이 글의 코드 조각들을 조합하면, **Sentinel-2/Landsat 기준의 변화지도**를  
전국/광역 규모에서도 **타일 기반**으로 안정적으로 산출할 수 있습니다.