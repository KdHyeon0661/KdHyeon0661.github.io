---
layout: post
title: DB 심화 - 옵티마이저의 한계
date: 2025-11-15 18:25:23 +0900
category: DB 심화
---
# Oracle 옵티마이저의 구조적 한계와 현실적인 극복 방법

## 시작하기 전: 항상 실제 측정 데이터부터 확인하라

옵티마이저의 추상적인 이론을 이해하기 전에, 가장 먼저 해야 할 일은 실제 실행 결과를 관찰하는 것입니다.

```sql
SELECT *
FROM   TABLE(DBMS_XPLAN.DISPLAY_CURSOR(
         NULL, NULL,
         'ALLSTATS LAST +PREDICATE +PEEKED_BINDS +IOSTATS +MEMSTATS'));
```

이 명령은 다음과 같은 핵심 정보를 제공합니다:
- **예상 행 수(E-Rows) vs 실제 행 수(A-Rows)**: 옵티마이저의 추정이 현실과 얼마나 일치하는지
- **실제 실행 시간(A-Time)**: 비용 모델의 예측과 실제 소요 시간 비교
- **자원 사용량(Buffers, Reads, TempSpc, Mem)**: I/O와 메모리 소비 패턴

이 데이터가 없는 최적화는 추측에 불과합니다. 옵티마이저의 한계를 이해한다는 것은 추정치와 현실의 차이를 파악하고, 그 원인을 분석하는 과정에서 시작됩니다.

## 옵티마이저가 보지 못하는 전체적인 그림: 애플리케이션 컨텍스트

옵티마이저의 비용 모델은 기본적으로 **단일 SQL문을 한 번 실행하는 데 필요한 데이터베이스 내부 작업량**만을 평가합니다. 그러나 실제 운영 환경은 훨씬 더 복잡한 요소들이 얽혀 있습니다.

### 데이터베이스 경계를 넘는 영향 요소들:

1. **캐시 상태의 역동성**: "따뜻한" 캐시 상태(데이터가 이미 메모리에 로드된 경우)와 "차가운" 캐시 상태(디스크에서 처음 읽는 경우)의 성능 차이는 비용 모델이 완전히 반영하지 못합니다.

2. **애플리케이션 패턴**: 
   - 배치 처리(Array Fetch)로 인한 네트워크 왕복 횟수 감소 효과
   - 사용자 응답 시간 중 데이터베이스가 아닌 부분
   - 세션별 상태 정보(임시 테이블, PL/SQL 패키지 캐시)

3. **동시성 영향**:
   - 핫 블록 경합(buffer busy waits)
   - 행 잠금 충돌
   - 라치(latch) 경쟁

4. **인프라 계층**:
   - 스토리지 캐시 계층화(SAN, NVMe 캐시)
   - 데이터 압축/해제에 필요한 CPU 오버헤드
   - 네트워크 지연 시간

이러한 요소들은 옵티마이저의 비용 계산 범위를 벗어나지만, 최종 사용자 경험에 결정적인 영향을 미칩니다.

**실제 시나리오: 반복 실행 패턴**

```sql
-- 애플리케이션에서 바인드 변수만 변경하며 반복 실행하는 패턴
SELECT o.order_id, o.order_dt, c.customer_name
FROM   orders o
JOIN   customers c ON c.customer_id = o.customer_id
WHERE  c.region = :region_bind
AND    o.order_date >= :date_bind;

-- 첫 실행: 차가운 캐시 상태, 디스크 I/O 발생
-- 두 번째 이후: 따뜻한 캐시 상태, 메모리 I/O만 발생
-- 옵티마이저는 이 차이를 비용에 반영하지 못함
```

이러한 현실을 고려하지 않고 순수한 비용 숫자만 믿는다면, 실제 운영 환경에서 예상치 못한 성능 문제에 직면할 수 있습니다.

## 통계 정보의 한계: 스냅샷의 불완전성

옵티마이저의 모든 결정은 통계 정보라는 토대 위에 세워집니다. 그러나 통계 정보는 본질적으로 다음과 같은 한계를 가집니다:

### 1. 시점적 제약
통계는 특정 시점의 데이터 스냅샷입니다. 데이터가 실시간으로 변하는 운영 환경에서 통계는 항상 현재 상태보다 뒤쳐질 수밖에 없습니다.

```sql
-- 대량 데이터 로드 후 통계 갱신이 지연된 경우
BEGIN
    -- 야간 배치 작업으로 100만 건 데이터 적재
    INSERT INTO sales SELECT * FROM sales_staging;
    COMMIT;
    
    -- 통계 갱신을 잊음
    -- DBMS_STATS.GATHER_TABLE_STATS('SH', 'SALES'); -- 누락됨
END;
/

-- 옵티마이저는 오래된 통계를 기반으로 실행 계획 수립
-- 실제 데이터 분포와 맞지 않는 비효율적인 계획 선택 가능성
```

### 2. 샘플링 편향
대용량 테이블의 통계 수집은 샘플링을 기반으로 하므로, 표본이 전체 데이터를 대표하지 못할 위험이 있습니다.

### 3. 계절성/이벤트성 패턴 반영의 어려움
특정 시즌(블랙프라이데이, 새해 이벤트)이나 프로모션 기간에만 발생하는 데이터 패턴을 통계가 반영하기 어렵습니다.

## 히스토그램의 구조적 제약

히스토그램은 컬럼 값의 분포 편향을 반영하는 강력한 도구이지만, 근본적인 제약을 가지고 있습니다:

### 단일 차원의 한계
히스토그램은 개별 컬럼의 값 분포만을 이해할 뿐, 컬럼 간의 상관관계를 인지하지 못합니다.

```sql
-- customers 테이블: 지역(region)과 고객 등급(tier) 간 강한 상관관계
-- '서울' 지역 고객의 80%가 'VIP' 등급
-- '부산' 지역 고객의 10%만 'VIP' 등급

-- 히스토그램이 있는 경우에도 옵티마이저의 추정:
SELECT COUNT(*) 
FROM customers 
WHERE region = '서울' AND tier = 'VIP';
-- 추정: P(region='서울') × P(tier='VIP')
-- 현실: P(region='서울' AND tier='VIP') ≠ P(region='서울') × P(tier='VIP')
```

이러한 상관관계 무시는 조인 순서, 조인 방법, 접근 경로 선택에 치명적인 오류를 초래할 수 있습니다.

**확장 통계로의 해결:**

```sql
-- 컬럼 그룹에 대한 확장 통계 생성
BEGIN
    -- (지역, 등급) 조합의 실제 분포를 학습
    DBMS_STATS.CREATE_EXTENDED_STATS(
        ownname    => 'SH',
        tabname    => 'CUSTOMERS',
        extension  => '(REGION, TIER)'
    );
    
    -- 확장 통계를 포함한 통계 수집
    DBMS_STATS.GATHER_TABLE_STATS(
        ownname    => 'SH',
        tabname    => 'CUSTOMERS',
        method_opt => 'FOR ALL COLUMNS SIZE SKEWONLY ' ||
                      'FOR COLUMNS (REGION, TIER) SIZE 254'
    );
END;
/
```

## 바인드 변수의 역설: 효율성과 정확성 사이의 줄다리기

바인드 변수 사용은 하드 파싱 감소와 라이브러리 캐시 효율성을 제공하지만, 중요한 트레이드오프를 동반합니다.

### 바인드 피킹(Bind Peeking)의 함정
옵티마이저는 SQL이 처음 파싱될 때 바인드 변수의 실제 값을 엿봅니다(peeking). 이 값이 비전형적일 경우, 전체 실행에 부적합한 계획이 선택될 수 있습니다.

```sql
-- 제품 브랜드별 판매 데이터: 'Apple' 50%, 'Samsung' 30%, 기타 브랜드 20%
-- 'Xiaomi' 브랜드는 전체의 0.1%만 차지

-- 첫 실행: 희소값으로 파싱
VARIABLE brand VARCHAR2(20);
EXEC :brand := 'Xiaomi';  -- 매우 드문 값

SELECT COUNT(*) 
FROM sales 
WHERE product_brand = :brand;
-- 옵티마이저: "드문 값이므로 인덱스 스캔이 효율적"

-- 이후 실행: 빈도 높은 값 사용
EXEC :brand := 'Apple';  -- 매우 흔한 값

-- 동일한 커서 재사용: 인덱스 스캔 계획 유지
-- 실제로는 전체 테이블 스캔이 더 효율적임
SELECT COUNT(*) 
FROM sales 
WHERE product_brand = :brand;
```

### 적응형 커서 공유(Adaptive Cursor Sharing)의 한계
ACS는 이 문제를 완화하려고 시도하지만, 완전한 해결책은 아닙니다:

1. **학습 지연**: 잘못된 계획으로 여러 번 실행된 후에야 수정됨
2. **자식 커서 폭발**: 값 조합이 많을수록 메모리 사용량 증가
3. **부분적 해결**: 복잡한 조건에서는 여전히 부정확할 수 있음

## 선택도 추정의 근본적 어려움: 독립성 가정과 현실의 괴리

옵티마이저는 기본적으로 컬럼 값들이 서로 독립적이라고 가정합니다. 그러나 실제 비즈니스 데이터는 강한 상관관계를 가지는 경우가 많습니다.

**전형적인 상관관계 패턴:**
- 고가격 제품은 특정 지역에서 더 많이 판매됨
- VIP 고객은 주말에 주문을 더 많이 함  
- 특정 이벤트 기간에는 반품률이 증가함

```sql
-- 실제 상관관계를 무시한 옵티마이저의 추정
SELECT COUNT(*)
FROM orders o
JOIN customers c ON c.customer_id = o.customer_id
WHERE c.membership_level = 'VIP'
AND   o.order_date BETWEEN SYSDATE - 30 AND SYSDATE
AND   o.order_amount > 1000000;

-- 옵티마이저의 추정: 
-- P(VIP) × P(최근30일) × P(고액주문)
-- 실제: VIP고객의 고액주문은 특정 기간에 집중되는 패턴 존재
```

이러한 오추정은 조인 순서, 조인 방법, 데이터 접근 경로 등 모든 후속 결정에 연쇄적으로 영향을 미칩니다.

## 비용 모델의 평균화 문제: 일반화된 가정의 위험

옵티마이저의 비용 모델은 일반적인 평균값을 기반으로 합니다:

### 디스크 I/O 비용 모델의 시대적 한계
전통적인 비용 모델은 HDD 기반 시스템을 가정하여 설계되었습니다:
- 순차 읽기가 랜덤 읽기보다 훨씬 효율적
- 블록 크기와 물리적 배치가 성능에 큰 영향

그러나 현대 스토리지 환경(SSD, NVMe)에서는:
- 랜덤 읽기와 순차 읽기의 성능 차이가 크게 줄어듦
- 캐시 계층화로 인한 예측 불가능성 증가
- 압축/암호화의 CPU 오버헤드

```sql
-- 시스템 통계의 중요성
BEGIN
    -- SSD 환경 특성 반영
    DBMS_STATS.GATHER_SYSTEM_STATS(
        gathering_mode => 'NOWORKLOAD'
    );
    
    -- 또는 실제 워크로드 기반 측정
    DBMS_STATS.GATHER_SYSTEM_STATS(
        gathering_mode => 'WORKLOAD',
        interval       => 30  -- 30분간 측정
    );
END;
/
```

### 캐시 효과의 무시
옵티마이저는 버퍼 캐시 히트율을 정확히 예측하지 못합니다:
- 핫 데이터셋은 캐시에 상주할 가능성이 높음
- 콜드 데이터는 디스크에서 읽어야 함
- 이 차이는 실제 실행 시간에 큰 영향을 미침

## 쿼리 변환의 휴리스틱적 특성

옵티마이저의 쿼리 변환 단계는 비용 기반이지만, 많은 경우 휴리스틱(경험적 규칙)에 의존합니다:

### 변환의 양면성
```sql
-- 뷰 머지(View Merging)의 예
SELECT *
FROM (
    SELECT product_id, SUM(quantity) as total_qty
    FROM order_items
    GROUP BY product_id
) v
WHERE v.total_qty > 100;

-- 옵티마이저는 이 쿼리를 다음과 같이 변환할 수 있음:
SELECT product_id, SUM(quantity) as total_qty
FROM order_items
GROUP BY product_id
HAVING SUM(quantity) > 100;
```

이 변환은 대부분 효율적이지만, 특정 상황에서는 역효과를 낼 수 있습니다. 옵티마이저가 이러한 특수 상황을 인지하지 못할 수 있습니다.

### 적응형 기능의 제약
Oracle의 적응형 쿼리 최적화 기능들은 진보적이지만 완벽하지 않습니다:
- **동적 통계(Dynamic Statistics)**: 파싱 시간 증가
- **카디널리티 피드백(Cardinality Feedback)**: 학습을 위한 추가 실행 필요
- **적응형 조인 방법(Adaptive Join Methods)**: 메모리 사용량 증가

## 현실적인 대응 전략

### 1. 계층적 최적화 접근법

```sql
-- 1차: 통계 최적화 (가장 근본적인 해결)
BEGIN
    -- 정기적인 통계 수집 스케줄 설정
    DBMS_STATS.SET_TABLE_PREFS(
        'SH', 'SALES', 
        'STALE_PERCENT', '10'  -- 10% 이상 변경 시 통계 오래된 것으로 간주
    );
    
    -- 확장 통계로 상관관계 반영
    DBMS_STATS.CREATE_EXTENDED_STATS(
        'SH', 'SALES', 
        '(PRODUCT_CATEGORY, SEASON)'
    );
END;
/

-- 2차: SQL 구조 최적화 (필요 시)
SELECT /*+ NO_UNNEST */ 
       customer_id, customer_name
FROM customers c
WHERE EXISTS (
    SELECT 1 
    FROM orders o 
    WHERE o.customer_id = c.customer_id
    AND o.order_date > SYSDATE - 30
);

-- 3차: 최소한의 힌트 사용 (최후의 수단)
SELECT /*+ LEADING(c o) USE_NL(o) INDEX(c CUSTOMERS_REGION_IDX) */
       c.customer_id, o.order_id
FROM customers c
JOIN orders o ON o.customer_id = c.customer_id
WHERE c.region = '서울'
AND   o.order_date >= DATE '2024-01-01';
```

### 2. 실행 계획 안정화 전략

```sql
-- SQL 계획 기준선(SQL Plan Baseline) 사용
DECLARE
    v_plan_name VARCHAR2(30);
BEGIN
    -- 현재 실행 계획을 기준선으로 캡처
    v_plan_name := DBMS_SPM.LOAD_PLANS_FROM_CURSOR_CACHE(
        sql_id => 'abc123def456'
    );
    
    -- 원하는 계획으로 고정
    DBMS_SPM.ALTER_SQL_PLAN_BASELINE(
        sql_handle => SYS.DBMS_SQLTUNE.SQLTEXT_TO_SIGNATURE(
            'SELECT * FROM sales WHERE product_id = :1'
        ),
        plan_name  => v_plan_name,
        attribute_name  => 'FIXED',
        attribute_value => 'YES'
    );
END;
/

-- SQL 프로파일을 통한 통계 보정
DECLARE
    v_sql_tune_task VARCHAR2(30);
BEGIN
    v_sql_tune_task := DBMS_SQLTUNE.CREATE_TUNING_TASK(
        sql_id      => 'problem_sql_id',
        scope       => DBMS_SQLTUNE.SCOPE_COMPREHENSIVE,
        time_limit  => 3600
    );
    
    DBMS_SQLTUNE.EXECUTE_TUNING_TASK(v_sql_tune_task);
    
    -- 권장 사항 적용
    DBMS_SQLTUNE.ACCEPT_SQL_PROFILE(
        task_name   => v_sql_tune_task,
        name        => 'sales_query_profile'
    );
END;
/
```

### 3. 모니터링과 피드백 루프 구축

```sql
-- 실행 계획 변화 모니터링
SELECT 
    sql_id,
    plan_hash_value,
    executions,
    elapsed_time_total,
    buffer_gets_total,
    disk_reads_total,
    LAST_ACTIVE_TIME
FROM v$sql
WHERE sql_text LIKE '%매출분석%'
ORDER BY LAST_ACTIVE_TIME DESC;

-- 카디널리티 오류 식별
SELECT 
    operation,
    options,
    object_name,
    cardinality as e_rows,
    -- 실제 행 수는 다른 방법으로 수집 필요
    ROUND((actual_rows - cardinality) / NULLIF(cardinality, 0) * 100, 2) as error_pct
FROM (
    SELECT 
        id,
        operation,
        options,
        object_name,
        cardinality,
        -- 실제 행 수 추정 (실행 통계 기반)
        (SELECT SUM(output_rows) 
         FROM v$sql_plan_statistics_all p2 
         WHERE p2.sql_id = p1.sql_id 
         AND p2.child_number = p1.child_number
         AND p2.id = p1.id) as actual_rows
    FROM v$sql_plan p1
    WHERE sql_id = :target_sql_id
    AND cardinality > 0
);
```

## 종합적인 문제 해결 프레임워크

### 1. 진단 단계
```sql
-- 문제 SQL 식별
SELECT 
    sql_id,
    sql_text,
    executions,
    elapsed_time_per_exec,
    buffer_gets_per_exec,
    disk_reads_per_exec,
    CASE 
        WHEN elapsed_time_per_exec > 1000000 THEN '심각'
        WHEN elapsed_time_per_exec > 100000 THEN '주의'
        ELSE '정상'
    END as severity
FROM (
    SELECT 
        sql_id,
        SUBSTR(sql_text, 1, 100) as sql_text,
        executions,
        ROUND(elapsed_time/executions/1000, 2) as elapsed_time_per_exec,
        ROUND(buffer_gets/executions, 2) as buffer_gets_per_exec,
        ROUND(disk_reads/executions, 2) as disk_reads_per_exec
    FROM v$sql
    WHERE executions > 100
    AND parsing_schema_name = 'SH'
)
ORDER BY elapsed_time_per_exec DESC
FETCH FIRST 10 ROWS ONLY;
```

### 2. 분석 단계
```sql
-- 실행 계획 상세 분석
SELECT 
    p.id,
    LPAD(' ', p.depth*2) || p.operation || ' ' || p.options as operation,
    p.object_name,
    p.cardinality as e_rows,
    s.output_rows as a_rows,
    ROUND((s.output_rows - p.cardinality) / NULLIF(p.cardinality, 0) * 100, 2) as error_pct,
    s.buffer_gets,
    s.disk_reads,
    s.etime
FROM v$sql_plan p
LEFT JOIN v$sql_plan_statistics_all s 
    ON p.sql_id = s.sql_id 
    AND p.child_number = s.child_number 
    AND p.id = s.id
WHERE p.sql_id = :problem_sql_id
ORDER BY p.id;
```

### 3. 처치 단계
```sql
-- 통계 보정
BEGIN
    -- 히스토그램 생성
    DBMS_STATS.GATHER_TABLE_STATS(
        ownname    => 'SH',
        tabname    => 'SALES',
        method_opt => 'FOR COLUMNS SIZE 254 PRODUCT_CATEGORY, SEASON',
        degree     => DBMS_STATS.AUTO_DEGREE
    );
    
    -- 확장 통계 생성
    DBMS_STATS.CREATE_EXTENDED_STATS(
        'SH', 'SALES', 
        '(PRODUCT_CATEGORY, REGION, SEASON)'
    );
    
    -- 시스템 통계 갱신
    DBMS_STATS.GATHER_SYSTEM_STATS('WORKLOAD');
END;
/

-- 실행 계획 안정화
BEGIN
    DBMS_SPM.CONFIGURE(
        parameter_name  => 'AUTO_CAPTURE_SQL_PLAN_BASELINES',
        parameter_value => 'TRUE'
    );
END;
/
```

## 결론: 옵티마이저와의 현명한 협업

옵티마이저는 강력한 도구이지만 완벽하지 않습니다. 그 한계를 이해하는 것은 이를 효과적으로 활용하는 첫걸음입니다. 핵심 교훈은 다음과 같습니다:

1. **옵티마이저는 통계의 질을 넘어설 수 없습니다**: 정확하고 시의적절한 통계는 모든 최적화의 기초입니다. 히스토그램과 확장 통계는 상관관계를 이해하는 데 필수적입니다.

2. **비용 모델은 추상화입니다**: 실제 하드웨어 특성, 캐시 상태, 동시성 영향을 완전히 반영하지 못합니다. 시스템 통계와 실제 측정을 통해 이 격차를 줄여야 합니다.

3. **애플리케이션 컨텍스트는 중요합니다**: 단일 쿼리 실행이 아닌, 전체 애플리케이션 흐름에서의 성능을 고려해야 합니다. 반복 실행 패턴, 캐시 효과, 네트워크 지연을 함께 분석하세요.

4. **점진적 개선이 안정적입니다**: 급진적인 변화보다는 체계적인 접근이 장기적인 성공을 보장합니다. 통계 개선 → SQL 구조 최적화 → 최소한의 힌트 사용 순서를 따르세요.

5. **모니터링은 지속적이어야 합니다**: 옵티마이저의 결정은 데이터와 환경의 변화에 따라 변할 수 있습니다. 지속적인 모니터링과 피드백 루프를 구축하세요.

옵티마이저의 한계를 인정하고, 그 한계를 보완할 방법을 아는 것이 전문가와 초보자를 구분하는 기준입니다. 옵티마이저를 '자동으로 모든 것을 해결해주는 마법사'가 아니라, '데이터와 시스템에 대한 우리의 이해를 바탕으로 결정을 내리는 동료'로 생각할 때, 진정한 최적화가 가능해집니다.