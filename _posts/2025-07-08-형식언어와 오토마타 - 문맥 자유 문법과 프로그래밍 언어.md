---
layout: post
title: 형식언어와 오토마타 - 문맥 자유 문법과 프로그래밍 언어
date: 2025-07-08 23:20:23 +0900
category: 형식언어와 오토마타
---
# 문맥 자유 문법(CFG)과 프로그래밍 언어

## 큰 그림: 정규 언어 vs 문맥 자유 언어

- **정규 언어(REG)**: 유한 오토마타/DFA/NFA/정규표현식으로 기술 가능. **중첩/균형 구조**는 불가.
- **문맥 자유 언어(CFL)**: **CFG**로 생성 가능, **PDA(스택)**로 인식 가능. **괄호 중첩/재귀 구조** 표현에 강함.
- 프로그래밍 언어의 **구문(syntax)**는 대부분 **CFG**로 정의됩니다. (토큰화는 정규 언어)

---

## 문맥 자유 문법(Context-Free Grammar, CFG)

### 정의(형식)

CFG는 4-튜플로 정의:
$$
G=(V,\Sigma,R,S)
$$

- \(V\): **비터미널**(Non-terminal) 집합
- \(\Sigma\): **터미널**(Terminal) 집합(토큰 집합)
- \(R\): 생성 규칙(Production) 집합, \(\;A\to\alpha\; (A\in V,\; \alpha\in (V\cup\Sigma)^\*)\)
- \(S\in V\): 시작 기호

**파생(derivation)**: \( A \Rightarrow \alpha \) 는 규칙 \(A\to\alpha\)의 1-step 적용.
언어:
$$
L(G)=\{\, w\in \Sigma^\* \mid S \Rightarrow^\* w \,\}
$$

### 예: 중첩 괄호 언어

$$
S \to (S)S \mid \varepsilon
$$
정규 언어로는 불가(스택 필요)하지만 CFG로는 간단.

---

## 프로그래밍 언어가 CFG를 쓰는 이유

| 요구 | CFG가 주는 해법 |
|---|---|
| **중첩 구조** `{ ... { ... } ... }` | 재귀 규칙로 자연스럽게 표현 |
| **우선순위·결합법칙** | 계층적 비터미널(Expr > Term > Factor)로 모델링 |
| **문법의 명세 가능성** | BNF/EBNF로 명시, 파서 생성에 활용 |
| **파싱 이론과 결합** | LL/LR 이론으로 **결정 가능**·**효율적** 파서 구축 |

---

## 수식 문법에서 우선순위·결합법칙

### 전형적(모호한) 문법

```
E → E + E | E * E | (E) | id
```
- 모호함(여러 파스 트리 가능) → 우선순위/결합법칙을 **문법에 내장**해야 함.

### 비모호·우선순위 반영 문법(곱셈 > 덧셈, 좌결합)

```
E  → T E'
E' → (+ T E') | ε
T  → F T'
T' → (* F T') | ε
F  → (E) | id
```
- `*`는 `T` 레벨, `+`는 `E` 레벨 → **곱셈이 더 강함**
- `E'`/`T'`의 재귀가 **좌결합**을 구현

---

## “모호성”과 전설의 *Dangling else*

### 모호한 if-else

```
Stmt → if (E) Stmt | if (E) Stmt else Stmt | other
```
- `if (E) if (E) S else S`의 `else`가 **어느 if에 붙는지** 애매.

### 표준 해법(가까운 if에 else 결합)

```
Stmt      → Matched | Unmatched
Matched   → if (E) Matched else Matched | Other
Unmatched → if (E) Stmt | if (E) Matched else Unmatched
Other     → id = E ; | { StmtList } | ...
```
- 이 문법은 *else는 가장 가까운 if에 붙는다*를 **명시적으로 보장** (비모호)

---

## LL(1) 친화 변환: 좌재귀 제거·좌측 공통 인자 제거

### 좌재귀 제거

좌재귀 형태:
$$
A \to A\alpha \mid \beta
$$
변환:
```
A  → β A'
A' → α A' | ε
```

### 좌측 공통 인자 제거(Left Factoring)

```
A → αβ | αγ
```
공통 접두사 `α` 추출:
```
A  → α A'
A' → β | γ
```

> LL 계열 파서는 **좌재귀 금지**, **FIRST/FOLLOW 충돌 회피**가 필수.

---

## FIRST/FOLLOW, LL(1) 파싱 테이블

### 정의(요지)

- **FIRST(X)**: \(X\)로부터 시작할 때 **맨 앞**에 올 수 있는 터미널들의 집합(ε 포함 가능).
- **FOLLOW(A)**: 어떤 문맥에서 비터미널 \(A\) **뒤에 올 수 있는** 터미널들의 집합(입력 끝 기호 `$` 포함).
- **LL(1)** 조건(생략 없이 핵심):
  각 비터미널 A의 두 규칙 \(A\to\alpha, A\to\beta\)에 대해
  1) \(FIRST(\alpha)\cap FIRST(\beta)=\varnothing\)
  2) ε이 FIRST에 있으면 \(FIRST(\alpha)\cap FOLLOW(A)=\varnothing\)

### 작은 예(표현식)

```
E  → T E'
E' → + T E' | ε
T  → F T'
T' → * F T' | ε
F  → ( E ) | id
```
- 위 문법은 고전적인 **LL(1)** 예시 → 예측 파싱 테이블을 구성해도 충돌 없음.

---

## 파이썬으로 FIRST/FOLLOW 및 LL(1) 테이블 만들기 (실행용)

> 아래 코드는 **문법 정의 → FIRST/FOLLOW 계산 → LL(1) 테이블 생성**까지 수행합니다.
> 문법은 토큰 문자열 기반(ε는 `'ε'`), 터미널/비터미널은 사용자가 구분하여 제공.

```python
# ll1_table.py

from collections import defaultdict

EPS = 'ε'
END = '$'

def compute_first(grammar, terminals, nonterminals, start):
    FIRST = {A:set() for A in nonterminals}
    # 터미널의 FIRST는 자기 자신
    for t in terminals: FIRST[t] = {t}
    changed = True
    while changed:
        changed = False
        for A, prods in grammar.items():
            for rhs in prods:
                # rhs = [X1, X2, ...]
                nullable = True
                for X in rhs:
                    for a in FIRST[X]:
                        if a != EPS and a not in FIRST[A]:
                            FIRST[A].add(a); changed = True
                    if EPS not in FIRST[X]:
                        nullable = False
                        break
                if nullable and EPS not in FIRST[A]:
                    FIRST[A].add(EPS); changed = True
    return FIRST

def first_of_sequence(seq, FIRST):
    # seq: [X1, X2, ...], FIRST: dict
    out = set()
    nullable = True
    for X in seq:
        out |= {a for a in FIRST[X] if a != EPS}
        if EPS not in FIRST[X]:
            nullable = False
            break
    if nullable: out.add(EPS)
    return out

def compute_follow(grammar, terminals, nonterminals, start, FIRST):
    FOLLOW = {A:set() for A in nonterminals}
    FOLLOW[start].add(END)
    changed = True
    while changed:
        changed = False
        for A, prods in grammar.items():
            for rhs in prods:
                # X ... beta
                for i, B in enumerate(rhs):
                    if B in nonterminals:
                        beta = rhs[i+1:]
                        FIRST_beta = first_of_sequence(beta, FIRST)
                        add = {a for a in FIRST_beta if a != EPS}
                        before = len(FOLLOW[B])
                        FOLLOW[B] |= add
                        if EPS in FIRST_beta:
                            FOLLOW[B] |= FOLLOW[A]
                        if len(FOLLOW[B]) != before:
                            changed = True
    return FOLLOW

def build_ll1_table(grammar, terminals, nonterminals, start):
    FIRST = compute_first(grammar, terminals, nonterminals, start)
    FOLLOW = compute_follow(grammar, terminals, nonterminals, start, FIRST)
    table = {A:{} for A in nonterminals}
    conflicts = []

    for A, prods in grammar.items():
        for rhs in prods:
            first = first_of_sequence(rhs, FIRST)
            for a in first - {EPS}:
                if a in table[A]:
                    conflicts.append((A, a, table[A][a], rhs))
                table[A][a] = rhs
            if EPS in first:
                for b in FOLLOW[A]:
                    if b in table[A]:
                        conflicts.append((A, b, table[A][b], rhs))
                    table[A][b] = [EPS]

    return FIRST, FOLLOW, table, conflicts

if __name__ == "__main__":
    # LL(1) 표현식 문법
    # E  → T E'
    # E' → + T E' | ε
    # T  → F T'
    # T' → * F T' | ε
    # F  → ( E ) | id
    nonterminals = {'E','E\'','T','T\'','F'}
    terminals    = {'id','+','*','(',')'}
    start = 'E'
    G = {
        'E':  [['T',"E'"]],
        "E'":[['+','T',"E'"], [EPS]],
        'T':  [['F',"T'"]],
        "T'":[['*','F',"T'"], [EPS]],
        'F':  [['(','E',')'], ['id']]
    }

    FIRST, FOLLOW, TABLE, CONFLICTS = build_ll1_table(G, terminals, nonterminals, start)
    print("FIRST:");  [print(f"  {A}: {sorted(v)}") for A,v in FIRST.items() if A in nonterminals]
    print("FOLLOW:"); [print(f"  {A}: {sorted(v)}") for A,v in FOLLOW.items()]
    print("\nLL(1) TABLE:")
    for A,row in TABLE.items():
        for a, rhs in row.items():
            print(f"  M[{A}, {a}] = {' '.join(rhs)}")
    if CONFLICTS:
        print("\n*** Conflicts found (not LL(1)):")
        for c in CONFLICTS: print("  ", c)
    else:
        print("\nNo conflicts. Grammar is LL(1) for given terminals.")
```

**설명**
- `compute_first`, `compute_follow`는 표준 고정점 반복으로 계산.
- `build_ll1_table`은 LL(1) 테이블을 구성하고 **충돌**(예측 불가 상황)을 보고.
- 위 표현식 문법은 **충돌 없음**(LL(1)).

---

## 미니 언어 설계: 문법(LL 친화), 렉서, 파서, AST, 인터프리터

### 미니 언어 BNF

- **토큰(정규 언어, 렉서가 담당)**
  `id`(식별자), `num`(정수), 키워드 `if`,`else`,`while`,`true`,`false`,
  기호 `= ; ( ) { } + - * / < > == != <= >= && ||`

- **문장(Statement)**
```
Program   → StmtList
StmtList  → Stmt StmtList | ε
Stmt      → id = Expr ;
          | if ( Expr ) Stmt else Stmt
          | while ( Expr ) Stmt
          | { StmtList }
```
- **표현식(우선순위: || < && < 비교 < + - < * / < 단항 < 원자)**
```
Expr      → Or
Or        → And Or'
Or'       → || And Or' | ε
And       → Cmp And'
And'      → && Cmp And' | ε
Cmp       → Add Cmp'
Cmp'      → (==|!=|<|>|<=|>=) Add Cmp' | ε
Add       → Mul Add'
Add'      → (+|-) Mul Add' | ε
Mul       → Unary Mul'
Mul'      → (*|/) Unary Mul' | ε
Unary     → (-|!) Unary | Primary
Primary   → ( Expr ) | id | num | true | false
```
> 위 구조는 **좌재귀 제거·좌측 팩토링 완료**로 LL(1) 친화.

### 구현(파이썬) — 렉서·재귀하강 파서·AST·간단 인터프리터

```python
# mini_lang.py

import re
from dataclasses import dataclass
from typing import List, Optional, Union, Dict, Any

# ----------- 1) Tokenizer (정규 언어) -----------

TOKEN_SPEC = [
    ('NUMBER',  r'\d+'),
    ('ID',      r'[A-Za-z_]\w*'),
    ('OP',      r'==|!=|<=|>=|\|\||&&|[+\-*/<>=!()]'),
    ('LBRACE',  r'\{'),
    ('RBRACE',  r'\}'),
    ('SEMI',    r';'),
    ('SKIP',    r'[ \t\r\n]+'),
    ('MISMATCH',r'.'),
]

KEYWORDS = {'if','else','while','true','false'}

Token = dataclass(frozen=True)
class Token:
    type: str
    value: str
    pos: int

def tokenize(code: str) -> List[Token]:
    regex = '|'.join(f'(?P<{name}>{pat})' for name, pat in TOKEN_SPEC)
    tokens = []
    for m in re.finditer(regex, code):
        kind = m.lastgroup
        val  = m.group()
        pos  = m.start()
        if kind == 'SKIP': continue
        if kind == 'ID' and val in KEYWORDS:
            tokens.append(Token(val.upper(), val, pos))
        elif kind == 'ID':
            tokens.append(Token('ID', val, pos))
        elif kind == 'NUMBER':
            tokens.append(Token('NUMBER', val, pos))
        elif kind in ('OP','LBRACE','RBRACE','SEMI'):
            tokens.append(Token(kind, val, pos))
        else:
            raise SyntaxError(f"Unexpected char `{val}` at {pos}")
    tokens.append(Token('EOF','$',len(code)))
    return tokens

# ----------- 2) AST 노드 -----------

@dataclass
class StmtList: items: List['Stmt']
@dataclass
class Assign:   name: str; expr: 'Expr'
@dataclass
class If:       cond: 'Expr'; then: 'Stmt'; els: 'Stmt'
@dataclass
class While:    cond: 'Expr'; body: 'Stmt'
@dataclass
class Block:    body: StmtList

Expr = Any
@dataclass
class BinOp:    op: str; left: Expr; right: Expr
@dataclass
class UnOp:     op: str; expr: Expr
@dataclass
class Var:      name: str
@dataclass
class Num:      value: int
@dataclass
class Bool:     value: bool

Stmt = Union[Assign, If, While, Block]

# ----------- 3) Recursive-Descent Parser (LL 스타일) -----------

class Parser:
    def __init__(self, tokens: List[Token]):
        self.toks = tokens
        self.i = 0
    def peek(self): return self.toks[self.i]
    def eat(self, kind=None, val=None):
        t = self.peek()
        if kind and t.type != kind:  raise SyntaxError(f"expected {kind}, got {t.type} at {t.pos}")
        if val  and t.value != val:  raise SyntaxError(f"expected `{val}`, got `{t.value}` at {t.pos}")
        self.i += 1
        return t

    # Program → StmtList
    def parse(self) -> StmtList:
        return self.parse_stmt_list()

    # StmtList → Stmt StmtList | ε
    def parse_stmt_list(self) -> StmtList:
        items = []
        while self.peek().type in ('ID','IF','WHILE','LBRACE'):
            items.append(self.parse_stmt())
        return StmtList(items)

    # Stmt → id = Expr ; | if (E) Stmt else Stmt | while (E) Stmt | { StmtList }
    def parse_stmt(self) -> Stmt:
        t = self.peek()
        if t.type == 'ID':
            name = self.eat('ID').value
            self.eat('OP','=')
            e = self.parse_expr()
            self.eat('SEMI',';')
            return Assign(name,e)
        if t.type == 'IF':
            self.eat('IF')
            self.eat('OP','(')
            cond = self.parse_expr()
            self.eat('OP',')')
            then = self.parse_stmt()
            self.eat('ELSE')  # dangling-else: 가장 가까운 if에 결합
            els = self.parse_stmt()
            return If(cond, then, els)
        if t.type == 'WHILE':
            self.eat('WHILE')
            self.eat('OP','(')
            cond = self.parse_expr()
            self.eat('OP',')')
            body = self.parse_stmt()
            return While(cond, body)
        if t.type == 'LBRACE':
            self.eat('LBRACE')
            body = self.parse_stmt_list()
            self.eat('RBRACE')
            return Block(body)
        raise SyntaxError(f"unexpected token {t.type} `{t.value}` at {t.pos}")

    # Expr 계층 (Or -> And -> Cmp -> Add -> Mul -> Unary -> Primary)
    def parse_expr(self):  return self.parse_or()

    def parse_or(self):
        node = self.parse_and()
        while self.peek().type=='OP' and self.peek().value=='||':
            self.eat('OP','||')
            node = BinOp('||', node, self.parse_and())
        return node

    def parse_and(self):
        node = self.parse_cmp()
        while self.peek().type=='OP' and self.peek().value=='&&':
            self.eat('OP','&&')
            node = BinOp('&&', node, self.parse_cmp())
        return node

    def parse_cmp(self):
        node = self.parse_add()
        while self.peek().type=='OP' and self.peek().value in ('==','!=','<','>','<=','>='):
            op = self.eat('OP').value
            node = BinOp(op, node, self.parse_add())
        return node

    def parse_add(self):
        node = self.parse_mul()
        while self.peek().type=='OP' and self.peek().value in ('+','-'):
            op = self.eat('OP').value
            node = BinOp(op, node, self.parse_mul())
        return node

    def parse_mul(self):
        node = self.parse_unary()
        while self.peek().type=='OP' and self.peek().value in ('*','/'):
            op = self.eat('OP').value
            node = BinOp(op, node, self.parse_unary())
        return node

    def parse_unary(self):
        if self.peek().type=='OP' and self.peek().value in ('-','!'):
            op = self.eat('OP').value
            return UnOp(op, self.parse_unary())
        return self.parse_primary()

    def parse_primary(self):
        t = self.peek()
        if t.type=='OP' and t.value=='(':
            self.eat('OP','(')
            node = self.parse_expr()
            self.eat('OP',')')
            return node
        if t.type=='ID':
            return Var(self.eat('ID').value)
        if t.type=='NUMBER':
            return Num(int(self.eat('NUMBER').value))
        if t.type=='TRUE':
            self.eat('TRUE');  return Bool(True)
        if t.type=='FALSE':
            self.eat('FALSE'); return Bool(False)
        raise SyntaxError(f"unexpected primary `{t.value}` at {t.pos}")

# ----------- 4) 간단 인터프리터(정수·불리언) -----------

class Env(dict): pass

def eval_expr(e: Expr, env: Env):
    if isinstance(e, Num):  return e.value
    if isinstance(e, Bool): return e.value
    if isinstance(e, Var):
        if e.name not in env: raise NameError(f"undefined variable `{e.name}`")
        return env[e.name]
    if isinstance(e, UnOp):
        v = eval_expr(e.expr, env)
        if e.op=='-': return -int(v)
        if e.op=='!': return not bool(v)
        raise RuntimeError("unknown unary")
    if isinstance(e, BinOp):
        l = eval_expr(e.left, env); r = eval_expr(e.right, env)
        if e.op=='+':  return int(l)+int(r)
        if e.op=='-':  return int(l)-int(r)
        if e.op=='*':  return int(l)*int(r)
        if e.op=='/':  return int(l)//int(r)
        if e.op=='<':  return int(l)<int(r)
        if e.op=='>':  return int(l)>int(r)
        if e.op=='<=': return int(l)<=int(r)
        if e.op=='>=': return int(l)>=int(r)
        if e.op=='==': return l==r
        if e.op=='!=': return l!=r
        if e.op=='&&': return bool(l) and bool(r)
        if e.op=='||': return bool(l) or  bool(r)
        raise RuntimeError("unknown binary")
    raise RuntimeError("unknown expr")

def exec_stmt(s: Stmt, env: Env):
    if isinstance(s, Assign):
        env[s.name] = eval_expr(s.expr, env)
    elif isinstance(s, If):
        if eval_expr(s.cond, env): exec_stmt(s.then, env)
        else:                      exec_stmt(s.els, env)
    elif isinstance(s, While):
        while eval_expr(s.cond, env): exec_stmt(s.body, env)
    elif isinstance(s, Block):
        for st in s.body.items: exec_stmt(st, env)
    else:
        raise RuntimeError("unknown stmt")

def run(code: str) -> Dict[str, Any]:
    toks = tokenize(code)
    ast  = Parser(toks).parse()
    env  = Env()
    for st in ast.items:
        exec_stmt(st, env)
    return env

if __name__ == "__main__":
    program = r"""
        x = 0;
        y = 1;
        while (x < 5) {
            y = y * 2;
            x = x + 1;
        }
        if (y >= 16) x = y; else x = -1;
    """
    print(run(program))  # {'x': 32, 'y': 32}
```

**포인트**
- **렉서**: 정규표현식(정규 언어)로 토큰화.
- **파서**: CFG 기반 **재귀하강(LL 스타일)**. 우선순위·결합법칙은 비터미널 계층으로 모델링.
- **AST/인터프리터**: 간단한 정수/불리언 평가, `while` 루프와 `if-else` 지원.

**테스트 아이디어**
```text
1) x=1; if (x==1) x=2; else x=3;      ==> x=2
2) x=0; while (x<3) { x=x+1; }         ==> x=3
3) x=1; y=2; z = (x+3)*y - 5;          ==> z= (4)*2 -5 = 3
4) x=1; y=2; x = !(y==2) || (x<y);     ==> x = True
```

---

## LR 계열 파싱(개요) — 큰 언어·복잡 문법에 강함

- **LR(0)/SLR(1)/LALR(1)/LR(1)**: **하향식 예측**이 어려운 문법도 **상향식**으로 안정적으로 처리.
- 핵심 아이디어: **아이템(점이 찍힌 규칙)**, **closure/goto**, **상태 기계** 구성 → **ACTION/GOTO 표**.
- 장점: 실제 언어의 대다수 구문이 **LR(1) 또는 LALR(1)** 범주에 들어 **자동 생성 도구(Yacc/Bison, ANTLR LR 모드 등)**로 실용적.

> 본 글의 코드 구현은 LL 기반이지만, 같은 언어를 LR로도 쉽게 커버 가능.

---

## 의미 분석(초간단 투어)

- **심벌 테이블**: 스코프별 identifier → 선언·타입·주소 등의 메타데이터
- **타입 규칙 예(발췌)**
  - 산술: \(int \;op\; int \to int\)
  - 비교: \(int \;cmp\; int \to bool\)
  - 논리: \(bool \;op\; bool \to bool\)
- **형식화(예)**
  $$
  \frac{\Gamma \vdash E_1:int \quad \Gamma \vdash E_2:int}{\Gamma \vdash (E_1+E_2):int}
  \qquad
  \frac{\Gamma \vdash E_1:int \quad \Gamma \vdash E_2:int}{\Gamma \vdash (E_1<E_2):bool}
  $$
- 본문 인터프리터는 “동적”하게 처리했지만, 정적 타입 언어라면 위 규칙을 AST 순회로 **타입 검사**.

---

## 실무 팁 & 도구

- **문법 작성 순서**:
  1) EBNF로 가독성 높게 초안 작성 → 2) LL/LR 타깃에 맞춰 변환(좌재귀 제거/팩토링 등)
  3) **FIRST/FOLLOW/테이블**로 충돌 점검 → 4) 오토테스트(수용/비수용·오류 메시지)
- **도구**:
  - **ANTLR**(LL(*) 예측, 풍부한 생태계)
  - **Bison/Yacc**(LR 계열)
  - **Tree-sitter**(IDE/하이라이팅/증분 파싱)
- **오류 회복**: `panic-mode`(세미콜론·중괄호 등 동기화 토큰까지 스킵) 등 전략 설계

---

## 요약

| 주제 | 핵심 |
|---|---|
| CFG 정의 | \(A\to \alpha\) 규칙으로 언어 생성, \(L(G)\)는 시작기호에서의 파생 집합 |
| 왜 CFG? | **중첩/재귀** 구조·우선순위·결합법칙을 자연스럽게 표현 |
| 모호성 | *Dangling else* 등은 비모호 문법(Matched/Unmatched)으로 해결 |
| LL 친화 | **좌재귀 제거/팩토링**, **FIRST/FOLLOW**로 LL(1) 만족 확인 |
| 코드 | 파이썬으로 **FIRST/FOLLOW/LL(1) 테이블 생성** + **미니 언어 파서/인터프리터** 제공 |
| 확장 | LR 계열로 큰 문법, 의미 분석·IR·최적화로 컴파일러 파이프라인 확장 |

---

## 연습 문제(권장)

1) 본문 LL(1) 표현식 문법의 **FIRST/FOLLOW**를 손으로 계산하고, 코드 출력과 대조.
2) `for(init; cond; step) Stmt`를 **CFG**로 추가(우선순위/결합법칙 유지)하고 파서 확장.
3) `let {x:int} in x = 3;` 같은 **블록 지역 선언/타입 표기**를 추가하고 **정적 타입 체크** 구현.
4) **오류 회복**: `;`까지 스킵하여 다음 문장으로 복구하는 파싱 전략을 추가.
