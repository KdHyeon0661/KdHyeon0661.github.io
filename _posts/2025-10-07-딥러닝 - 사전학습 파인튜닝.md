---
layout: post
title: 딥러닝 - 사전학습 파인튜닝
date: 2025-10-07 17:25:23 +0900
category: 딥러닝
---
# 사전학습(BERT류) 파인튜닝 개요 — **분류 · 질의응답(Extractive QA)**  

## 0) 준비물 & 용어

- **사전학습 모델**(PLM): `bert-base-uncased`, `klue/roberta-base`, `mDeBERTa`, `electra-base-discriminator` 등  
- **토크나이저**: WordPiece/BPE(모델별), 특수토큰(`[CLS] [SEP]`) 또는 `<s> </s>`(RoBERTa류)  
- **입력 텐서**: `input_ids`, `attention_mask`, (`token_type_ids`: BERT류에서 문장쌍 구분)  
- **패딩/트렁케이션**: 시퀀스 길이를 `max_length`로 맞춤  
- **손실**:  
  - 분류(다중 클래스): **CrossEntropy**  
  - 분류(멀티라벨): **BCEWithLogits**  
  - QA: **start/end 위치에 대한 CrossEntropy**

---

## 1) 토크나이즈 & 인코딩 핵심

- **분류** 입력:  
  - 단일 문장 → `[CLS] sent [SEP]`  
  - 문장쌍 → `[CLS] sentA [SEP] sentB [SEP]`(BERT류는 `token_type_ids`로 A/B 구분)  
- **QA** 입력: `question + context`를 하나의 시퀀스로 합치고, 긴 컨텍스트는 **stride**로 슬라이딩 분할  
- **주의**: RoBERTa/DeBERTa는 기본적으로 `token_type_ids`를 **사용하지 않음**(항상 0)

---

## 2) 텍스트 분류 파인튜닝 (단일/멀티 라벨)

### 2.1 데이터 형식 (예시)
- 단일 라벨 분류: `label`이 0..C-1
```json
{"text": "이 서비스 정말 편리해요!", "label": 1}
{"text": "품질이 별로고 배송도 느림", "label": 0}
```
- 멀티라벨 분류: `labels`가 0/1 배열
```json
{"text": "모바일 앱 보안 취약점 보고", "labels": [1,0,1,0]}
```

### 2.2 수식 요약
- **단일 라벨**(C 클래스):  
  $$\mathcal{L}_{\text{CE}} = -\sum_{c=1}^{C} y_c \log \text{softmax}(\mathbf{W}h_{[\text{CLS}]} + \mathbf{b})_c$$
- **멀티라벨**(K 태그):  
  $$\mathcal{L}_{\text{BCE}} = -\frac{1}{K}\sum_{k=1}^K \big[y_k \log \sigma(z_k) + (1-y_k)\log (1-\sigma(z_k))\big]$$
- **라벨 스무딩**(선택):  
  $$y_c'=(1-\epsilon)\cdot \mathbb{1}[c=\text{gold}] + \frac{\epsilon}{C}$$

### 2.3 파이프라인 코드 (데이터셋 → 토크나이저 → 모델/학습 루프)

```python
# pip install transformers datasets accelerate
import os, json, math, random
import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
from transformers import (AutoTokenizer, AutoModel, AutoConfig,
                          get_linear_schedule_with_warmup)
from sklearn.metrics import f1_score, accuracy_score, classification_report
from dataclasses import dataclass

SEED = 42
random.seed(SEED); torch.manual_seed(SEED); torch.cuda.manual_seed_all(SEED)

@dataclass
class ClsExample:
    text: str
    label: int | None = None
    labels: list[int] | None = None  # multi-label 용

class ClsDataset(Dataset):
    def __init__(self, path, multi_label=False):
        self.multi_label = multi_label
        self.samples = []
        with open(path, encoding="utf-8") as f:
            for line in f:
                j = json.loads(line)
                if multi_label:
                    self.samples.append(ClsExample(j["text"], labels=j["labels"]))
                else:
                    self.samples.append(ClsExample(j["text"], label=j["label"]))

    def __len__(self): return len(self.samples)
    def __getitem__(self, i): return self.samples[i]

class ClsCollator:
    def __init__(self, tokenizer, max_len=256, multi_label=False, num_labels=None):
        self.tok = tokenizer
        self.max_len = max_len
        self.multi_label = multi_label
        self.num_labels = num_labels
    def __call__(self, batch):
        texts = [x.text for x in batch]
        enc = self.tok(texts, padding=True, truncation=True,
                       max_length=self.max_len, return_tensors="pt")
        if self.multi_label:
            Y = torch.tensor([x.labels for x in batch], dtype=torch.float)
        else:
            Y = torch.tensor([x.label  for x in batch], dtype=torch.long)
        return enc, Y

class BertForClassification(nn.Module):
    def __init__(self, model_name, num_labels, multi_label=False, dropout=0.1):
        super().__init__()
        self.config = AutoConfig.from_pretrained(model_name, num_labels=num_labels)
        self.encoder = AutoModel.from_pretrained(model_name, config=self.config)
        self.dropout = nn.Dropout(dropout)
        self.classifier = nn.Linear(self.config.hidden_size, num_labels)
        self.multi_label = multi_label

    def forward(self, input_ids, attention_mask, token_type_ids=None, labels=None):
        out = self.encoder(input_ids=input_ids,
                           attention_mask=attention_mask,
                           token_type_ids=token_type_ids if "token_type_ids" in self.encoder.config.to_dict() else None)
        # CLS pool (마지막 layer의 [CLS])
        pooled = out.last_hidden_state[:, 0]  # [B, H]
        logits = self.classifier(self.dropout(pooled))
        loss = None
        if labels is not None:
            if self.multi_label:
                loss = nn.BCEWithLogitsLoss()(logits, labels)
            else:
                loss = nn.CrossEntropyLoss()(logits, labels)
        return logits, loss

def build_dataloaders(train_path, valid_path, model_name, batch_size=16,
                      max_len=256, multi_label=False, num_labels=None):
    tok = AutoTokenizer.from_pretrained(model_name, use_fast=True)
    tr_ds = ClsDataset(train_path, multi_label)
    va_ds = ClsDataset(valid_path, multi_label)
    coll = ClsCollator(tok, max_len=max_len, multi_label=multi_label, num_labels=num_labels)
    tr_dl = DataLoader(tr_ds, batch_size=batch_size, shuffle=True, num_workers=2, collate_fn=coll)
    va_dl = DataLoader(va_ds, batch_size=batch_size, shuffle=False, num_workers=2, collate_fn=coll)
    return tok, tr_dl, va_dl

def train_cls(model_name, train_jsonl, valid_jsonl,
              num_labels, multi_label=False, max_len=256,
              lr=2e-5, epochs=3, batch_size=16, warmup_ratio=0.1,
              grad_clip=1.0, device="cuda", amp=True):
    tok, tr_dl, va_dl = build_dataloaders(train_jsonl, valid_jsonl, model_name,
                                          batch_size, max_len, multi_label, num_labels)
    model = BertForClassification(model_name, num_labels, multi_label).to(device)
    # AdamW + Linear Warmup/Decay
    no_decay = ["bias", "LayerNorm.weight"]
    params = [
        {"params":[p for n,p in model.named_parameters() if not any(nd in n for nd in no_decay)], "weight_decay":0.01},
        {"params":[p for n,p in model.named_parameters() if any(nd in n for nd in no_decay)], "weight_decay":0.0},
    ]
    opt = torch.optim.AdamW(params, lr=lr)
    t_total = epochs * len(tr_dl)
    sch = get_linear_schedule_with_warmup(opt, int(t_total*warmup_ratio), t_total)

    scaler = torch.cuda.amp.GradScaler(enabled=amp)

    best_f1, best_path = -1, "best_cls.pt"
    for ep in range(1, epochs+1):
        model.train(); running=0
        for enc, y in tr_dl:
            enc = {k:v.to(device) for k,v in enc.items()}
            y = y.to(device)
            opt.zero_grad(set_to_none=True)
            with torch.cuda.amp.autocast(enabled=amp):
                logits, loss = model(**enc, labels=y)
            scaler.scale(loss).backward()
            torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)
            scaler.step(opt)
            scaler.update()
            sch.step()
            running += loss.item()
        tr_loss = running/len(tr_dl)

        # ----- Validation -----
        model.eval(); ys=[]; ps=[]
        with torch.no_grad():
            for enc, y in va_dl:
                enc = {k:v.to(device) for k,v in enc.items()}
                y = y.to(device)
                logits, _ = model(**enc, labels=None)
                if multi_label:
                    prob = torch.sigmoid(logits).cpu().numpy()
                    ps.append(prob); ys.append(y.cpu().numpy())
                else:
                    pred = torch.argmax(logits, dim=-1).cpu().numpy()
                    ps.append(pred); ys.append(y.cpu().numpy())
        import numpy as np
        if multi_label:
            Y = np.vstack(ys); P = np.vstack(ps)
            # 임계 0.5 기본, 필요 시 클래스별 threshold 튜닝
            P_bin = (P>=0.5).astype(int)
            micro_f1 = f1_score(Y, P_bin, average="micro")
            macro_f1 = f1_score(Y, P_bin, average="macro")
            val_score = micro_f1
            print(f"[ep {ep}] train_loss={tr_loss:.4f} val_microF1={micro_f1:.4f} val_macroF1={macro_f1:.4f}")
        else:
            Y = np.concatenate(ys); P = np.concatenate(ps)
            acc = accuracy_score(Y, P)
            f1 = f1_score(Y, P, average="macro")
            val_score = f1
            print(f"[ep {ep}] train_loss={tr_loss:.4f} val_acc={acc:.4f} val_macroF1={f1:.4f}")

        if val_score > best_f1:
            best_f1 = val_score
            torch.save({"model": model.state_dict(),
                        "tok": tok.name_or_path,
                        "config": model.config.to_dict()}, best_path)
            print(">> saved:", best_path)
    return best_path
```

#### 사용 예
```python
# 분류 클래스 수
best = train_cls(
    model_name="klue/roberta-base",
    train_jsonl="train.jsonl",
    valid_jsonl="valid.jsonl",
    num_labels=3,        # 단일 라벨 3클래스(예: 부정/중립/긍정)
    multi_label=False,   # 멀티라벨이면 True
    max_len=256, lr=3e-5, epochs=3, batch_size=32
)
```

### 2.4 추론/서빙
```python
def load_cls(model_ckpt, model_name=None, device="cuda"):
    ckpt = torch.load(model_ckpt, map_location=device)
    config = AutoConfig.from_pretrained(model_name or ckpt["tok"], num_labels=ckpt["config"]["num_labels"])
    tok = AutoTokenizer.from_pretrained(model_name or ckpt["tok"], use_fast=True)
    model = BertForClassification(model_name or ckpt["tok"], config.num_labels).to(device)
    model.load_state_dict(ckpt["model"]); model.eval()
    return tok, model

@torch.inference_mode()
def classify_texts(texts, tok, model, max_len=256, multi_label=False, threshold=0.5, device="cuda"):
    enc = tok(texts, padding=True, truncation=True, max_length=max_len, return_tensors="pt").to(device)
    logits, _ = model(**enc)
    if multi_label:
        prob = torch.sigmoid(logits).cpu().numpy()
        return (prob >= threshold).astype(int), prob
    else:
        prob = torch.softmax(logits, dim=-1).cpu().numpy()
        pred = prob.argmax(-1)
        return pred, prob

# tok, model = load_cls("best_cls.pt")
# pred, prob = classify_texts(["정말 최고!", "별로네요"], tok, model)
```

### 2.5 불균형/멀티라벨 팁
- **클래스 가중치**: `CrossEntropy(weight=tensor)`  
- **임계 튜닝**(멀티라벨): 각 클래스 **PR 곡선** 기반 최적 threshold  
- **라벨 스무딩**: 소수/노이즈 레이블 데이터에서 overconfidence 완화  
- **데이터 증강**: 백트랜슬레이션/랜덤 삭제/스팬 마스킹 등

---

## 3) 추출형 질의응답(Extractive QA, SQuAD 스타일)

### 3.1 태스크 정의
- 질문 \(Q\)와 문서/문단 \(C\)가 주어질 때, \(C\)의 연속된 토큰 구간 \([s,e]\)를 정답으로 예측  
- **학습 목표**: 시작/끝 위치 각각의 **CrossEntropy** 최소화  
  $$
  \mathcal{L} = \frac{1}{2}\Big(\text{CE}(y_s,\hat{y}_s)+\text{CE}(y_e,\hat{y}_e)\Big)
  $$

### 3.2 데이터 형식(SQuAD 유사)
```json
{
  "id": "ex-1",
  "title": "세종대왕",
  "context": "세종대왕은 조선의 제4대 임금이다...",
  "question": "세종대왕은 어느 왕조의 임금인가?",
  "answers": {"text": ["조선"], "answer_start": [0]}
}
```
- **긴 컨텍스트**: 토크나이즈 시 **stride**로 슬라이딩 분할 → 한 질문이 **여러 feature**로 변환  
- **오버플로우 매핑**: feature → 원본 example 인덱스/오프셋 기록

### 3.3 데이터셋/피처 만들기(오프셋 맵, stride)

```python
from typing import List, Dict, Any
from transformers import AutoTokenizer, AutoModelForQuestionAnswering
from torch.utils.data import DataLoader, Dataset
import numpy as np

class QaExample:
    def __init__(self, j):
        self.id = j["id"]; self.context = j["context"]
        self.question = j["question"]; self.title = j.get("title","")
        self.answers = j.get("answers", None)

class QaDataset(Dataset):
    def __init__(self, path):
        self.data = []
        with open(path, encoding="utf-8") as f:
            for line in f:
                self.data.append(QaExample(json.loads(line)))
    def __len__(self): return len(self.data)
    def __getitem__(self, i): return self.data[i]

def prepare_qa_features(examples: List[QaExample], tokenizer, max_len=384, doc_stride=128, is_train=True):
    # 원본 리스트를 토크나이저가 요구하는 batch dict로 변환
    questions = [ex.question for ex in examples]
    contexts  = [ex.context  for ex in examples]
    enc = tokenizer(
        questions, contexts, truncation="only_second", max_length=max_len,
        stride=doc_stride, return_overflowing_tokens=True, return_offsets_mapping=True,
        padding="max_length"
    )
    sample_mapping = enc.pop("overflow_to_sample_mapping")  # feature -> example
    offset_mapping = enc.pop("offset_mapping")              # [T, 2] char offsets

    # 학습: start/end labels 생성
    start_positions, end_positions = [], []
    if is_train:
        for i, offsets in enumerate(offset_mapping):
            ex_id = sample_mapping[i]
            ans = examples[ex_id].answers
            # 없는 경우(예: SQuAD v2)면 CLS로
            if ans is None or len(ans["answer_start"])==0:
                start_positions.append(0); end_positions.append(0)  # CLS 위치(보통 0)
                continue
            # 첫 정답만 사용(여러개면 랜덤/첫 번째)
            start_char = ans["answer_start"][0]
            end_char   = start_char + len(ans["text"][0])
            # sequence_ids: (0=question, 1=context, None=special)
            sequence_ids = enc.sequence_ids(i)
            # context token 범위
            idx = 0
            while sequence_ids[idx] != 1: idx += 1
            ctx_start = idx
            while idx < len(sequence_ids) and sequence_ids[idx] == 1: idx += 1
            ctx_end = idx - 1
            # 정답 범위와 겹치는 토큰 찾기
            tok_start, tok_end = 0, 0
            if not (offsets[ctx_start][0] <= start_char and offsets[ctx_end][1] >= end_char):
                # 정답이 이 feature의 context 구간에 없음 → CLS로
                tok_start, tok_end = 0, 0
            else:
                # start position
                s = ctx_start
                while s <= ctx_end and offsets[s][0] <= start_char:
                    s += 1
                tok_start = s-1
                # end position
                e = ctx_end
                while e >= ctx_start and offsets[e][1] >= end_char:
                    e -= 1
                tok_end = e+1
            start_positions.append(tok_start)
            end_positions.append(tok_end)

        enc["start_positions"] = start_positions
        enc["end_positions"]   = end_positions

    # 추론/후처리용 메타
    enc["example_id"] = [examples[sample_mapping[i]].id for i in range(len(sample_mapping))]
    enc["offset_mapping"] = offset_mapping
    return enc, sample_mapping
```

### 3.4 학습 루프 (BERT QA 헤드)
```python
def build_qa(model_name, num_labels=2):
    model = AutoModelForQuestionAnswering.from_pretrained(model_name)
    tok   = AutoTokenizer.from_pretrained(model_name, use_fast=True)
    return tok, model

class QaFeatDataset(Dataset):
    def __init__(self, features: Dict[str, Any], is_train=True):
        self.features = features; self.is_train = is_train
        self.keys = list(features.keys())
        self.length = len(features["input_ids"])
    def __len__(self): return self.length
    def __getitem__(self, i):
        item = {k: torch.tensor(self.features[k][i]) for k in [
            "input_ids", "attention_mask"
        ]}
        if "token_type_ids" in self.features:
            item["token_type_ids"] = torch.tensor(self.features["token_type_ids"][i])
        if self.is_train:
            item["start_positions"] = torch.tensor(self.features["start_positions"][i])
            item["end_positions"]   = torch.tensor(self.features["end_positions"][i])
        return item

def train_qa(train_jsonl, valid_jsonl, model_name="klue/roberta-base",
             max_len=384, doc_stride=128, lr=3e-5, epochs=2, bs=16, warmup_ratio=0.1,
             device="cuda", amp=True):
    tok, model = build_qa(model_name); model.to(device)
    tr_raw = QaDataset(train_jsonl); va_raw = QaDataset(valid_jsonl)

    tr_feat, _ = prepare_qa_features(tr_raw.data, tok, max_len, doc_stride, is_train=True)
    va_feat, va_map = prepare_qa_features(va_raw.data, tok, max_len, doc_stride, is_train=True)

    tr_ds = QaFeatDataset(tr_feat, is_train=True)
    va_ds = QaFeatDataset(va_feat, is_train=True)
    tr_dl = DataLoader(tr_ds, batch_size=bs, shuffle=True, num_workers=2)
    va_dl = DataLoader(va_ds, batch_size=bs, shuffle=False, num_workers=2)

    opt = torch.optim.AdamW(model.parameters(), lr=lr)
    t_total = epochs*len(tr_dl)
    sch = get_linear_schedule_with_warmup(opt, int(t_total*warmup_ratio), t_total)
    scaler = torch.cuda.amp.GradScaler(enabled=amp)

    for ep in range(1, epochs+1):
        model.train(); running=0
        for batch in tr_dl:
            batch = {k:v.to(device) for k,v in batch.items()}
            opt.zero_grad(set_to_none=True)
            with torch.cuda.amp.autocast(enabled=amp):
                out = model(**batch)
                loss = out.loss
            scaler.scale(loss).backward()
            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)
            scaler.step(opt); scaler.update(); sch.step()
            running += loss.item()
        print(f"[ep {ep}] train_loss={running/len(tr_dl):.4f}")

        # 간단 검증: loss만 (정확 평가는 n-best 추론 필요)
        model.eval(); vl=0
        with torch.no_grad():
            for batch in va_dl:
                batch = {k:v.to(device) for k,v in batch.items()}
                out = model(**batch)
                vl += out.loss.item()
        print(f"[ep {ep}] valid_loss={vl/len(va_dl):.4f}")

    torch.save({"model": model.state_dict(), "tok": tok.name_or_path}, "best_qa.pt")
    return tok, model
```

### 3.5 n-best 추론 & EM/F1 평가
- **아이디어**: 각 feature 별 **start/end logits**에서 상위 n 쌍을 추려 **텍스트 span** 복원,  
  동일 example의 여러 feature 후보 중 **최고 점수** 선택  
- **SQuAD v2(없음 가능)**: `cls` 토큰(보통 index 0)의 점수와 비교해 **no-answer** 결정

```python
def normalize_answer(s):
    import re, string
    def remove_punc(text):
        return "".join(ch for ch in text if ch not in set(string.punctuation))
    def white_space_fix(text):
        return " ".join(text.split())
    def lower(text): return text.lower()
    return white_space_fix(remove_punc(lower(s)))

def f1_em(prediction, ground_truth):
    # SQuAD 평가 규칙 준수 간단 버전
    pred = normalize_answer(prediction)
    gold = normalize_answer(ground_truth)
    EM = 1 if pred == gold else 0
    pred_tokens = pred.split(); gold_tokens = gold.split()
    common = set(pred_tokens) & set(gold_tokens)
    if len(pred_tokens)==0 or len(gold_tokens)==0: return EM, 0.0
    num_same = sum(min(pred_tokens.count(w), gold_tokens.count(w)) for w in common)
    if num_same==0: return EM, 0.0
    precision = num_same/len(pred_tokens); recall = num_same/len(gold_tokens)
    F1 = 2*precision*recall/(precision+recall)
    return EM, F1

@torch.inference_mode()
def predict_qa(examples: List[QaExample], features, model, tokenizer,
               n_best=20, max_answer_len=30, device="cuda"):
    from collections import defaultdict
    model.to(device).eval()
    ds = QaFeatDataset(features, is_train=False)  # start/end 없음
    dl = DataLoader(ds, batch_size=32, shuffle=False)
    all_start, all_end = [], []
    for batch in dl:
        enc = {k:v.to(device) for k,v in batch.items()}
        out = model(**enc)
        all_start.append(out.start_logits.cpu().numpy())
        all_end.append(out.end_logits.cpu().numpy())
    import numpy as np
    start_logits = np.concatenate(all_start, 0)
    end_logits   = np.concatenate(all_end, 0)

    example_to_features = defaultdict(list)
    for i,eid in enumerate(features["example_id"]):
        example_to_features[eid].append(i)

    preds = {}
    for ex in examples:
        prelim = []
        for fi in example_to_features[ex.id]:
            offsets = features["offset_mapping"][fi]
            input_ids = features["input_ids"][fi]
            s_logit = start_logits[fi]; e_logit = end_logits[fi]
            # 상위 n-best start/end 후보 탐색
            start_indexes = np.argsort(s_logit)[-n_best:][::-1]
            end_indexes   = np.argsort(e_logit)[-n_best:][::-1]
            for s in start_indexes:
                for e in end_indexes:
                    if e < s or (e - s + 1) > max_answer_len: 
                        continue
                    # 문맥 토큰인지 확인 (offset이 None이 아닌가)
                    if offsets[s] is None or offsets[e] is None:
                        continue
                    score = s_logit[s] + e_logit[e]
                    prelim.append((score, fi, s, e))
        if len(prelim)==0:
            preds[ex.id] = ""
            continue
        # 최고 점수 스팬
        best = max(prelim, key=lambda x:x[0])
        _, fi, s, e = best
        offsets = features["offset_mapping"][fi]
        # char 단위로 복원
        start_char, end_char = offsets[s][0], offsets[e][1]
        context = ex.context
        preds[ex.id] = context[start_char:end_char]
    return preds

def evaluate_qa(gold: List[QaExample], preds: dict):
    EMs, F1s = [], []
    for ex in gold:
        gold_texts = ex.answers["text"] if ex.answers and "text" in ex.answers else [""]
        pred = preds.get(ex.id, "")
        # 여러 정답 중 최고 점수
        scores = [f1_em(pred, g) for g in gold_texts]
        EMs.append(max(s[0] for s in scores))
        F1s.append(max(s[1] for s in scores))
    import numpy as np
    return float(np.mean(EMs)), float(np.mean(F1s))
```

#### 사용 예 (평가)
```python
# 학습 후
tok, model = build_qa("klue/roberta-base")
ckpt = torch.load("best_qa.pt", map_location="cuda")
model.load_state_dict(ckpt["model"])

va_raw = QaDataset("valid.jsonl")
va_feat, _ = prepare_qa_features(va_raw.data, tok, is_train=False)
preds = predict_qa(va_raw.data, va_feat, model, tok)
EM, F1 = evaluate_qa(va_raw.data, preds)
print("EM:", EM, "F1:", F1)
```

### 3.6 긴 문서/도메인 이슈
- **긴 콘텍스트**: `max_len↑`, `doc_stride`(128~192)로 **겹치기**  
- **도메인 용어**: PLM 토크나이저가 과도하게 분절되면 성능 하락 →  
  **도메인 MLM 추가 사전학습(continued pretraining)** 또는 **특수토큰 사전확대** 고려  
- **SQuAD v2(무정답)**: CLS 점수와 후보 스팬 점수 비교로 **no-answer** 판단 임계 설정

---

## 4) 학습 공학(AMP/재현성/스케일링)

### 4.1 AMP 혼합정밀
- **속도/메모리** 이점, 대부분 BERT류에서 안전  
- 위 코드에서는 `torch.cuda.amp.autocast` + `GradScaler` 사용

### 4.2 시드 고정/결정성
```python
import numpy as np, random, torch
def set_seed(seed=42):
    random.seed(seed); np.random.seed(seed)
    torch.manual_seed(seed); torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False
```

### 4.3 분산 학습(DDP) 개요
- 데이터 병렬(DDP)로 배치/속도 확장.  
- **주의**:  
  - 데이터 셔플 시 **DistributedSampler**  
  - `get_linear_schedule_with_warmup`의 `t_total`은 **전 프로세스 합 기준**  
  - AMP/스케일러는 프로세스별 개별 사용

---

## 5) 하이퍼파라미터 & 튜닝 가이드

- **학습률**: 2e-5 ~ 5e-5(BERT/roBERTa base), large는 1e-5 ~ 3e-5  
- **배치**: 16~64(메모리 내에서 최대), **gradient accumulation**으로 유효 배치 ↑  
- **에폭**: 분류 3±2, QA 2±1(과적합 체크)  
- **스케줄러**: Linear warmup(10%) → decay  
- **드롭아웃**: 0.1 기본, 데이터 적으면 0.2~0.3  
- **조기 종료**: valid macro-F1/EM-F1 모니터링

---

## 6) 문제해결(트러블슈팅)

1) **과적합**: train↑, valid↓ → 드롭아웃↑, L2↑, 데이터 증강/라벨 검수, 라벨 스무딩  
2) **학습 불안정/NaN**: LR↓, grad clip, AMP off, 시드 고정  
3) **멀티라벨 편향**: positive rare → 클래스별 임계/가중치, Focal Loss  
4) **QA에서 틀린 스팬**: `doc_stride`↑, `max_answer_len` 조정, 토크나이저 fast/offset 확인  
5) **문장쌍 분류 오류**: BERT류만 `token_type_ids` 사용, RoBERTa/DeBERTa는 무시됨 유의

---

## 7) 확장 토픽(선택)

- **Layer-wise LR decay(LLRD)**: 하위 레이어 작은 LR(예: 0.95^layer) → 섬세한 미세튜닝  
- **Freeze 전략**: 하위 6층 freeze → 빠른 수렴/과적합 감소  
- **PEFT(LoRA/IA3)**: 적은 파라미터로 태스크 전이(리소스 제한/다중 태스크 운영에 유리)  
- **도메인 MLM 추가학습**: 자체 말뭉치로 몇천~수만 step → 용어 분절 개선/성능↑

---

## 8) 체크리스트

- [ ] 데이터 정합: 라벨/텍스트 누락/UTF-8 깨짐 확인  
- [ ] 토크나이즈: `max_length`, `truncation`, 문장쌍/QA stride 설정  
- [ ] 옵티마이저/스케줄러: AdamW + Linear warmup/decay  
- [ ] AMP + grad clip(1.0)  
- [ ] 메트릭: 분류(macro-F1/ROC-AUC), QA(EM/F1)  
- [ ] 저장: `state_dict`, `tokenizer`, `config` 버전 기록(재현성)  
- [ ] 추론: 배치화, CPU fallback, 최대 길이/stride 일치

---

## 9) 미니 실습 시나리오

### 9.1 감성분류(3-way)
- 데이터: `train.jsonl / valid.jsonl`  
- 모델: `klue/roberta-base`  
- 실행:
```python
best = train_cls("klue/roberta-base", "train.jsonl", "valid.jsonl",
                 num_labels=3, multi_label=False, max_len=256,
                 lr=3e-5, epochs=3, batch_size=32)
```
- 결과 확인:
```python
tok, model = load_cls(best)
pred, prob = classify_texts(["배송 빨라서 만족", "환불 늦고 불친절"], tok, model)
print(pred, prob)
```

### 9.2 도메인 QA
- 데이터: `train_qa.jsonl / valid_qa.jsonl`(SQuAD 스타일)  
- 실행:
```python
tok, model = train_qa("train_qa.jsonl", "valid_qa.jsonl",
                      model_name="klue/roberta-base",
                      max_len=384, doc_stride=128, lr=3e-5, epochs=2, bs=16)
va_raw = QaDataset("valid_qa.jsonl")
va_feat, _ = prepare_qa_features(va_raw.data, tok, is_train=False)
preds = predict_qa(va_raw.data, va_feat, model, tok)
EM, F1 = evaluate_qa(va_raw.data, preds)
print("EM:", EM, "F1:", F1)
```

---

## 10) 수식 모음 (참고)

- **CrossEntropy**:  
  $$\mathrm{CE}(y,\hat{y}) = -\sum_{c=1}^C y_c \log \hat{y}_c,\quad \hat{y}=\mathrm{softmax}(z)$$
- **Binary Cross-Entropy with Logits**:  
  $$\mathrm{BCE}(y,\hat{z}) = -\big(y\log \sigma(\hat{z}) + (1-y)\log (1-\sigma(\hat{z}))\big)$$
- **QA 손실**(start/end 평균):  
  $$\mathcal{L}=\tfrac{1}{2}\big(\mathrm{CE}(y_s,\hat{y}_s)+\mathrm{CE}(y_e,\hat{y}_e)\big)$$

---

# 마무리
- **분류**는 입력 풀링(보통 **[CLS]**) 뒤 얕은 분류기 하나로도 강력합니다. **불균형/멀티라벨**이면 손실/임계/가중치 설계를 꼭 하세요.  
- **QA**는 **stride**·**오프셋 맵**·**n-best** 후처리가 성능을 가릅니다.  
- 운영 단계에서는 **AMP**·**스케줄러**·**재현성**·**메트릭 회귀**를 자동화하세요.  
- 도메인 특이성이 크면 **MLM 추가 사전학습** 또는 **PEFT**로 비용 대비 성능을 올릴 수 있습니다.
