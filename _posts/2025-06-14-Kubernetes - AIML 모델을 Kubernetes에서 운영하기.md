---
layout: post
title: Kubernetes - ì‹¤ìŠµ : AI/ML ëª¨ë¸ì„ Kubernetesì—ì„œ ìš´ì˜í•˜ê¸°
date: 2025-06-13 22:20:23 +0900
category: Kubernetes
---
# ğŸ§  ì‹¤ìŠµ: AI/ML ëª¨ë¸ì„ Kubernetesì—ì„œ ìš´ì˜í•˜ê¸°

AI/ML ëª¨ë¸ ê°œë°œì´ ì™„ë£Œëœ í›„, ê°€ì¥ í° ê³¼ì œëŠ” **ì•ˆì •ì ì´ê³  ìœ ì—°í•œ ìš´ì˜ í™˜ê²½ êµ¬ì¶•**ì…ë‹ˆë‹¤. KubernetesëŠ” AI ëª¨ë¸ì„ **ì„œë²„ë¦¬ìŠ¤ì²˜ëŸ¼ ë°°í¬í•˜ê³  í™•ì¥í•˜ë©°, ìì›ì„ íš¨ìœ¨ì ìœ¼ë¡œ ê´€ë¦¬**í•  ìˆ˜ ìˆëŠ” ê°•ë ¥í•œ í”Œë«í¼ì…ë‹ˆë‹¤.

ì´ë²ˆ ì‹¤ìŠµì—ì„œëŠ” **ì‚¬ì „ í•™ìŠµëœ ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ì„ Kubernetesì— ì„œë¹™**í•˜ê³ , ì´ë¥¼ ì™¸ë¶€ì—ì„œ í˜¸ì¶œí•˜ëŠ” êµ¬ì¡°ë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤.

---

## âœ… ì‹¤ìŠµ ëª©í‘œ

- í•™ìŠµëœ AI ëª¨ë¸ì„ Docker ì´ë¯¸ì§€ë¡œ ê°ì‹¸ê³  ë°°í¬
- Flask + Pickle ê¸°ë°˜ API êµ¬ì„±
- Kubernetesì—ì„œ Deployment + Service + Ingress êµ¬í˜„
- Resource Limit ë° Auto-scaling ì ìš©

---

## ğŸ§± ì „ì²´ ì•„í‚¤í…ì²˜

```plaintext
ì‚¬ìš©ì â†’ Ingress â†’ Service â†’ Pod (Flask + ML ëª¨ë¸)
                          â†•
                     PersistentVolume (ëª¨ë¸ ì €ì¥)
```

---

## ğŸ“¦ 1. ëª¨ë¸ ì¤€ë¹„

### ëª¨ë¸ í•™ìŠµ ë° ì €ì¥ ì˜ˆ (scikit-learn)

```python
# train_model.py
from sklearn.ensemble import RandomForestClassifier
from sklearn.datasets import load_iris
import joblib

X, y = load_iris(return_X_y=True)
clf = RandomForestClassifier()
clf.fit(X, y)

joblib.dump(clf, 'model.pkl')
```

```bash
python train_model.py
```

---

## ğŸ³ 2. Dockerfile ì‘ì„±

```Dockerfile
FROM python:3.9-slim

WORKDIR /app

COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

COPY model.pkl .
COPY app.py .

CMD ["python", "app.py"]
```

### `requirements.txt`

```
flask
scikit-learn
joblib
```

### `app.py` (Flask API)

```python
from flask import Flask, request, jsonify
import joblib
import numpy as np

app = Flask(__name__)
model = joblib.load("model.pkl")

@app.route("/predict", methods=["POST"])
def predict():
    data = request.get_json(force=True)
    inputs = np.array(data["inputs"]).reshape(1, -1)
    prediction = model.predict(inputs)
    return jsonify({"prediction": prediction.tolist()})
```

### ì´ë¯¸ì§€ ë¹Œë“œ ë° ì—…ë¡œë“œ

```bash
docker build -t <username>/ml-api:latest .
docker push <username>/ml-api:latest
```

---

## ğŸš€ 3. Kubernetes ë°°í¬ íŒŒì¼ ì‘ì„±

### `ml-deployment.yaml`

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: ml-api
spec:
  replicas: 1
  selector:
    matchLabels:
      app: ml-api
  template:
    metadata:
      labels:
        app: ml-api
    spec:
      containers:
        - name: ml-api
          image: <username>/ml-api:latest
          ports:
            - containerPort: 5000
          resources:
            requests:
              cpu: "100m"
              memory: "128Mi"
            limits:
              cpu: "500m"
              memory: "512Mi"
---
apiVersion: v1
kind: Service
metadata:
  name: ml-api-service
spec:
  selector:
    app: ml-api
  ports:
    - protocol: TCP
      port: 80
      targetPort: 5000
```

```bash
kubectl apply -f ml-deployment.yaml
```

---

## ğŸŒ 4. Ingressë¡œ ì™¸ë¶€ì— ê³µê°œ

### `ml-ingress.yaml`

```yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: ml-api-ingress
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /
spec:
  rules:
    - host: ml.local
      http:
        paths:
          - path: /
            pathType: Prefix
            backend:
              service:
                name: ml-api-service
                port:
                  number: 80
```

```bash
kubectl apply -f ml-ingress.yaml
```

ğŸ“Œ `/etc/hosts` ì— ì•„ë˜ ë¼ì¸ ì¶”ê°€:

```plaintext
127.0.0.1 ml.local
```

---

## ğŸ§ª 5. í…ŒìŠ¤íŠ¸: ì˜ˆì¸¡ í˜¸ì¶œ

```bash
curl -X POST http://ml.local/predict \
  -H "Content-Type: application/json" \
  -d '{"inputs": [5.1, 3.5, 1.4, 0.2]}'
```

```json
{"prediction": [0]}
```

---

## ğŸ“ˆ 6. Horizontal Pod Autoscaler ì„¤ì •

```bash
kubectl autoscale deployment ml-api \
  --cpu-percent=50 \
  --min=1 \
  --max=5
```

í™•ì¸:

```bash
kubectl get hpa
```

ë¡œë“œ í…ŒìŠ¤íŠ¸ í›„ ìë™ ìŠ¤ì¼€ì¼ë§ ë˜ëŠ”ì§€ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

---

## ğŸ“Š 7. ëª¨ë‹ˆí„°ë§ ì—°ë™ (ì„ íƒ)

- `Prometheus + Grafana`ë¡œ Flask API ëª¨ë‹ˆí„°ë§
- `Kubernetes Dashboard`ë‚˜ `Lens`ë¡œ Pod ìƒíƒœ í™•ì¸
- `kube-metrics-server` ì„¤ì¹˜ í•„ìš”

---

## ğŸ“ ì „ì²´ êµ¬ì„± ì •ë¦¬

```plaintext
- Dockerfile
- model.pkl
- app.py
- ml-deployment.yaml
- ml-ingress.yaml
```

---

## ğŸ’¡ ì‹¤ì „ ì‘ìš© ì•„ì´ë””ì–´

| ì‘ìš© ì‹œë‚˜ë¦¬ì˜¤ | ì„¤ëª… |
|----------------|------|
| REST API ê¸°ë°˜ ëª¨ë¸ ì„œë¹™ | Flask â†’ FastAPIë¡œ í™•ì¥ |
| ëª¨ë¸ ë²„ì „ ê´€ë¦¬ | `/v1`, `/v2` ë“±ì˜ ê²½ë¡œë¡œ Ingress ë¼ìš°íŒ… |
| A/B í…ŒìŠ¤íŠ¸ | ë‘ ëª¨ë¸ì„ ê°ê° ë°°í¬í•˜ê³  íŠ¸ë˜í”½ ë¶„í•  |
| GPU ì„œë¹™ | nodeSelector + nvidia runtime ì ìš© |
| TensorFlow Serving / TorchServe | ì „ìš© ì„œë¹™ ì†”ë£¨ì…˜ìœ¼ë¡œ êµì²´ ê°€ëŠ¥ |

---

## ğŸ§¼ ì‚­ì œ ì •ë¦¬

```bash
kubectl delete -f ml-deployment.yaml
kubectl delete -f ml-ingress.yaml
kubectl delete hpa ml-api
```

---

## ğŸ“š ì°¸ê³  ë§í¬

- [Kubernetes Python ëª¨ë¸ ì„œë¹™](https://kubernetes.io/docs/tutorials/)
- [Joblib + Flask ëª¨ë¸ ì˜ˆì‹œ](https://scikit-learn.org/)
- [Horizontal Pod Autoscaler](https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/)

---

## âœ… ë§ˆë¬´ë¦¬ ìš”ì•½

- í•™ìŠµëœ ëª¨ë¸ì„ Flask APIë¡œ ê°ì‹¸ Docker ì´ë¯¸ì§€ë¡œ ë§Œë“¤ê³  ë°°í¬
- Kubernetesì—ì„œ ì•ˆì •ì ì´ê³  ìœ ì—°í•˜ê²Œ ìš´ì˜ ê°€ëŠ¥
- Ingressë¡œ ì™¸ë¶€ ì„œë¹„ìŠ¤ ì œê³µ, HPAë¡œ ë¶€í•˜ ëŒ€ì‘
- ì‹¤ë¬´ í™˜ê²½ì— í™•ì¥ ì ìš© ê°€ëŠ¥ (CI/CD, GPU, ë²„ì „ ê´€ë¦¬ ë“±)