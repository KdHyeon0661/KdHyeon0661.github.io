---
layout: post
title: 컴퓨터시스템 - 프로그램 성능에 대한 캐시의 영향
date: 2025-08-06 22:20:23 +0900
category: 컴퓨터시스템
---
# 프로그램 성능에 대한 캐시의 영향 — 이론·징후·최적화·검증

> 핵심 메시지: **캐시 히트율과 미스 페널티**가 성능을 좌우한다.  
> 같은 알고리즘이라도 **데이터 접근 패턴**과 **코드 크기/배치**에 따라 수십 배 성능 차이가 난다.  
> 여기서는 캐시가 성능에 미치는 구체적 경로를 해부하고, 실제로 **무엇을 고치고 어떻게 확인할지**까지 정리한다.

---

## 1) 왜 캐시가 성능을 지배하는가

CPU는 나노초 단위로 일하지만 DRAM은 여전히 수백 ns 레벨이다.  
캐시는 **자주 쓰는 데이터/명령**을 코어 가까이 두어 이 격차를 숨긴다.  
핵심 변수는 두 가지:

1. **히트 확률 \(1-m\)** — 미스율 \(m\) 이 작을수록 좋다.  
2. **미스 페널티 \(P\)** — 미스가 발생했을 때 하위 계층에서 채워오는 시간.

평균 접근 시간(AMAT)은 계층적으로 이렇게 쌓인다:

\[
\text{AMAT} = T_{L1} + m_1\Big(T_{L2} + m_2\big(T_{L3} + m_3\cdot T_{\text{Mem}}\big)\Big)
\]

여기서 \(T_{Lk}\)는 각 캐시 레벨의 히트 시간, \(m_k\)는 해당 레벨의 미스율.  
**미스율과 페널티의 곱**이 커질수록 성능은 무너진다.

---

## 2) CPI 모델: 캐시 미스가 CPU 시간을 늘리는 방식

CPU 시간은 대략 아래로 표현할 수 있다:

\[
\text{CPI} \approx \text{CPI}_\text{base} \;+\;
\underbrace{\frac{\text{MemAccesses}}{\text{Instr}} \times
\frac{\text{Misses}}{\text{Access}} \times
\frac{\text{MissPenalty}}{\text{MLP}}}_{\text{메모리 스톨}}
\]

- \(\text{MemAccesses}/\text{Instr}\): 명령 1개당 메모리 접근 수  
- \(\text{Misses}/\text{Access}\): 접근 1회당 미스율  
- \(\text{MissPenalty}\): 미스당 추가 비용(사이클)  
- **MLP**(Memory-Level Parallelism): 동시에 outstanding 가능한 미스 수(클수록 스톨이 겹쳐져 완화)

> 포인터 추적처럼 **직렬 의존**이 큰 코드는 MLP≈1 → 미스가 **그대로** 지연으로 반영된다.

---

## 3) 데이터 캐시가 성능에 미치는 구체적 경로

### 3.1 미스의 3(+1)가지 원인
- **Compulsory**: 처음 보는 데이터 → 피하기 어렵다(타일링·프리패치로 완화).
- **Capacity**: 워킹셋 > 캐시 용량 → 타일링/재사용 극대화로 해결.
- **Conflict**: 특정 세트에 핫 데이터가 몰려 **스래싱** → **패딩/오프셋**으로 분산.
- **Coherence**: (멀티코어) 타 코어의 쓰기로 라인이 무효화 → **폴스 셰어링** 주의.

### 3.2 쓰기 정책이 만드는 차이
- **Write-back + Write-allocate**(보편): 재사용이 있으면 효율적.
- **Write-through/No-write-allocate**: **다시 보지 않을 스트리밍 결과**엔 유리할 수 있음.
- **Non-temporal store**: 큰 결과를 캐시 오염 없이 메모리로 직행(플랫폼 힌트).

### 3.3 로드/스토어의 “불필요” 제거
- store 직후 같은 주소를 다시 load 하는 패턴은 레지스터 값 재사용으로 제거.  
- 같은 원소를 반복 로드하지 말고 **스칼라 변수**로 재사용.

---

## 4) 명령어(코드) 캐시의 영향

- **루프 언롤·인라인**은 분기/호출 오버헤드를 줄이지만 **코드 크기 증가 → I-캐시 압박**.  
- I-캐시 미스가 늘면 프론트엔드가 μop 공급을 못 해 **IPC가 급락**.  
- 최적 포인트: **핫 루프만 적당히 언롤/인라인**하고, 콜드 경로는 분리(Hot/Cold 분리)한다.

---

## 5) TLB와 캐시의 교차 효과

- TLB 미스(가상→물리 변환 실패)는 **페이지 워크**를 일으켜 지연이 급증한다.  
- 워킹셋이 크면 **Huge Page(2MB/1GB)** 로 **TLB reach**를 늘려 미스를 줄인다.  
- 대형 배열 초기화는 **연속 쓰기**로 페이지들을 “워밍업”하라(first-touch).

---

## 6) 프리패처와 MLP: 미스를 겹쳐서 숨기기

- 하드웨어 프리패처는 **연속/스트라이드/근접** 패턴에서 잘 작동한다.  
- 소프트웨어 프리패치는 DRAM 왕복 지연과 루프 소비 사이클을 고려해 **거리**를 조정해야 한다.
- **포인터 추적/랜덤 접근**은 프리패처가 무력화되기 쉬우므로, **배치/압축·리오더링**으로 순차성 확보가 중요.

---

## 7) 멀티코어에서 캐시가 만드는 병목

- **폴스 셰어링**: 서로 다른 변수가 **같은 캐시 라인**에 있고, 여러 스레드가 번갈아 쓰면 라인 무효화가 빈발 → 처리량 급락.
- **LLC(공유 L3) 스래싱**: 스레드 수가 늘수록 핫셋이 충돌 → 타일 크기/스레드 배치/워크 분할로 충돌을 완화.
- **NUMA**: 원격 노드 접근은 지연/대역 손해 → first-touch, 스레드/데이터 바인딩 필수.

```c
typedef struct { _Alignas(64) long v; } Padded;  // 64B 패딩으로 폴스 셰어링 방지
Padded counters[64];
```

---

## 8) 캐시 친화적 설계 원칙 (데이터·루프·동시성)

### 8.1 데이터 레이아웃
- **AoS → SoA**: 열 단위 연산(DLP)을 키워 **Stride-1**과 벡터화를 확보.
- **정렬/패딩**: 64B 정렬과 세트 충돌 분산(오프셋)으로 라인/세트 스래싱 완화.
- **연속 할당**: 아레나/풀 할당으로 포인터 추적 비용 절감.

### 8.2 루프 변환
- **Interchange**로 **안쪽 루프를 Stride-1**로.  
- **Fusion**으로 같은 배열을 한 번의 통과에 처리(재사용↑).  
- **Blocking(타일링)** 으로 L1/L2에 맞게 워킹셋을 자른다.

```c
void mm_block(int n, const float *A, const float *B, float *C, int Bsz){
  for (int ii=0; ii<n; ii+=Bsz)
    for (int jj=0; jj<n; jj+=Bsz)
      for (int kk=0; kk<n; kk+=Bsz){
        int im=(ii+Bsz<n?ii+Bsz:n), jm=(jj+Bsz<n?jj+Bsz:n), km=(kk+Bsz<n?kk+Bsz:n);
        for (int i=ii;i<im;i++)
          for (int j=jj;j<jm;j++){
            float acc=C[i*n+j];                  // 레지스터 누적
            for (int k=kk;k<km;k++) acc += A[i*n+k]*B[k*n+j];
            C[i*n+j]=acc;
          }
      }
}
```

### 8.3 스트리밍/오염 억제
- 다시 보지 않을 큰 결과는 **non-temporal store**(플랫폼 힌트)로 캐시 오염을 줄인다.

### 8.4 프리패치
```c
void sum_prefetch(const float *a, int n){
  float s=0;
  for (int i=0;i<n;i+=16){
    __builtin_prefetch(&a[i+64], 0, 1);  // 읽기, 약한 지역성
    for (int k=0;k<16 && i+k<n;k++) s += a[i+k];
  }
  (void)s;
}
```

---

## 9) 코드/데이터 예시: “같은 일, 다른 속도”

### 9.1 행/열 순회 (I-캐시 동일, D-캐시만 차이)
```c
// C는 row-major
long long sum_row(int (*a)[N]){
  long long s=0;
  for(int i=0;i<N;i++)
    for(int j=0;j<N;j++)
      s += a[i][j];    // Stride-1
  return s;
}
long long sum_col(int (*a)[N]){
  long long s=0;
  for(int j=0;j<N;j++)
    for(int i=0;i<N;i++)
      s += a[i][j];    // 큰 스트라이드 → 미스↑
  return s;
}
```
**결과 패턴**: `sum_row`는 L1/L2 히트율이 높고 IPC가 높다. `sum_col`은 LLC/DRAM 왕복이 잦아 IPC<1로 떨어진다.

### 9.2 AoS → SoA로 벡터화/대역 효율
```c
typedef struct { float *x, *y, *z; } Vec3SoA;
void norm_soa(const Vec3SoA v, float *out, int n){
  #pragma omp simd
  for (int i=0;i<n;i++){
    float dx=v.x[i], dy=v.y[i], dz=v.z[i];
    out[i] = dx*dx + dy*dy + dz*dz; // 연속 로드 → 히트율/벡터화↑
  }
}
```

### 9.3 불필요한 메모리 참조 제거
```c
for (int i=0;i<n;i++){
  float xi=x[i], yi=y[i];        // 두 번 로드하지 않음
  y[i] = yi + a*xi;              // 레지스터 재사용
}
```

---

## 10) 성능 진단: 어떤 수치를 봐야 하나

리눅스 기준 **perf** 카운터 예:

```bash
perf stat -e \
  cycles,instructions,IPC,\
  L1-dcache-loads,L1-dcache-load-misses,\
  LLC-loads,LLC-load-misses,\
  dTLB-load-misses,branch-misses,\
  stalled-cycles-frontend,stalled-cycles-backend \
  ./app
```

- **IPC**: 1 미만이면 대체로 메모리 바운드 의심.  
- **L1/LLC 미스율**: 행/열 순회, 타일링 전후 비교에 민감.  
- **dTLB-load-misses**: 페이지 워크로 인한 지연. Huge Page 적용 전후로 확인.  
- **frontend/back-end stalled**: I-캐시/분기 vs 데이터/메모리 문제 구분.  
- 플레임그래프로 **핫 루프**와 호출 경로를 특정하고, 변경 전후를 비교한다.

---

## 11) 캐시가 성능을 제한하는 전형적 시나리오와 처방

증상(관측) | 징후/카운터 | 원인 | 처방(1차) | 처방(2차)
---|---|---|---|---
IPC<1, LLC-miss↑ | backend stalled↑ | 열 우선/랜덤 접근 | **Interchange/타일링** | SoA/프리패치
p95만 나쁨 | 큐 길이↑, 락 대기↑ | 폴스 셰어링 | **패딩/샤딩** | 락 범위 축소/리듀스
branch-miss↑ | frontend stalled↑ | 복잡한 조건/코드 팽창 | 분기 단순화/적정 인라인 | Hot/Cold 분리
dTLB-miss↑ | page-walk↑ | 워킹셋>TLB reach | **Huge Page** | 데이터 레이아웃/페이지 컬러링
LLC thrash | LLC-load-miss↑ | 스레드/데이터 충돌 | 타일/스레드 배치 | NUMA 바인딩/파티션

---

## 12) 캐시와 알고리즘/자료구조 선택

- **해시 테이블**: 체이닝(포인터)보다 **오픈 어드레싱**(선형/이차 탐사)이 **연속 접근**으로 유리.  
- **트리**: 페이지 크기에 맞춘 **큰 노드(B-tree류)** 가 캐시·디스크 모두 친화적.  
- **그래프**: CSR/CSC 압축, **정점/에지 리오더링**(Z-order, Cuthill–McKee)로 지역성 개선.  
- **배열 정렬/검색**: 분기 예측과 연속 접근을 활용하는 **galloping/blocked** 변형 고려.

---

## 13) 체크리스트 (바로 적용)

- [ ] 안쪽 루프가 **Stride-1**인가(언어의 레이아웃과 일치)?  
- [ ] **타일링**으로 L1/L2에 맞는 워킹셋을 만들었는가?  
- [ ] **SoA/정렬/패딩**으로 벡터화·충돌을 도왔는가?  
- [ ] **스칼라 치환/루프 불변 호이스팅**으로 중복 로드를 없앴는가?  
- [ ] **프리패치** 거리 튜닝이 효과적인가?  
- [ ] **non-temporal store** 로 스트리밍 결과의 캐시 오염을 막았는가?  
- [ ] **폴스 셰어링/NUMA**를 해결했는가?  
- [ ] `perf`로 **IPC/미스율/스톨**이 실제로 개선되었는가?

---

## 14) 한 줄 결론

캐시는 **지역성**을 전제로 설계되었고, 프로그램 성능은 그 지역성을 **얼마나 잘 실현**하느냐에 달려 있다.  
**데이터 레이아웃 → 루프 변환(타일/Stride-1) → 충돌·오염 억제 → 멀티코어·TLB 대응**의 순서로 손보면,  
대부분의 워크로드에서 **대역을 아끼고 지연을 줄여 IPC를 끌어올릴 수 있다**.  
항상 **측정→개선→재측정**으로 사실 확인을 마무리하자.