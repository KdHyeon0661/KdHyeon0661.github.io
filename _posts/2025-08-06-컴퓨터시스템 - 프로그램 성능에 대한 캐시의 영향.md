---
layout: post
title: 컴퓨터시스템 - 프로그램 성능에 대한 캐시의 영향
date: 2025-08-06 22:20:23 +0900
category: 컴퓨터시스템
---
# 프로그램 성능에 대한 캐시의 영향

## 0. 한 페이지 요약 (TL;DR)

- **이론**  
  - 평균 접근 시간(AMAT):
    $$
    \text{AMAT} = T_{L1} + m_1\Big(T_{L2} + m_2\big(T_{L3} + m_3 T_{\text{Mem}}\big)\Big)
    $$
  - CPI 근사:
    $$
    \text{CPI} \approx \text{CPI}_{\text{base}} + 
    \frac{\text{MemAccesses}}{\text{Instr}} \times
    \frac{\text{Misses}}{\text{Access}} \times
    \frac{\text{MissPenalty}}{\text{MLP}}
    $$
- **징후**  
  - IPC<1 & LLC 미스↑ → 메모리 바운드 의심  
  - branch-miss↑ & front-end stalled↑ → 코드(분기/I-캐시) 문제  
  - dTLB-miss↑ → 페이지/워크셋/TLB reach 문제
- **최적화**  
  - **Stride-1** 접근, **타일링**, **AoS→SoA**, **스칼라 치환**, **프리패치**, **non-temporal store**, **패딩/샤딩(폴스 셰어링)**, **NUMA first-touch**
- **검증**  
  - 동일 입력/환경에서 **워밍업→N회→중앙값+p95**  
  - `perf stat/report`, 플레임그래프 전/후 비교  
  - 카운터: `IPC, L1/LLC-miss, dTLB-miss, stalled-frontend/backend`

---

## 1. 왜 캐시가 성능을 지배하는가

CPU는 나노초 단위, DRAM은 수십~수백 ns. 캐시는 이 격차를 **지역성(locality)** 로 가린다:

- **시간 지역성**: 최근 사용 데이터를 곧 다시 사용  
- **공간 지역성**: 인접 데이터의 사용 확률 높음

평균 접근 시간(AMAT):

$$
\text{AMAT} = T_{L1} + m_1\Big(T_{L2} + m_2\big(T_{L3} + m_3 T_{\text{Mem}}\big)\Big)
$$

미스율 \(m_k\)의 작은 개선이 전체 시간에 **기하급수적** 영향을 준다. 특히 \(m_3 T_{\text{Mem}}\) 항의 영향이 크다.

### 1.1 수치 감각 예
- 가정: \(T_{L1}=4\), \(T_{L2}=12\), \(T_{L3}=40\), \(T_{\text{Mem}}=180\) (cycle)
- 미스율: \(m_1=2\%\), \(m_2=20\%\), \(m_3=50\%\)

$$
\begin{aligned}
\text{AMAT}
&= 4 + 0.02\big(12 + 0.2(40 + 0.5\cdot 180)\big) \\
&= 4 + 0.02\big(12 + 0.2(40 + 90)\big) \\
&= 4 + 0.02\big(12 + 0.2\cdot 130\big) \\
&= 4 + 0.02 (12 + 26) \\
&= 4 + 0.02 \cdot 38 = 4 + 0.76 = 4.76\ \text{cycles}
\end{aligned}
$$

여기서 \(m_1\)을 2%→1%로 낮추면:

$$
\text{AMAT}_{\text{new}} = 4 + 0.01 \cdot 38 = 4.38
$$

**L1 미스 1%p 개선만으로 8% 이상 단축**.

---

## 2. CPI 모델: 캐시 미스가 CPU 시간을 늘리는 방식

CPI 근사:

$$
\text{CPI} \approx \text{CPI}_{\text{base}} +
\frac{\text{MemAccesses}}{\text{Instr}}
\times \frac{\text{Misses}}{\text{Access}}
\times \frac{\text{MissPenalty}}{\text{MLP}}
$$

- \(\text{MemAccesses}/\text{Instr}\): 명령 1개당 메모리 접근 수(로드/스토어, 인스트럭션 페치 포함)
- \(\text{MissPenalty}\): 라인 필/페이지 워크/코히어런시 포함한 추가 사이클
- **MLP**: 독립 미스가 **겹칠수록** 유효 페널티가 줄어든다(분모). 포인터 추적은 MLP≈1.

### 2.1 하드웨어 요소(간단 개론)
- **MSHR/Line Fill Buffer**: 동시 미스 추적 슬롯 수(MLP 상한)  
- **Store Buffer & Write-Combine**: 쓰기 지연/결합  
- **프리패처**: 선형/스트라이드/근접 패턴 추적

---

## 3. 데이터 캐시 — 미스의 3C(+1C)와 쓰기 경로

### 3.1 3C(+1C)
1. **Compulsory**: 첫 접근 미스(불가피) → **타일링/프리패치**로 **보이는 비용** 완화  
2. **Capacity**: 워킹셋 > 캐시 용량 → **타일링/재사용**  
3. **Conflict**: 세트 충돌 → **패딩/오프셋/배치**  
4. **Coherence**: 멀티코어 쓰기로 무효화 → **폴스 셰어링** 제거

### 3.2 쓰기 정책
- **Write-back + Write-allocate**(기본): 재사용이 있을 때 효율적  
- **Write-through + No-allocate**: 스트리밍 결과에 유리할 수 있음  
- **Non-temporal store**: 결과를 캐시에 **올리지 않고** DRAM으로(오염 억제)

---

## 4. 명령어(코드) 캐시 — “인라인 과유불급”

- **과도한 인라인/언롤** → 코드 크기↑ → I-캐시/ITLB 미스↑ → front-end 공급 부족  
- 해결: **핫 루프만 적당히** 인라인/언롤, **cold 경로 분리**(PGO/LTO 활용)

---

## 5. TLB와 페이지 — TLB reach가 작으면 캐시가 좋아도 느리다

- **TLB miss**는 페이지 워크로 **수십~수백 cycles**  
- **Huge Page(2MB/1GB)** 로 **TLB reach** 확대  
- **first-touch**: 초기화를 **스레드 바인딩** 상태에서 **연속 쓰기**로

---

## 6. 프리패처·MLP — 미스를 겹쳐 숨기는 법

- 하드웨어 프리패처는 **규칙적 패턴**에서만 강력  
- 소프트웨어 프리패치 거리:
  $$
  D \approx \frac{T_{\text{miss}}}{\text{iter당 소비 사이클}}
  $$
- 포인터 추적/랜덤 접근은 **리오더링/압축/배치**로 순차성 확보를 먼저

---

## 7. 멀티코어 — 코히어런시와 폴스 셰어링

- 동일 라인에 다른 스레드가 교대로 쓰면 **무효화 폭풍**  
- 해결: **패딩/샤딩/리듀스 단계화**

```c
typedef struct { _Alignas(64) long v; } Padded;
Padded counters[64];  // 스레드별 샤딩 + 64B 정렬
```

- LLC(공유 L3) 스래싱: 스레드 수↑ → 핫셋 충돌↑ → 타일/파티셔닝/스케줄링

---

## 8. 캐시 친화적 설계 — 데이터·루프·동시성

### 8.1 데이터 레이아웃: AoS→SoA, 정렬/패딩
```c
typedef struct { float *x, *y, *z; } Vec3SoA;
void norm_soa(const Vec3SoA v, float *out, int n){
  #pragma omp simd
  for (int i=0;i<n;i++){
    float dx=v.x[i], dy=v.y[i], dz=v.z[i];
    out[i] = dx*dx + dy*dy + dz*dz; // 연속 로드 → 벡터화/히트율↑
  }
}
```

- **64B 정렬**: 라인 경계와 포트 효율  
- **세트 충돌 완화**: 배열 간 **오프셋/더미**로 색 분산

### 8.2 루프 변환: Stride-1/타일링/퓨전/스칼라 치환
```c
// 행 우선(Stride-1)
for (int i=0;i<N;i++)
  for (int j=0;j<N;j++)
    sum += A[i][j];

// 타일링
void mm_block(int n, const float *A, const float *B, float *C, int Bsz){
  for (int ii=0; ii<n; ii+=Bsz)
    for (int jj=0; jj<n; jj+=Bsz)
      for (int kk=0; kk<n; kk+=Bsz){
        int im=(ii+Bsz<n?ii+Bsz:n), jm=(jj+Bsz<n?jj+Bsz:n), km=(kk+Bsz<n?kk+Bsz:n);
        for (int i=ii;i<im;i++)
          for (int j=jj;j<jm;j++){
            float acc=C[i*n+j];          // 레지스터 누적(스칼라 치환)
            for (int k=kk;k<km;k++) acc += A[i*n+k]*B[k*n+j];
            C[i*n+j]=acc;
          }
      }
}
```

### 8.3 스트리밍/오염 억제: non-temporal store
- 큰 결과 버퍼는 **캐시 우회 저장**(플랫폼 내장 사용)으로 **유효 라인 보존**

### 8.4 소프트웨어 프리패치
```c
void sum_prefetch(const float *a, int n){
  float s=0;
  for (int i=0;i<n;i+=16){
    __builtin_prefetch(&a[i+64], 0, 1);  // read, temporal locality 약함
    for (int k=0;k<16 && i+k<n;k++) s += a[i+k];
  }
  (void)s;
}
```

---

## 9. 코드/데이터 예시 — “같은 일, 다른 속도”

### 9.1 행/열 순회
```c
#define N 4096
long long sum_row(int (*a)[N]){
  long long s=0;
  for(int i=0;i<N;i++)
    for(int j=0;j<N;j++)
      s += a[i][j];              // Stride-1
  return s;
}
long long sum_col(int (*a)[N]){
  long long s=0;
  for(int j=0;j<N;j++)
    for(int i=0;i<N;i++)
      s += a[i][j];              // 큰 스트라이드 → 미스↑
  return s;
}
```
- 관측 기대: `sum_row`는 L1/L2 히트↑, IPC↑. `sum_col`은 LLC/DRAM 왕복↑, IPC<1.

### 9.2 불필요 로드 제거(스칼라 치환)
```c
void axpy(int n, float a, const float *x, float *y){
  float aa=a;
  #pragma omp simd
  for (int i=0;i<n;i++){
    float xi=x[i], yi=y[i];  // 중복 로드 금지
    y[i] = yi + aa*xi;
  }
}
```

---

## 10. 실전 진단 — 어떤 수치를 어떻게 볼 것인가

### 10.1 perf 카운터(리눅스)
```bash
perf stat -e \
  cycles,instructions,IPC,\
  L1-dcache-loads,L1-dcache-load-misses,\
  LLC-loads,LLC-load-misses,\
  dTLB-load-misses,branch-misses,\
  stalled-cycles-frontend,stalled-cycles-backend \
  ./app
```
- **IPC**: 1 미만이면 메모리/프론트엔드 바운드 가능성  
- **L1/LLC 미스율**: 타일링/레이아웃 전후 체감 지표  
- **dTLB-load-misses**: Huge Page 전/후 확인  
- **stalled-frontend/backend**: I-캐시/분기 vs D-캐시/메모리 문제 구분

### 10.2 플레임그래프(샘플링 프로파일)
- 핫 루프/함수 Top-N 파악 → **우선순위 20%** 먼저

### 10.3 실험 프로토콜
- **워밍업**(캐시/BTB/OS 페이징 안정화)  
- **N회 반복** 후 **중앙값 + p95** 보고  
- 입력 크기를 **L1/L2/L3 경계**를 넘나들게 스윕

---

## 11. 전형적 시나리오 ↔ 처방 매핑

증상(관측) | 징후/카운터 | 원인 | 1차 처방 | 2차 처방
---|---|---|---|---
IPC<1, LLC-miss↑ | backend stalled↑ | 열 우선/랜덤 접근 | **Interchange/타일링** | SoA/프리패치
p95만 나쁨 | run queue↑, lock wait↑ | 폴스 셰어링 | **패딩/샤딩** | 락 범위 축소/리듀스
branch-miss↑ | frontend stalled↑ | 복잡 분기/코드 팽창 | 분기 단순화/적정 인라인 | Hot/Cold 분리(PGO)
dTLB-miss↑ | page-walk↑ | 워킹셋>TLB reach | **Huge Page** | 페이지 컬러링/레이아웃
LLC thrash | LLC-load-miss↑ | 스레드/데이터 충돌 | 타일/스레드 배치 | NUMA 바인딩/파티셔닝

---

## 12. 알고리즘·자료구조 선택과 캐시

- **해시 테이블**: 체이닝(포인터)보다 **오픈 어드레싱**(선형/이차 탐사) → 연속 접근  
- **트리**: **큰 노드(B-tree류)** 로 페이지/캐시 효율  
- **그래프**: CSR/CSC 압축 + **정점/에지 리오더링**(Hilbert/Z-order, Cuthill–McKee)

---

## 13. NUMA·메모리 컨트롤러 고려

- **first-touch** 초기화:
```c
#pragma omp parallel for
for (long i=0;i<n;i++) buf[i]=0;  // 각 스레드 노드에 페이지 할당
```
- 스레드/데이터 **바인딩**(numactl, pthread_setaffinity)  
- 워크로드 **샤딩**으로 원격 접근 최소화

---

## 14. Roofline 관점 — “왜 더 안 빨라지지?”

연산집약도(AI):

$$
\text{AI} = \frac{\text{FLOPs}}{\text{Bytes moved}},
\qquad
\text{Perf} \le \min(\text{Peak FLOPs},\ \text{AI}\cdot\text{Peak BW})
$$

- **SAXPY**: 요소당 2 FLOPs, 24B 이동(8+8 read + 8 write) →  
  \(\text{AI}\approx 0.083\ \text{FLOP/B}\) → **메모리 바운드**  
- 개선은 **데이터 이동을 줄이는 것**(타일링/스칼라 치환/SoA/NT store)

---

## 15. 미니 케이스 스터디

### 15.1 행렬-벡터 곱 (나쁜 열 순회 → 좋은 행 순회 + 타일)
```c
// before: 열 우선(랜덤에 가까운 큰 스트라이드)
for (int i=0;i<n;i++)
  for (int j=0;j<n;j++)
    y[i] += A[j*n+i] * x[j];

// after: 행 우선 + 타일링
for (int ii=0; ii<n; ii+=B){
  int im = (ii+B<n)? ii+B : n;
  for (int i=ii; i<im; i++){
    float acc = y[i];
    for (int j=0; j<n; j++) acc += A[i*n+j]*x[j];
    y[i] = acc;
  }
}
```
- 관측 기대: LLC-miss↓, IPC↑, 시간 단축

### 15.2 락 경합 및 폴스 셰어링 → 샤딩/리듀스
```c
#define P 64
typedef struct { _Alignas(64) long v; } Pad64;
Pad64 cnt[P];

void add(int tid, long x){ cnt[tid].v += x; }
long total(){ long s=0; for(int i=0;i<P;i++) s+=cnt[i].v; return s; }
```

---

## 16. 측정·검증 템플릿

### 16.1 최소 타이머 유틸(C)
```c
#include <time.h>
double now(){
  struct timespec t; clock_gettime(CLOCK_MONOTONIC, &t);
  return t.tv_sec + t.tv_nsec*1e-9;
}
```

### 16.2 실험 절차
1. **워밍업** 2~3회  
2. **N회 실행(예: 30회)** → 중앙값(±IQR), p95 함께 보고  
3. **카운터**: `perf stat` 동일 옵션으로 전/후 수집  
4. 입력 크기 **스윕**: L1/L2/L3/메모리 구간을 가로지르게

### 16.3 perf 예시
```bash
# 기본
perf stat -e cycles,instructions,IPC ./app

# 메모리 상세
perf stat -e \
  L1-dcache-loads,L1-dcache-load-misses,\
  LLC-loads,LLC-load-misses,\
  dTLB-load-misses,stalled-cycles-frontend,stalled-cycles-backend \
  ./app
```

---

## 17. 체크리스트 (바로 적용)

- [ ] **안쪽 루프=Stride-1**인가?  
- [ ] **타일링**으로 L1/L2에 맞췄는가(블록 크기 실험)?  
- [ ] **AoS→SoA/정렬/패딩**으로 충돌 완화·벡터화 촉진?  
- [ ] **스칼라 치환/루프 불변 호이스팅**으로 중복 로드 제거?  
- [ ] **프리패치**가 통하는 패턴이며 거리 튜닝 완료?  
- [ ] **non-temporal store**로 스트리밍 결과의 오염 억제?  
- [ ] **폴스 셰어링/NUMA**를 제거/최적화?  
- [ ] `perf`로 **IPC/미스율/스톨** 개선이 **숫자로 확인**되었나?

---

## 18. 자주 나오는 안티패턴

- 측정 없이 **인라인/언롤 남발** → I-캐시 붕괴  
- 캐시 친화 루프를 **분산 접근**으로 망침  
- **거대한 구조체**를 포인터로 이리저리 전달 → AoS 병목  
- **락 범위**가 넓고 공유 데이터가 같은 라인에 밀집  
- Huge Page 없이 **대형 워킹셋**을 랜덤 접근

---

## 19. 부록 — 벤치 하네스(셸/C)

### 19.1 빌드/실행 스크립트(셸)
```bash
set -euo pipefail

CC=${CC:-gcc}
CFLAGS="-O3 -march=native -fno-omit-frame-pointer"
LDFLAGS=""

$CC $CFLAGS bench.c -o bench $LDFLAGS

# 워밍업
./bench 1024 >/dev/null

for n in 1024 4096 8192 16384; do
  echo "=== N=$n ==="
  perf stat -e cycles,instructions,IPC,\
L1-dcache-loads,L1-dcache-load-misses,\
LLC-loads,LLC-load-misses,dTLB-load-misses \
    ./bench $n
done
```

### 19.2 샘플 벤치 드라이버(C)
```c
#include <stdio.h>
#include <stdlib.h>
#include <time.h>
#include <stdint.h>

extern long long sum_row(int **a, int n);
extern long long sum_col(int **a, int n);

static double now(){
  struct timespec t; clock_gettime(CLOCK_MONOTONIC, &t);
  return t.tv_sec + t.tv_nsec*1e-9;
}

int main(int argc, char**argv){
  int n = (argc>1)? atoi(argv[1]) : 4096;
  int **a = (int**)aligned_alloc(64, n*sizeof(*a));
  for(int i=0;i<n;i++){
    a[i] = (int*)aligned_alloc(64, n*sizeof(int));
    for(int j=0;j<n;j++) a[i][j] = (i+j)&255;
  }

  double t0=now(); volatile long long s1 = sum_row(a,n); double t1=now();
  double t2=now(); volatile long long s2 = sum_col(a,n); double t3=now();

  printf("row: %.3f ms, col: %.3f ms, ignore: %lld,%lld\n",
         (t1-t0)*1e3, (t3-t2)*1e3, s1, s2);

  for(int i=0;i<n;i++) free(a[i]); free(a);
  return 0;
}
```

> 실제 코어·메모리·컴파일러에 따라 수치는 달라진다. 중요한 것은 **전/후 추세와 카운터**다.

---

## 20. 마무리

캐시는 **지역성**을 가정하고 설계되었다. 성능을 높이려면:

1) **데이터 레이아웃(AoS→SoA, 정렬/패딩)** 으로 **Stride-1**과 벡터화를 확보하고,  
2) **루프 변환(Interchange/Fusion/Blocking)** 으로 **재사용**을 극대화하며,  
3) **프리패치/NT store/락 샤딩/NUMA**로 **페널티**와 **경합**을 줄이고,  
4) **측정→개선→재측정**으로 **숫자**로 검증하라.

이 네 단계를 반복하면, 같은 알고리즘이라도 **캐시 친화성**을 통해 **수배의 체감 성능**을 끌어낼 수 있다.