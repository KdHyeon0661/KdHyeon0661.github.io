---
layout: post
title: Elixir - 슈퍼비저닝
date: 2025-11-20 23:25:23 +0900
category: Elixir
---
# 슈퍼비저닝은 신뢰성 확보의 토대다

## 슈퍼비전이 “토대”라는 말의 정확한 의미

OTP에서 “신뢰성(reliability)”은 **코드 품질**만으로 얻는 게 아니다.
**구조(Structure)** 로 얻는다. 그 구조의 핵심이 슈퍼비전이다.

왜 구조가 중요하냐면, 복잡한 시스템에서 장애의 원인은 대부분

- 버그(논리 오류)
- 자원 고갈(메모리/FD/연결)
- 외부 의존(네트워크/DB/3rd-party)
- 부하 급증(트래픽, 이벤트 폭주)

같은 **불확실하고 반복되는 런타임 사건**이기 때문이다.
OTP는 이 불확실성을 “**감당 가능한 형태로 좁히기**” 위한 언어/런타임 규범을 제공한다.

슈퍼비전은 그 규범에서 가장 아래(바닥)층을 깐다.

- **장애가 날 수 있다는 사실을 전제**한다.
- 장애가 나도 **전체가 죽지 않게** 경계를 만든다.
- 죽은 애를 **표준 규칙으로 되살린다.**
- 되살려도 안 되면 **더 큰 리셋으로 승격**시킨다.
- 이 모든 것을 코드가 아니라 **트리 구조로 선언**한다.

---

## 왜 토대인가: 신뢰성 모델의 간단한 수식 (초안 포함)

가용도 \(A\)는

$$
A=\frac{\text{MTBF}}{\text{MTBF}+\text{MTTR}}
$$

로 정의한다.
슈퍼비전은 **자동 재시작**으로 **평균 복구 시간(MTTR)**을 줄인다.
또한 **격리**로 **고장 전파 가능성**(사실상 MTBF 악화 요인)을 줄인다.

OTP 슈퍼바이저는 다음을 **언어 차원에서 표준화**한다.

- **격리**: 각 기능을 워커 프로세스에 가둔다.
- **복구**: 재시작 전략(`:one_for_one`, `:rest_for_one`, `:one_for_all`)과 **강도/시간창**으로 플래핑을 제어한다.
- **순서**: 부팅·정지 **순서를 선언**한다.
- **관찰**: 텔레메트리·로그·재시작 카운트를 제도화한다.

### 수식이 말해주는 “슈퍼비전의 2중 효과”

위 수식을 조금 더 운영 관점으로 해석해보자.

1) MTTR 감소
   - 장애가 생길 때마다 사람이 붙어서 원인 파악 → 재배포 → 복구
     이런 수작업의 MTTR은 분 단위, 시간 단위가 된다.
   - 슈퍼비전은 **크래시 → 즉시 재시작**을 기계적으로 수행한다.
     MTTR이 초 단위 이하로 떨어진다.

2) MTBF “실질적 증가”
   - MTBF는 “고장 자체가 적게 난다”는 뜻이지만,
     시스템 전체 관점에서는 “**치명적 고장(전파)의 빈도**”가 핵심이다.
   - 격리는 **작은 고장이 큰 고장으로 번지는 경로를 차단**한다.
     즉, 개별 워커는 자주 실패해도 **시스템 전체 실패는 드물게** 만든다.

결국 OTP가 “Fail fast / Let it crash” 철학을 말할 수 있는 이유도 여기 있다.

- “크래시는 정상이다.”
- “정상이 아닌 건 **복구 규약이 없는 구조**다.”

---

## 운영 관점 체크리스트 (초안 포함)

- [ ] **재시작 설계**: 각 워커의 `restart`(permanent/transient/temporary), `shutdown` 타임, 슈퍼바이저의 `max_restarts/max_seconds`.
- [ ] **경계 나누기**: 공통 자원 묶음은 **서브 슈퍼바이저**로 격리.
- [ ] **플래핑 방지**: 초기화 무거운 서버는 `handle_continue`와 **백오프**(지수/선형)를 도입.
- [ ] **큐 안전성**: 메일박스 길이 임계, 배치 플러시, `call` 중심 역압.
- [ ] **정리 보장**: I/O는 매 처리 경로에서 `try ... after` + 프로세스 종료시 `terminate/2`.
- [ ] **관찰성**: 재시작 이벤트, 큐 길이, 지연, 오류율을 Telemetry로 내보내고 알람.

#### 예: 재시작 강도 튜닝 (초안 코드)

```elixir
# 최상위 슈퍼바이저

Supervisor.start_link(children,
  strategy: :rest_for_one,
  max_restarts: 3,   # 3회
  max_seconds: 5     # 5초 동안 초과하면 상위로 전파
)
```

- 의도: “진짜로 고장난 상태”에선 **빠르게 상위로 실패를 전파**해 더 큰 리셋을 유도.

#### 예: 지수 백오프 초기화 (초안 코드)

```elixir
defmodule Booting.Server do
  use GenServer
  @max_attempts 5

  def init(:ok), do: {:ok, %{attempt: 0}, {:continue, :warmup}}

  def handle_continue(:warmup, %{attempt: n}=st) do
    case do_warmup() do
      :ok -> {:noreply, st}
      {:error, _} when n < @max_attempts ->
        backoff = trunc(:math.pow(2, n)) * 100
        Process.send_after(self(), :retry, backoff)
        {:noreply, %{st | attempt: n + 1}}
      {:error, _} ->
        # 의도적 크래시 -> 슈퍼바이저가 재시작
        exit(:warmup_failed)
    end
  end

  def handle_info(:retry, st), do: handle_continue(:warmup, st)

  defp do_warmup(), do: :ok
end
```

- 실패 초동에서는 **자체 백오프**, 그래도 실패면 **정상 크래시** → 슈퍼바이저가 개입.

#### 예: 종료 안전성 (초안 코드)

```elixir
@impl true
def handle_call({:write, line}, _from, %{io: io}=st) do
  try do
    IO.write(io, line <> "\n")
    {:reply, :ok, st}
  after
    :ok
  end
end

@impl true
def terminate(_reason, %{io: io}), do: File.close(io)
```

- 요청 단위 `after`와 프로세스 단위 `terminate/2`를 **둘 다** 쓴다.

---

## OTP 슈퍼바이저의 “재시작 의미론”을 정확히 이해하기

현업에서 가장 자주 터지는 사고는
“재시작이 일어나긴 하는데 의도대로 안 돈다/상태가 꼬인다/폭풍 재시작이 난다”다.

이걸 막으려면 **재시작 의미론 3종(워커 restart) + 3종(슈퍼바이저 strategy)** 를 명확히 알아야 한다.

### 워커 restart 옵션: permanent / transient / temporary

각 child spec에는 `restart:` 옵션이 있다.

- `:permanent`
  - **이유가 뭐든 죽으면 다시 올린다.**
  - 가장 기본. “계속 살아야 하는 서버”에 사용.

- `:transient`
  - **비정상 종료일 때만 재시작.**
  - 정상 종료(`:normal`, `:shutdown`, `{:shutdown, term}`)는 재시작 안 함.
  - “작업(Task)처럼 성공하면 끝나는 워커”에 자주 사용.

- `:temporary`
  - **절대 재시작 안 함.**
  - “일회성 작업” 혹은 “상위가 직접 재시작을 제어할 워커”에 사용.

#### 예시: 같은 워커라도 역할에 따라 restart를 바꾼다

```elixir
children = [
  %{
    id: Seq.FibServer,
    start: {Seq.Server, :start_link, [[name: Seq.FibServer, sequence: Seq.Fib]]},
    restart: :permanent
  },
  %{
    id: Seq.BatchJob,
    start: {Seq.BatchJob, :start_link, [[input: "file.txt"]]},
    restart: :transient,
    shutdown: 10_000
  }
]
```

- `Seq.FibServer`는 “항상 살아야 하는 상태ful 서버” → permanent
- `Seq.BatchJob`은 “성공하면 끝나는 작업” → transient

### 슈퍼바이저 전략: one_for_one / rest_for_one / one_for_all

- `:one_for_one`
  - 해당 child만 재시작.
  - 가장 흔함.
  - 장애 격리 강함.

- `:rest_for_one`
  - **죽은 child + 그 뒤에 시작된 child들**을 재시작.
  - “부팅 순서가 의존관계”를 의미할 때 사용.

- `:one_for_all`
  - child 하나 죽으면 **모두 재시작**.
  - “서로 강하게 결합된 구성요소”일 때만 사용.

#### 전략 선택 가이드

- 기능들이 **독립적**이면 `one_for_one`
- A가 먼저 올라가야 B가 의미가 있으면 `rest_for_one`
- A/B/C가 **같은 상태/리소스를 공유**해서 하나 꼬이면 전체 리셋이 맞으면 `one_for_all`

#### 예시: rest_for_one이 맞는 구조

```
[ConnPool] -> [CacheServer] -> [ApiServer]
```

- 캐시 서버는 커넥션 풀 위에서만 의미가 있고
- API 서버는 캐시가 정상일 때만 정상 동작
- 순서가 깨지면 하위 계층을 같이 리셋하는 게 안전

```elixir
children = [
  {MyApp.ConnPool, []},
  {MyApp.CacheServer, []},
  {MyApp.ApiServer, []}
]

Supervisor.start_link(children, strategy: :rest_for_one)
```

### 재시작 강도(max_restarts/max_seconds)의 해석

슈퍼바이저는 “**재시작 폭풍(플래핑)**”을 감지하면
상위로 실패를 전파한다.

- `max_restarts: N`
- `max_seconds: S`

의 의미는:

> S초 동안 N번을 초과해 재시작이 일어나면
> **슈퍼바이저 자신이 죽고 상위가 개입**한다.

즉 **국소 복구가 실패한 상태**라고 판단하는 기준이다.

#### 고전적 실수

- 너무 크게 잡으면
  → **기도하는 시스템**(계속 살아나지만 실제로는 고장 상태 지속)
- 너무 작게 잡으면
  → **작은 흔들림에도 상위가 무너짐**

실무에서는:

- **핫패스/핵심 자원**은 작게(빠른 승격)
- **비핵심·변동 큰 워커**는 넉넉히

---

## child spec을 직접 쓰며 의도를 명확히 하기

Elixir는 `{Mod, arg}` 튜플만 넣어도 자동으로 spec을 만들지만,
운영 의도를 정확히 드러내려면 child spec을 명시하는 습관이 좋다.

### 기본 child spec 구조

```elixir
%{
  id: MyWorker,
  start: {MyWorker, :start_link, [arg]},
  restart: :permanent,
  shutdown: 5_000,
  type: :worker,
  modules: [MyWorker]
}
```

각 필드의 실무적 의미:

- `id`
  - 슈퍼바이저 내부에서 child 식별자
- `start`
  - start_link 호출 정보
- `restart`
  - 재시작 의미론
- `shutdown`
  - 종료 시 “정상 정리 시간”
  - 지나면 강제 kill
- `type`
  - `:worker` or `:supervisor`
- `modules`
  - 핫 업그레이드, 툴링에 도움

### 종료 시간(shutdown) 설계

- 상태 flush, 파일 close, 네트워크 정리 등 “정리 시간이 필요한 워커”는
  `shutdown: timeout`을 넉넉히 줘야 한다.

```elixir
%{
  id: MyWriter,
  start: {MyWriter, :start_link, []},
  shutdown: 30_000
}
```

- 반대로 “즉시 죽어야 하는 워커”는 짧게:

```elixir
%{
  id: MyTempJob,
  start: {MyTempJob, :start_link, []},
  shutdown: 1_000,
  restart: :transient
}
```

---

## 경계 나누기: 서브 슈퍼바이저로 실패 도메인 설계

초안의 “경계 나누기”를 더 구체화하자.

### 왜 서브 슈퍼바이저가 필요한가

한 루트 슈퍼바이저 아래에 모든 걸 평평하게 놓으면

- 장애가 **과도하게 전파**되거나
- 전략 선택이 **모호**해지거나
- 재시작 강도 튜닝이 **한 군데로 뭉개**진다.

서브 슈퍼바이저는

- **실패 도메인(failure domain)** 을 나누고
- 도메인별로 **전략/강도**를 다르게 가져가게 한다.

### 예시: 도메인 분리 트리

아래는 “웹 서비스”에서 흔히 쓰는 구조다.

```
MyApp.RootSupervisor
 ├─ MyApp.InfraSupervisor
 │    ├─ RepoPool
 │    ├─ CachePool
 │    └─ MetricsExporter
 ├─ MyApp.ServiceSupervisor
 │    ├─ UserService
 │    ├─ OrderService
 │    └─ BillingService
 └─ MyApp.Endpoint
```

의도:

- 인프라 계층(Repo/Cache/Metrics)이 흔들리면
  → 서비스 계층은 같이 재시작되면 안 된다.
  (리퀘스트 처리만 멈추고, 인프라가 복구되면 다시 이어지는 게 맞음)
- 서비스 계층 내부는 업무 결합도에 따라
  → `one_for_one` 혹은 `rest_for_one`으로 세부 조정.

코드(스케치):

```elixir
defmodule MyApp.RootSupervisor do
  use Supervisor
  def start_link(arg), do: Supervisor.start_link(__MODULE__, arg, name: __MODULE__)

  @impl true
  def init(_arg) do
    children = [
      {MyApp.InfraSupervisor, []},
      {MyApp.ServiceSupervisor, []},
      {MyApp.Endpoint, []}
    ]

    Supervisor.init(children, strategy: :one_for_one)
  end
end
```

---

## 플래핑 방지: 백오프/자체 리트라이/정상 크래시의 조합

초안의 백오프 예제는 핵심 아이디어를 잘 보여준다.
여기에 **현업형 규율**을 더하자.

### “자체 백오프 vs 슈퍼바이저 백오프”의 역할 분담

- 자체 백오프(워커 내부)
  - “외부가 잠깐 불안정” 같은 **일시적 실패**를 부드럽게 흡수
  - 재시작을 남발하지 않게 한다.

- 슈퍼바이저 재시작
  - “상태가 꼬였거나 논리적으로 실패한 경우”
  - 워커가 더 이상 책임질 수 없을 때 **상위가 개입**

즉:

> **작은 흔들림은 워커 내부에서,
> 근본 실패는 슈퍼비전으로.**

### 백오프를 표준화한 패턴

```elixir
defmodule MyApp.Backoff do
  def next_delay(attempt, base_ms \\ 100, max_ms \\ 10_000) do
    delay = trunc(:math.pow(2, attempt)) * base_ms
    min(delay, max_ms)
  end
end
```

워커에서 사용:

```elixir
def handle_continue(:warmup, %{attempt: n}=st) do
  case do_warmup() do
    :ok -> {:noreply, st}
    {:error, _} when n < @max_attempts ->
      d = MyApp.Backoff.next_delay(n)
      Process.send_after(self(), :retry, d)
      {:noreply, %{st | attempt: n + 1}}
    {:error, _} ->
      exit(:warmup_failed)
  end
end
```

### “정상 크래시”로 실패를 명확히 하기

Elixir/OTP에서 “실패”는 숨기면 악화된다.
워커가 **복구 불가능한 상태**를 만났으면

- 에러 리턴을 길게 끌지 말고
- 상태 안고 버티지 말고
- **의도적으로 크래시**해서 슈퍼바이저에게 넘긴다.

이게 “Let it crash”의 실전적 의미다.

---

## 메일박스/큐 안전성: 슈퍼비전만으로는 부족하다

“슈퍼바이저가 있으니 안전하다”는 착각이 가장 위험하다.
슈퍼바이저는 **죽은 뒤**를 책임지는 구조다.
하지만 “죽지 않고도 망가지는” 경우가 많다.

대표적인 게 **메일박스 폭주**다.

### 왜 메일박스가 위험한가

프로세스는 메시지를 받을수록 메일박스가 쌓인다.

- 쌓인 메시지는 **메모리**
- 스케줄링 지연 증가
- GC 부담 증가
- 결국 OOM/락업

슈퍼바이저는 “OOM으로 죽으면 재시작”은 해주지만
OOM이 났다는 건 이미 사용자 경험이 깨졌다는 뜻이다.

### 큐 안전성 실전 기법

1) **핫패스는 call로 역압(backpressure)**
   - `cast`는 무제한 적재라 폭주에 취약.
   - “요청 속도를 제어해야 하는 경로”는 `call` 중심으로.

```elixir
def publish(msg), do: GenServer.call(__MODULE__, {:pub, msg}, 1_000)
```

2) **메일박스 길이 임계 체크**

```elixir
def handle_call(req, from, st) do
  {:message_queue_len, qlen} = Process.info(self(), :message_queue_len)
  if qlen > 5_000 do
    {:reply, {:error, :busy}, st}
  else
    # 정상 처리
  end
end
```

3) **배치 처리**
   - 작은 요청을 모아 한 번에 처리 → 큐 감소 및 I/O 효율 증가

4) **타임아웃/드롭 정책**
   - “무조건 처리”가 아니라 “최대 지연을 넘으면 버린다”는 정책도 필요할 때가 있다.

### 메일박스 안전성과 슈퍼비전의 연결

메일박스 정책은
“죽었을 때 복구하는 구조”와
“죽지 않게 제어하는 정책”이 함께 있어야 한다.

- 정책(역압/임계/배치)
- 구조(서브 슈퍼바이저, 재시작 전략)

둘이 맞물릴 때 진짜 신뢰성이 나온다.

---

## 정리 보장: try/after + terminate/2를 “이중 안전장치”로

초안의 종료 안전성 예제를 확장하자.

### 요청 단위 정리: try/after

- 기능 경로마다 “정리할 자원”이 있다면 항상 `after`로 보장한다.

```elixir
def handle_call({:write, line}, _from, st) do
  try do
    IO.write(st.io, line <> "\n")
    {:reply, :ok, st}
  after
    # 파일 flush, 잠금 해제 등
    :ok
  end
end
```

### 프로세스 단위 정리: terminate/2

- 프로세스가 죽을 때 최종 정리를 수행한다.

```elixir
@impl true
def terminate(_reason, st) do
  if st.io, do: File.close(st.io)
  :ok
end
```

### 왜 둘 다 필요한가

- `after`는 **요청 경로가 정상/비정상으로 끝나도** 정리되게 한다.
- `terminate/2`는 **프로세스 자체가 종료될 때** 마지막 정리를 한다.

실무에서 둘 중 하나만 쓰면 빈틈이 생긴다.

---

## 관찰성: 재시작·큐·지연·오류율을 표준 이벤트로 뽑기

슈퍼비전은 **관찰이 내장된 구조**다.

- 어떤 워커가 몇 번 재시작됐는지
- 얼마나 자주 플래핑하는지
- 어느 도메인이 약한지

관찰이 없으면
“자동 복구가 잘 되고 있는지”를 알 길이 없다.

### 슈퍼바이저 재시작 이벤트 관찰

`Supervisor`는 재시작을 시스템 로그로 남긴다.
하지만 실무에서는 이를 Telemetry/Logger로 표준화해 내보내는 경우가 많다.

워커에서 직접 emit:

```elixir
def handle_info(:some_event, st) do
  :telemetry.execute([:my_app, :worker, :event], %{count: 1}, %{worker: __MODULE__})
  {:noreply, st}
end
```

슈퍼바이저/워커 재시작 카운터는
`observer`나 `:sys.get_state/1`로도 볼 수 있다.

### “알람으로 올려야 하는 지표” 최소 세트

- 재시작 카운트(단기/장기)
- 메일박스 길이(임계 초과)
- p95 / p99 지연
- 오류율(비정상 종료 비중)
- 메모리/FD/연결 수

OTP를 운영한다는 건
이 지표를 “트리 도메인별로” 끊어서 본다는 뜻이다.

---

## 릴리즈와 슈퍼비전의 상호작용: “부팅-복구-종료의 일관성”

OTP 애플리케이션은 릴리즈에서

- 의존 순서대로 부팅되고
- 슈퍼비전 트리로 기능이 올라가고
- 종료 시 역순으로 내려간다.

슈퍼비전 설계가 나쁘면 릴리즈의 장점이 사라진다.

### 가장 흔한 실수: start_link에서 무거운 초기화

- `start_link/1`에서 DB 마이그레이션, 대용량 로드, 네트워크 핸드셰이크를 하면
- 부팅이 느려지고
- 실패하면 “부팅 루프”에 빠진다.

해결:

- `handle_continue/2`로 초기화를 분리
- 자체 백오프 후 실패 시 정상 크래시

이건 초안에서 이미 다룬 핵심이며, 실무에서 가장 중요한 패턴이다.

### 부팅 순서와 전략의 정합성

릴리즈의 의존 순서는 `.app` → `Application.start`
슈퍼비전 순서는 `children` 리스트 순서 → `strategy`

두 순서가 의도를 공유해야 한다.

- 외부 의존(A) 위에서만 의미 있는 워커(B)가 있다면
  - `.app` 의존 or 루트 트리 순서
  - + `rest_for_one` 같은 전략이 같이 가야 한다.

---

## 실전 예제 1: “커넥션 풀 + 캐시 + API” 트리

### 요구 시나리오

- 외부 DB 연결이 불안정할 수 있다.
- 캐시는 DB 풀 위에서만 의미가 있다.
- API 서버는 캐시가 살아야 정상 동작한다.
- 그러나 API 서버가 죽는다고 DB 풀까지 내릴 필요는 없다.

### 트리 설계

```
RootSupervisor (one_for_one)
 ├─ InfraSupervisor (rest_for_one)
 │    ├─ RepoPool (permanent)
 │    └─ CacheServer (permanent)
 └─ ApiSupervisor (one_for_one)
      ├─ ApiServer (permanent)
      └─ Metrics (permanent)
```

의도:

- 인프라 도메인 내부는 순서 의존 → rest_for_one
- API 도메인은 인프라와 격리 → root의 one_for_one 아래 별도 트리

### 코드 스케치

```elixir
defmodule MyApp.InfraSupervisor do
  use Supervisor
  def start_link(_), do: Supervisor.start_link(__MODULE__, :ok, name: __MODULE__)

  @impl true
  def init(:ok) do
    children = [
      {MyApp.RepoPool, []},
      {MyApp.CacheServer, []}
    ]
    Supervisor.init(children, strategy: :rest_for_one, max_restarts: 3, max_seconds: 5)
  end
end

defmodule MyApp.ApiSupervisor do
  use Supervisor
  def start_link(_), do: Supervisor.start_link(__MODULE__, :ok, name: __MODULE__)

  @impl true
  def init(:ok) do
    children = [
      {MyApp.ApiServer, []},
      {MyApp.Metrics, []}
    ]
    Supervisor.init(children, strategy: :one_for_one)
  end
end

defmodule MyApp.RootSupervisor do
  use Supervisor
  def start_link(_), do: Supervisor.start_link(__MODULE__, :ok, name: __MODULE__)

  @impl true
  def init(:ok) do
    children = [
      {MyApp.InfraSupervisor, []},
      {MyApp.ApiSupervisor, []}
    ]
    Supervisor.init(children, strategy: :one_for_one)
  end
end
```

이 구조에서:

- 캐시가 죽으면 → RepoPool 뒤에 있으니 CacheServer만 재시작
- RepoPool이 죽으면 → CacheServer까지 같이 재시작
- ApiServer가 죽으면 → ApiServer만 재시작
- Infra가 플래핑하면 → InfraSupervisor가 죽고 RootSupervisor가 개입(도메인 리셋)

---

## 실전 예제 2: “작업 파이프라인”에 one_for_all을 쓰는 경우

### 요구 시나리오

- 단계 A/B/C가 같은 상태(예: ETS 버퍼)를 공유
- B가 죽으면 버퍼 상태가 깨져 A/C도 신뢰할 수 없음
- 전체를 리셋하는 게 안전

### 코드

```elixir
children = [
  {MyPipeline.StepA, []},
  {MyPipeline.StepB, []},
  {MyPipeline.StepC, []}
]

Supervisor.start_link(children, strategy: :one_for_all, max_restarts: 2, max_seconds: 3)
```

이건 드문 패턴이지만,
“**강한 결합 + 공유 상태**”가 있을 땐 정답이 된다.

---

## 안티패턴: 슈퍼비전으로 “모든 문제를 숨기는” 순간

다음 징후가 보이면 설계가 잘못됐을 가능성이 크다.

1) 워커가 끊임 없이 재시작되는데 서비스는 계속 느리다
   - 플래핑을 **근본 원인 해결 대신 재시작으로 덮고 있음**

2) 트리가 평평하고 전략이 늘 one_for_one이다
   - 실패 도메인 설계가 없다.

3) start_link가 실패하면 시스템 전체가 못 뜬다
   - 초기화를 분리하지 않았다.

4) cast가 남발되고 메일박스 폭주로 죽는다
   - 슈퍼비전은 사후 복구일 뿐 **역압/큐 정책이 없다.**

5) terminate/2가 없거나, shutdown 시간을 안 줬다
   - 리소스 누수/지연 종료가 반복된다.

OTP에서 슈퍼비전은 만능이 아니다.

> “복구 구조”는 **정책(역압/정리/초기화 분리)** 과 합쳐질 때만
> 진짜 신뢰성을 만든다.

---

## 이 섹션 요약

- 슈퍼비전은 가용도 수식에서
  **MTTR을 줄이고, MTBF 악화(전파)를 막는 구조적 토대**다.
- 워커 restart 의미론(permanent/transient/temporary)과
  슈퍼바이저 전략(one_for_one/rest_for_one/one_for_all)은
  **운영 의도를 표현하는 언어**다.
- 플래핑 방지는
  **워커 내부 백오프 + 실패 시 정상 크래시 + 상위 강도 제어**의 조합으로 만든다.
- 메일박스/큐 안전성은
  슈퍼비전만으로 해결되지 않으며,
  **역압·임계·배치·타임아웃 정책**을 함께 설계해야 한다.
- 정리 보장은
  `try/after`(요청 경로) + `terminate/2`(프로세스 경로)로
  **이중 안전장치**를 둔다.
- 관찰성은 신뢰성의 일부다.
  **재시작/큐/지연/오류율**을 도메인별로 끊어 Telemetry/Logger에 올려라.
- 슈퍼비전 트리는 릴리즈의 부팅·종료 순서와 정합성을 가져야 한다.
- 결국 OTP 신뢰성은
  “**실패를 전제로 한 구조**” 위에 정책이 붙어 완성된다.
