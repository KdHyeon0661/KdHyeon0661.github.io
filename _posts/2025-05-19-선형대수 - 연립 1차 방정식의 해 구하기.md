---
layout: post
title: 선형대수 - 연립 1차 방정식의 해 구하기
date: 2025-05-14 19:20:23 +0900
category: 선형대수
---
# 연립 1차 방정식의 해 구하기 — 행렬로 해석하는 선형 시스템

선형 시스템은 보통 $$A\mathbf{x}=\mathbf{b}$$ 로 표현합니다. 여기서 $$A\in\mathbb{R}^{m\times n}$$, 미지수 벡터 $$\mathbf{x}\in\mathbb{R}^{n}$$, 상수 벡터 $$\mathbf{b}\in\mathbb{R}^{m}$$ 입니다.

---

## 1) 문제 표기와 기하학적 의미

- 행렬식 표기  
  $$
  A=
  \begin{bmatrix}
  a_{11}&\cdots&a_{1n}\\
  \vdots &      &\vdots\\
  a_{m1}&\cdots&a_{mn}
  \end{bmatrix},\quad
  \mathbf{x}=
  \begin{bmatrix}x_1\\ \vdots\\ x_n\end{bmatrix},\quad
  \mathbf{b}=
  \begin{bmatrix}b_1\\ \vdots\\ b_m\end{bmatrix}.
  $$
- 각 방정식은 열공간의 선형결합과 같음  
  $$
  A\mathbf{x}=\sum_{j=1}^{n}x_j\,\mathbf{a}_j=\mathbf{b},
  $$
  여기서 $$\mathbf{a}_j$$ 는 $$A$$ 의 $$j$$ 번째 열. 즉, **열공간에 $$\mathbf{b}$$ 를 표현할 수 있느냐**가 해 존재의 핵심입니다.

---

## 2) 해의 존재·유일성: 랭크와 Rouché–Capelli

- 랭크 표기  
  $$
  r(A)=\mathrm{rank}(A),\quad r([A\mid \mathbf{b}])=\mathrm{rank}\big(\,[A\ \mathbf{b}]\,\big).
  $$
- Rouché–Capelli 정리  
  - 해 존재: $$r(A)=r([A\mid \mathbf{b}])$$.  
  - 해 없음(불일치): $$r(A)<r([A\mid \mathbf{b}])$$.  
  - 유일해: 해가 존재하고 $$r(A)=n$$(피벗이 모든 열에 존재).  
  - 무한해: 해가 존재하고 $$r(A)<n$$(자유변수 개수 $$=n-r(A)$$).

특히 정방행렬 $$A\in\mathbb{R}^{n\times n}$$ 의 경우
$$
\det(A)\neq 0 \iff r(A)=n \iff \text{유일해} \iff A^{-1}\ \text{존재}.
$$

---

## 3) 상황별 해법 선택 가이드

- 정방·가역(보통의 우변 개수): $$A\in\mathbb{R}^{n\times n},\ \det(A)\neq 0$$  
  → $$\mathbf{x}=A^{-1}\mathbf{b}$$ 이론은 맞지만, **수치적으로는 역행렬을 직접 구하지 말고** $$\mathrm{solve}$$(LU) 사용.
- 과잉결정(식이 더 많음, $$m>n$$): 정확해 없음이 일반적 → **최소제곱**  
  $$
  \min_{\mathbf{x}}\|A\mathbf{x}-\mathbf{b}\|_2 \quad\Rightarrow\quad
  \mathbf{x}_\star=\arg\min\|A\mathbf{x}-\mathbf{b}\|_2.
  $$
  안정적 순서: QR/SVD ＞ 정규방정식 $$(A^\top A)\mathbf{x}=A^\top \mathbf{b}$$.
- 과소결정(미지수가 더 많음, $$m<n$$): 해가 무한개 → **최소놈해**(의사역행렬)  
  $$
  \mathbf{x}_\dagger = A^{+}\mathbf{b} \quad(\text{무어–펜로즈}).
  $$
- 랭크부족(열/행 종속): **SVD 기반 의사역행렬**로 최적해(최소제곱/최소놈) 계산.

---

## 4) 대표 해법들의 핵심과 차이

### 4.1 가우스 소거 + 후방대입(REF)
- $$[A\mid \mathbf{b}]$$ 를 위삼각 형태로 만들고 뒤에서부터 해를 구함.  
- 부분 피벗팅으로 수치안정성 확보.

### 4.2 가우스–조르당(RREF)
- 피벗 열 위·아래를 모두 0으로 만들어 바로 해를 읽음.  
- 연산량이 더 크므로 교육·분석용, 실전은 보통 가우스 소거/LU.

### 4.3 LU 분해
- $$A=LU$$(부분 피벗팅 시 $$PA=LU$$). 한 번 분해 후 여러 $$\mathbf{b}$$ 에 빠르게 대응.  
- 정방·가역 또는 적어도 정방에서 선호.

### 4.4 QR 분해(최소제곱의 표준)
- $$A=QR,\ Q^\top Q=I$$, **과잉결정**에서 안정적.  
  $$
  \min\|A\mathbf{x}-\mathbf{b}\|_2 \Rightarrow R\mathbf{x}=Q^\top \mathbf{b}.
  $$

### 4.5 SVD·의사역행렬
- $$A=U\Sigma V^\top$$, $$A^{+}=V\Sigma^{+}U^\top$$.  
- 랭크부족/ ill-conditioned 에서 가장 신뢰도 높음(비용 큼).

### 4.6 정규방정식
- $$(A^\top A)\mathbf{x}=A^\top \mathbf{b}$$  
- 빠르지만 **조건수 제곱 악화**: $$\kappa(A^\top A)=\kappa(A)^2$$. 데이터가 깨끗하고 치수가 작을 때만.

---

## 5) 동작 예제: 손풀이와 해석

### 5.1 유일해(정방·가역)
$$
\begin{cases}
2x+3y=5\\
x-y=1
\end{cases}
\quad\Rightarrow\quad
A=\begin{bmatrix}2&3\\ 1&-1\end{bmatrix},\ 
\mathbf{b}=\begin{bmatrix}5\\ 1\end{bmatrix}.
$$
$$
\det(A)=-5\neq 0\ \Rightarrow\ \text{유일해}.
$$

### 5.2 불일치(해 없음)
$$
\begin{cases}
x+y=1\\
2x+2y=3
\end{cases}
\quad\Rightarrow\quad
r(A)=1,\ r([A\mid \mathbf{b}])=2 \Rightarrow \text{무해}.
$$

### 5.3 무한해(과소결정)
$$
x+2y+z=0,\quad 2x+4y+2z=0.
$$
두 번째 식은 첫 번째의 두 배 → 자유변수 2개(예: $$y=s,\ z=t$$).  
$$
x=-2s-t.
$$

---

## 6) 최소제곱의 기하: 열공간으로의 직교정사영

과잉결정 $$A\mathbf{x}\approx\mathbf{b}$$ 에서 해 $$\mathbf{x}_\star$$ 는
$$
A\mathbf{x}_\star=\mathrm{proj}_{\mathcal{R}(A)}(\mathbf{b}),\quad
A^\top(\mathbf{b}-A\mathbf{x}_\star)=\mathbf{0}.
$$
즉, 잔차는 열공간에 **직교**합니다.

---

## 7) 수치 안정성 체크리스트

1. 정방이면 `solve`(LU) 우선, **역행렬 직접 곱 금지**.  
2. 과잉결정은 `lstsq`(QR/SVD 백엔드) 우선, 정규방정식은 보조.  
3. 랭크 의심·다중공선성은 SVD/의사역행렬.  
4. 조건수 $$\kappa(A)=\|A\|\,\|A^{-1}\|$$ 가 크면 작은 오차가 크게 증폭됩니다.  
5. 스케일링(열 표준화)·피벗팅·배정밀도 사용.  
6. 잔차 $$\|A\hat{\mathbf{x}}-\mathbf{b}\|_2$$, 상대오차, 랭크(수치 임계) 확인.

---

## 8) PyTorch 예제 모음

아래 모든 텐서는 기본적으로 $$\mathrm{float64}$$ 를 권장합니다.

### 8.1 정방·가역: `torch.linalg.solve`
```python
import torch
torch.set_printoptions(precision=6, sci_mode=False)
DT = torch.float64

A = torch.tensor([[2., 3.],
                  [1., -1.]], dtype=DT)
b = torch.tensor([5., 1.], dtype=DT)

x = torch.linalg.solve(A, b)
print("unique solution:", x)

# 검증
res = A @ x - b
print("residual norm:", torch.linalg.norm(res))
```

### 8.2 역행렬 사용은 지양(비교만)
```python
x_bad = torch.linalg.inv(A) @ b    # 데모용, 실무 비권장
print("via inv:", x_bad)
```

### 8.3 과잉결정: 최소제곱 `torch.linalg.lstsq`
```python
A = torch.tensor([[1., 1.],
                  [1., 2.],
                  [1., 3.]], dtype=DT)      # 3x2
b = torch.tensor([1., 2., 2.5], dtype=DT)   # 3

ls = torch.linalg.lstsq(A, b)               # QR/SVD 백엔드
x_ls = ls.solution
print("least-squares x:", x_ls)
print("residual norm:", torch.linalg.norm(A @ x_ls - b))
print("rank:", int(ls.rank))
print("singular values:", ls.singular_values)
```

### 8.4 정규방정식(주의: 조건수 제곱 악화)
```python
AtA = A.T @ A
Atb = A.T @ b
x_ne = torch.linalg.solve(AtA, Atb)   # 가급적 lstsq 권장
print("normal-eq x:", x_ne)
```

### 8.5 과소결정/랭크부족: 의사역행렬(최소놈해)
```python
A = torch.tensor([[1., 2., 1.],
                  [2., 4., 2.]], dtype=DT)   # 2x3, rank=1
b = torch.tensor([0., 0.], dtype=DT)

x_min_norm = torch.linalg.pinv(A) @ b       # 최소놈해
print("min-norm solution:", x_min_norm)
```

### 8.6 SVD로 영공간(자유변수) 근사 기저 구하기
```python
A = torch.tensor([[1., 2., 1.],
                  [2., 4., 2.]], dtype=DT)
U, S, Vh = torch.linalg.svd(A)              # A = U diag(S) V^T

tol = 1e-12
null_mask = S < tol
# Vh는 V^T. 영특값에 대응하는 V의 열이 영공간 기저.
# rank-deficient 예제에선 거의 모든 축이 영특값에 가까움.
print("singular values:", S)

# 간단 예시: 가장 작은 특값에 대응하는 V의 열을 영공간 벡터로 사용
null_vec = Vh[-1, :]                        # 마지막 행 = V^T의 마지막 행
print("one nullspace vector (approx):", null_vec)
```

### 8.7 해의 분류와 자동 풀이 유틸
```python
def solve_linear_system(A, b, atol=1e-12):
    A = A.to(DT); b = b.to(DT)
    m, n = A.shape
    # 랭크 판정
    rA  = int(torch.linalg.matrix_rank(A, atol=atol).item())
    rAb = int(torch.linalg.matrix_rank(torch.cat([A, b.reshape(-1,1)], dim=1), atol=atol).item())

    if rA < rAb:
        return {"kind":"inconsistent"}

    if m == n and rA == n:
        # 정방·가역
        x = torch.linalg.solve(A, b)
        return {"kind":"unique", "x":x, "res_norm":torch.linalg.norm(A@x-b)}

    # 최소제곱 또는 최소놈
    # PyTorch lstsq는 m>=n, m<n 모두 지원(문맥에 맞는 해 반환)
    res = torch.linalg.lstsq(A, b)
    return {
        "kind":"ls_or_min_norm",
        "x":res.solution,
        "rank":int(res.rank),
        "res_norm":float(torch.linalg.norm(A@res.solution-b)),
        "singular_values":res.singular_values
    }

# 테스트
A = torch.tensor([[2.,3.],[1.,-1.]], dtype=DT)
b = torch.tensor([5.,1.], dtype=DT)
print(solve_linear_system(A,b))

A = torch.tensor([[1.,1.],[2.,2.]], dtype=DT)
b = torch.tensor([1.,3.], dtype=DT)
print(solve_linear_system(A,b))

A = torch.tensor([[1.,1.],[1.,2.],[1.,3.]], dtype=DT)
b = torch.tensor([1.,2.,2.5], dtype=DT)
print(solve_linear_system(A,b))
```

---

## 9) 실전 팁과 검증 절차

- 차원 확인: $$A\in\mathbb{R}^{m\times n},\ b\in\mathbb{R}^{m}$$.  
- 정방이면 `solve`; 과잉결정·과소결정이면 `lstsq` 또는 `pinv`.  
- 잔차 $$\|A\hat{\mathbf{x}}-\mathbf{b}\|_2$$, 랭크, 특이값 분포(급격한 감소는 ill-conditioned 신호) 점검.  
- 스케일 편차가 크면 열 표준화로 개선.  
- 반복적으로 다른 $$\mathbf{b}$$ 를 풀면 LU/QR 사전분해를 재사용.  
- 정규화가 필요한 문제는 릿지(티호노프)도 고려  
  $$
  \min_{\mathbf{x}}\bigl(\|A\mathbf{x}-\mathbf{b}\|_2^2+\lambda\|\mathbf{x}\|_2^2\bigr)
  \Rightarrow
  (A^\top A+\lambda I)\mathbf{x}=A^\top \mathbf{b}.
  $$

---

## 10) 요약

- 해의 존재·유일성은 $$r(A)$$, $$r([A\mid \mathbf{b}])$$ 로 판정합니다.  
- 정방·가역은 `solve`(LU), 과잉결정은 `lstsq`(QR/SVD), 랭크부족·과소결정은 `pinv`/SVD가 안전합니다.  
- 역행렬 곱은 피하고, 잔차·조건수·특이값으로 결과를 항상 검증하세요.