---
layout: post
title: DB 심화 - 비교 연산자·컬럼 순서·인덱스 군집성, 그리고 비효율 해소 전략
date: 2025-11-07 21:25:23 +0900
category: DB 심화
---
# 비교 연산자, 컬럼 순서, 인덱스 군집성과 최적화 전략

> **핵심 원리**
> 데이터베이스 성능 최적화의 핵심은 인덱스 설계와 쿼리 작성의 조화에 있습니다. 비교 연산자의 선택, 컬럼 순서의 결정, 인덱스 군집성의 이해가 효율적인 데이터 접근을 위한 기본 요소입니다.

---

## 실습 환경 설정

```sql
-- 실습용 테이블 및 데이터 생성
ALTER SESSION SET nls_date_format = 'YYYY-MM-DD';
ALTER SESSION SET statistics_level = ALL;

DROP TABLE ix_demo PURGE;

CREATE TABLE ix_demo (
  cust_id    NUMBER        NOT NULL,
  order_dt   DATE          NOT NULL,
  order_id   NUMBER        NOT NULL,
  status     VARCHAR2(8)   NOT NULL,
  amount     NUMBER(12,2)  NOT NULL,
  note       VARCHAR2(100),
  CONSTRAINT pk_ix_demo PRIMARY KEY (order_id)
);

-- 샘플 데이터 생성 (약 250만 건)
BEGIN
  FOR c IN 1..100000 LOOP
    FOR k IN 1..TRUNC(DBMS_RANDOM.VALUE(15, 40)) LOOP
      INSERT INTO ix_demo
      VALUES (
        c,
        DATE '2024-01-01' + TRUNC(DBMS_RANDOM.VALUE(0, 730)),
        c*1000 + k,
        CASE MOD(c+k,5)
          WHEN 0 THEN 'NEW'
          WHEN 1 THEN 'PAID'
          WHEN 2 THEN 'SHIP'
          WHEN 3 THEN 'DONE'
          ELSE 'CANC'
        END,
        ROUND(DBMS_RANDOM.VALUE(10, 200000), 2),
        CASE WHEN MOD(c+k,97)=0 THEN 'gift' END
      );
    END LOOP;
  END LOOP;
  COMMIT;
END;
/

-- 다양한 컬럼 순서의 인덱스 생성
CREATE INDEX ix_c_dt ON ix_demo(cust_id, order_dt, order_id);
CREATE INDEX ix_dt_c ON ix_demo(order_dt, cust_id, order_id);
CREATE INDEX ix_status ON ix_demo(status);

-- 통계 정보 수집
BEGIN
  DBMS_STATS.GATHER_TABLE_STATS(
    USER,
    'IX_DEMO',
    cascade     => TRUE,
    method_opt  => 'for all columns size skewonly'
  );
END;
/
```

---

## 인덱스 군집성과 성능의 관계

### 군집성의 개념 이해
인덱스 군집성은 인덱스 키 순서와 테이블 데이터의 물리적 저장 순서 간의 일치도를 의미합니다. 높은 군집성은 다음과 같은 이점을 제공합니다:

1. **I/O 효율성 향상**: 연관된 데이터가 물리적으로 근접 저장되어 캐시 효율성이 높아집니다.
2. **범위 스캔 최적화**: 연속된 데이터 접근 시 디스크 탐색 시간이 감소합니다.
3. **버퍼 캐시 활용도 증가**: 동일한 데이터 블록의 재사용률이 높아집니다.

### 클러스터링 팩터 분석
```sql
-- 인덱스별 클러스터링 팩터 확인
SELECT index_name, 
       clustering_factor,
       leaf_blocks,
       num_rows,
       ROUND(clustering_factor / num_rows * 100, 2) as cf_percentage
FROM user_indexes
WHERE table_name = 'IX_DEMO'
ORDER BY clustering_factor;
```

클러스터링 팩터 값이 테이블 블록 수에 가까울수록 군집성이 좋으며, 행 수에 가까울수록 군집성이 나쁩니다.

---

## 비교 연산자의 성능 영향

### 연산자별 효율성 분석
다양한 비교 연산자는 인덱스 사용 효율성에 서로 다른 영향을 미칩니다:

```sql
-- 등치 비교: 최적의 인덱스 활용
SELECT order_id, order_dt, amount
FROM ix_demo
WHERE cust_id = 12345;

-- 범위 비교: 선택적 인덱스 활용
SELECT order_id, order_dt, amount
FROM ix_demo
WHERE cust_id BETWEEN 1000 AND 2000;

-- IN 연산자: 다중 등치 비교
SELECT order_id, order_dt, amount
FROM ix_demo
WHERE cust_id IN (1000, 2000, 3000);

-- LIKE 패턴: 접두사 검색만 인덱스 활용
SELECT order_id, order_dt, amount
FROM ix_demo
WHERE note LIKE 'gift%';
```

### 연산자 효율성 지표
| 연산자 유형 | 인덱스 활용도 | 성능 영향 | 최적화 포인트 |
|------------|--------------|----------|--------------|
| 등치(=) | 최상 | 매우 효율적 | 선두 컬럼에 사용 |
| IN | 우수 | 값 개수에 비례 | 적절한 값 개수 유지 |
| BETWEEN | 양호 | 범위 크기에 영향 | 범위 크기 최소화 |
| LIKE 'prefix%' | 보통 | 접두사 길이 영향 | 접두사 최소 2-3자 권장 |
| >, >=, <, <= | 제한적 | 편향 데이터 주의 | 선택도 고려 |

---

## 컬럼 순서 최적화 전략

### 선행 컬럼 선택 원칙
인덱스의 첫 번째 컬럼은 가장 중요한 성능 결정 요소입니다:

```sql
-- 효율적인 인덱스 설계 예시
CREATE INDEX ix_optimal_order ON orders(
  customer_id,     -- 높은 선택도, 등치 조건 빈번
  order_date,      -- 범위 조건 자주 사용
  status,          -- 추가 필터링
  order_id         -- 유니크 보장
);

-- 최적화된 쿼리 패턴
SELECT order_id, total_amount
FROM orders
WHERE customer_id = :cust_id
  AND order_date >= :start_date
  AND order_date <= :end_date
  AND status = 'COMPLETED'
ORDER BY order_date DESC;
```

### 컬럼 순서 결정 매트릭스
다음 요소를 고려하여 컬럼 순서를 결정하세요:

1. **선택도**: 높은 선택도를 가진 컬럼을 선두에
2. **조건 빈도**: 자주 사용되는 조건을 우선
3. **조인 패턴**: 조인에 사용되는 컬럼 포함
4. **정렬 요구**: ORDER BY 절과의 일치성
5. **데이터 분포**: 편향된 분포 고려

---

## BETWEEN 연산자 최적화 기법

### IN 리스트 변환 전략
적절한 경우 BETWEEN을 IN 리스트로 변환하여 성능을 개선할 수 있습니다:

```sql
-- BETWEEN 사용 (비효율적일 수 있음)
SELECT COUNT(*)
FROM ix_demo
WHERE order_dt BETWEEN DATE '2025-10-01' AND DATE '2025-10-31'
  AND cust_id = 12345;

-- IN 리스트로 변환 (특정 경우 효율적)
SELECT COUNT(*)
FROM ix_demo
WHERE order_dt IN (
  DATE '2025-10-01', DATE '2025-10-02', DATE '2025-10-03',
  DATE '2025-10-04', DATE '2025-10-05', DATE '2025-10-06'
  -- ... 필요한 날짜만 포함
)
AND cust_id = 12345;
```

### 동적 IN 리스트 생성
```sql
-- PL/SQL을 활용한 동적 IN 리스트 생성
DECLARE
  v_sql CLOB;
  v_start_date DATE := DATE '2025-10-01';
  v_end_date DATE := DATE '2025-10-07';
  v_current_date DATE;
BEGIN
  v_sql := 'SELECT COUNT(*) FROM ix_demo WHERE cust_id = :cid AND order_dt IN (';
  
  v_current_date := v_start_date;
  WHILE v_current_date <= v_end_date LOOP
    IF v_current_date > v_start_date THEN
      v_sql := v_sql || ', ';
    END IF;
    v_sql := v_sql || 'TO_DATE(''' || 
             TO_CHAR(v_current_date, 'YYYY-MM-DD') || 
             ''', ''YYYY-MM-DD'')';
    v_current_date := v_current_date + 1;
  END LOOP;
  
  v_sql := v_sql || ')';
  
  -- 실행 및 결과 확인
  DBMS_OUTPUT.PUT_LINE('생성된 SQL: ' || v_sql);
END;
/
```

---

## 인덱스 Skip Scan 활용

### Skip Scan의 적절한 사용
Skip Scan은 선행 컬럼이 조건에 없을 때 유용한 대체 접근법입니다:

```sql
-- Skip Scan 힌트 활용
SELECT /*+ INDEX_SS(ix_demo ix_c_dt) */
       COUNT(*)
FROM ix_demo
WHERE order_dt = DATE '2025-10-15';

-- 실행 계획 확인
EXPLAIN PLAN FOR
SELECT /*+ INDEX_SS(ix_demo ix_c_dt) */
       COUNT(*)
FROM ix_demo
WHERE order_dt = DATE '2025-10-15';

SELECT * FROM TABLE(DBMS_XPLAN.DISPLAY);
```

### Skip Scan 적용 기준
Skip Scan은 다음 조건에서 효과적입니다:
- 선행 컬럼의 고유 값 수가 적을 때 (수십~수백 개)
- 후행 컬럼의 선택도가 높을 때
- 대체 인덱스가 없을 때

---

## 실전 최적화 시나리오

### 시나리오 1: 고객별 최근 거래 조회
```sql
-- 최적화 전
SELECT order_id, order_dt, amount
FROM ix_demo
WHERE cust_id = 12345
  AND order_dt BETWEEN SYSDATE - 30 AND SYSDATE
ORDER BY order_dt DESC;

-- 최적화 후 (DESC 인덱스 + Stopkey)
CREATE INDEX ix_cust_dt_desc ON ix_demo(cust_id, order_dt DESC, order_id DESC);

SELECT /*+ INDEX(ix_demo ix_cust_dt_desc) */
       order_id, order_dt, amount
FROM ix_demo
WHERE cust_id = 12345
ORDER BY order_dt DESC
FETCH FIRST 100 ROWS ONLY;
```

### 시나리오 2: 날짜별 거래 분석
```sql
-- 날짜 중심 인덱스 활용
CREATE INDEX ix_dt_cust_status ON ix_demo(order_dt, cust_id, status);

SELECT order_dt, 
       status,
       COUNT(*) as transaction_count,
       SUM(amount) as total_amount
FROM ix_demo
WHERE order_dt BETWEEN DATE '2025-10-01' AND DATE '2025-10-31'
  AND cust_id BETWEEN 1000 AND 5000
GROUP BY order_dt, status
ORDER BY order_dt, status;
```

### 시나리오 3: 복합 조건 검색
```sql
-- 다중 조건 최적화
CREATE INDEX ix_cust_status_dt ON ix_demo(cust_id, status, order_dt);

SELECT order_id, order_dt, amount
FROM ix_demo
WHERE cust_id = :cust_id
  AND status = :status
  AND order_dt >= :start_date
ORDER BY order_dt;
```

---

## 성능 측정과 분석 방법

### 실행 계획 심층 분석
```sql
-- 상세한 실행 계획 분석
ALTER SESSION SET statistics_level = ALL;

-- 테스트 쿼리 실행
SELECT order_id, order_dt, amount
FROM ix_demo
WHERE cust_id = 12345
  AND order_dt BETWEEN SYSDATE - 30 AND SYSDATE;

-- 실행 계획 확인
SELECT *
FROM TABLE(DBMS_XPLAN.DISPLAY_CURSOR(
  NULL, NULL,
  'ALLSTATS LAST +PREDICATE +PEEKED_BINDS'
));
```

### 성능 비교 프레임워크
```sql
-- 성능 측정을 위한 테스트 프로시저
CREATE OR REPLACE PROCEDURE compare_query_performance AS
  TYPE result_rec IS RECORD (
    query_name VARCHAR2(50),
    buffer_gets NUMBER,
    disk_reads NUMBER,
    elapsed_time NUMBER
  );
  
  TYPE result_tab IS TABLE OF result_rec;
  results result_tab := result_tab();
  
  v_start_time NUMBER;
  v_end_time NUMBER;
BEGIN
  -- 쿼리 1: 기존 방식
  v_start_time := DBMS_UTILITY.GET_TIME;
  EXECUTE IMMEDIATE 'SELECT /*+ QUERY1 */ COUNT(*) FROM ix_demo WHERE cust_id = 12345 AND order_dt BETWEEN SYSDATE-30 AND SYSDATE';
  v_end_time := DBMS_UTILITY.GET_TIME;
  
  results.EXTEND;
  results(results.LAST) := result_rec(
    'QUERY1_BETWEEN',
    NULL, -- buffer_gets
    NULL, -- disk_reads
    v_end_time - v_start_time
  );
  
  -- 쿼리 2: 최적화된 방식
  v_start_time := DBMS_UTILITY.GET_TIME;
  EXECUTE IMMEDIATE 'SELECT /*+ QUERY2 INDEX(ix_demo ix_c_dt) */ COUNT(*) FROM ix_demo WHERE cust_id = 12345 AND order_dt >= SYSDATE-30 AND order_dt <= SYSDATE';
  v_end_time := DBMS_UTILITY.GET_TIME;
  
  results.EXTEND;
  results(results.LAST) := result_rec(
    'QUERY2_RANGE',
    NULL,
    NULL,
    v_end_time - v_start_time
  );
  
  -- 결과 출력
  FOR i IN 1..results.COUNT LOOP
    DBMS_OUTPUT.PUT_LINE(
      results(i).query_name || ': ' || 
      results(i).elapsed_time || ' ms'
    );
  END LOOP;
END;
/
```

---

## 통계 기반 최적화 전략

### 선택도 분석
```sql
-- 컬럼별 통계 분석
SELECT column_name,
       num_distinct,
       density,
       num_nulls,
       histogram,
       ROUND((num_rows - num_nulls) / num_distinct) as avg_rows_per_value
FROM user_tab_col_statistics
WHERE table_name = 'IX_DEMO'
ORDER BY density;
```

### 히스토그램 활용
값 분포가 편향된 컬럼에는 히스토그램을 생성하여 정확한 선택도 추정을 지원합니다:

```sql
-- 히스토그램 생성
BEGIN
  DBMS_STATS.GATHER_TABLE_STATS(
    ownname    => USER,
    tabname    => 'IX_DEMO',
    method_opt => 'FOR COLUMNS status SIZE 254'
  );
END;
/

-- 히스토그램 정보 확인
SELECT endpoint_value,
       endpoint_number,
       endpoint_number - LAG(endpoint_number, 1, 0) 
         OVER (ORDER BY endpoint_number) as frequency
FROM user_tab_histograms
WHERE table_name = 'IX_DEMO'
  AND column_name = 'STATUS'
ORDER BY endpoint_number;
```

---

## 일반적인 문제와 해결책

### 문제 1: 선행 컬럼이 범위 조건인 경우
**증상**: 인덱스를 사용하지만 여전히 높은 I/O 발생

**해결책**:
```sql
-- 문제 있는 설계
CREATE INDEX ix_problem ON orders(order_date, customer_id);

-- 개선된 설계
CREATE INDEX ix_solution ON orders(customer_id, order_date);

-- 쿼리 최적화
SELECT order_id, total_amount
FROM orders
WHERE customer_id = :cust_id  -- 선행 등치 조건
  AND order_date >= :start_date  -- 후행 범위 조건
  AND order_date <= :end_date;
```

### 문제 2: LIKE 패턴의 비효율성
**증상**: `%keyword%` 패턴으로 인한 전체 테이블 스캔

**해결책**:
```sql
-- 전문 검색이 필요한 경우
CREATE INDEX idx_note_ctx ON ix_demo(note) INDEXTYPE IS CTXSYS.CONTEXT;

-- 또는 역인덱스 활용
CREATE INDEX idx_note_reverse ON ix_demo(REVERSE(note));

SELECT order_id, note
FROM ix_demo
WHERE REVERSE(note) LIKE REVERSE('%gift');
```

### 문제 3: 낮은 카디널리티 컬럼의 인덱스 활용
**증상**: status 같은 저카디널리티 컬럼의 단독 인덱스 비효율

**해결책**:
```sql
-- 단독 인덱스 대신 복합 인덱스
CREATE INDEX ix_status_dt_cust ON ix_demo(status, order_dt, cust_id);

SELECT order_id, order_dt, amount
FROM ix_demo
WHERE status = 'PAID'
  AND order_dt >= SYSDATE - 7
  AND cust_id = :cust_id;
```

---

## 종합 성능 테스트

### A/B 테스트 구현
```sql
-- 다양한 접근법 성능 비교
ALTER SESSION SET statistics_level = ALL;

-- 테스트 케이스 A: BETWEEN 연산자
SELECT /*+ TEST_A */ COUNT(*)
FROM ix_demo
WHERE cust_id = 12345
  AND order_dt BETWEEN DATE '2025-10-01' AND DATE '2025-10-31';

-- 테스트 케이스 B: 개별 조건
SELECT /*+ TEST_B */ COUNT(*)
FROM ix_demo
WHERE cust_id = 12345
  AND order_dt >= DATE '2025-10-01'
  AND order_dt <= DATE '2025-10-31';

-- 테스트 케이스 C: IN 리스트
SELECT /*+ TEST_C */ COUNT(*)
FROM ix_demo
WHERE cust_id = 12345
  AND order_dt IN (DATE '2025-10-15', DATE '2025-10-16', DATE '2025-10-17');

-- 성능 결과 비교
SELECT sql_id,
       plan_hash_value,
       executions,
       buffer_gets,
       disk_reads,
       elapsed_time/1000000 as elapsed_seconds,
       SUBSTR(sql_text, 1, 100) as sql_snippet
FROM v$sql
WHERE sql_text LIKE '%TEST_%'
ORDER BY elapsed_time;
```

---

## 결론: 효과적인 인덱스 설계와 쿼리 최적화의 종합적 접근

인덱스 최적화는 단순한 기술적 작업을 넘어 데이터 접근 패턴의 깊은 이해를 요구합니다. 효과적인 성능 개선을 위해 다음 원칙을 준수하세요:

### 1. 기본 설계 원칙
- **선행 컬럼 최적화**: 가장 높은 선택도와 빈번한 등치 조건을 가진 컬럼을 선두에 배치하세요.
- **정렬 요구사항 반영**: ORDER BY, GROUP BY에 사용되는 컬럼을 인덱스에 포함하세요.
- **커버링 인덱스 활용**: 자주 접근하는 컬럼 조합을 인덱스로 커버하세요.

### 2. 비교 연산자 선택 전략
- **등치 조건 우선**: 가능한 한 `=` 연산자를 사용하세요.
- **범위 조건 최소화**: `BETWEEN` 대신 적절한 경우 `IN` 리스트를 고려하세요.
- **패턴 검색 최적화**: `LIKE`는 접두사 검색에만 사용하고, 전문 검색이 필요하면 적절한 인덱스 유형을 선택하세요.

### 3. 군집성 관리
- **물리적 데이터 정렬**: 자주 함께 접근되는 데이터를 물리적으로 근접 저장하세요.
- **정기적 재구성**: 데이터 변경 패턴에 따라 주기적인 테이블 재구성을 고려하세요.
- **파티셔닝 활용**: 대용량 테이블에서는 파티셔닝으로 군집성을 향상시키세요.

### 4. 성능 측정과 검증
- **실제 데이터 기반 테스트**: 운영 환경과 유사한 데이터 볼륨과 분포에서 테스트하세요.
- **종합적 성능 분석**: 실행 계획, I/O 통계, 대기 이벤트를 모두 고려하세요.
- **지속적 모니터링**: 성능 변화를 지속적으로 추적하고 필요시 조정하세요.

### 5. 조직적 협업과 지식 공유
- **개발 표준 수립**: 인덱스 설계와 쿼리 작성 가이드라인을 문서화하세요.
- **교육 프로그램 운영**: 개발자 대상 성능 최적화 교육을 정기적으로 진행하세요.
- **코드 리뷰 문화**: 성능 관련 코드 리뷰를 체계적으로 수행하세요.

### 최종 원칙: 데이터 중심 접근
모든 최적화 결정은 실제 성능 데이터에 기반해야 합니다. 직관이나 경험에만 의존하지 말고, 측정 가능한 성능 지표를 통해 개선 효과를 검증하세요. 인덱스 설계는 비즈니스 요구사항, 데이터 특성, 시스템 아키텍처를 종합적으로 고려한 균형 있는 접근이 필요합니다.

효과적인 인덱스 최적화는 더 빠른 응답 시간, 더 높은 처리량, 더 낮은 운영 비용으로 이어집니다. 이러한 개선은 단순한 기술적 성취를 넘어 사용자 경험 향상과 비즈니스 가치 창출에 직접적으로 기여합니다. 지속적인 학습, 실험, 개선을 통해 데이터베이스 시스템의 최적 성능을 유지하세요.