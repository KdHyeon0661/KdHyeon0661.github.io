---
layout: post
title: 선형대수 - 행렬식
date: 2025-05-24 22:20:23 +0900
category: 선형대수
---
# 행렬식(Determinant)의 정의와 의미

행렬식(det)은 **정방행렬만**을 입력으로 받아 **스칼라 하나**를 내놓는 함수다.
선형변환의 **부피(면적) 스케일**, **방향(오리엔테이션)**, **역행렬의 존재**, **특이성**(singularity),
그리고 **연립방정식의 해 유무**와도 직결된다. 이 글은 정의 → 성질 → 계산법(안정/효율) → 응용 순으로 정리한다.

---

## 무엇이 행렬식인가?

### 표기와 기본

- 표기: $$\det(A),\ |A|$$
- 도메인: 정방행렬 $$A\in\mathbb{R}^{n\times n}$$ (혹은 복소/유수체)
- 핵심 역할:
  - $$\det(A)=0 \iff A \text{ 특이(singular)} \iff A^{-1} \text{ 없음}$$
  - $$\det(A)\neq 0 \Rightarrow A^{-1} \text{ 존재}$$
  - $$|\det(A)|$$: 부피(면적) 스케일, 부호는 방향(오리엔테이션)

### 기하학적 직관

- 2×2에서 $$A$$는 **평행사변형 면적 스케일**:
  $$\text{Area}(A\cdot\mathcal{S}) = |\det(A)|\cdot \text{Area}(\mathcal{S})$$
- 3×3에서 $$A$$는 **평행육면체(평행다면체) 부피 스케일**:
  $$\text{Vol}(A\cdot\mathcal{V}) = |\det(A)|\cdot \text{Vol}(\mathcal{V})$$
- $$\det(A)>0$$: **방향 유지**, $$\det(A)<0$$: **방향 반전(반사 포함)**

---

## 정의: 전개식과 순열식

### 2×2, 3×3

- 2×2:
$$
A=\begin{bmatrix}a&b\\c&d\end{bmatrix},\quad \det(A)=ad-bc.
$$
- 3×3(사루스(Sarrus) 규칙):
$$
\det\!\begin{bmatrix}
a&b&c\\ d&e&f\\ g&h&i
\end{bmatrix}
= aei+bfg+cdh-ceg-bdi-afh.
$$

> ⚠️ 사루스는 **3×3에만** 유효. 그 이상 차원에 억지 확장은 금물.

### 라플라스 전개(Laplace expansion, 여인자 전개)

임의의 행(또는 열) 1개를 잡아 전개:
$$
\det(A)=\sum_{j=1}^n (-1)^{i+j}a_{ij}\det(M_{ij})
$$
- $$M_{ij}$$: $$i$$행 $$j$$열을 지운 소행렬(minor)
- $$(-1)^{i+j}$$: 교대 부호(여인자)

> 이 정의는 직관적이지만 계산량이 **지수적**으로 커져 고차원에 비효율.

### 공식

$$
\det(A)=\sum_{\sigma\in S_n} \operatorname{sgn}(\sigma)\prod_{i=1}^n a_{i,\sigma(i)}.
$$
- $$S_n$$: 순열집합, $$\operatorname{sgn}(\sigma)\in\{+1,-1\}$$

> 이 또한 정의적 의미는 크지만 직접 계산엔 부적합.

---

## 공리적 성질(멀티선형·교대·정규화)

행렬식은 아래 세 성질로 **유일하게** 특징지어진다.

1) **(행에 대해) 다중선형(multilinear)**
  같은 열(혹은 같은 행)만 고정하면 나머지 방향에 **선형**
2) **교대(Alternating)**
  두 행(또는 두 열)이 같으면 $$\det(A)=0$$, 서로 바꾸면 부호 반전
3) **정규화(Normalization)**
  $$\det(I_n)=1$$

여기에서 **행 연산 효과**도 바로 나온다:
- 행 교환: 부호 반전
- 행에 배수 곱: 그 배수만큼 스케일
- 한 행에 **다른 행의 배수 더하기**: **행렬식 불변**

---

## 핵심 성질 요약표

| 성질 | 식/설명 |
|---|---|
| 단위행렬 | $$\det(I_n)=1$$ |
| 전치 불변 | $$\det(A^T)=\det(A)$$ |
| 곱의 행렬식 | $$\det(AB)=\det(A)\det(B)$$ |
| 역행렬 | $$\det(A^{-1})=\frac{1}{\det(A)}$$ (가역일 때) |
| 삼각·대각 | 삼각/대각행렬의 $$\det$$은 **대각 원소 곱** |
| 행 교환 | 한 번 교환할 때마다 부호 반전 |
| 행 스케일 | 한 행을 $$k$$배 → 행렬식도 $$k$$배 |
| 행 덧셈 | $$R_i\leftarrow R_i+kR_j$$ 는 행렬식 **불변** |
| 고윳값 | $$\det(A)=\prod_{i=1}^n \lambda_i$$ (대수적 중복 포함) |
| 특성다항식 | $$p_A(\lambda)=\det(\lambda I-A)$$, 상수항은 $$(-1)^n\det(A)$$ |

---

## 계산법: 이론적 vs 실전적

### 이론적(교육용)

- 사루스(3×3), 라플라스 전개(작은 차원)
- **장점**: 구조 이해
- **단점**: 고차원 비실용(연산량 폭증, 수치적 불안정)

### — **LU/QR/Cholesky/SVD**

- **LU 분해(부분 피벗팅)**: $$P A=L U\ \Rightarrow\ \det(A)=\operatorname{sgn}(P)\prod_i U_{ii}$$
  (*행 교환 횟수*에 따라 부호 결정)
- **QR(정규직교)**: $$A=QR\ \Rightarrow\ \det(A)=\det(Q)\prod_i R_{ii}$$, $$\det(Q)=\pm1$$
- **Cholesky**(대칭 양정치 SPD): $$A=LL^T\ \Rightarrow\ \det(A)=(\prod_i L_{ii})^2$$
  → **log-det**: $$\log\det(A)=2\sum_i \log L_{ii}$$ (안정적)
- **SVD**: $$A=U\Sigma V^T\ \Rightarrow\ |\det(A)|=\prod_i \sigma_i$$, 부호는 $$\det(U)\det(V)$$로 정해짐

> 큰 행렬에서는 **log-abs-det**를 많이 쓴다: `slogdet` (부호, 로그 절댓값 동시 제공)

---

## 파이썬 예제

### NumPy 기본

```python
import numpy as np

A = np.array([[1., 2.], [3., 4.]])
print("det(A)=", np.linalg.det(A))  # -2.0 근사
```

### SymPy(정확 산술·상징)

```python
from sympy import Matrix, symbols

a,b,c,d = symbols('a b c d')
A = Matrix([[a,b],[c,d]])
print("det(A) =", A.det())  # a*d - b*c (상징식)
```

### PyTorch (logdet 포함)

```python
import torch
A = torch.tensor([[1., 2.],[3., 4.]])
sign, logabs = torch.linalg.slogdet(A)
print("sign:", sign.item(), " log|det|:", logabs.item(),
      " => det≈", sign.item()*torch.exp(logabs).item())
```

### LU로 계산(부호 포함)

```python
import numpy as np
from scipy.linalg import lu_factor

def det_via_lu(A):
    A = np.array(A, dtype=float)
    lu, piv = lu_factor(A)  # 부분피벗 LU
    # 행교환 횟수의 부호 계산: piv는 교환된 행의 인덱스 기록
    # 간단히: 교환 횟수 = sum(piv[i] != i) 의 패리티로 추정
    swaps = sum(int(piv[i] != i) for i in range(len(piv)))
    sign = -1 if (swaps % 2) else 1
    return sign * np.prod(np.diag(lu))

A = [[2,3,1],[4,7,9],[2,3,4]]
print(det_via_lu(A))
```

### SPD에서 Cholesky logdet(강추)

```python
import numpy as np

def logdet_spd(A):
    # A: symmetric positive definite
    L = np.linalg.cholesky(A)
    return 2.0*np.sum(np.log(np.diag(L)))

S = np.array([[4.,1.],[1.,3.]])
print("log det(S) =", logdet_spd(S))
print("det(S) =", np.exp(logdet_spd(S)))
```

---

## 응용 모음

### 선형시스템 가역성

- $$\det(A)\neq 0 \iff A^{-1} \text{ exists} \iff A\vec{x}=\vec{b} \text{가 유일해}$$

### 좌표변환·적분의 변수변환(Jacobian)

$$
\int_{\Omega} f(\mathbf{x})\,d\mathbf{x}
= \int_{\Phi^{-1}(\Omega)} f(\Phi(\mathbf{u}))\ |\det J_\Phi(\mathbf{u})|\, d\mathbf{u}.
$$
- 야코비안의 **절댓값**이 국소 부피 스케일.

### PCA·통계(공분산 행렬의 det)

- $$\det(\Sigma)$$: **generalized variance**(분산의 전역적 지표)
- 정규분포의 정규화 상수에 **$(\det\Sigma)^{-1/2}$** 등장

### 최적설계·최적화 (D-Optimality, LogDet Barrier)

- **D-optimal design**: $$\max \log\det(X^\top X)$$
- 반정의 제약 $$X\succeq 0$$에 **LogDet barrier** 사용

### 그래프 이론(행렬-나무 정리; Kirchhoff)

- 라플라시안 $$L=D-A$$ 의 **어떤 1×1 소행렬의 여인자(cofactor)**가
  그래프의 **spanning tree 개수**와 동일:
  $$\tau(G)=\det(L_{ii})$$

### 고윳값·특성다항식

- $$\det(A)=\prod_i \lambda_i$$
- $$p_A(\lambda)=\det(\lambda I-A)$$의 상수항이 $$(-1)^n\det(A)$$

---

## 블록 행렬과 중요 항등식

### 블록 삼각행렬

$$
\det\begin{bmatrix}A&*\\0&D\end{bmatrix}=\det(A)\det(D).
$$

### 슈어 보완(Schur complement)

$$
\det\begin{bmatrix}A&B\\C&D\end{bmatrix}
=\det(A)\,\det(D-CA^{-1}B)\quad(A \text{ 가역})
$$

### 행렬식 보조정리(Matrix Determinant Lemma)

$$
\det(A+u v^\top)=\det(A)\,(1+v^\top A^{-1}u).
$$

### 정리

$$
\det(I_m+AB)=\det(I_n+BA)\quad(A\in\mathbb{R}^{m\times n},\,B\in\mathbb{R}^{n\times m})
$$

### 코시-비네(Cauchy–Binet)

직사각 $$A\in\mathbb{R}^{m\times n},B\in\mathbb{R}^{n\times m}$$,
$$m\le n$$일 때
$$
\det(AB)=\sum_{S\subseteq\{1,\dots,n\},|S|=m}\det(A_{:,S})\det(B_{S,:}).
$$

### 반데르몬드(Vandermonde)

$$
V=\begin{bmatrix}
1 & x_1 & x_1^2 & \cdots & x_1^{n-1}\\
1 & x_2 & x_2^2 & \cdots & x_2^{n-1}\\
\vdots & \vdots & \vdots & & \vdots\\
1 & x_n & x_n^2 & \cdots & x_n^{n-1}
\end{bmatrix},\quad
\det(V)=\prod_{1\le i<j\le n}(x_j-x_i).
$$
- 모든 $$x_i$$가 서로 다르면 **가역**(보간 유일해).

---

## 수치 안정성과 실전 팁

- ❌ **라플라스 전개**: n이 조금만 커도 연산량 폭증(수치오차에도 취약)
- ✅ **LU(부분피벗)**: 표준. 큰 n에서 빠르고 안정
- ✅ **SPD**면 **Cholesky**로 **log-det** 계산(오버/언더플로 방지)
- ✅ **`slogdet`**(부호, log|det|) 사용 → under/overflow 회피
- ⚠️ **거의-특이(near-singular)**: det는 매우 작은 수 → 상대오차 커짐
  → 랭크 추정(SVD), 조건수 검사 권장
- ✅ 정수/유리 정확 계산은 **SymPy**로

---

## 작은 실전 시나리오

### 2D 변환: 스케일·회전·반사

- 스케일 $$S=\mathrm{diag}(s_x,s_y)$$ → $$\det(S)=s_x s_y$$ (면적 스케일)
- 회전 $$R(\theta)$$ → $$\det(R)=+1$$ (면적 보존, 방향 유지)
- 반사 $$F=\begin{bmatrix}-1&0\\0&1\end{bmatrix}$$ → $$\det(F)=-1$$ (면적 보존, 방향 반전)

```python
import numpy as np

def rot(theta):
    c,s = np.cos(theta), np.sin(theta)
    return np.array([[c,-s],[s,c]])

S = np.diag([2., 0.5])
R = rot(np.deg2rad(30))
F = np.array([[-1.,0.],[0.,1.]])

for M,name in [(S,"scale"),(R,"rot"),(F,"flip"),(R@S,"rot@scale")]:
    sign, logabs = np.linalg.slogdet(M)
    print(name, "det=", sign*np.exp(logabs))
```

### 그래프 나무 수(3노드 경로)

그래프: 1—2—3
라플라시안
$$
L=\begin{bmatrix}1&-1&0\\-1&2&-1\\0&-1&1\end{bmatrix}
$$
아무 1행1열 제거 소행렬의 det = spanning tree 수 = 1.

```python
from sympy import Matrix
L = Matrix([[1,-1,0],[-1,2,-1],[0,-1,1]])
print((L[1:,1:]).det())  # 1
```

### Vandermonde 가역성 체크

```python
import numpy as np
xs = np.array([0., 1., 2., 3.])
V = np.vander(xs, increasing=True)  # [1, x, x^2, ...]
print(np.linalg.det(V))  # 0이 아니면 보간 유일
```

---

## 자주 하는 실수와 체크리스트

- **행 덧셈**(Ri←Ri+kRj)은 행렬식을 **바꾸지 않는다**. (배수 곱과 혼동 금지)
- **사루스 규칙**은 **3×3만**. 4×4 이상은 적용 X.
- **A+B의 det**는 **det(A)+det(B)**가 아니다. (선형 아님)
- **정방이 아니면** det **정의 안됨**.
- **수치오차**를 고려해 det≈0 판단엔 **허용오차** 필요.

---

## 심화: 미분과 로그-행렬식

### 야코비 공식(Jacobi’s formula)

$$
\frac{d}{dt}\det(A(t)) = \det(A(t))\ \mathrm{tr}\!\big(A(t)^{-1}A'(t)\big).
$$
- 최적화, 민감도 분석에 등장

### SPD에서 LogDet의 그라디언트

$$
f(X)=\log\det(X),\ X\succ0\ \Rightarrow\ \nabla f(X)=X^{-1}.
$$
- 반정의 제약 최적화(그래프학습, 가우시안 그래픽컬 모델)에 매우 중요

---

## 연습문제

1) 아래 3×3 행렬의 det를 (i) 사루스, (ii) 행연산→상삼각 후 대각곱으로 각각 구하라.
$$
\begin{bmatrix}2&1&0\\0&3&4\\1&0&5\end{bmatrix}
$$

2) $$A=\begin{bmatrix}1&1\\1&1\end{bmatrix}$$ 의 det와 랭크를 구하고,
   왜 $$A^{-1}$$가 존재하지 않는지 설명하라.

3) $$A\succ0$$에 대해 Cholesky로 $$\log\det(A)$$을 구현하고,
   임의 SPD를 생성해 NumPy `slogdet`과 결과를 비교하라.

---

## 핵심 요약

- **의미**: $$|\det(A)|$$는 **부피 스케일**, 부호는 **방향**.
- **가역성**: $$\det(A)\neq 0 \iff A^{-1}\ \text{존재}$$.
- **계산**: 이론은 전개/순열, **실전은 LU/QR/Cholesky/SVD** + **slogdet**.
- **응용**: 변수변환(야코비안), 고윳값 곱, 그래프 라플라시안, D-optimal 설계, LogDet 최적화.

---

## 교육용 구현: 재귀적 여인자 전개(작은 n 전용)

```python
import numpy as np

def det_cofactor(A):
    A = np.array(A, dtype=float)
    n = A.shape[0]
    assert A.shape[0] == A.shape[1]
    if n == 1:
        return A[0,0]
    if n == 2:
        return A[0,0]*A[1,1] - A[0,1]*A[1,0]
    s = 0.0
    for j in range(n):
        # 소행렬
        M = np.delete(np.delete(A, 0, axis=0), j, axis=1)
        s += ((-1)**(0+j)) * A[0,j] * det_cofactor(M)
    return s

print(det_cofactor([[1,2],[3,4]]))  # -2.0
```

> 교육용 외에는 권장 X. 큰 n에서는 반드시 LU/Cholesky/QR 등을 사용.

---

## PyTorch: SPD logdet와 안정성

```python
import torch

def make_spd(n=5, seed=0):
    g = torch.Generator().manual_seed(seed)
    M = torch.randn((n,n), generator=g, dtype=torch.float64)
    A = M @ M.T + 1e-3*torch.eye(n, dtype=torch.float64)  # SPD
    return A

A = make_spd(5)
sign, logabs = torch.linalg.slogdet(A)
print("sign:", sign.item(), " log|det(A)|:", logabs.item())

# Cholesky 기반 logdet (SPD 가정)

L = torch.linalg.cholesky(A)
logdet_chol = 2*torch.log(torch.diag(L)).sum()
print("diff:", (logdet_chol - logabs).abs().item())
```

> SPD에서 `slogdet`과 Cholesky logdet는 수치적으로 일치해야 한다(허용오차 이내).
