---
layout: post
title: DB 심화 - 전략적 통계 수집
date: 2025-11-18 14:25:23 +0900
category: DB 심화
---
# 오라클 옵티마이저 통계(Statistics) 운영

> 목표
> - CBO가 “좋은 플랜”을 고르게 만드는 **통계 수집/게시/검증/자동화**의 전 과정을 실험 가능한 형태로 정리한다.
> - **대형 파티션 팩트 테이블**과 **스큐 컬럼**, **OLTP 커서 안정성**에서 실제로 터지는 문제를 **재현 → 진단 → 개선**까지 한 흐름으로 익힌다.
> - 모든 절차는 **실측 플랜(ALLSTATS LAST)**과 **E-Rows vs A-Rows**로 검증한다.

실행 후에는 반드시 실측 플랜을 확인한다.

```sql
SELECT *
FROM   TABLE(DBMS_XPLAN.DISPLAY_CURSOR(
         NULL, NULL,
        'ALLSTATS LAST +PREDICATE +PEEKED_BINDS +IOSTATS +MEMSTATS'
));
```

---

## 통계가 왜 중요한가

오라클 CBO는 **통계 기반 비용 모델**로 실행계획을 세운다.
따라서 통계가 대표성을 잃으면 아래가 연쇄로 흔들린다.

- **카디널리티(행 수) 추정 오판** → 조인 순서/방식, 접근 경로, 변환(unnest/merge/expand/stopkey…)이 달라짐
- **I/O 비용 오판** → 인덱스 탐색 vs 풀스캔, 파티션 프루닝, 파티션-와이즈 조인 선택 실패
- **플랜 불안정성** → 자동 통계/수동 통계가 기존 커서를 무효화하며 child cursor 폭증

요약하면,
**통계 = CBO의 시력**이다.
통계를 “빠르게, 안전하게, 재현 가능하게” 관리하는 것이 곧 시스템 성능과 안정성이다.

---

## 실습 스키마(파티션 포함) 준비

```sql
ALTER SESSION SET nls_date_format = 'YYYY-MM-DD';
ALTER SESSION SET statistics_level = ALL;

-- 깨끗이
BEGIN
  FOR t IN (SELECT table_name FROM user_tables
            WHERE table_name IN ('D_CUSTOMER','D_PRODUCT','F_SALES','F_SALES_STG')) LOOP
    EXECUTE IMMEDIATE 'DROP TABLE '||t.table_name||' PURGE';
  END LOOP;
END;
/

-- 차원 테이블
CREATE TABLE D_CUSTOMER(
  CUST_ID NUMBER PRIMARY KEY,
  REGION  VARCHAR2(8),
  TIER    VARCHAR2(8)
);

CREATE TABLE D_PRODUCT(
  PROD_ID  NUMBER PRIMARY KEY,
  CATEGORY VARCHAR2(12),
  BRAND    VARCHAR2(12)
);

-- 월 파티션 사실 테이블
CREATE TABLE F_SALES(
  SALES_ID NUMBER PRIMARY KEY,
  CUST_ID  NUMBER NOT NULL,
  PROD_ID  NUMBER NOT NULL,
  SALES_DT DATE   NOT NULL,
  QTY      NUMBER NOT NULL,
  AMOUNT   NUMBER(12,2) NOT NULL
)
PARTITION BY RANGE (SALES_DT)(
  PARTITION P202401 VALUES LESS THAN (DATE '2024-02-01'),
  PARTITION P202402 VALUES LESS THAN (DATE '2024-03-01'),
  PARTITION P202403 VALUES LESS THAN (DATE '2024-04-01'),
  PARTITION PMAX    VALUES LESS THAN (MAXVALUE)
);

-- 인덱스
CREATE INDEX IX_CUST_REGION     ON D_CUSTOMER(REGION, CUST_ID);
CREATE INDEX IX_PROD_CAT_BRAND  ON D_PRODUCT(CATEGORY, BRAND, PROD_ID);
CREATE INDEX IX_FS_CUST_DT      ON F_SALES(CUST_ID, SALES_DT) LOCAL;
CREATE INDEX IX_FS_PROD_DT      ON F_SALES(PROD_ID, SALES_DT) LOCAL;

-- 데이터(스큐 포함)
BEGIN
  FOR c IN 1..50000 LOOP
    INSERT INTO D_CUSTOMER
    VALUES(
      c,
      CASE MOD(c,6) WHEN 0 THEN 'KOR' WHEN 1 THEN 'KOR'
                    WHEN 2 THEN 'APAC' WHEN 3 THEN 'EMEA'
                    WHEN 4 THEN 'AMER' ELSE 'JPN' END,
      CASE MOD(c,4) WHEN 0 THEN 'VIP' WHEN 1 THEN 'GOLD'
                    WHEN 2 THEN 'SILVER' ELSE 'GEN' END
    );
  END LOOP;

  FOR p IN 1..20000 LOOP
    INSERT INTO D_PRODUCT
    VALUES(
      p,
      CASE MOD(p,5) WHEN 0 THEN 'ELEC' WHEN 1 THEN 'FOOD'
                    WHEN 2 THEN 'TOY'  WHEN 3 THEN 'HOME' ELSE 'FASH' END,
      CASE WHEN p <= 6000 THEN 'B0' ELSE 'B'||LPAD(TO_CHAR(MOD(p,80)),2,'0') END
    );
  END LOOP;

  FOR m IN 1..3 LOOP  -- 1~3월
    FOR r IN 1..150000 LOOP
      INSERT INTO F_SALES
      VALUES(
        (m-1)*150000 + r,
        MOD(r,50000)+1,
        MOD(r,20000)+1,
        ADD_MONTHS(DATE '2024-01-10', m-1) + MOD(r,20),
        1 + MOD(r,5),
        ROUND(DBMS_RANDOM.VALUE(10,800),2)
      );
    END LOOP;
  END LOOP;
  COMMIT;
END;
/

-- 최초 통계(히스토그램은 후술)
BEGIN
  DBMS_STATS.GATHER_TABLE_STATS(USER,'D_CUSTOMER', cascade=>TRUE, method_opt=>'FOR ALL COLUMNS SIZE 1');
  DBMS_STATS.GATHER_TABLE_STATS(USER,'D_PRODUCT' , cascade=>TRUE, method_opt=>'FOR ALL COLUMNS SIZE 1');
  DBMS_STATS.GATHER_TABLE_STATS(USER,'F_SALES'   , cascade=>TRUE, method_opt=>'FOR ALL COLUMNS SIZE 1',
                                granularity=>'GLOBAL AND PARTITION');
END;
/
```

---

## 데이터 샘플링(estimate_percent) — 정확도 vs 비용의 균형

### 기본 원칙

1) **기본은 AUTO**
```sql
estimate_percent => DBMS_STATS.AUTO_SAMPLE_SIZE
```
- 오라클은 테이블 크기/분포/컬럼 특성에 따라 **자동으로 적절한 샘플로 수집**한다.
- 최근 버전에서는 **근사 NDV(Approx NDV)** 같은 기법으로 NDV(고유값 수)를 빠르게 추정해,
  “정확도와 속도”를 동시에 잡는 방향으로 기본값이 진화했다.

2) **수동 퍼센트는 “정말 필요한 경우만”**
- 테이블이 너무 커서 AUTO가 과도하게 오래 걸릴 때(예: 1~10%)
- 스큐/NDV가 비즈니스적으로 매우 중요한데 AUTO가 흔들릴 때
  → 해당 테이블/컬럼만 높게(또는 FULL)
  → 그러나 **대부분은 히스토그램/확장 통계가 먼저다.**

### 샘플링 비교 실습

```sql
-- ① AUTO
BEGIN
  DBMS_STATS.GATHER_TABLE_STATS(USER,'D_PRODUCT',
    estimate_percent => DBMS_STATS.AUTO_SAMPLE_SIZE,
    method_opt       => 'FOR ALL COLUMNS SIZE AUTO',
    cascade          => TRUE);
END;
/

-- ② 저퍼센트(빠르지만 스큐 왜곡 가능)
BEGIN
  DBMS_STATS.GATHER_TABLE_STATS(USER,'D_PRODUCT',
    estimate_percent => 5,
    method_opt       => 'FOR ALL COLUMNS SIZE AUTO',
    cascade          => TRUE);
END;
/

-- ③ FULL
BEGIN
  DBMS_STATS.GATHER_TABLE_STATS(USER,'D_PRODUCT',
    estimate_percent => 100,
    method_opt       => 'FOR ALL COLUMNS SIZE AUTO',
    cascade          => TRUE);
END;
/

-- 결과 비교(컬럼 통계/히스토그램/NDV)
SELECT column_name, num_distinct, histogram, density, last_analyzed
FROM   user_tab_col_statistics
WHERE  table_name='D_PRODUCT'
ORDER  BY column_name;

-- 변화 리포트(이전 vs 현재)
SELECT DBMS_STATS.DIFF_TABLE_STATS_IN_HISTORY(USER,'D_PRODUCT',
       SYSTIMESTAMP-1, SYSTIMESTAMP) AS diff
FROM   dual;
```

#### 관찰 포인트

- `NUM_DISTINCT`가 **저퍼센트에서 과도하게 흔들리는지**
- 스큐 컬럼(BRAND)의 히스토그램이 **FULL/AUTO vs 5%에서 어떤 차이인지**
- 그 결과로 **BRAND='B0' vs BRAND='B47'** 같은 선택도에 대해 플랜이 바뀌는지

### 실무 팁

- “샘플을 더 크게”는 마지막 수단.
  **스큐 → 히스토그램, 결합 선택도 → 확장 통계**가 정석이다.
- 보고서 핵심 컬럼만 **SIZE 254** 등 정밀, 나머지는 **SIZE 1**로 절약.
- 대형 운영 DB에서는
  **Pending → 검증 → Publish**를 습관화한다(5절).

---

## 히스토그램과 확장 통계 — 샘플링의 한계를 넘기는 핵심

샘플링을 아무리 올려도 못 잡는 영역이 있다.
특히 **스큐 컬럼**과 **컬럼 결합 선택도**는 별도 통계가 필요하다.

### 히스토그램 정책

```sql
-- 자동 정책: 컬럼 사용 기반으로 SIZE AUTO
BEGIN
  DBMS_STATS.GATHER_TABLE_STATS(USER,'D_PRODUCT',
    estimate_percent => DBMS_STATS.AUTO_SAMPLE_SIZE,
    method_opt       => 'FOR ALL COLUMNS SIZE AUTO',
    cascade          => TRUE);
END;
/
```

- `SIZE AUTO`는 **컬럼 사용량(Col Usage)** 에 기반해 “필요한 컬럼만 히스토그램”을 만든다.
- 불필요한 히스토그램은 오히려 플랜 변동성을 키울 수 있어
  **업무 핵심 컬럼만 선별**이 중요하다.

### 컬럼 사용량 기반 선별

```sql
EXEC DBMS_STATS.SEED_COL_USAGE(NULL, NULL, 300);
SELECT DBMS_STATS.REPORT_COL_USAGE(USER,'F_SALES') AS report FROM dual;
```

- 보고서에서 **Predicate/Join에 자주 쓰이는 컬럼**만 골라 SIZE를 올린다.

### 스큐 컬럼만 정밀 히스토그램

```sql
BEGIN
  DBMS_STATS.GATHER_TABLE_STATS(
    ownname    => USER,
    tabname    => 'D_PRODUCT',
    method_opt => 'FOR COLUMNS SIZE 254 BRAND, FOR ALL COLUMNS SIZE 1',
    cascade    => TRUE);
END;
/
```

---

## 파티션 테이블 통계 — 증분 통계로 빠르고 안전하게

### Granularity & Incremental 개념

- 파티션 테이블은 통계 레벨이 두 층이다.
  - **Partition level stats**(파티션별)
  - **Global level stats**(전체 합성)

대형 팩트에서 매번 GLOBAL을 FULL로 다시 모으면 비용이 폭발한다.
그래서 **증분 통계**가 필수다.

```sql
BEGIN
  DBMS_STATS.SET_TABLE_PREFS(USER,'F_SALES','INCREMENTAL','TRUE');
  DBMS_STATS.SET_TABLE_PREFS(USER,'F_SALES','GRANULARITY','AUTO');
END;
/
```

- 이후 변경된 파티션만 수집하면
  오라클이 내부 시놉시스(synopsis)를 이용해 GLOBAL을 자동 합성한다.

### 표준 운영 플로우(Partition Exchange + Incremental)

```sql
-- 신월 스테이징
CREATE TABLE F_SALES_STG AS SELECT * FROM F_SALES WHERE 1=0;

-- (ETL) 신월 데이터 로드 → 스테이징 통계 선수집
BEGIN
  DBMS_STATS.GATHER_TABLE_STATS(USER,'F_SALES_STG',
    estimate_percent => DBMS_STATS.AUTO_SAMPLE_SIZE,
    method_opt       => 'FOR ALL COLUMNS SIZE 1', cascade=>TRUE);
END;
/

-- 파티션 교체(메타데이터 수준 → 빠름)
ALTER TABLE F_SALES EXCHANGE PARTITION P202404 WITH TABLE F_SALES_STG WITHOUT VALIDATION;

-- 변경 파티션만 수집(증분)
BEGIN
  DBMS_STATS.GATHER_PARTITION_STATS(USER,'F_SALES','P202404', cascade=>TRUE);
END;
/

-- 확인
SELECT table_name, partition_name, num_rows, last_analyzed
FROM   user_tab_statistics
WHERE  table_name='F_SALES'
ORDER  BY partition_position NULLS LAST;
```

#### 포인트

- **신월 데이터는 STG에서 통계까지 끝내고 교체**
- 교체 후 **그 파티션만 재수집**
- GLOBAL은 자동 합성 → 비용 최소화

### Pending Stats + 검증 → Publish

```sql
-- 게시 보류(플랜 급변 방지)
BEGIN
  DBMS_STATS.SET_TABLE_PREFS(USER,'F_SALES','PUBLISH','FALSE');
END;
/

-- 수집(게시 보류 상태)
BEGIN
  DBMS_STATS.GATHER_TABLE_STATS(USER,'F_SALES', options=>'GATHER STALE',
                                cascade=>TRUE, granularity=>'AUTO');
END;
/

-- 검증 세션에서 Pending 사용
ALTER SESSION SET optimizer_use_pending_statistics = TRUE;

EXPLAIN PLAN FOR
SELECT p.category, SUM(s.amount)
FROM   F_SALES s JOIN D_PRODUCT p ON p.prod_id=s.prod_id
WHERE  s.sales_dt BETWEEN DATE '2024-03-01' AND DATE '2024-03-31'
GROUP  BY p.category;
SELECT * FROM TABLE(DBMS_XPLAN.DISPLAY);

-- 이상 없으면 게시
BEGIN
  DBMS_STATS.PUBLISH_PENDING_STATS(USER,'F_SALES');
END;
/
```

- 운영에서 가장 안전한 루틴은
  **야간 수집(Pending)** → **아침 검증 세션** → **Publish**다.

---

## 인덱스 통계 — cascade와 CF의 의미

### 왜 인덱스 통계가 플랜을 바꾸는가

CBO는 인덱스의 물리/논리 특성을 통계로 본다.

- **BLEVEL**: B-Tree 깊이
- **LEAF_BLOCKS**: 리프 블록 수
- **DISTINCT_KEYS**: 키 NDV
- **CLUSTERING_FACTOR(CF)**: 인덱스 키 순서와 테이블 물리 순서의 정렬 정도

CF가 높을수록
- 인덱스 탐색 후 테이블을 **랜덤하게 많이 찍게 된다**
- NL JOIN / Index Range Scan 비용이 커져
  **HASH JOIN/Full Scan 쪽으로 플랜이 틀어진다**

### 수집 방법

```sql
-- 테이블 통계 + 인덱스 동시(cascade)
BEGIN
  DBMS_STATS.GATHER_TABLE_STATS(USER,'D_PRODUCT',
    estimate_percent => DBMS_STATS.AUTO_SAMPLE_SIZE,
    method_opt       => 'FOR ALL COLUMNS SIZE AUTO',
    cascade          => TRUE);
END;
/

-- 인덱스만 별도
BEGIN
  DBMS_STATS.GATHER_INDEX_STATS(USER,'IX_PROD_CAT_BRAND');
END;
/

-- 지표 확인
SELECT index_name, blevel, leaf_blocks, distinct_keys, clustering_factor, num_rows, last_analyzed
FROM   user_indexes
WHERE  table_name IN ('D_PRODUCT','F_SALES')
ORDER  BY table_name, index_name;
```

### 로컬/글로벌 파티션 인덱스

- **LOCAL 인덱스**: 파티션별 인덱스 통계가 자동 관리
- **GLOBAL 인덱스**: 일부 파티션만 변해도 전체 인덱스 비용이 달라질 수 있음
  → **변경 후 인덱스 통계 재수집**을 습관화

### Rebuild/Coalesce 후

```sql
ALTER INDEX IX_PROD_CAT_BRAND COALESCE;
BEGIN
  DBMS_STATS.GATHER_INDEX_STATS(USER,'IX_PROD_CAT_BRAND');
END;
/
```

- Rebuild/Coalesce는 BLEVEL/LEAF_BLOCKS를 바꿀 수 있다.
- 다만 **CF는 테이블 물리 순서에 좌우**되므로
  인덱스만 만져서 CF가 극적으로 좋아지진 않는다.
  CF 문제는 **테이블 재정렬(MOVE/CTAS) + 인덱스 재생성**이 더 확실하다.

---

## 커서 Invalidation — 플랜 급변/하드파스를 막는 법

### 언제 커서가 무효화되는가

- 테이블/인덱스 통계 변경
- DDL(인덱스 생성/삭제/재빌드, 컬럼 추가 등)
- 옵티마이저 관련 파라미터 변경
- 권한/동의어/객체 재컴파일 등 네임스페이스 변화

무효화가 발생하면
- 기존 child cursor가 재하드파싱 대상
- 새 통계를 기준으로 **플랜이 바뀔 수 있다**
- OLTP에서 CPU와 지연이 급증한다

### 통계 수집 시 완충: NO_INVALIDATE + Pending

```sql
BEGIN
  DBMS_STATS.SET_TABLE_PREFS(USER,'F_SALES','NO_INVALIDATE','TRUE');
  DBMS_STATS.SET_TABLE_PREFS(USER,'F_SALES','PUBLISH','FALSE');
END;
/

BEGIN
  DBMS_STATS.GATHER_TABLE_STATS(USER,'F_SALES', options=>'GATHER STALE', cascade=>TRUE);
END;
/

ALTER SESSION SET optimizer_use_pending_statistics = TRUE;
/* 핵심 쿼리 검증 */

BEGIN
  DBMS_STATS.PUBLISH_PENDING_STATS(USER,'F_SALES');
END;
/
```

- `NO_INVALIDATE=TRUE`는 기존 커서를 즉시 날리지 않아
  **주간 안정성**을 지킨다.
- `PUBLISH=FALSE`는 새 통계를 “검증 전까지 잠가”
  **플랜 급변을 컨트롤**한다.

### 관찰 SQL

```sql
SELECT sql_id, child_number, plan_hash_value, executions, parsing_schema_name
FROM   v$sql
WHERE  sql_text LIKE 'SELECT p.category, SUM(s.amount)%' ESCAPE '\'
ORDER  BY sql_id, child_number;
```

- child cursor가 늘면
  통계/파라미터/바인드 피킹 등으로 플랜이 흔들린 신호다.

---

## 자동 통계 수집(Auto Optimizer Stats Collection)

### 무엇을 언제 어떻게 수집하나

오라클은 자동 작업(AutoTask)으로
- **통계가 없거나(stale/missing)**
- 변경량이 큰 객체를 우선하여
- **야간 유지보수 윈도우**에서 수집한다.

자동 작업도 결국 **DBMS_STATS 기본값과 Preferences**를 따른다.
따라서 Preferences가 곧 자동 통계의 정책이다.

### 상태/스케줄 확인

```sql
SELECT client_name, status, window_group
FROM   dba_autotask_client;

SELECT window_name, repeat_interval, duration, enabled
FROM   dba_scheduler_windows
ORDER  BY window_name;
```

### 자동 통계 비활성/재활성

```sql
BEGIN
  DBMS_AUTO_TASK_ADMIN.DISABLE(
    client_name => 'auto optimizer stats collection',
    operation   => NULL, window_name => NULL);
  -- DBMS_AUTO_TASK_ADMIN.ENABLE(...) 로 재활성
END;
/
```

### 고빈도 자동 통계(High-frequency)와 실시간 통계

- 최근 버전에서는
  **stale 객체만 더 자주 확인/수집**하는 고빈도 자동 통계가 옵션으로 제공된다.
- 대형 변동 테이블(실시간 적재/트래픽)에 의미가 있다.

```sql
EXEC dbms_stats.set_global_prefs('AUTO_TASK_STATUS','ON');     -- OFF로 끔
EXEC dbms_stats.set_global_prefs('AUTO_TASK_INTERVAL','900'); -- 점검 주기(초)
EXEC dbms_stats.set_global_prefs('AUTO_TASK_MAX_RUN_TIME','3600'); -- 회차 최대 실행(초)
```

### Direct-Path 로드의 Online Stats

- CTAS/IAS/Direct-Path Insert는
  로딩 중 통계를 “동시에” 만드는 **온라인 통계 기능**을 제공한다.
- 파티션 로드에서도 **증분 통계 시놉시스**까지 함께 생성될 수 있다.
  → **ETL 이후 별도 풀스캔을 줄이는 핵심 전술**

---

## Statistics Preferences — 정책을 코드로 고정하는 방법

### Preferences 계층

| 계층 | 적용 범위 | 사용 API |
|---|---|---|
| Global | DB 전체 기본값 | `SET_GLOBAL_PREFS` |
| Database | 사용자 스키마 전체 | `SET_DATABASE_PREFS` |
| Schema | 해당 스키마 테이블 | `SET_SCHEMA_PREFS` |
| Table | 특정 테이블 | `SET_TABLE_PREFS` |

원칙:
- **가장 작은 스코프에서만 오버라이드**
- 기본값을 많이 뒤틀수록 운영 난이도가 폭증한다.

### 주요 Preference 목록

- `ESTIMATE_PERCENT` : 샘플 비율 (기본 AUTO 권장)
- `METHOD_OPT` : 히스토그램 정책
- `CASCADE` : 인덱스 동시 수집
- `DEGREE` : 병렬 수집 정도
- `NO_INVALIDATE` : 커서 무효화 제어
- `PUBLISH` : Pending 여부
- `STALE_PERCENT` : stale 임계치
- `GRANULARITY` : GLOBAL/PARTITION/AUTO
- `INCREMENTAL` : 증분 통계
- `INCREMENTAL_STALENESS` : 시놉시스 신선도 정책
- (옵션) `AUTO_TASK_STATUS/INTERVAL/MAX_RUN_TIME` : 자동 통계 세부 정책

### 조회/설정

```sql
-- 조회
SELECT DBMS_STATS.GET_PREFS('METHOD_OPT') AS method_opt FROM dual;
SELECT DBMS_STATS.GET_PREFS('METHOD_OPT', ownname=>USER) FROM dual;
SELECT DBMS_STATS.GET_PREFS('METHOD_OPT', ownname=>USER, tabname=>'F_SALES') FROM dual;

-- 설정
BEGIN
  DBMS_STATS.SET_SCHEMA_PREFS(USER, 'STALE_PERCENT', '5');
  DBMS_STATS.SET_TABLE_PREFS(USER, 'D_PRODUCT',
    'METHOD_OPT', 'FOR COLUMNS SIZE 254 BRAND, FOR ALL COLUMNS SIZE 1');
END;
/

SELECT *
FROM   user_tab_stat_prefs
WHERE  table_name IN ('F_SALES','D_PRODUCT');
```

---

## 종합 시나리오 — “빠르고, 안전하고, 재현 가능하게”

### 야간 자동 + 주간 정밀

1) Global Prefs: AUTO 기반, NO_INVALIDATE=AUTO
2) Fact: INCREMENTAL=TRUE, PUBLISH=FALSE, NO_INVALIDATE=TRUE
3) AutoTask가 stale만 수집
4) 아침에 Pending 검증 세션으로 핵심 SQL 실측
5) 문제 없으면 Publish
6) 월 1회 스큐 컬럼 히스토그램 정밀 수집

### Fast Track 튜닝 순서

1) 느려진 SQL 실측 플랜에서 **E-Rows vs A-Rows 비교**
2) 어디서 오판했는지 확인(브랜드? 날짜? 컬럼 조합?)
3) 히스토그램/확장 통계/증분 통계 보정
4) Pending 수집 → 검증 → Publish
5) 필요 시 SQL Baseline/Profile로 마지막 안정화

---

## 문제 재현 → 진단 → 개선 (핵심 실습 모음)

### 샘플링/히스토그램에 따른 플랜 차이

```sql
-- 1) 히스토그램 제거(균등 가정)
BEGIN
  DBMS_STATS.GATHER_TABLE_STATS(USER,'D_PRODUCT',
    estimate_percent => 10, method_opt => 'FOR COLUMNS SIZE 1 BRAND', cascade=>TRUE);
END;
/
EXPLAIN PLAN FOR SELECT COUNT(*) FROM D_PRODUCT WHERE BRAND='B0';
EXPLAIN PLAN FOR SELECT COUNT(*) FROM D_PRODUCT WHERE BRAND='B47';
SELECT * FROM TABLE(DBMS_XPLAN.DISPLAY);

-- 2) 히스토그램 정밀
BEGIN
  DBMS_STATS.GATHER_TABLE_STATS(USER,'D_PRODUCT',
    estimate_percent => DBMS_STATS.AUTO_SAMPLE_SIZE,
    method_opt       => 'FOR COLUMNS SIZE 254 BRAND, FOR ALL COLUMNS SIZE 1',
    cascade          => TRUE);
END;
/
EXPLAIN PLAN FOR SELECT COUNT(*) FROM D_PRODUCT WHERE BRAND='B0';
EXPLAIN PLAN FOR SELECT COUNT(*) FROM D_PRODUCT WHERE BRAND='B47';
SELECT * FROM TABLE(DBMS_XPLAN.DISPLAY);
```

### 증분 통계와 Partition Exchange

```sql
CREATE TABLE F_SALES_STG AS SELECT * FROM F_SALES WHERE 1=0;
/* ... ETL 로드 ... */
ALTER TABLE F_SALES EXCHANGE PARTITION P202404 WITH TABLE F_SALES_STG WITHOUT VALIDATION;

BEGIN
  DBMS_STATS.GATHER_PARTITION_STATS(USER,'F_SALES','P202404', cascade=>TRUE);
END;
/
```

### 인덱스 통계의 영향(CF/LEAF/BLEVEL)

```sql
BEGIN
  DBMS_STATS.GATHER_INDEX_STATS(USER,'IX_FS_CUST_DT');
END;
/

SELECT index_name, blevel, leaf_blocks, clustering_factor
FROM   user_indexes
WHERE  index_name='IX_FS_CUST_DT';
```

### 커서 Invalidation 제어

```sql
BEGIN
  DBMS_STATS.SET_TABLE_PREFS(USER,'F_SALES','NO_INVALIDATE','TRUE');
  DBMS_STATS.SET_TABLE_PREFS(USER,'F_SALES','PUBLISH','FALSE');
  DBMS_STATS.GATHER_TABLE_STATS(USER,'F_SALES', options=>'GATHER STALE', cascade=>TRUE);
END;
/

ALTER SESSION SET optimizer_use_pending_statistics = TRUE;
/* 핵심 쿼리 검증 */

BEGIN
  DBMS_STATS.PUBLISH_PENDING_STATS(USER,'F_SALES');
END;
/
```

---

## 운영 체크리스트

### 데이터 샘플링

- [ ] 기본은 AUTO_SAMPLE_SIZE
- [ ] 대형 Fact는 AUTO로 시작 → 병목 시 저퍼센트 절충
- [ ] 스큐 컬럼은 히스토그램/확장 통계로 보정

### 파티션 통계

- [ ] INCREMENTAL=TRUE, GRANULARITY=AUTO
- [ ] Partition Exchange + 변경 파티션만 수집
- [ ] Pending → 검증 → Publish

### 인덱스 통계

- [ ] 테이블 수집 시 cascade=>TRUE
- [ ] Rebuild/Coalesce 후 재수집
- [ ] CF/LEAF/BLEVEL 정기 모니터링

### 커서 Invalidation

- [ ] NO_INVALIDATE=TRUE(대형 OLTP) + PUBLISH=FALSE(Pending)
- [ ] 검증 세션에서 플랜/E-Rows 확인 후 게시
- [ ] 변동이 큰 SQL은 Baseline/Profile 고려

### 자동 통계

- [ ] AutoTask 활성/윈도우 확인
- [ ] Global/Schema/Table Prefs로 정책 통일
- [ ] Stale 기준(예: 5~10%) 조정

---

## 부록 — 자주 쓰는 DBMS_STATS 템플릿

```sql
-- Global
BEGIN
  DBMS_STATS.SET_GLOBAL_PREFS('ESTIMATE_PERCENT','AUTO');
  DBMS_STATS.SET_GLOBAL_PREFS('METHOD_OPT','FOR ALL COLUMNS SIZE AUTO');
  DBMS_STATS.SET_GLOBAL_PREFS('CASCADE','TRUE');
  DBMS_STATS.SET_GLOBAL_PREFS('DEGREE','AUTO');
  DBMS_STATS.SET_GLOBAL_PREFS('NO_INVALIDATE','DBMS_STATS.AUTO_INVALIDATE');
  DBMS_STATS.SET_GLOBAL_PREFS('PUBLISH','TRUE');
END;
/

-- Schema
BEGIN
  DBMS_STATS.SET_SCHEMA_PREFS(USER,'STALE_PERCENT','5');
END;
/

-- Table(Fact)
BEGIN
  DBMS_STATS.SET_TABLE_PREFS(USER,'F_SALES','INCREMENTAL','TRUE');
  DBMS_STATS.SET_TABLE_PREFS(USER,'F_SALES','GRANULARITY','AUTO');
  DBMS_STATS.SET_TABLE_PREFS(USER,'F_SALES','PUBLISH','FALSE');
  DBMS_STATS.SET_TABLE_PREFS(USER,'F_SALES','NO_INVALIDATE','TRUE');
END;
/

-- 히스토그램(선별)
BEGIN
  DBMS_STATS.GATHER_TABLE_STATS(
    ownname    => USER,
    tabname    => 'D_PRODUCT',
    method_opt => 'FOR COLUMNS SIZE 254 BRAND, FOR ALL COLUMNS SIZE 1',
    cascade    => TRUE);
END;
/
```

---

## 결론

- **데이터 샘플링**은 AUTO가 기본이며, 샘플 확대는 마지막 수단이다.
  스큐/NDV 문제는 히스토그램과 확장 통계로 해결한다.
- **파티션 팩트 테이블**은 증분 통계 + Partition Exchange로 “빠르고 최소 I/O” 전략을 취한다.
- **인덱스 통계**는 cascade로 동행하고, CF/LEAF/BLEVEL 변화를 상시 감시한다.
- **커서 무효화**는 NO_INVALIDATE + Pending으로 완충하고 “검증 후 게시”가 운영 정석이다.
- 자동 통계는 Preferences 정책대로 움직이므로, Preferences를 “조직 표준 코드”로 고정하라.
- 최종 판단은 늘 실측 플랜과 E-Rows vs A-Rows로 팩트 체크한다.
