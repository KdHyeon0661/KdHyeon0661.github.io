---
layout: post
title: 파이썬 심화 - 유틸리티 스크립트와 시스템 관리 (3)
date: 2025-12-06 21:30:23 +0900
category: 파이썬 심화
---
# 유틸리티 스크립트와 시스템 관리 (3)

## 이름으로 파일 찾기: 고급 파일 시스템 탐색

파이썬에서 파일 시스템을 효율적으로 탐색하고 관리하는 것은 많은 애플리케이션에서 필수적인 기능입니다. `os`, `pathlib`, `fnmatch`, `glob` 모듈을 활용하면 다양한 파일 검색 패턴을 구현할 수 있습니다.

### 고급 파일 검색 시스템

```python
import os
import fnmatch
import glob
import re
from pathlib import Path
from typing import List, Dict, Any, Optional, Generator, Tuple
from datetime import datetime
import hashlib
import mimetypes
import shutil

class AdvancedFileFinder:
    """
    고급 파일 검색 및 관리 시스템
    
    다양한 검색 조건과 필터링을 지원하는 파일 탐색기
    """
    
    def __init__(self, search_path: str = "."):
        """
        파일 검색기 초기화
        
        Args:
            search_path: 검색 시작 경로 (기본값: 현재 디렉토리)
        """
        self.search_path = Path(search_path).resolve()
        if not self.search_path.exists():
            raise FileNotFoundError(f"경로를 찾을 수 없습니다: {search_path}")
        
        print(f"파일 검색기 초기화됨: {self.search_path}")
    
    def find_by_name(self, 
                    pattern: str, 
                    recursive: bool = True,
                    case_sensitive: bool = False) -> List[Path]:
        """
        파일명 패턴으로 파일 검색
        
        Args:
            pattern: 검색 패턴 (와일드카드 지원)
            recursive: 하위 디렉토리 재귀적 검색 여부
            case_sensitive: 대소문자 구분 여부
        
        Returns:
            찾은 파일 경로 목록
        """
        found_files = []
        
        if recursive:
            search_method = self.search_path.rglob
        else:
            search_method = self.search_path.glob
        
        # 패턴에 따라 적절한 검색 방법 선택
        if '*' in pattern or '?' in pattern or '[' in pattern:
            # 와일드카드 패턴
            for file_path in search_method(pattern):
                if file_path.is_file():
                    found_files.append(file_path)
        else:
            # 정확한 이름 매칭
            for file_path in search_method('*'):
                if file_path.is_file():
                    filename = file_path.name
                    if not case_sensitive:
                        filename = filename.lower()
                        pattern = pattern.lower()
                    
                    if pattern in filename:
                        found_files.append(file_path)
        
        return sorted(found_files)
    
    def find_by_extension(self, 
                         extensions: List[str],
                         recursive: bool = True) -> List[Path]:
        """
        파일 확장자로 검색
        
        Args:
            extensions: 확장자 목록 (예: ['.py', '.txt'])
            recursive: 하위 디렉토리 검색 여부
        
        Returns:
            찾은 파일 경로 목록
        """
        found_files = []
        
        # 확장자 정규화 (점으로 시작하도록)
        normalized_exts = []
        for ext in extensions:
            if not ext.startswith('.'):
                ext = '.' + ext
            normalized_exts.append(ext.lower())
        
        if recursive:
            search_method = self.search_path.rglob
        else:
            search_method = self.search_path.glob
        
        for file_path in search_method('*'):
            if file_path.is_file():
                file_ext = file_path.suffix.lower()
                if file_ext in normalized_exts:
                    found_files.append(file_path)
        
        return sorted(found_files)
    
    def find_by_regex(self, 
                     pattern: str,
                     recursive: bool = True,
                     search_in_content: bool = False) -> List[Dict[str, Any]]:
        """
        정규식 패턴으로 파일 검색
        
        Args:
            pattern: 정규식 패턴
            recursive: 하위 디렉토리 검색 여부
            search_in_content: 파일 내용에서도 검색할지 여부
        
        Returns:
            파일 정보 목록 (경로, 매칭 라인 등)
        """
        import re
        
        regex = re.compile(pattern, re.IGNORECASE)
        results = []
        
        if recursive:
            search_method = self.search_path.rglob
        else:
            search_method = self.search_path.glob
        
        for file_path in search_method('*'):
            if file_path.is_file():
                file_info = {
                    'path': file_path,
                    'filename': file_path.name,
                    'size': file_path.stat().st_size,
                    'matches': []
                }
                
                # 파일명에서 검색
                filename_matches = list(regex.finditer(file_path.name))
                if filename_matches:
                    for match in filename_matches:
                        file_info['matches'].append({
                            'type': 'filename',
                            'match': match.group(),
                            'position': match.span()
                        })
                
                # 파일 내용에서 검색 (옵션)
                if search_in_content:
                    try:
                        # 텍스트 파일만 내용 검색
                        if self._is_text_file(file_path):
                            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                                content = f.read()
                                content_matches = list(regex.finditer(content))
                                
                                for match in content_matches:
                                    # 매칭된 라인 찾기
                                    line_start = content.rfind('\n', 0, match.start()) + 1
                                    line_end = content.find('\n', match.end())
                                    if line_end == -1:
                                        line_end = len(content)
                                    
                                    line = content[line_start:line_end].strip()
                                    
                                    file_info['matches'].append({
                                        'type': 'content',
                                        'match': match.group(),
                                        'line': line,
                                        'position': match.span()
                                    })
                    except Exception as e:
                        print(f"파일 읽기 오류 {file_path}: {e}")
                        continue
                
                if file_info['matches']:
                    results.append(file_info)
        
        return results
    
    def find_by_size(self, 
                    min_size: Optional[int] = None,
                    max_size: Optional[int] = None,
                    recursive: bool = True) -> List[Dict[str, Any]]:
        """
        파일 크기로 검색
        
        Args:
            min_size: 최소 파일 크기 (바이트)
            max_size: 최대 파일 크기 (바이트)
            recursive: 하위 디렉토리 검색 여부
        
        Returns:
            파일 정보 목록
        """
        results = []
        
        if recursive:
            search_method = self.search_path.rglob
        else:
            search_method = self.search_path.glob
        
        for file_path in search_method('*'):
            if file_path.is_file():
                size = file_path.stat().st_size
                
                # 크기 필터링
                if min_size is not None and size < min_size:
                    continue
                if max_size is not None and size > max_size:
                    continue
                
                results.append({
                    'path': file_path,
                    'size': size,
                    'size_human': self._human_readable_size(size),
                    'modified': datetime.fromtimestamp(file_path.stat().st_mtime)
                })
        
        # 크기별 정렬
        return sorted(results, key=lambda x: x['size'], reverse=True)
    
    def find_by_date(self,
                    start_date: Optional[datetime] = None,
                    end_date: Optional[datetime] = None,
                    date_type: str = 'modified',
                    recursive: bool = True) -> List[Dict[str, Any]]:
        """
        날짜 범위로 파일 검색
        
        Args:
            start_date: 시작 날짜
            end_date: 종료 날짜
            date_type: 날짜 유형 ('modified', 'created', 'accessed')
            recursive: 하위 디렉토리 검색 여부
        
        Returns:
            파일 정보 목록
        """
        if date_type not in ['modified', 'created', 'accessed']:
            raise ValueError("date_type은 'modified', 'created', 'accessed' 중 하나여야 합니다.")
        
        results = []
        
        if recursive:
            search_method = self.search_path.rglob
        else:
            search_method = self.search_path.glob
        
        for file_path in search_method('*'):
            if file_path.is_file():
                stat = file_path.stat()
                
                # 날짜 정보 가져오기
                if date_type == 'modified':
                    file_date = datetime.fromtimestamp(stat.st_mtime)
                elif date_type == 'created':
                    file_date = datetime.fromtimestamp(stat.st_ctime)
                else:  # accessed
                    file_date = datetime.fromtimestamp(stat.st_atime)
                
                # 날짜 필터링
                if start_date and file_date < start_date:
                    continue
                if end_date and file_date > end_date:
                    continue
                
                results.append({
                    'path': file_path,
                    f'{date_type}_date': file_date,
                    'size': stat.st_size,
                    'size_human': self._human_readable_size(stat.st_size)
                })
        
        # 날짜별 정렬
        return sorted(results, key=lambda x: x[f'{date_type}_date'], reverse=True)
    
    def find_duplicates(self,
                       recursive: bool = True,
                       compare_by: str = 'hash') -> Dict[str, List[Path]]:
        """
        중복 파일 찾기
        
        Args:
            recursive: 하위 디렉토리 검색 여부
            compare_by: 비교 기준 ('hash', 'size_name', 'size')
        
        Returns:
            중복 파일 그룹
        """
        file_groups = {}
        
        if recursive:
            search_method = self.search_path.rglob
        else:
            search_method = self.search_path.glob
        
        for file_path in search_method('*'):
            if file_path.is_file():
                key = None
                
                if compare_by == 'hash':
                    # 파일 해시로 비교
                    key = self._calculate_file_hash(file_path)
                elif compare_by == 'size_name':
                    # 파일 크기와 이름으로 비교
                    stat = file_path.stat()
                    key = f"{stat.st_size}_{file_path.name}"
                elif compare_by == 'size':
                    # 파일 크기만으로 비교
                    key = str(file_path.stat().st_size)
                else:
                    raise ValueError("compare_by는 'hash', 'size_name', 'size' 중 하나여야 합니다.")
                
                if key not in file_groups:
                    file_groups[key] = []
                file_groups[key].append(file_path)
        
        # 중복이 있는 그룹만 필터링
        duplicates = {k: v for k, v in file_groups.items() if len(v) > 1}
        return duplicates
    
    def search_files(self,
                    name_pattern: Optional[str] = None,
                    extensions: Optional[List[str]] = None,
                    min_size: Optional[int] = None,
                    max_size: Optional[int] = None,
                    start_date: Optional[datetime] = None,
                    end_date: Optional[datetime] = None,
                    recursive: bool = True) -> List[Dict[str, Any]]:
        """
        다중 조건으로 파일 검색
        
        Args:
            name_pattern: 파일명 패턴
            extensions: 확장자 목록
            min_size: 최소 파일 크기
            max_size: 최대 파일 크기
            start_date: 시작 날짜
            end_date: 종료 날짜
            recursive: 하위 디렉토리 검색 여부
        
        Returns:
            파일 정보 목록
        """
        results = []
        
        if recursive:
            search_method = self.search_path.rglob
        else:
            search_method = self.search_path.glob
        
        for file_path in search_method('*'):
            if not file_path.is_file():
                continue
            
            # 파일 정보 수집
            stat = file_path.stat()
            file_info = {
                'path': file_path,
                'name': file_path.name,
                'size': stat.st_size,
                'modified': datetime.fromtimestamp(stat.st_mtime),
                'created': datetime.fromtimestamp(stat.st_ctime),
                'extension': file_path.suffix.lower()
            }
            
            # 조건별 필터링
            if name_pattern and not fnmatch.fnmatch(file_path.name, name_pattern):
                continue
            
            if extensions:
                normalized_exts = [ext.lower() if ext.startswith('.') else f'.{ext.lower()}' 
                                  for ext in extensions]
                if file_info['extension'] not in normalized_exts:
                    continue
            
            if min_size is not None and file_info['size'] < min_size:
                continue
            
            if max_size is not None and file_info['size'] > max_size:
                continue
            
            if start_date and file_info['modified'] < start_date:
                continue
            
            if end_date and file_info['modified'] > end_date:
                continue
            
            results.append(file_info)
        
        return results
    
    def _is_text_file(self, file_path: Path) -> bool:
        """텍스트 파일 여부 확인"""
        try:
            # MIME 타입 확인
            mime_type, _ = mimetypes.guess_type(str(file_path))
            if mime_type and mime_type.startswith('text/'):
                return True
            
            # 파일 내용 확인 (첫 1KB)
            with open(file_path, 'rb') as f:
                chunk = f.read(1024)
                # 널 바이트가 없으면 텍스트 파일로 간주
                return b'\x00' not in chunk
                
        except Exception:
            return False
    
    def _calculate_file_hash(self, file_path: Path, algorithm: str = 'md5') -> str:
        """파일 해시 계산"""
        hash_func = hashlib.new(algorithm)
        
        try:
            with open(file_path, 'rb') as f:
                # 대용량 파일을 위해 청크 단위로 읽기
                for chunk in iter(lambda: f.read(4096), b''):
                    hash_func.update(chunk)
            return hash_func.hexdigest()
        except Exception as e:
            print(f"파일 해시 계산 오류 {file_path}: {e}")
            return ''
    
    def _human_readable_size(self, size_bytes: int) -> str:
        """사람이 읽기 쉬운 파일 크기 형식으로 변환"""
        for unit in ['B', 'KB', 'MB', 'GB', 'TB']:
            if size_bytes < 1024.0:
                return f"{size_bytes:.2f} {unit}"
            size_bytes /= 1024.0
        return f"{size_bytes:.2f} PB"

# 데모: 고급 파일 검색 시스템
def demonstrate_file_finding():
    """
    파일 검색 시스템 데모
    """
    print("=" * 60)
    print("고급 파일 검색 시스템")
    print("=" * 60)
    
    # 테스트를 위한 임시 디렉토리 생성
    import tempfile
    test_dir = tempfile.mkdtemp(prefix="file_search_test_")
    print(f"\n테스트 디렉토리: {test_dir}")
    
    # 테스트 파일 생성
    test_files = [
        ("document.txt", b"이것은 테스트 문서입니다."),
        ("report.pdf", b"PDF 리포트 내용"),
        ("image.jpg", b"JPEG 이미지 데이터"),
        ("script.py", b"print('Hello World')"),
        ("config.json", b'{"name": "test", "value": 123}'),
        ("backup_2023.tar.gz", b"압축 파일 데이터"),
        ("important_document_final_v2.txt", b"중요 문서 내용"),
        ("photo (1).jpg", b"사진 데이터 1"),
        ("photo (2).jpg", b"사진 데이터 2"),
    ]
    
    # 서브디렉토리도 생성
    sub_dir = Path(test_dir) / "subdir"
    sub_dir.mkdir(exist_ok=True)
    
    for filename, content in test_files:
        filepath = Path(test_dir) / filename
        with open(filepath, 'wb') as f:
            f.write(content)
        
        # 일부 파일은 서브디렉토리에도 생성
        if filename.startswith("photo"):
            sub_filepath = sub_dir / filename
            with open(sub_filepath, 'wb') as f:
                f.write(content + b"_copy")
    
    print(f"테스트 파일 {len(test_files)}개 생성됨")
    
    # 파일 검색기 생성
    finder = AdvancedFileFinder(test_dir)
    
    print("\n1. 이름 패턴으로 파일 검색:")
    
    # 와일드카드 검색
    txt_files = finder.find_by_name("*.txt")
    print(f"  *.txt 파일: {len(txt_files)}개")
    for file in txt_files[:3]:  # 처음 3개만 출력
        print(f"    - {file.name}")
    
    # 부분 일치 검색
    doc_files = finder.find_by_name("document")
    print(f"\n  'document' 포함 파일: {len(doc_files)}개")
    for file in doc_files:
        print(f"    - {file.name}")
    
    print("\n2. 확장자로 파일 검색:")
    
    # 이미지 파일 검색
    image_exts = ['.jpg', '.jpeg', '.png']
    image_files = finder.find_by_extension(image_exts)
    print(f"  이미지 파일: {len(image_files)}개")
    for file in image_files:
        print(f"    - {file.name}")
    
    print("\n3. 파일 크기로 검색:")
    
    # 10바이트 이상 100바이트 이하 파일
    sized_files = finder.find_by_size(min_size=10, max_size=100)
    print(f"  10-100바이트 파일: {len(sized_files)}개")
    for file_info in sized_files[:3]:
        print(f"    - {file_info['path'].name}: {file_info['size_human']}")
    
    print("\n4. 정규식으로 검색:")
    
    # 숫자가 포함된 파일명 검색
    regex_results = finder.find_by_regex(r'\(\d+\)')
    print(f"  숫자 패턴 파일: {len(regex_results)}개")
    for result in regex_results:
        print(f"    - {result['filename']}")
    
    print("\n5. 중복 파일 찾기:")
    
    # 크기와 이름으로 중복 검색
    duplicates = finder.find_duplicates(compare_by='size_name')
    print(f"  중복 파일 그룹: {len(duplicates)}개")
    for key, files in list(duplicates.items())[:2]:  # 처음 2개 그룹만 출력
        print(f"    그룹 ({key}):")
        for file in files:
            print(f"      - {file}")
    
    print("\n6. 다중 조건 검색:")
    
    # 복합 조건 검색
    from datetime import datetime, timedelta
    
    yesterday = datetime.now() - timedelta(days=1)
    complex_results = finder.search_files(
        name_pattern="*.txt",
        extensions=['.txt', '.py'],
        min_size=5,
        start_date=yesterday
    )
    
    print(f"  복합 조건 파일: {len(complex_results)}개")
    for file_info in complex_results:
        print(f"    - {file_info['name']} ({file_info['size']}바이트, {file_info['modified']})")
    
    # 정리
    import shutil
    shutil.rmtree(test_dir)
    print(f"\n테스트 디렉토리 정리됨: {test_dir}")
    
    print("\n파일 검색 데모 완료")

if __name__ == "__main__":
    demonstrate_file_finding()
```

## 환경 설정 파일 읽기: 유연한 설정 관리 시스템

애플리케이션 설정 관리는 유지보수성과 확장성을 위해 중요한 요소입니다. 다양한 형식의 설정 파일을 지원하고 환경 변수와 통합하는 시스템을 구현합니다.

### 통합 설정 관리 시스템

```python
import os
import json
import yaml
import configparser
import tomllib
from typing import Dict, Any, Optional, Union, List
from pathlib import Path
from dataclasses import dataclass, field, asdict
from enum import Enum
import logging

class ConfigFormat(Enum):
    """지원하는 설정 파일 형식"""
    JSON = "json"
    YAML = "yaml"
    TOML = "toml"
    INI = "ini"
    ENV = "env"
    PYTHON = "py"

@dataclass
class ConfigValue:
    """설정 값 메타데이터"""
    value: Any
    source: str  # 파일, 환경변수, 기본값 등
    required: bool = False
    description: str = ""
    env_var: Optional[str] = None
    validation: Optional[callable] = None
    
    def validate(self) -> bool:
        """값 검증"""
        if self.required and self.value is None:
            return False
        if self.validation and not self.validation(self.value):
            return False
        return True

class ConfigurationManager:
    """
    통합 설정 관리 시스템
    
    다양한 형식의 설정 파일, 환경 변수, 기본값을 통합 관리
    """
    
    def __init__(self, 
                 config_name: str = "config",
                 search_paths: Optional[List[str]] = None,
                 env_prefix: str = "APP_"):
        """
        설정 관리자 초기화
        
        Args:
            config_name: 설정 파일 기본 이름
            search_paths: 설정 파일 검색 경로
            env_prefix: 환경 변수 접두사
        """
        self.config_name = config_name
        self.env_prefix = env_prefix
        self.config_data: Dict[str, Any] = {}
        self.config_values: Dict[str, ConfigValue] = {}
        self.loaded_files: List[str] = []
        
        # 기본 검색 경로 설정
        if search_paths is None:
            self.search_paths = [
                ".",  # 현재 디렉토리
                "~/.config",  # 사용자 설정 디렉토리
                "/etc",  # 시스템 설정 디렉토리
                Path(__file__).parent  # 모듈 디렉토리
            ]
        else:
            self.search_paths = search_paths
        
        # 로거 설정
        self.logger = logging.getLogger(__name__)
        
        print(f"설정 관리자 초기화: {config_name}")
    
    def find_config_file(self, 
                        formats: Optional[List[ConfigFormat]] = None) -> Optional[str]:
        """
        설정 파일 찾기
        
        Args:
            formats: 검색할 파일 형식 목록
        
        Returns:
            찾은 설정 파일 경로 또는 None
        """
        if formats is None:
            formats = [
                ConfigFormat.YAML,
                ConfigFormat.JSON,
                ConfigFormat.TOML,
                ConfigFormat.INI,
                ConfigFormat.PYTHON
            ]
        
        # 지원되는 확장자 매핑
        format_extensions = {
            ConfigFormat.JSON: ['.json', '.jsonc'],
            ConfigFormat.YAML: ['.yaml', '.yml'],
            ConfigFormat.TOML: ['.toml'],
            ConfigFormat.INI: ['.ini', '.cfg', '.conf'],
            ConfigFormat.PYTHON: ['.py']
        }
        
        for search_path in self.search_paths:
            path = Path(search_path).expanduser().resolve()
            
            if not path.exists():
                continue
            
            for fmt in formats:
                extensions = format_extensions.get(fmt, [])
                
                # 다양한 파일명 패턴 시도
                patterns = [
                    f"{self.config_name}{ext}" for ext in extensions
                ]
                patterns.append(f".{self.config_name}{extensions[0]}" if extensions else "")
                
                for pattern in patterns:
                    if pattern:
                        for config_file in path.glob(pattern):
                            if config_file.is_file():
                                found_path = str(config_file)
                                self.logger.info(f"설정 파일 발견: {found_path}")
                                return found_path
        
        self.logger.warning("설정 파일을 찾을 수 없습니다.")
        return None
    
    def load_config_file(self, 
                        filepath: str,
                        format: Optional[ConfigFormat] = None) -> Dict[str, Any]:
        """
        설정 파일 로드
        
        Args:
            filepath: 설정 파일 경로
            format: 파일 형식 (None이면 자동 감지)
        
        Returns:
            로드된 설정 데이터
        """
        path = Path(filepath)
        
        if not path.exists():
            raise FileNotFoundError(f"설정 파일을 찾을 수 없습니다: {filepath}")
        
        # 파일 형식 자동 감지
        if format is None:
            format = self._detect_format(filepath)
        
        try:
            if format == ConfigFormat.JSON:
                with open(filepath, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    
            elif format == ConfigFormat.YAML:
                # PyYAML이 설치되어 있어야 함
                try:
                    import yaml
                    with open(filepath, 'r', encoding='utf-8') as f:
                        data = yaml.safe_load(f) or {}
                except ImportError:
                    self.logger.error("PyYAML이 설치되어 있지 않습니다.")
                    data = {}
                    
            elif format == ConfigFormat.TOML:
                try:
                    import tomllib
                    with open(filepath, 'rb') as f:
                        data = tomllib.load(f)
                except ImportError:
                    self.logger.error("tomllib이 설치되어 있지 않습니다.")
                    data = {}
                    
            elif format == ConfigFormat.INI:
                parser = configparser.ConfigParser(
                    interpolation=configparser.ExtendedInterpolation()
                )
                parser.read(filepath, encoding='utf-8')
                data = {}
                for section in parser.sections():
                    data[section] = dict(parser[section])
                    
            elif format == ConfigFormat.PYTHON:
                # Python 파일을 모듈로 임포트
                import importlib.util
                spec = importlib.util.spec_from_file_location(
                    "config_module", 
                    filepath
                )
                module = importlib.util.module_from_spec(spec)
                spec.loader.exec_module(module)
                
                # 모듈에서 설정 값 수집
                data = {}
                for attr_name in dir(module):
                    if not attr_name.startswith('_'):
                        attr_value = getattr(module, attr_name)
                        if not callable(attr_value):
                            data[attr_name] = attr_value
                            
            else:
                raise ValueError(f"지원되지 않는 형식: {format}")
            
            self.loaded_files.append(filepath)
            self.logger.info(f"설정 파일 로드 완료: {filepath}")
            
            # 중첩 딕셔너리 병합
            self._merge_config(data, source=f"file:{filepath}")
            
            return data
            
        except Exception as e:
            self.logger.error(f"설정 파일 로드 실패 {filepath}: {e}")
            raise
    
    def load_environment_variables(self, 
                                  prefix: Optional[str] = None) -> Dict[str, Any]:
        """
        환경 변수에서 설정 로드
        
        Args:
            prefix: 환경 변수 접두사 (None이면 기본 접두사 사용)
        
        Returns:
            로드된 설정 데이터
        """
        if prefix is None:
            prefix = self.env_prefix
        
        env_data = {}
        prefix_len = len(prefix)
        
        for key, value in os.environ.items():
            if key.startswith(prefix):
                # 접두사 제거 및 키 변환 (APP_DB_HOST -> db.host)
                config_key = key[prefix_len:].lower()
                
                # 언더스코어를 점으로 변환하여 중첩 구조 생성
                parts = config_key.split('_')
                
                # 값 변환 시도 (숫자, 불리언, JSON 등)
                converted_value = self._convert_value(value)
                
                # 중첩 구조 생성
                current = env_data
                for i, part in enumerate(parts):
                    if i == len(parts) - 1:
                        current[part] = converted_value
                    else:
                        if part not in current:
                            current[part] = {}
                        current = current[part]
        
        if env_data:
            self._merge_config(env_data, source="environment")
            self.logger.info(f"환경 변수에서 {len(env_data)}개 설정 로드됨")
        
        return env_data
    
    def set_defaults(self, defaults: Dict[str, Any]):
        """
        기본값 설정
        
        Args:
            defaults: 기본 설정 값
        """
        self._merge_config(defaults, source="defaults")
        self.logger.info(f"기본값 {len(defaults)}개 설정됨")
    
    def get(self, 
           key: str, 
           default: Any = None,
           required: bool = False,
           description: str = "",
           env_var: Optional[str] = None,
           validation: Optional[callable] = None) -> Any:
        """
        설정 값 가져오기
        
        Args:
            key: 설정 키 (점 표기법: 'database.host')
            default: 기본값
            required: 필수 값 여부
            description: 값 설명
            env_var: 환경 변수 이름
            validation: 값 검증 함수
        
        Returns:
            설정 값
        """
        # 환경 변수 체크 (우선순위)
        if env_var and env_var in os.environ:
            value = os.environ[env_var]
            config_value = ConfigValue(
                value=self._convert_value(value),
                source="environment",
                required=required,
                description=description,
                env_var=env_var,
                validation=validation
            )
            
            if config_value.validate():
                self.config_values[key] = config_value
                return config_value.value
        
        # 메모리 캐시 체크
        if key in self.config_values:
            config_value = self.config_values[key]
            if config_value.validate():
                return config_value.value
        
        # 중첩 키 파싱
        keys = key.split('.')
        current = self.config_data
        
        # 중첩 구조 탐색
        for k in keys:
            if isinstance(current, dict) and k in current:
                current = current[k]
            else:
                # 값을 찾을 수 없음
                config_value = ConfigValue(
                    value=default,
                    source="default",
                    required=required,
                    description=description,
                    env_var=env_var,
                    validation=validation
                )
                
                if required and default is None:
                    raise ValueError(f"필수 설정 값이 없습니다: {key}")
                
                if config_value.validate():
                    self.config_values[key] = config_value
                    return default
                else:
                    raise ValueError(f"설정 값 검증 실패: {key}")
        
        config_value = ConfigValue(
            value=current,
            source="loaded",
            required=required,
            description=description,
            env_var=env_var,
            validation=validation
        )
        
        if config_value.validate():
            self.config_values[key] = config_value
            return current
        else:
            raise ValueError(f"설정 값 검증 실패: {key}")
    
    def save(self, 
            filepath: str, 
            format: ConfigFormat = ConfigFormat.YAML,
            include_metadata: bool = False):
        """
        설정 파일 저장
        
        Args:
            filepath: 저장할 파일 경로
            format: 파일 형식
            include_metadata: 메타데이터 포함 여부
        """
        data = self.config_data.copy()
        
        if include_metadata:
            # 메타데이터 추가
            data['_metadata'] = {
                'generated': datetime.now().isoformat(),
                'sources': self.loaded_files,
                'values': {k: asdict(v) for k, v in self.config_values.items()}
            }
        
        try:
            path = Path(filepath)
            path.parent.mkdir(parents=True, exist_ok=True)
            
            if format == ConfigFormat.JSON:
                with open(filepath, 'w', encoding='utf-8') as f:
                    json.dump(data, f, indent=2, ensure_ascii=False)
                    
            elif format == ConfigFormat.YAML:
                import yaml
                with open(filepath, 'w', encoding='utf-8') as f:
                    yaml.dump(data, f, default_flow_style=False, allow_unicode=True)
                    
            elif format == ConfigFormat.TOML:
                import tomli_w
                with open(filepath, 'wb') as f:
                    tomli_w.dump(data, f)
                    
            elif format == ConfigFormat.INI:
                # INI 형식은 평평한 구조만 지원
                parser = configparser.ConfigParser()
                
                for key, value in data.items():
                    if isinstance(value, dict):
                        parser[key] = value
                    else:
                        if 'DEFAULT' not in parser:
                            parser['DEFAULT'] = {}
                        parser['DEFAULT'][key] = str(value)
                
                with open(filepath, 'w', encoding='utf-8') as f:
                    parser.write(f)
            
            self.logger.info(f"설정 파일 저장 완료: {filepath}")
            
        except Exception as e:
            self.logger.error(f"설정 파일 저장 실패: {e}")
            raise
    
    def reload(self):
        """설정 재로드"""
        old_data = self.config_data.copy()
        self.config_data.clear()
        self.config_values.clear()
        
        # 파일 재로드
        for filepath in self.loaded_files:
            try:
                self.load_config_file(filepath)
            except Exception as e:
                self.logger.error(f"설정 파일 재로드 실패 {filepath}: {e}")
        
        # 환경 변수 재로드
        self.load_environment_variables()
        
        # 변경 사항 로깅
        changed = self._find_changes(old_data, self.config_data)
        if changed:
            self.logger.info(f"설정 변경됨: {', '.join(changed)}")
    
    def _detect_format(self, filepath: str) -> ConfigFormat:
        """파일 형식 자동 감지"""
        path = Path(filepath)
        suffix = path.suffix.lower()
        
        if suffix in ['.json', '.jsonc']:
            return ConfigFormat.JSON
        elif suffix in ['.yaml', '.yml']:
            return ConfigFormat.YAML
        elif suffix == '.toml':
            return ConfigFormat.TOML
        elif suffix in ['.ini', '.cfg', '.conf']:
            return ConfigFormat.INI
        elif suffix == '.py':
            return ConfigFormat.PYTHON
        else:
            # 내용 기반으로 추측
            with open(filepath, 'r', encoding='utf-8') as f:
                first_line = f.readline().strip()
                
                if first_line.startswith('{') or first_line.startswith('['):
                    return ConfigFormat.JSON
                elif '=' in first_line and not first_line.startswith('#'):
                    return ConfigFormat.INI
                elif first_line.startswith('---'):
                    return ConfigFormat.YAML
                else:
                    # 기본값으로 YAML 사용
                    return ConfigFormat.YAML
    
    def _convert_value(self, value: str) -> Any:
        """문자열 값을 적절한 타입으로 변환"""
        if value.lower() == 'true':
            return True
        elif value.lower() == 'false':
            return False
        elif value.lower() == 'null' or value.lower() == 'none':
            return None
        
        # 숫자 변환 시도
        try:
            if '.' in value:
                return float(value)
            else:
                return int(value)
        except ValueError:
            pass
        
        # JSON 배열/객체 변환 시도
        if (value.startswith('[') and value.endswith(']')) or \
           (value.startswith('{') and value.endswith('}')):
            try:
                return json.loads(value)
            except json.JSONDecodeError:
                pass
        
        # 문자열로 반환
        return value
    
    def _merge_config(self, new_data: Dict[str, Any], source: str = "unknown"):
        """
        설정 데이터 재귀적으로 병합
        
        Args:
            new_data: 새 설정 데이터
            source: 데이터 소스
        """
        def merge_dicts(base: Dict, update: Dict, path: str = "") -> Dict:
            for key, value in update.items():
                full_path = f"{path}.{key}" if path else key
                
                # ConfigValue 생성
                if key not in self.config_values or not full_path.startswith('_'):
                    config_value = ConfigValue(
                        value=value,
                        source=source,
                        required=False,
                        description=f"From {source}"
                    )
                    self.config_values[full_path] = config_value
                
                if isinstance(value, dict) and key in base and isinstance(base[key], dict):
                    # 재귀적으로 병합
                    base[key] = merge_dicts(base[key], value, full_path)
                else:
                    # 값 설정
                    base[key] = value
            
            return base
        
        self.config_data = merge_dicts(self.config_data, new_data)
    
    def _find_changes(self, old: Dict, new: Dict, path: str = "") -> List[str]:
        """설정 변경 사항 찾기"""
        changes = []
        
        all_keys = set(old.keys()) | set(new.keys())
        
        for key in all_keys:
            current_path = f"{path}.{key}" if path else key
            
            if key in old and key in new:
                if isinstance(old[key], dict) and isinstance(new[key], dict):
                    # 재귀적으로 비교
                    changes.extend(self._find_changes(old[key], new[key], current_path))
                elif old[key] != new[key]:
                    changes.append(current_path)
            elif key in old and key not in new:
                changes.append(f"{current_path} (제거됨)")
            elif key not in old and key in new:
                changes.append(f"{current_path} (추가됨)")
        
        return changes

# 설정 스키마 관리
class ConfigSchema:
    """설정 스키마 정의 및 검증"""
    
    def __init__(self):
        self.schema: Dict[str, Dict] = {}
    
    def define(self, 
              key: str, 
              type: type, 
              default: Any = None,
              required: bool = False,
              description: str = "",
              env_var: Optional[str] = None,
              validator: Optional[callable] = None,
              choices: Optional[List] = None):
        """
        설정 항목 정의
        
        Args:
            key: 설정 키
            type: 값 타입
            default: 기본값
            required: 필수 여부
            description: 설명
            env_var: 환경 변수 이름
            validator: 검증 함수
            choices: 허용 값 목록
        """
        self.schema[key] = {
            'type': type,
            'default': default,
            'required': required,
            'description': description,
            'env_var': env_var,
            'validator': validator,
            'choices': choices
        }
    
    def validate_config(self, config: Dict[str, Any]) -> Dict[str, List[str]]:
        """
        설정 검증
        
        Args:
            config: 검증할 설정
        
        Returns:
            오류 메시지 딕셔너리
        """
        errors = {}
        
        for key, rules in self.schema.items():
            value = config.get(key)
            
            # 필수 항목 검사
            if rules['required'] and value is None:
                if key not in errors:
                    errors[key] = []
                errors[key].append("필수 항목이 누락되었습니다.")
                continue
            
            # 타입 검사
            if value is not None and not isinstance(value, rules['type']):
                if key not in errors:
                    errors[key] = []
                errors[key].append(f"타입 오류: {type(value)} -> {rules['type']} 기대됨")
            
            # 선택지 검사
            if rules['choices'] and value not in rules['choices']:
                if key not in errors:
                    errors[key] = []
                errors[key].append(f"허용되지 않은 값: {value}. 허용: {rules['choices']}")
            
            # 커스텀 검증
            if rules['validator'] and not rules['validator'](value):
                if key not in errors:
                    errors[key] = []
                errors[key].append("커스텀 검증 실패")
        
        return errors

# 데모: 설정 관리 시스템
def demonstrate_config_management():
    """
    설정 관리 시스템 데모
    """
    print("=" * 60)
    print("통합 설정 관리 시스템")
    print("=" * 60)
    
    import tempfile
    import os
    
    # 테스트 디렉토리 생성
    test_dir = tempfile.mkdtemp(prefix="config_test_")
    print(f"테스트 디렉토리: {test_dir}")
    
    # 다양한 형식의 설정 파일 생성
    config_files = []
    
    # YAML 설정 파일
    yaml_config = """
# 데이터베이스 설정
database:
  host: localhost
  port: 5432
  name: myapp
  user: ${DB_USER:-admin}
  password: ${DB_PASSWORD:-secret}
  
# 서버 설정
server:
  host: 0.0.0.0
  port: 8080
  debug: false
  workers: 4
  
# 로깅 설정
logging:
  level: INFO
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  file: /var/log/myapp.log
"""
    
    yaml_file = Path(test_dir) / "config.yaml"
    with open(yaml_file, 'w', encoding='utf-8') as f:
        f.write(yaml_config)
    config_files.append(yaml_file)
    
    # JSON 설정 파일
    json_config = {
        "features": {
            "cache_enabled": True,
            "cache_ttl": 300,
            "rate_limit": 100
        },
        "api": {
            "timeout": 30,
            "retries": 3
        }
    }
    
    json_file = Path(test_dir) / "config.json"
    with open(json_file, 'w', encoding='utf-8') as f:
        json.dump(json_config, f, indent=2)
    config_files.append(json_file)
    
    print(f"\n1. 다양한 형식의 설정 파일 생성:")
    for cf in config_files:
        print(f"  - {cf.name}")
    
    print("\n2. 설정 관리자 초기화:")
    
    # 환경 변수 설정 (테스트용)
    os.environ['APP_DB_USER'] = 'testuser'
    os.environ['APP_SERVER_PORT'] = '9000'
    os.environ['APP_FEATURES_CACHE_TTL'] = '600'
    
    # 설정 관리자 생성
    config_manager = ConfigurationManager(
        config_name="config",
        search_paths=[test_dir],
        env_prefix="APP_"
    )
    
    print("\n3. 설정 파일 자동 검색 및 로드:")
    
    # 설정 파일 찾기
    found_file = config_manager.find_config_file()
    if found_file:
        print(f"  발견된 파일: {found_file}")
        
        # 설정 파일 로드
        config_manager.load_config_file(found_file)
    else:
        print("  설정 파일을 찾을 수 없습니다.")
    
    print("\n4. 환경 변수에서 설정 로드:")
    
    # 환경 변수 로드
    env_config = config_manager.load_environment_variables()
    if env_config:
        print(f"  환경 변수에서 {len(env_config)}개 설정 로드됨")
    
    print("\n5. 기본값 설정:")
    
    # 기본값 설정
    defaults = {
        "app": {
            "name": "MyApp",
            "version": "1.0.0"
        },
        "security": {
            "secret_key": "default-secret-key",
            "token_expiry": 3600
        }
    }
    
    config_manager.set_defaults(defaults)
    
    print("\n6. 설정 값 조회:")
    
    # 다양한 방식으로 설정 값 조회
    values_to_get = [
        "database.host",
        "server.port",
        "features.cache_ttl",
        "app.name",
        "security.secret_key"
    ]
    
    for key in values_to_get:
        try:
            value = config_manager.get(key)
            print(f"  {key}: {value}")
        except Exception as e:
            print(f"  {key}: 오류 - {e}")
    
    print("\n7. 필수 값 검증:")
    
    # 필수 값 검증 예시
    try:
        required_value = config_manager.get(
            "database.password",
            required=True,
            description="데이터베이스 비밀번호",
            env_var="DB_PASSWORD",
            validation=lambda x: len(x) >= 8 if x else False
        )
        print(f"  database.password: {required_value}")
    except Exception as e:
        print(f"  database.password: 검증 실패 - {e}")
    
    print("\n8. 설정 스키마 검증:")
    
    # 스키마 정의 및 검증
    schema = ConfigSchema()
    
    schema.define(
        key="server.port",
        type=int,
        default=8080,
        required=True,
        description="서버 포트",
        validator=lambda x: 1024 <= x <= 65535,
        choices=None
    )
    
    schema.define(
        key="logging.level",
        type=str,
        default="INFO",
        required=False,
        description="로그 레벨",
        validator=lambda x: x in ["DEBUG", "INFO", "WARNING", "ERROR", "CRITICAL"],
        choices=["DEBUG", "INFO", "WARNING", "ERROR", "CRITICAL"]
    )
    
    # 검증 실행
    errors = schema.validate_config(config_manager.config_data)
    if errors:
        print("  검증 오류:")
        for key, msgs in errors.items():
            print(f"    {key}:")
            for msg in msgs:
                print(f"      - {msg}")
    else:
        print("  모든 설정이 유효합니다.")
    
    print("\n9. 설정 파일 저장:")
    
    # 설정 파일 저장
    output_file = Path(test_dir) / "merged_config.yaml"
    config_manager.save(str(output_file), include_metadata=True)
    print(f"  통합 설정 파일 저장됨: {output_file}")
    
    # 저장된 파일 내용 확인
    with open(output_file, 'r', encoding='utf-8') as f:
        lines = f.readlines()[:10]
        print("  파일 내용 미리보기:")
        for line in lines:
            print(f"    {line.rstrip()}")
    
    print("\n10. 설정 재로드 시뮬레이션:")
    
    # 설정 재로드
    config_manager.reload()
    print("  설정 재로드 완료")
    
    # 정리
    import shutil
    shutil.rmtree(test_dir)
    
    # 환경 변수 정리
    os.environ.pop('APP_DB_USER', None)
    os.environ.pop('APP_SERVER_PORT', None)
    os.environ.pop('APP_FEATURES_CACHE_TTL', None)
    
    print(f"\n테스트 디렉토리 정리됨: {test_dir}")
    print("\n설정 관리 데모 완료")

if __name__ == "__main__":
    demonstrate_config_management()
```

## 간단한 스크립트에 로그 추가

로깅은 스크립트의 디버깅과 모니터링에 필수적입니다. 적절한 로깅 시스템을 구축하면 문제 진단과 성능 모니터링이 훨씬 쉬워집니다.

### 스크립트용 로깅 시스템

```python
import logging
import logging.handlers
import sys
import os
from typing import Optional, Dict, Any
from datetime import datetime
import json
from pathlib import Path

class ScriptLogger:
    """
    스크립트용 로깅 시스템
    
    콘솔, 파일, JSON 로깅을 지원하는 통합 로깅 시스템
    """
    
    def __init__(self, 
                 name: str = "script",
                 log_level: str = "INFO",
                 log_dir: str = "./logs",
                 enable_file_logging: bool = True,
                 enable_json_logging: bool = False,
                 max_file_size: int = 10 * 1024 * 1024,  # 10MB
                 backup_count: int = 5):
        """
        스크립트 로거 초기화
        
        Args:
            name: 로거 이름
            log_level: 로그 레벨 (DEBUG, INFO, WARNING, ERROR, CRITICAL)
            log_dir: 로그 디렉토리
            enable_file_logging: 파일 로깅 활성화 여부
            enable_json_logging: JSON 로깅 활성화 여부
            max_file_size: 최대 로그 파일 크기 (바이트)
            backup_count: 보관할 백업 파일 수
        """
        self.name = name
        self.log_dir = Path(log_dir)
        self.enable_file_logging = enable_file_logging
        self.enable_json_logging = enable_json_logging
        
        # 로그 디렉토리 생성
        self.log_dir.mkdir(parents=True, exist_ok=True)
        
        # 로거 생성
        self.logger = logging.getLogger(name)
        self.logger.setLevel(self._get_log_level(log_level))
        
        # 기존 핸들러 제거 (중복 방지)
        self.logger.handlers.clear()
        
        # 로그 포맷 설정
        formatter = logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            datefmt='%Y-%m-%d %H:%M:%S'
        )
        
        # 콘솔 핸들러 (항상 활성화)
        console_handler = logging.StreamHandler(sys.stdout)
        console_handler.setLevel(self._get_log_level(log_level))
        console_handler.setFormatter(formatter)
        self.logger.addHandler(console_handler)
        
        # 파일 핸들러 (옵션)
        if enable_file_logging:
            self._setup_file_handlers(formatter, max_file_size, backup_count)
        
        # JSON 핸들러 (옵션)
        if enable_json_logging:
            self._setup_json_handler()
        
        # 시작 로그
        self.logger.info(f"로깅 시스템 초기화됨: {name}")
        self.logger.info(f"로그 레벨: {log_level}")
        self.logger.info(f"로그 디렉토리: {log_dir}")
    
    def _get_log_level(self, level_str: str) -> int:
        """문자열 로그 레벨을 숫자로 변환"""
        levels = {
            'DEBUG': logging.DEBUG,
            'INFO': logging.INFO,
            'WARNING': logging.WARNING,
            'ERROR': logging.ERROR,
            'CRITICAL': logging.CRITICAL
        }
        return levels.get(level_str.upper(), logging.INFO)
    
    def _setup_file_handlers(self, 
                            formatter: logging.Formatter,
                            max_file_size: int,
                            backup_count: int):
        """파일 로깅 핸들러 설정"""
        
        # 일반 로그 파일
        log_file = self.log_dir / f"{self.name}.log"
        file_handler = logging.handlers.RotatingFileHandler(
            log_file,
            maxBytes=max_file_size,
            backupCount=backup_count,
            encoding='utf-8'
        )
        file_handler.setLevel(logging.INFO)
        file_handler.setFormatter(formatter)
        self.logger.addHandler(file_handler)
        
        # 에러 로그 파일 (별도 관리)
        error_log_file = self.log_dir / f"{self.name}_error.log"
        error_handler = logging.handlers.RotatingFileHandler(
            error_log_file,
            maxBytes=max_file_size,
            backupCount=backup_count,
            encoding='utf-8'
        )
        error_handler.setLevel(logging.ERROR)
        error_handler.setFormatter(formatter)
        self.logger.addHandler(error_handler)
    
    def _setup_json_handler(self):
        """JSON 로깅 핸들러 설정"""
        json_log_file = self.log_dir / f"{self.name}.json.log"
        
        class JsonFormatter(logging.Formatter):
            """JSON 형식으로 로그 포맷팅"""
            
            def format(self, record: logging.LogRecord) -> str:
                log_data = {
                    'timestamp': datetime.fromtimestamp(record.created).isoformat(),
                    'logger': record.name,
                    'level': record.levelname,
                    'message': record.getMessage(),
                    'module': record.module,
                    'function': record.funcName,
                    'line': record.lineno,
                    'process': record.process,
                    'thread': record.threadName
                }
                
                # 예외 정보 추가
                if record.exc_info:
                    log_data['exception'] = self.formatException(record.exc_info)
                
                return json.dumps(log_data, ensure_ascii=False)
        
        json_handler = logging.handlers.RotatingFileHandler(
            json_log_file,
            maxBytes=10 * 1024 * 1024,  # 10MB
            backupCount=3,
            encoding='utf-8'
        )
        json_handler.setLevel(logging.INFO)
        json_handler.setFormatter(JsonFormatter())
        self.logger.addHandler(json_handler)
    
    def log_with_context(self, 
                        level: str, 
                        message: str, 
                        context: Optional[Dict[str, Any]] = None,
                        exception: Optional[Exception] = None):
        """
        컨텍스트 정보와 함께 로깅
        
        Args:
            level: 로그 레벨
            message: 로그 메시지
            context: 추가 컨텍스트 정보
            exception: 예외 객체
        """
        log_method = getattr(self.logger, level.lower(), self.logger.info)
        
        if context:
            # 컨텍스트 정보를 메시지에 추가
            context_str = ' '.join(f'{k}={v}' for k, v in context.items())
            full_message = f"{message} [{context_str}]"
        else:
            full_message = message
        
        if exception:
            log_method(full_message, exc_info=exception)
        else:
            log_method(full_message)
    
    def log_performance(self, 
                       operation: str, 
                       start_time: datetime,
                       end_time: Optional[datetime] = None,
                       additional_info: Optional[Dict[str, Any]] = None):
        """
        성능 로깅
        
        Args:
            operation: 작업 이름
            start_time: 시작 시간
            end_time: 종료 시간 (None이면 현재 시간 사용)
            additional_info: 추가 정보
        """
        if end_time is None:
            end_time = datetime.now()
        
        duration = (end_time - start_time).total_seconds()
        
        log_data = {
            'operation': operation,
            'start_time': start_time.isoformat(),
            'end_time': end_time.isoformat(),
            'duration_seconds': duration,
            'duration_ms': duration * 1000
        }
        
        if additional_info:
            log_data.update(additional_info)
        
        self.logger.info(f"성능 측정: {operation} - {duration:.3f}초", extra=log_data)
    
    def log_memory_usage(self, label: str = "현재 메모리 사용량"):
        """메모리 사용량 로깅"""
        try:
            import psutil
            import os
            
            process = psutil.Process(os.getpid())
            memory_info = process.memory_info()
            
            memory_mb = memory_info.rss / 1024 / 1024
            memory_percent = process.memory_percent()
            
            self.logger.info(
                f"{label}: {memory_mb:.1f}MB ({memory_percent:.1f}%)",
                extra={
                    'memory_mb': memory_mb,
                    'memory_percent': memory_percent,
                    'label': label
                }
            )
            
        except ImportError:
            self.logger.warning("메모리 사용량 로깅에 psutil이 필요합니다")
    
    def get_log_file_paths(self) -> Dict[str, Path]:
        """로그 파일 경로 정보 반환"""
        paths = {
            'directory': self.log_dir,
            'main_log': self.log_dir / f"{self.name}.log",
            'error_log': self.log_dir / f"{self.name}_error.log",
        }
        
        if self.enable_json_logging:
            paths['json_log'] = self.log_dir / f"{self.name}.json.log"
        
        return paths
    
    def cleanup_old_logs(self, days_to_keep: int = 30):
        """
        오래된 로그 파일 정리
        
        Args:
            days_to_keep: 보관할 일수
        """
        import time
        from datetime import datetime, timedelta
        
        cutoff_time = time.time() - (days_to_keep * 24 * 60 * 60)
        
        for log_file in self.log_dir.glob(f"{self.name}*.log*"):
            if log_file.is_file():
                file_time = log_file.stat().st_mtime
                if file_time < cutoff_time:
                    try:
                        log_file.unlink()
                        self.logger.info(f"오래된 로그 파일 삭제: {log_file.name}")
                    except Exception as e:
                        self.logger.error(f"로그 파일 삭제 실패 {log_file}: {e}")

# 데코레이터를 활용한 함수 로깅
def log_function_call(logger: Optional[ScriptLogger] = None):
    """
    함수 호출 로깅 데코레이터
    
    Args:
        logger: 사용할 로거 (None이면 기본 로거 생성)
    """
    def decorator(func):
        def wrapper(*args, **kwargs):
            # 로거 설정
            if logger is None:
                func_logger = ScriptLogger(name=func.__module__)
            else:
                func_logger = logger
            
            start_time = datetime.now()
            
            # 함수 정보 로깅
            func_logger.logger.info(
                f"함수 실행 시작: {func.__name__}",
                extra={
                    'function': func.__name__,
                    'module': func.__module__,
                    'args': str(args),
                    'kwargs': str(kwargs)
                }
            )
            
            try:
                result = func(*args, **kwargs)
                
                # 성공 로깅
                end_time = datetime.now()
                duration = (end_time - start_time).total_seconds()
                
                func_logger.logger.info(
                    f"함수 실행 성공: {func.__name__} - {duration:.3f}초",
                    extra={
                        'function': func.__name__,
                        'duration': duration,
                        'result_type': type(result).__name__
                    }
                )
                
                return result
                
            except Exception as e:
                # 실패 로깅
                end_time = datetime.now()
                duration = (end_time - start_time).total_seconds()
                
                func_logger.logger.error(
                    f"함수 실행 실패: {func.__name__} - {duration:.3f}초",
                    exc_info=e,
                    extra={
                        'function': func.__name__,
                        'duration': duration,
                        'exception': str(e)
                    }
                )
                raise
        
        return wrapper
    return decorator

# 예시 스크립트
def example_script_with_logging():
    """
    로깅이 포함된 예시 스크립트
    """
    print("=" * 60)
    print("로깅이 포함된 스크립트 예시")
    print("=" * 60)
    
    # 로거 초기화
    logger = ScriptLogger(
        name="example_script",
        log_level="DEBUG",
        log_dir="./example_logs",
        enable_file_logging=True,
        enable_json_logging=True
    )
    
    logger.logger.info("스크립트 시작")
    
    # 메모리 사용량 로깅
    logger.log_memory_usage("초기 메모리 사용량")
    
    # 다양한 레벨의 로그
    logger.logger.debug("디버그 메시지 - 상세 정보")
    logger.logger.info("정보 메시지 - 일반 작업 진행")
    logger.logger.warning("경고 메시지 - 주의 필요")
    
    # 컨텍스트와 함께 로깅
    context = {
        'user_id': 12345,
        'action': 'file_upload',
        'file_size': 1024 * 1024  # 1MB
    }
    
    logger.log_with_context(
        level="INFO",
        message="파일 업로드 시도",
        context=context
    )
    
    # 성능 측정 로깅
    import time
    
    start_time = datetime.now()
    
    # 작업 시뮬레이션
    logger.logger.info("작업 시작...")
    time.sleep(0.5)  # 작업 시간 시뮬레이션
    
    end_time = datetime.now()
    
    logger.log_performance(
        operation="데이터 처리",
        start_time=start_time,
        end_time=end_time,
        additional_info={'records_processed': 1000}
    )
    
    # 데코레이터 사용 예시
    @log_function_call(logger)
    def process_data(data):
        """데이터 처리 함수"""
        logger.logger.info(f"데이터 처리 중: {len(data)}개 항목")
        time.sleep(0.2)  # 처리 시간 시뮬레이션
        return [x * 2 for x in data]
    
    # 함수 호출
    try:
        result = process_data([1, 2, 3, 4, 5])
        logger.logger.info(f"처리 결과: {result}")
    except Exception as e:
        logger.logger.error("데이터 처리 중 오류 발생", exc_info=e)
    
    # 예외 상황 로깅
    try:
        # 의도적으로 예외 발생
        result = 10 / 0
    except ZeroDivisionError as e:
        logger.log_with_context(
            level="ERROR",
            message="계산 중 오류 발생",
            context={'operation': 'division'},
            exception=e
        )
    
    # 최종 메모리 사용량
    logger.log_memory_usage("최종 메모리 사용량")
    
    # 로그 파일 정보 출력
    log_paths = logger.get_log_file_paths()
    print(f"\n생성된 로그 파일:")
    for key, path in log_paths.items():
        if path.exists():
            size_kb = path.stat().st_size / 1024
            print(f"  {key}: {path} ({size_kb:.1f}KB)")
    
    logger.logger.info("스크립트 종료")
    
    print("\n로깅 데모 완료")
    print("로그 파일들을 확인해보세요.")

if __name__ == "__main__":
    example_script_with_logging()
```

## 라이브러리에 로그 추가

라이브러리에 적절한 로깅을 추가하면 사용자가 문제를 진단하고 라이브러리의 동작을 이해하는 데 도움이 됩니다.

### 라이브러리용 로깅 시스템

```python
import logging
import sys
from typing import Optional, Dict, Any
from enum import Enum
import inspect

class LogLevel(Enum):
    """로그 레벨 열거형"""
    DEBUG = "DEBUG"
    INFO = "INFO"
    WARNING = "WARNING"
    ERROR = "ERROR"
    CRITICAL = "CRITICAL"

class LibraryLogger:
    """
    라이브러리용 로깅 시스템
    
    라이브러리 사용자가 쉽게 구성하고 제어할 수 있는 로깅 시스템
    """
    
    # 클래스 변수로 전역 로거 저장
    _loggers: Dict[str, logging.Logger] = {}
    _default_log_level = LogLevel.WARNING
    _configured = False
    
    @classmethod
    def get_logger(cls, 
                   name: Optional[str] = None,
                   level: Optional[LogLevel] = None) -> logging.Logger:
        """
        로거 인스턴스 가져오기
        
        Args:
            name: 로거 이름 (None이면 호출 모듈 이름 사용)
            level: 로그 레벨 (None이면 기본값 사용)
        
        Returns:
            구성된 로거 인스턴스
        """
        # 로거 이름 결정
        if name is None:
            # 호출한 모듈의 이름 사용
            frame = inspect.currentframe()
            caller_frame = frame.f_back if frame else None
            if caller_frame:
                module = inspect.getmodule(caller_frame)
                name = module.__name__ if module else __name__
            else:
                name = __name__
        
        # 기존 로거 확인
        if name in cls._loggers:
            return cls._loggers[name]
        
        # 새 로거 생성
        logger = logging.getLogger(name)
        
        # 로그 레벨 설정
        log_level = level.value if level else cls._default_log_level.value
        logger.setLevel(getattr(logging, log_level))
        
        # 기본 구성이 되어있지 않으면 구성
        if not cls._configured:
            cls._configure_default()
        
        # 로거 저장
        cls._loggers[name] = logger
        
        return logger
    
    @classmethod
    def _configure_default(cls):
        """기본 로깅 구성"""
        if cls._configured:
            return
        
        # 기본 포맷터
        formatter = logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            datefmt='%Y-%m-%d %H:%M:%S'
        )
        
        # 기본 핸들러 (NullHandler)
        # 라이브러리는 기본적으로 로그를 출력하지 않음
        # 사용자가 명시적으로 구성할 때까지
        null_handler = logging.NullHandler()
        
        # 루트 로거 구성
        root_logger = logging.getLogger()
        root_logger.addHandler(null_handler)
        root_logger.setLevel(logging.WARNING)
        
        cls._configured = True
    
    @classmethod
    def configure(cls,
                 level: LogLevel = LogLevel.WARNING,
                 format_string: Optional[str] = None,
                 date_format: Optional[str] = None,
                 stream: Optional[Any] = sys.stderr,
                 filename: Optional[str] = None):
        """
        라이브러리 로깅 구성
        
        Args:
            level: 로그 레벨
            format_string: 로그 포맷 문자열
            date_format: 날짜 포맷 문자열
            stream: 출력 스트림 (None이면 스트림 핸들러 사용 안함)
            filename: 로그 파일 경로 (None이면 파일 핸들러 사용 안함)
        """
        # 포맷터 설정
        if format_string is None:
            format_string = '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        
        if date_format is None:
            date_format = '%Y-%m-%d %H:%M:%S'
        
        formatter = logging.Formatter(format_string, date_format)
        
        # 기존 핸들러 제거
        root_logger = logging.getLogger()
        for handler in root_logger.handlers[:]:
            root_logger.removeHandler(handler)
        
        # 스트림 핸들러 추가
        if stream is not None:
            stream_handler = logging.StreamHandler(stream)
            stream_handler.setLevel(getattr(logging, level.value))
            stream_handler.setFormatter(formatter)
            root_logger.addHandler(stream_handler)
        
        # 파일 핸들러 추가
        if filename is not None:
            try:
                file_handler = logging.FileHandler(filename, encoding='utf-8')
                file_handler.setLevel(getattr(logging, level.value))
                file_handler.setFormatter(formatter)
                root_logger.addHandler(file_handler)
            except Exception as e:
                # 파일 핸들러 생성 실패 시 경고
                warning_logger = cls.get_logger(__name__)
                warning_logger.warning(f"파일 로깅 구성 실패: {e}")
        
        # 로그 레벨 설정
        root_logger.setLevel(getattr(logging, level.value))
        
        # 모든 기존 로거에 레벨 적용
        for logger in cls._loggers.values():
            logger.setLevel(getattr(logging, level.value))
        
        cls._default_log_level = level
        cls._configured = True
    
    @classmethod
    def enable_debug_mode(cls, module_name: Optional[str] = None):
        """
        디버그 모드 활성화
        
        Args:
            module_name: 특정 모듈만 디버그 모드로 설정 (None이면 모두)
        """
        if module_name:
            # 특정 모듈만 디버그 모드
            logger = cls.get_logger(module_name)
            logger.setLevel(logging.DEBUG)
        else:
            # 전체 디버그 모드
            cls.configure(level=LogLevel.DEBUG)
    
    @classmethod
    def disable_logging(cls):
        """로깅 비활성화"""
        root_logger = logging.getLogger()
        root_logger.setLevel(logging.CRITICAL + 1)  # 모든 로그 무시
    
    @classmethod
    def log_exception(cls,
                     logger_name: Optional[str] = None,
                     message: str = "예외 발생",
                     exc_info: Optional[Exception] = None,
                     context: Optional[Dict[str, Any]] = None):
        """
        예외 로깅 헬퍼 메서드
        
        Args:
            logger_name: 로거 이름
            message: 로그 메시지
            exc_info: 예외 객체
            context: 추가 컨텍스트 정보
        """
        logger = cls.get_logger(logger_name)
        
        if context:
            context_str = ' '.join(f'{k}={v}' for k, v in context.items())
            full_message = f"{message} [{context_str}]"
        else:
            full_message = message
        
        logger.error(full_message, exc_info=exc_info)
    
    @classmethod
    def log_performance(cls,
                       logger_name: Optional[str] = None,
                       operation: str = "",
                       duration: float = 0.0,
                       threshold: Optional[float] = None,
                       additional_info: Optional[Dict[str, Any]] = None):
        """
        성능 로깅 헬퍼 메서드
        
        Args:
            logger_name: 로거 이름
            operation: 작업 이름
            duration: 소요 시간 (초)
            threshold: 경고 임계값 (초)
            additional_info: 추가 정보
        """
        logger = cls.get_logger(logger_name)
        
        log_data = {
            'operation': operation,
            'duration_seconds': duration,
            'duration_ms': duration * 1000
        }
        
        if additional_info:
            log_data.update(additional_info)
        
        # 임계값 체크
        if threshold and duration > threshold:
            logger.warning(
                f"작업이 임계값을 초과: {operation} - {duration:.3f}초 (임계값: {threshold}초)",
                extra=log_data
            )
        else:
            logger.info(
                f"작업 완료: {operation} - {duration:.3f}초",
                extra=log_data
            )

# 예시 라이브러리
class DataProcessor:
    """
    예시 라이브러리 클래스
    
    내부적으로 로깅을 사용하는 라이브러리 예시
    """
    
    def __init__(self, name: str = "DataProcessor"):
        self.name = name
        self.logger = LibraryLogger.get_logger(f"{__name__}.{name}")
        
        self.logger.info(f"{name} 초기화됨")
    
    def process(self, data: list, chunk_size: int = 100):
        """
        데이터 처리 메서드
        
        Args:
            data: 처리할 데이터
            chunk_size: 청크 크기
        
        Returns:
            처리된 데이터
        """
        import time
        
        self.logger.info(f"데이터 처리 시작: {len(data)}개 항목, 청크 크기: {chunk_size}")
        
        start_time = time.time()
        
        try:
            results = []
            total_chunks = (len(data) + chunk_size - 1) // chunk_size
            
            for i in range(0, len(data), chunk_size):
                chunk = data[i:i + chunk_size]
                chunk_num = i // chunk_size + 1
                
                self.logger.debug(f"청크 {chunk_num}/{total_chunks} 처리 중: {len(chunk)}개 항목")
                
                # 청크 처리
                processed_chunk = self._process_chunk(chunk)
                results.extend(processed_chunk)
                
                # 진행 상황 로깅
                if chunk_num % 10 == 0 or chunk_num == total_chunks:
                    self.logger.info(f"진행 상황: {chunk_num}/{total_chunks} 청크 완료")
            
            duration = time.time() - start_time
            
            # 성능 로깅
            LibraryLogger.log_performance(
                logger_name=self.logger.name,
                operation=f"{self.name}.process",
                duration=duration,
                threshold=5.0,  # 5초 이상이면 경고
                additional_info={
                    'total_items': len(data),
                    'chunk_size': chunk_size,
                    'total_chunks': total_chunks
                }
            )
            
            self.logger.info(f"데이터 처리 완료: {len(results)}개 항목 생성")
            
            return results
            
        except Exception as e:
            # 예외 로깅
            LibraryLogger.log_exception(
                logger_name=self.logger.name,
                message="데이터 처리 중 오류 발생",
                exc_info=e,
                context={
                    'data_length': len(data),
                    'chunk_size': chunk_size
                }
            )
            raise
    
    def _process_chunk(self, chunk: list):
        """청크 처리 (내부 메서드)"""
        self.logger.debug(f"청크 처리: {len(chunk)}개 항목")
        
        # 처리 시뮬레이션
        import time
        time.sleep(0.01)  # 10ms 시뮬레이션
        
        return [x * 2 for x in chunk]
    
    def validate_data(self, data: list) -> bool:
        """데이터 검증"""
        self.logger.info(f"데이터 검증 시작: {len(data)}개 항목")
        
        if not data:
            self.logger.warning("빈 데이터 제공됨")
            return False
        
        # 간단한 검증
        for i, item in enumerate(data):
            if not isinstance(item, (int, float)):
                self.logger.error(
                    f"데이터 타입 오류: 인덱스 {i}, 값: {item}, 타입: {type(item)}",
                    extra={'index': i, 'value': item, 'type': str(type(item))}
                )
                return False
        
        self.logger.info("데이터 검증 통과")
        return True

# 사용자 코드 예시
def demonstrate_library_logging():
    """
    라이브러리 로깅 데모
    """
    print("=" * 60)
    print("라이브러리 로깅 시스템 데모")
    print("=" * 60)
    
    print("\n1. 라이브러리 로깅 기본 동작:")
    print("   라이브러리는 기본적으로 로그를 출력하지 않음")
    
    # 라이브러리 사용 (기본 설정)
    processor = DataProcessor("테스트프로세서")
    
    # 로깅이 비활성화된 상태에서 작업
    test_data = list(range(100))
    
    print("\n2. 로깅 활성화:")
    
    # 사용자가 라이브러리 로깅 구성
    LibraryLogger.configure(
        level=LogLevel.INFO,
        format_string='%(asctime)s - [%(name)s] - %(levelname)s - %(message)s',
        stream=sys.stdout
    )
    
    print("   INFO 레벨로 콘솔 로깅 활성화됨")
    
    # 로깅이 활성화된 상태에서 작업
    try:
        print("\n3. 데이터 처리 (로깅 활성화):")
        result = processor.process(test_data, chunk_size=25)
        print(f"   처리 결과: {len(result)}개 항목")
        
    except Exception as e:
        print(f"   처리 중 오류: {e}")
    
    print("\n4. 디버그 모드 활성화:")
    
    # 디버그 모드 활성화
    LibraryLogger.enable_debug_mode()
    print("   디버그 모드 활성화됨")
    
    # 디버그 모드에서 작업 (더 상세한 로그)
    processor2 = DataProcessor("디버그프로세서")
    
    try:
        print("\n5. 데이터 처리 (디버그 모드):")
        debug_data = list(range(50))
        result2 = processor2.process(debug_data, chunk_size=10)
        print(f"   처리 결과: {len(result2)}개 항목")
        
    except Exception as e:
        print(f"   처리 중 오류: {e}")
    
    print("\n6. 파일 로깅 활성화:")
    
    # 파일 로깅 구성
    import tempfile
    import os
    
    temp_dir = tempfile.mkdtemp(prefix="library_logs_")
    log_file = os.path.join(temp_dir, "library.log")
    
    LibraryLogger.configure(
        level=LogLevel.DEBUG,
        filename=log_file,
        stream=None  # 콘솔 출력 비활성화
    )
    
    print(f"   파일 로깅 활성화됨: {log_file}")
    
    # 파일 로깅 테스트
    processor3 = DataProcessor("파일로깅프로세서")
    
    try:
        file_data = list(range(30))
        valid = processor3.validate_data(file_data)
        print(f"   데이터 검증 결과: {'통과' if valid else '실패'}")
        
        if valid:
            result3 = processor3.process(file_data, chunk_size=5)
            print(f"   처리 결과: {len(result3)}개 항목")
    
    except Exception as e:
        print(f"   처리 중 오류: {e}")
    
    # 로그 파일 내용 확인
    print(f"\n7. 생성된 로그 파일 확인: {log_file}")
    
    if os.path.exists(log_file):
        with open(log_file, 'r', encoding='utf-8') as f:
            lines = f.readlines()
            print(f"   로그 파일 라인 수: {len(lines)}")
            
            # 마지막 5줄 출력
            print("   최근 로그:")
            for line in lines[-5:]:
                print(f"     {line.strip()}")
    
    # 정리
    import shutil
    if os.path.exists(temp_dir):
        shutil.rmtree(temp_dir)
        print(f"\n테스트 디렉토리 정리됨: {temp_dir}")
    
    print("\n8. 로깅 비활성화:")
    
    LibraryLogger.disable_logging()
    print("   모든 로깅 비활성화됨")
    
    # 로깅이 비활성화된 상태 테스트
    silent_processor = DataProcessor("사일런트프로세서")
    silent_data = list(range(10))
    
    try:
        silent_result = silent_processor.process(silent_data)
        print(f"   무음 모드 처리 완료: {len(silent_result)}개 항목")
    except Exception as e:
        print(f"   처리 중 오류: {e}")
    
    print("\n라이브러리 로깅 데모 완료")

if __name__ == "__main__":
    demonstrate_library_logging()
```

## 결론

파일 시스템 작업, 설정 관리, 로깅 시스템은 모든 파이썬 애플리케이션의 핵심 구성 요소입니다. 이러한 시스템을 잘 설계하고 구현하면 애플리케이션의 유지보수성, 디버깅 용이성, 운영 효율성을 크게 향상시킬 수 있습니다.

**고급 파일 검색 시스템**은 단순한 파일 찾기를 넘어서 다양한 검색 조건(이름 패턴, 확장자, 크기, 날짜, 내용)을 조합하고 효율적으로 처리할 수 있는 기능을 제공합니다. `AdvancedFileFinder` 클래스는 재귀적 검색, 정규식 지원, 중복 파일 탐지, 다중 조건 필터링 등을 구현하여 실무에서 필요한 파일 관리 작업을 포괄적으로 지원합니다. 특히 대용량 파일 시스템에서 효율적으로 작동하도록 청크 기반 처리와 메모리 최적화를 고려해야 합니다.

**통합 설정 관리 시스템**은 다양한 형식(JSON, YAML, TOML, INI, 환경 변수)의 설정을 통합 관리하고 우선순위에 따라 값을 결정하는 체계를 제공합니다. `ConfigurationManager` 클래스는 설정 파일의 자동 검색, 형식 감지, 환경 변수 통합, 값 검증, 설정 재로드 등의 기능을 포함합니다. 설정 스키마를 정의하고 검증하는 기능은 애플리케이션의 안정성을 보장하는 데 중요합니다. 또한 설정 값의 출처 추적과 변경 감지는 운영 환경에서 문제를 진단하는 데 유용합니다.

**스크립트용 로깅 시스템**은 콘솔, 파일, JSON 형식의 로깅을 지원하며 로그 회전, 레벨 제어, 성능 측정, 메모리 모니터링 등의 고급 기능을 제공합니다. `ScriptLogger` 클래스는 간단한 스크립트에서도 전문적인 수준의 로깅을 쉽게 구현할 수 있도록 설계되었습니다. 로그 데코레이터 패턴은 함수 호출 추적과 성능 프로파일링을 간편하게 구현하는 방법을 보여줍니다.

**라이브러리용 로깅 시스템**은 라이브러리 개발자와 사용자 모두에게 유용한 로깅 인터페이스를 제공합니다. `LibraryLogger` 클래스는 라이브러리가 기본적으로 침묵을 유지하지만 사용자가 필요에 따라 다양한 수준의 로깅을 활성화할 수 있는 유연성을 제공합니다. 클래스 메서드 기반 설계는 전역 상태 관리와 일관된 로깅 정책 적용을 가능하게 합니다. 예외 로깅 헬퍼와 성능 로깅 헬퍼는 라이브러리 내부에서 일관된 로깅 패턴을 적용하는 데 도움이 됩니다.

이러한 시스템들을 통합적으로 적용할 때의 주요 장점은:

1. **일관성**: 모든 구성 요소에서 동일한 패턴과 인터페이스 사용
2. **유지보수성**: 설정과 로깅이 중앙 집중식으로 관리됨
3. **운영 효율성**: 문제 진단과 모니터링이 용이함
4. **확장성**: 새로운 파일 형식, 로그 대상, 설정 소스 추가가 쉬움
5. **테스트 용이성**: 모의 객체와 설정 격리를 통한 효과적인 테스트

실제 프로덕션 환경에서는 이러한 시스템에 보안(민감 정보 마스킹), 성능 모니터링(로그 처리 오버헤드 측정), 통합(중앙 로깅 시스템 연동) 등의 추가 고려사항이 필요합니다. 또한 국제화(i18n)와 접근성을 고려한 로그 메시지 포맷팅도 중요한 요소입니다.

이러한 기반 시스템을 튼튼하게 구축하면 애플리케이션의 전체 수명주기 동안 개발자와 운영자 모두에게 가치를 제공할 수 있으며, 특히 대규모 분산 시스템이나 장기 실행 서비스에서는 그 중요성이 더욱 커집니다.