---
layout: post
title: AWS - 실제 아키텍처 패턴
date: 2025-08-08 23:25:23 +0900
category: AWS
---
# 실제 아키텍처 패턴 — 멀티 리전 고가용성, 라우팅·가속, 오리진 페일오버, 하이브리드 연결, 보안 경계 분리

아래 문서는 **실무에서 바로 적용 가능한 아키텍처 패턴**을 중심으로 정리했습니다. 각 섹션은 개념 → 구성 요소 → 예제(설정 스니펫/다이어그램) → 운영/검증/주의사항 순서로 다룹니다.

---

## 목차
1. 멀티 리전 고가용성(Active-Active / Active-Passive 패턴)  
2. Route 53 Latency-based Routing + Global Accelerator 조합 설계  
3. CloudFront Origin Failover 구성 (오리진 장애 시 자동 전환)  
4. 하이브리드 연결: VPC Endpoint + Direct Connect + PrivateLink 조합  
5. 보안 경계 분리: 퍼블릭 서브넷(CloudFront/ALB) ↔ 프라이빗 서브넷(NLB/GWLB)  
6. 운영·테스트·비용 고려사항  
7. 체크리스트 & 권장 실행 순서

---

## 1) 멀티 리전 고가용성 (HA) — 개념 및 패턴

### 주요 목표
- 리전 단위 장애(리전 전체 장애)에 대비
- 지리적 근접성으로 레이턴시 개선
- RTO/RPO 요구사항에 따른 설계 선택

### 대표 패턴
- **Active-Active (다중 리전에서 동시 서비스 제공)**  
  - 트래픽을 여러 리전에 분산(예: Route 53, Global Accelerator)  
  - 데이터: 글로벌 DB(예: Aurora Global DB, DynamoDB Global Tables) 또는 비동기 복제  
  - 장점: 낮은 레이턴시, 리전 장애 시 자동 지속  
  - 단점: 데이터 충돌/일관성 복잡성, 비용 증가
- **Active-Passive (주 리전 + 대기 리전)**  
  - 주 리전에서 운영, 대기 리전은 리소스 프로비저닝 또는 스탠바이(스냅샷/AMI 보관)  
  - 페일오버 시 Route 53 또는 Global Accelerator에서 트래픽 전환  
  - 장점: 비용 절감, 데이터 일관성 관리 쉬움  
  - 단점: 페일오버 시간(수분~수십분)

### 아키텍처 다이어그램 (간단)
```mermaid
graph LR
  User --> DNS[Route 53 / GA]
  DNS --> RegionA[Region-A (prod)]
  DNS --> RegionB[Region-B (prod)]
  RegionA --> ALB_A --> ASG_A --> RDS_A
  RegionB --> ALB_B --> ASG_B --> RDS_B
  RDS_A <--> AsyncReplica --> RDS_B
```

### 데이터 고려사항
- **관계형 DB**: Aurora Global DB (읽기 로컬, 복제 지연 짧음) 또는 Primary/Secondary 복제  
- **NoSQL**: DynamoDB Global Tables (Active-Active)  
- **파일 스토리지**: S3 CRR (Cross-Region Replication) 또는 객체 복제 파이프라인

---

## 2) Route 53 Latency-based Routing + Global Accelerator 설계

### 목적
- **Route 53 LBR**: 사용자에서 가장 레이턴시가 낮은 리전으로 DNS 응답을 제공  
- **Global Accelerator (GA)**: Anycast IP로 TCP/UDP 트래픽을 AWS 전용 백본으로 전달 → 더 일관된 레이턴시 및 빠른 장애 전환

### 언제 조합할까?
- 전 세계 분포 사용자 + TCP/UDP(또는 비캐시 가능한 동적 API) + 짧은 레이턴시 필요 → **Global Accelerator** 고려  
- 정적 콘텐츠/HTTP 캐시가 가능한 경우 → **CloudFront** 우선 권장(비용 효율적)

### 아키텍처 (권장)
- **웹 API(지연 민감)**: Global Accelerator → Regional ALB/NLB → Targets  
- **정적/캐시 가능 자원**: CloudFront (오리진은 각 리전 ALB 또는 S3)

### Route 53 + GA 연계 패턴
- Route 53: 사용자 DNS 요청에 대해 GA의 Anycast 고정 IP를 반환하거나, 경우에 따라 LBR로 리전별 엔드포인트(예: CloudFront, ALB) 반환  
- GA: 장애 감지 시 다른 리전 엔드포인트로 즉시 전환(대기시간 보통 수 초~수십 초)

### 예시: DNS 흐름
- User -> DNS -> returns GA anycast IP -> GA 엣지 -> AWS Backbone -> Region ALB

### 구성 스니펫 (논리)
```text
1. Create Global Accelerator
   - Add Endpoint Group for Region A (ALB_A)
   - Add Endpoint Group for Region B (ALB_B)
2. Route53 records:
   - A/AAAA record pointing to GA static IP(s) (optional)
   - Or use latency-records to ALB endpoints for non-GA flow
```

### 운영 팁
- GA는 고정 IP 제공으로 방화벽/고객 네트워크에 유리  
- 비용: GA는 고정 시간요금 + 데이터 전송요금 → 사용 전 비용/성능 비교 필수

---

## 3) CloudFront Origin Failover 구성

### 목적
- 오리진(예: ALB 또는 S3) 장애 시 **CloudFront가 자동으로 백업 오리진**으로 전환하여 서비스 유지

### 동작 원리
- CloudFront 배포에 Primary Origin + Secondary Origin을 구성  
- 오리진 헬스 체크(Origin Shield 또는 CloudFront 자체의 오리진 실패 감지)에 따라 자동으로 페일오버

### 설정(콘솔/CloudFormation 개념)
- CloudFront Distribution:
  - Origin 1: ALB-prod-us (Primary)
  - Origin 2: ALB-prod-eu (Failover)
  - Cache Behavior: Origin Failover 활성화, Failover Criteria 설정(HTTP 5xx 등)

### CloudFormation snippet (요지)
```yaml
Resources:
  MyDistribution:
    Type: AWS::CloudFront::Distribution
    Properties:
      DistributionConfig:
        Origins:
          - Id: primary-origin
            DomainName: alb-primary.example.com
          - Id: secondary-origin
            DomainName: alb-secondary.example.com
        DefaultCacheBehavior:
          TargetOriginId: primary-origin
          ForwardedValues: ...
        OriginGroups:
          Quantity: 1
          Items:
            - Id: origin-group-1
              Members:
                Quantity: 2
                Items:
                  - OriginId: primary-origin
                  - OriginId: secondary-origin
              FailoverCriteria:
                StatusCodes:
                  Quantity: 2
                  Items: [503, 504]
```

### 장점
- 엣지 레이어에서 장애 대응 → 빠른 복구  
- Origin Shield와 조합 시 Origin 요청 감소 및 동시성 완화

### 주의사항
- 데이터 일관성(특히 쓰기 경로)은 오리진 간 복제 모델을 사전에 설계해야 함  
- DNS 수준 페일오버와 달리 CloudFront는 HTTP 응답 코드 기반으로 더 세밀한 페일오버 제어 가능

---

## 4) 하이브리드 연결: VPC Endpoint + Direct Connect + PrivateLink

### 시나리오
- 온프레 데이터센터와 AWS 간의 안정적, 저지연 연결(Direct Connect)  
- 내부 서비스(AWS 서비스나 사설 SaaS)를 VPC 내부에서 안전하게 호출 → PrivateLink / Interface Endpoint  
- S3/DynamoDB 접근은 Gateway Endpoint로 비용·보안 최적화

### 구성 요소 역할
- **Direct Connect**: 온프레 ↔ AWS 전용 회선(또는 DX + Transit Gateway)  
- **Transit Gateway**: 여러 VPC/계정 간 라우팅 통합 (DX 연결 허브)  
- **VPC Endpoint (Gateway)**: S3/DynamoDB 프라이빗 접근 (무료)  
- **PrivateLink (Interface Endpoint)**: 서비스(예: 내부 API, SaaS) 프라이빗 접근을 위한 ENI 기반 접속

### 하이브리드 아키텍처 예
```mermaid
graph LR
  OnPrem -->|DX| DXGW[Direct Connect Gateway]
  DXGW --> TGW[Transit Gateway]
  TGW --> VPC_A[VPC - App]
  TGW --> VPC_S[Shared Services VPC]
  VPC_S --> EndpointS3[Gateway Endpoint (S3)]
  VPC_A --> InterfaceEP[Interface Endpoint / PrivateLink -> Partner Service]
```

### 구현 팁
- **Private VIF**로 Direct Connect와 Transit Gateway 연결 → VPC 간 라우팅 일원화  
- **Endpoint policies**로 PrivateLink / Interface Endpoint 접근 제어  
- **S3 Gateway Endpoint**는 리전 내 S3에 무료 접근 가능 → 온프레에서 S3 접근 시 리전 라우팅 유념

### 보안/운영 팁
- Direct Connect 회선 당 장애 대비를 위해 **다중 DX 접속(다른 포인트)** 추천  
- Transit Gateway route table 분리로 계정/환경(Prod/Non-prod) 간 트래픽 통제  
- PrivateLink는 서비스 제공자가 VPC에 노출하는 방식이므로 계약·권한 검토 필수

---

## 5) 보안 경계 분리: 퍼블릭 서브넷(CloudFront/ALB) ↔ 프라이빗 서브넷(NLB/GWLB)

### 개념
- **퍼블릭 서브넷**: 퍼블릭 IP를 가진 리소스(인터넷-facing ALB, NAT Gateway, CloudFront 오리진 등)  
- **프라이빗 서브넷**: 외부 직접 노출을 허용하지 않는 리소스(어플리케이션 서버, DB, 내부 NLB, GWLB 뒤의 IDS/IPS)

### 일반 패턴
- **CloudFront (엣지)** → ALB(퍼블릭) → 애플리케이션(프라이빗)  
- **Global Accelerator / NLB** → NLB는 퍼블릭 서브넷에 배치하여 TCP/UDP 트래픽을 프라이빗 Target으로 라우팅  
- **GWLB**는 트래픽을 보안 어플라이언스 ASG로 보내 검사 후 내부 리소스로 전달

### 예제 아키텍처
```mermaid
graph LR
  Internet --> CloudFront --> ALB_public
  ALB_public --> PrivateSubnet[App Servers (private subnet)]
  Internet -->|TCP| NLB_public --> PrivateSubnet[Backend services]
  VPC --> GWLB --> IDS_ASG --> PrivateSubnet
```

### 세부 구현 지침
1. **ALB (인터넷 facing)**  
   - 리스너는 HTTPS만 허용(HTTP → HTTPS 리다이렉트)  
   - WAF 적용(필요 시 CloudFront 앞단 WAF + ALB WAF 중첩 검토)
2. **CloudFront + OAC/OAI**  
   - S3 오리진은 OAC/OAI로 직접 접근 제어  
   - ALB 오리진은 OAC 불필요하나 Origin Shield 고려
3. **NLB 사용**  
   - TCP/UDP(게임, IoT) 또는 TLS passthrough가 필요할 때 사용  
   - 정적 IP(EIP) 필요 시 NLB 추천
4. **GWLB (보안 서비스 체인)**  
   - 트래픽을 GWLB → 보안 어플라이언스 → 내부 리소스로 투명 전달  
   - 보안 ASG 오토스케일링과 연동

### 보안 그룹 / NACL 설계
- 퍼블릭 서브넷의 ALB/NLB 보안 그룹은 최소 포트만 오픈(예: 443)  
- 프라이빗 서브넷의 인스턴스는 ALB/NLB의 보안 그룹만 인바운드 허용  
- NACL은 기본 거부 정책을 고려하되, 세밀한 제어보다 보안 그룹 기반 설계 권장

---

## 6) 운영·테스트·비용 고려사항

### 운영 & 테스트
- **DR/Failover 테스트**: 정기적으로 리전 장애 시뮬레이션(게임데이) 수행  
- **헬스 체크**: ALB/CloudFront/GA의 헬스 체크 설정을 조정하여 과도한 페일오버를 방지  
- **모니터링**: CloudWatch, Route 53 health checks, VPC Flow Logs, ELB access logs, CloudFront logs 집계  
- **Chaos Engineering**: 인스턴스/리전/네트워크 장애를 의도적으로 발생시켜 복원력 검증

### 비용 고려사항
- 멀티 리전 Active-Active는 데이터 복제·리소스 중복으로 비용 증가  
- Global Accelerator 및 Transit Gateway 등은 고정요금·데이터 비용 발생  
- CloudFront 캐시 효율화로 Origin egress 비용 절감 권장

---

## 7) 체크리스트 & 권장 실행 순서

### 설계 전 확인
- [ ] RTO(Recovery Time Objective) / RPO(Recovery Point Objective) 정의  
- [ ] 각 서비스의 장애 허용 범위(데이터 일관성 요구 등) 문서화

### 구현 우선순위 (권장)
1. 핵심 리소스(데이터베이스, S3) 복제/백업/리전 복제 설정  
2. 네트워크 연결(Direct Connect, Transit Gateway) 및 VPC 설계  
3. 엣지·라우팅(GA/Route 53/CloudFront) 구성  
4. 오리진 페일오버 및 헬스 체크 튜닝  
5. 보안(Endpoint policies, SG/NACL, WAF/Shield, GWLB 보안 체인) 적용  
6. 모니터링 및 자동화(알람, Runbook, Playbook) 구성  
7. 가동 전 DR 테스트(스모크 → 부분 장애 → 전체 DR)

### 운영(정기)
- 월간 비용·태깅 감사  
- 분기별 DR/페일오버 테스트  
- 변경 시 Canary / Blue-Green 배포로 리스크 감소

---

## 결론 — 설계 원칙 요약
- **목표 기반 설계**: RTO/RPO와 트래픽 패턴에 맞춰 Active-Active 또는 Active-Passive 결정  
- **엣지 우선**: 캐싱 가능한 리소스는 CloudFront로 오프로드  
- **네트워크 경계 명확화**: 퍼블릭 vs 프라이빗 구분 + GWLB로 보안 체인 구성  
- **하이브리드 통합**: Direct Connect + Transit Gateway + PrivateLink 조합으로 온프레와 안전하게 연결  
- **검증 반복**: 정기적 DR/Chaos 테스트 + 모니터링 자동화
