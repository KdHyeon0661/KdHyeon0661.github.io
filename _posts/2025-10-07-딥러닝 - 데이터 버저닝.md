---
layout: post
title: 딥러닝 - 데이터 버저닝
date: 2025-10-07 22:25:23 +0900
category: 딥러닝
---
# 데이터 버저닝(DVC) 가이드

## 0. 한눈에 보는 큰그림

```
Git (코드/메타: dvc.yaml, .dvc, params.yaml, metrics.json 등)
     └─ DVC Remote(스토리지: S3/MinIO/GDrive/Azure/SSH/Local)
           ├─ data/raw        (원본: 불변성)
           ├─ data/processed  (파생: 정규화/증강 등)
           ├─ data/features   (특성: 임베딩/통계 벡터)
           └─ models/         (학습 가중치, 배포 아티팩트)
```

- **원본은 무조건 보존/버전관리** (불변성 원칙)  
- **파생/특성은 선택적으로 저장**: 재계산 비용, 빈도, 크기, 결정적(deterministic) 여부에 따라  
- **dvc.yaml**에 전처리→특성→학습→평가 **스테이지 체인**을 기술하여 `dvc repro`로 재현성 보장  
- **params.yaml**로 하이퍼/전처리 파라미터를 선언하고, `dvc exp run`으로 실험을 관리  
- **metrics/plots**로 품질 회귀(정확도/손실/ROC 등) 추적

---

## 1. 저장 전략의 핵심 원칙

### 1.1 원본(raw)
- **불변(immutable)** + **정식 버전 태깅** 권장(예: `raw-v1.0`, `raw-2025-10-28`)  
- 확보 경로: *크롤링/다운로드/외부 제공/센서 수집*  
- DVC로 **포인터만 Git**에 커밋되고, 실제 바이트는 **Remote**에 보관  
- **법/컴플라이언스(PII)** 준수: 민감 정보는 **암호화 원격/SSE**, 접근권한 분리

### 1.2 파생(processed)  
- 예: 정규화(픽셀 범위, 표준화), 결측 처리, 리샘플, 타일링, 패딩/마스킹, 라벨 정제 등  
- **결정적 변환**이면 **굳이 저장하지 않아도 됨**(코드/파라미터로 재현 가능)  
- 단, **시간·비용이 큰 변환**(예: 수백 GB 타일링/클라우드 마스킹)은 **스냅샷 저장** 권장

### 1.3 특성(features)
- 예: CNN 임베딩(ResNet), RoI/BoW/TF-IDF, 스펙트럼/통계 벡터, 문서 임베딩 등  
- **매우 비싼 추출**(대형 모델, 원격탐사 대량 타일링)은 **저장**  
- 반면 **상대적으로 싸고 변경 잦음**(모델 자주 바꿈)이라면 **코드로 재계산**  
- **파티셔닝**(날짜/샤드/폴더) + **컬럼 포맷**(Parquet/NPZ) 권장

### 1.4 스토리지 ↔ 재계산 트레이드오프(거친 근사)

- 일 단위/배치 기준으로
$$
\text{총비용} \approx C_{\text{저장}} + N_{\text{요청}} \cdot \min(C_{\text{재계산}}, C_{\text{다운로드}})
$$
- 여기서
  - $$C_{\text{저장}}$$: 원격 스토리지 비용(GB·월) + 네트워크 이그레스  
  - $$C_{\text{재계산}}$$: GPU/CPU 시간·전력·큐 대기  
  - $$C_{\text{다운로드}}$$: 캐시 미스 시 Remote→로컬 전송비용  
- **룰오브썸**  
  - $$C_{\text{재계산}} \gg C_{\text{다운로드}}$$ → **저장**  
  - $$C_{\text{재계산}} \ll C_{\text{다운로드}}$$ → **재계산**  
  - 변경 빈도↑이면 저장보다 재계산 쪽으로 기우는 경향

---

## 2. 프로젝트 스캐폴딩(예시)

```
mlproj/
├─ data/
│  ├─ raw/                # DVC 추적 (불변 스냅샷)
│  ├─ processed/          # 선택 (저장 or 재계산)
│  └─ features/           # 선택 (저장 or 재계산)
├─ src/
│  ├─ 01_preprocess.py
│  ├─ 02_split.py
│  ├─ 03_featurize.py
│  ├─ 04_train.py
│  └─ 05_eval.py
├─ models/                # 학습 산출물 (DVC outs)
├─ params.yaml            # 하이퍼/전처리 파라미터
├─ dvc.yaml               # 파이프라인 정의
├─ .dvc/                  # DVC 메타
├─ .gitignore
└─ README.md
```

---

## 3. 빠른 시작: DVC 초기화 & 원격(Remote) 연결

```bash
# 0. 새 repo
git init mlproj && cd mlproj

# 1. DVC 초기화
dvc init

# 2. 원격 추가 (S3 예: MinIO/S3 호환도 OK)
dvc remote add -d s3remote s3://my-bucket/mlproj
# 민감 자격증명은 로컬 설정에
dvc remote modify s3remote access_key_id $AWS_ACCESS_KEY_ID --local
dvc remote modify s3remote secret_access_key $AWS_SECRET_ACCESS_KEY --local
dvc remote modify s3remote region us-east-1
# (필요 시) SSE나 endpointurl 등도 modify로 설정

git add .dvc .gitignore .dvc/config
git commit -m "init dvc + s3 remote"
```

> GDrive/SSH/Azure/Local path 원격도 동일 패턴. **자격정보는 `.dvc/config.local`**(Git 미추적)에 둡니다.

---

## 4. 원본 데이터 관리 패턴

### 4.1 `dvc add`로 원본 스냅샷
```bash
# 예: raw 이미지를 날짜 파티션으로 수집했다고 가정
mkdir -p data/raw/2025-10-28
# (여기에 수집/다운로드… 파일이 있다고 가정)
dvc add data/raw/2025-10-28     # .dvc 파일 생성 + .gitignore 반영
git add data/raw/2025-10-28.dvc .gitignore
git commit -m "raw snapshot 2025-10-28"
dvc push   # 실제 바이트는 S3로 업로드
```

- **여러 스냅샷**을 같은 디렉터리 레벨에서 유지: `data/raw/2025-10-29`, `.../2025-11-01`  
- 혹은 **단일 디렉터리** `data/raw`에 누적하며 `dvc add data/raw`(디렉터리 추적).  
  - 다만 **파일 수 대폭 증가** 시 push/pull 성능에 영향 → **샤딩** 권장(예: 날짜/월 단위)

### 4.2 외부 소스는 `import-url` 또는 `import`
```bash
# URL에서 바로 DVC에 등록 (ex: 공개 S3, http)
dvc import-url https://example.com/dataset.tar.gz data/raw/dataset.tar.gz

# 타 Git+DVC 리포지토리의 특정 버전을 가져오기(데이터 레지스트리 패턴)
dvc import git@github.com:org/data-registry.git \
          path/in/registry/data/raw-v1 \
          -o data/raw/registry-v1
```

- `dvc update`로 원본 리포지토리 변경분 추적 가능 → **데이터 의존성 버전고정**

---

## 5. 파이프라인 구성(전처리→특성→학습→평가)

### 5.1 파라미터(`params.yaml`)
```yaml
seed: 42
preprocess:
  resize: 256
  normalize_mean: [0.485, 0.456, 0.406]
  normalize_std:  [0.229, 0.224, 0.225]
split:
  train_ratio: 0.8
features:
  backbone: resnet18
  pool: avg
  batch_size: 64
train:
  lr: 0.001
  epochs: 5
  batch_size: 64
```

### 5.2 파이프라인(`dvc.yaml`)
```yaml
stages:
  preprocess:
    cmd: python src/01_preprocess.py \
           --src data/raw/2025-10-28 --dst data/processed/2025-10-28
    deps:
      - src/01_preprocess.py
      - data/raw/2025-10-28
    params:
      - preprocess
      - seed
    outs:
      - data/processed/2025-10-28

  split:
    cmd: python src/02_split.py \
           --src data/processed/2025-10-28 --dst data/processed/split-2025-10-28
    deps:
      - src/02_split.py
      - data/processed/2025-10-28
    params:
      - split
      - seed
    outs:
      - data/processed/split-2025-10-28

  featurize:
    cmd: python src/03_featurize.py \
           --src data/processed/split-2025-10-28 --dst data/features/r18-2025-10-28
    deps:
      - src/03_featurize.py
      - data/processed/split-2025-10-28
    params:
      - features
    outs:
      - data/features/r18-2025-10-28

  train:
    cmd: python src/04_train.py \
           --feat data/features/r18-2025-10-28 --out models/run-r18-2025-10-28
    deps:
      - src/04_train.py
      - data/features/r18-2025-10-28
    params:
      - train
      - seed
    outs:
      - models/run-r18-2025-10-28
    metrics:
      - metrics.json:
          cache: false
```

> `metrics.json`은 Git에 그대로 들어가도 작으므로 `cache:false`로 DVC 캐시를 쓰지 않게 설정 가능.  
> 큰 결과(예: 모델 가중치)는 **DVC outs**로 Remote에 저장.

---

## 6. 파이썬 스크립트(요지)

> 실제 파일 경로/라벨 체계는 예시입니다.

### 6.1 `src/01_preprocess.py`
```python
import argparse, random, os, shutil
from pathlib import Path
from PIL import Image
import numpy as np
import torch

def set_seed(s):
    random.seed(s); np.random.seed(s); torch.manual_seed(s)

def iter_images(root):
    for p in Path(root).rglob("*"):
        if p.suffix.lower() in [".jpg",".jpeg",".png",".bmp"]: yield p

def main():
    ap = argparse.ArgumentParser()
    ap.add_argument("--src", required=True)
    ap.add_argument("--dst", required=True)
    args = ap.parse_args()

    # params는 환경변수나 파일에서 읽는 패턴도 가능. 여기선 단순화
    resize = 256
    set_seed(42)
    Path(args.dst).mkdir(parents=True, exist_ok=True)

    for imgp in iter_images(args.src):
        outp = Path(args.dst) / imgp.relative_to(args.src)
        outp.parent.mkdir(parents=True, exist_ok=True)
        im = Image.open(imgp).convert("RGB").resize((resize, resize))
        im.save(outp)

if __name__=="__main__":
    main()
```

### 6.2 `src/02_split.py`
```python
import argparse, json, random
from pathlib import Path

def list_images(root):
    return [p for p in Path(root).rglob("*") if p.suffix.lower() in [".jpg",".jpeg",".png"]]

def main():
    ap = argparse.ArgumentParser()
    ap.add_argument("--src", required=True)
    ap.add_argument("--dst", required=True)
    args = ap.parse_args()

    imgs = list_images(args.src)
    random.Random(42).shuffle(imgs)
    n = len(imgs); tr = int(n*0.8)
    train, val = imgs[:tr], imgs[tr:]

    (Path(args.dst)/"train.txt").write_text("\n".join(map(str,train)), encoding="utf-8")
    (Path(args.dst)/"val.txt").write_text("\n".join(map(str,val)), encoding="utf-8")

if __name__=="__main__":
    main()
```

### 6.3 `src/03_featurize.py` (torchvision ResNet 임베딩 → NPZ/Parquet)
```python
import argparse, numpy as np, torch
from pathlib import Path
from PIL import Image
import torchvision.models as models
import torchvision.transforms as T

@torch.no_grad()
def main():
    ap = argparse.ArgumentParser()
    ap.add_argument("--src", required=True)  # split-... 디렉터리
    ap.add_argument("--dst", required=True)
    ap.add_argument("--batch_size", type=int, default=64)
    args = ap.parse_args()

    Path(args.dst).mkdir(parents=True, exist_ok=True)
    device = "cuda" if torch.cuda.is_available() else "cpu"

    # resnet18 backbone + global avg pooling
    net = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)
    net.fc = torch.nn.Identity()  # feature only
    net.eval().to(device)

    tfm = T.Compose([
        T.ToTensor(),
        T.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225])
    ])

    def load_paths(fname): 
        return [Path(x) for x in Path(fname).read_text(encoding="utf-8").splitlines() if x.strip()]

    for split in ["train","val"]:
        txt = Path(args.src)/f"{split}.txt"
        paths = load_paths(txt)
        feats, labels = [], []
        # 라벨: 상위 폴더명 기준 가정 (…/class_x/img.jpg)
        classes = sorted({p.parent.name for p in paths})
        cls2id = {c:i for i,c in enumerate(classes)}

        batch = []
        def flush():
            if not batch: return
            imgs = torch.stack([tfm(Image.open(p).convert("RGB").resize((256,256))) for p,_ in batch]).to(device)
            ys = torch.tensor([cls2id[p.parent.name] for p,_ in batch], device=device)
            z = net(imgs).detach().cpu().numpy()
            feats.append(z); labels.append(ys.cpu().numpy())
            batch.clear()

        for p in paths:
            batch.append((p, p.parent.name))
            if len(batch)>=args.batch_size: flush()
        flush()

        X = np.concatenate(feats,0) if feats else np.zeros((0,512))
        y = np.concatenate(labels,0) if labels else np.zeros((0,),dtype=np.int64)
        np.savez(Path(args.dst)/f"{split}.npz", X=X, y=y, classes=np.array(classes))

if __name__=="__main__":
    main()
```

### 6.4 `src/04_train.py` (간단 MLP 분류기)
```python
import argparse, json, numpy as np, torch
import torch.nn as nn
from pathlib import Path

class MLP(nn.Module):
    def __init__(self, d_in=512, d_h=256, n_cls=2):
        super().__init__()
        self.net = nn.Sequential(
            nn.Linear(d_in, d_h), nn.ReLU(),
            nn.Linear(d_h, n_cls)
        )
    def forward(self, x): return self.net(x)

def load_npz(path):
    d = np.load(path)
    return torch.tensor(d["X"], dtype=torch.float32), torch.tensor(d["y"], dtype=torch.long)

def main():
    ap = argparse.ArgumentParser()
    ap.add_argument("--feat", required=True)
    ap.add_argument("--out", required=True)
    ap.add_argument("--lr", type=float, default=1e-3)
    ap.add_argument("--epochs", type=int, default=5)
    ap.add_argument("--batch_size", type=int, default=64)
    args = ap.parse_args()
    Path(args.out).mkdir(parents=True, exist_ok=True)

    Xtr, ytr = load_npz(Path(args.feat)/"train.npz")
    Xva, yva = load_npz(Path(args.feat)/"val.npz")
    n_cls = int(ytr.max().item()+1)

    device = "cuda" if torch.cuda.is_available() else "cpu"
    model = MLP(d_in=Xtr.shape[1], n_cls=n_cls).to(device)
    opt = torch.optim.AdamW(model.parameters(), lr=args.lr)
    crit = nn.CrossEntropyLoss()

    def loop(X, y, train=True):
        model.train(train)
        B=args.batch_size
        tot, correct, loss_sum = 0,0,0.0
        for i in range(0, len(X), B):
            xb = X[i:i+B].to(device); yb = y[i:i+B].to(device)
            if train: opt.zero_grad()
            out = model(xb)
            loss = crit(out, yb)
            if train:
                loss.backward(); opt.step()
            loss_sum += loss.item()*len(xb)
            pred = out.argmax(1)
            correct += (pred==yb).sum().item()
            tot += len(xb)
        return loss_sum/tot, correct/tot

    best = -1.0
    for ep in range(1, args.epochs+1):
        tr_loss, tr_acc = loop(Xtr, ytr, True)
        va_loss, va_acc = loop(Xva, yva, False)
        print(f"[{ep}] tr {tr_loss:.4f}/{tr_acc:.3f}  va {va_loss:.4f}/{va_acc:.3f}")
        if va_acc>best:
            best=va_acc
            torch.save(model.state_dict(), Path(args.out)/"weights.pt")

    # DVC metrics
    Path("metrics.json").write_text(json.dumps({"val_acc":best}, indent=2), encoding="utf-8")

if __name__=="__main__":
    main()
```

### 6.5 `src/05_eval.py` (선택: 추가 지표/플롯 저장)
```python
# 필요시 dvclive로 학습 로그/플롯을 남길 수 있습니다.
# pip install dvclive
```

---

## 7. 실행 & 버전관리 흐름

```bash
# 1. 원본 스냅샷 추가/푸시
dvc add data/raw/2025-10-28
git add data/raw/2025-10-28.dvc
git commit -m "raw snapshot 2025-10-28"
dvc push

# 2. 파이프라인 재현
dvc repro
# -> preprocess → split → featurize → train 순차 실행
#    결과는 DVC 캐시 + Remote로 관리

# 3. 메트릭/비교
dvc metrics show
dvc metrics diff  # 이전 커밋 대비 변경

# 4. Git에 메타 커밋
git add dvc.yaml dvc.lock params.yaml metrics.json models/
git commit -m "r18 features + mlp train; val_acc=..."
dvc push  # 큰 아티팩트/데이터는 Remote로 업로드
```

- `dvc.lock`는 **사용된 입력 해시/파라미터**가 기록되어 **정확한 재현**이 가능합니다.  
- 팀원은 `git pull && dvc pull`만으로 동일 상태를 복원.

---

## 8. “무엇을 저장할까?”—결정 프레임워크

### 8.1 의사결정표
| 데이터 | 크기 | 재계산 비용 | 변경 빈도 | 컴플라이언스 | 권장 전략 |
|---|---:|---:|---:|---|---|
| 원본(raw) | 중~대 | 매우 큼 | 낮음 | 높음(PII 가능) | **DVC 저장(필수)**, 스냅샷·태그 |
| 파생(processed) | 중 | 중~대(타일링/클린) | 중 | 중 | **상황별**(비용 크면 저장, 아니면 재계산) |
| 특성(features) | 중~대 | **매우 큼**(대형모델/임베딩) | **높음**(모델 바꿈) | 낮음 | **하이브리드**: 비싼 백본만 저장, 나머지 재계산 |

### 8.2 예시 결론
- **원격탐사 타일링 + 클라우드 마스킹**: 저장(월 10~100GB라도 GPU·API 호출비가 훨씬 큼)  
- **ResNet18 임베딩**: 모델이 자주 바뀌지 않는다면 저장(특히 수백만 타일)  
- **학습용 증강/정규화**: 코드로 재현(저장 비권장)

---

## 9. 고급: DVC 캐시/링크/성능 팁

- **캐시 링크**: `dvc config cache.type "reflink,hardlink,copy"`  
  - 가능하면 **reflink/hardlink**로 **복사 없이 빠른 스냅샷**  
- **작은 파일 많을 때**: **샤딩 압축**(tar/zip) or Parquet로 묶기 → push/pull 성능 개선  
- **멀티스레드**: `dvc push -j 8`, `dvc pull -j 8`  
- **GC(garbage collect)**: 오래된 실험/브랜치 정리  
  ```bash
  # 현재 워크스페이스 + 원격 모두에서 불필요 블롭 정리 (주의!)
  dvc gc -w -c
  ```

---

## 10. 데이터 레지스트리 패턴

- **전용 리포지토리**에 데이터를 DVC로 관리(코드는 없음) → 실험 리포에서 `dvc import`  
- 장점: **생산/소비 분리**, 다양한 프로젝트가 **같은 데이터 태그** 사용  
- 운영:
  ```bash
  # 레지스트리에서 데이터 갱신 → 릴리스 태그 생성
  git tag raw-v1.2 && git push --tags

  # 소비측:
  dvc update data/raw/registry-v1   # import된 대상 최신화
  ```

---

## 11. 실험 관리(DVC Experiments)

- `dvc exp run -S train.lr=0.0005 -S features.backbone=resnet34`  
- `dvc exp show`로 표 비교, `dvc exp apply <exp_id>`로 선택 적용  
- `dvc exp push`/`pull`로 **원격에 실험 메타** 공유 가능(선택)  
- **체크포인트 학습**(`checkpoint: true`)도 가능 → 장기학습/중단복구

---

## 12. CI 파이프라인(예: GitHub Actions)

`.github/workflows/ci.yaml` (요지)
```yaml
name: dvc-ci
on: [push, pull_request]
jobs:
  repro:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4
    - name: Setup Python
      uses: actions/setup-python@v5
      with: { python-version: "3.11" }
    - name: Install deps
      run: |
        pip install -U dvc[s3] torch torchvision dvclive
    - name: DVC Pull
      env:
        AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
        AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
      run: dvc pull -j 8
    - name: Reproduce
      run: dvc repro
    - name: Show metrics
      run: dvc metrics show
```

> 대형 데이터는 CI에서 **전부 재현하지 않도록** 스테이지를 분기하거나 샘플 서브셋 파이프라인을 두세요.

---

## 13. 보안/컴플라이언스

- **자격정보**: `.dvc/config.local`(Git 미추적), 환경변수/CI Secret  
- **암호화**: S3 SSE-KMS, GCS CMEK, Azure SSE 등 스토리지 레벨 암호화  
- **PII/민감데이터**: 원본 경로/포맷을 **명확 분리**(`data/raw_sensitive`), 접근제어 별도 원격  
- **감사/추적**: 커밋/태그로 데이터 릴리스 이력 관리, `dvc.lock`으로 재현증빙

---

## 14. 운영 시나리오별 권장 패턴

### 14.1 매일 신규 수집(일배치)
```bash
# 당일 폴더만 add & push
dvc add data/raw/2025-10-28 && git add data/raw/2025-10-28.dvc
git commit -m "raw snapshot 2025-10-28"
dvc push

# 파이프라인 재현 (부분 재실행)
dvc repro featurize train
```
- **스플릿/특성**을 **날짜-버킷**으로 유지 → 회귀분석/드리프트 감시 용이

### 14.2 초거대 특성(수 TB)  
- **고정 백본**(ex: ResNet50) 임베딩은 **스냅샷 저장**  
- 모델이 자주 바뀌는 경우 **학습 직전의 투입 가공**만 재계산  
- **파티션 메타**(manifest)로 필요한 조각만 `dvc pull`

### 14.3 RAG/텍스트 임베딩
- 문서 파싱/정규화는 재계산 가능(저장 X)  
- **임베딩(대형 encoder)**은 저장, 단 **embedding 모델 버전**으로 디렉터리 분리  
  - 예: `data/features/e5-base-v2/2025-10-28`

---

## 15. 자주 하는 실수 & 디버깅

- **`.dvc`/`.gitignore` 충돌**: 수동 수정 금지. `dvc add`가 추가한 ignore 라인을 유지  
- **로컬 캐시 손상/실행기기 변경**: `dvc checkout`로 워킹 디렉터리 동기화  
- **병합 충돌**(dvc.lock): `dvc repro`로 재생성하여 충돌 해소  
- **속도 저하**: 너무 많은 작은 파일 → **샤딩**/**Parquet**/**tar**로 묶기  
- **원격 용량 급증**: 불필요 실험/브랜치 gc(`dvc gc -w -c`), 혹은 **수명주기 정책** 적용(S3 Lifecycle)

---

## 16. 빠른 체크리스트(요약)

- [ ] **원본은 항상 DVC 저장** + 스냅샷 태깅  
- [ ] 파생/특성은 **비용 기반**으로 저장·재계산 선택(룰오브썸 적용)  
- [ ] **dvc.yaml**에 **전체 체인**(preprocess→featurize→train→eval) 기술  
- [ ] **params.yaml**로 하이퍼·전처리 파라미터 관리  
- [ ] **metrics.json/plots**로 회귀 추적, `dvc metrics diff`로 비교  
- [ ] **data registry** 패턴 고려(팀/조직 간 공유)  
- [ ] **보안**: 자격정보는 local, 원격 암호화, PII 분리  
- [ ] **성능**: 캐시 링크(reflink/hardlink), 샤딩, 멀티스레드 push/pull  
- [ ] **청소**: 주기적 `dvc gc` + 원격 수명주기 정책

---

## 17. 부록 — 명령어 레퍼런스

```bash
# 기초
dvc init
dvc add <path>                  # 데이터 포인터(.dvc) 생성
dvc push / dvc pull             # 원격 업/다운
dvc checkout                    # 워킹 디렉터리를 잠금/해시대로 복원
dvc status                      # 로컬 vs 원격 동기화 상태

# 파이프라인
dvc repro                       # dvc.yaml 체인 재현
dvc stage add ...               # (대화형 대신 수동 stage 추가)
dvc dag                         # 그래프 보기
dvc params diff                 # 파라미터 변경 비교
dvc metrics show/diff           # 메트릭 표시/차이

# 원격
dvc remote add -d name url
dvc remote modify name key val

# 실험
dvc exp run -S key=val          # 파라미터 override
dvc exp show / list / apply
dvc exp gc                      # 실험 메타 청소

# 외부 데이터
dvc import-url <url> <out>
dvc import <git-repo> <path-in-repo> -o <out>
dvc update <out>                # import 갱신

# 유지관리
dvc gc -w -c                    # 워크스페이스/원격 청소(주의!)
```

---

# 마무리

- **핵심은 “코드는 Git, 바이트는 DVC Remote”** 입니다.
- **원본은 항상 저장**, **파생/특성은 비용 기반**으로 저장 여부를 결정하세요.
- `dvc.yaml`·`dvc.lock`·`params.yaml`을 통한 **완전 재현성**이 담보되면,
  어떤 시점·브랜치에서도 **한 줄(`dvc repro`)**로 동일 산출물을 복원할 수 있습니다.