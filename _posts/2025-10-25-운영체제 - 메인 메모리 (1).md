---
layout: post
title: 운영체제 - 메인 메모리 (1)
date: 2025-10-25 14:30:23 +0900
category: 운영체제
---
# Chapter 9 — Main Memory

## 9.1 Background

### 9.1.1 목표와 역할
운영체제의 **메인 메모리 관리**는 다음을 동시에 달성해야 한다.

- **Relocation(재배치)**: 프로그램은 **어디에 로드되어도** 잘 동작해야 한다.
- **Protection(보호)**: 프로세스들은 **서로의 주소 공간**을 침범하면 안 된다.
- **Sharing(공유)**: 코드·데이터를 안전하게 공유(예: libc 텍스트 공유).
- **Logical vs Physical**: 프로세스는 **논리 주소**(가상 주소)를, 하드웨어는 **물리 주소**를 사용 → **MMU**가 변환.

### 9.1.2 주소 바인딩과 시점
- **Compile time**: 절대 주소(거의 사용 X).
- **Load time**: 로더가 기저(base)에 상대 오프셋을 더해 기록.
- **Execution time**: **MMU**가 **동적 재배치**(가상→물리) 수행 → 현대 CPU 기본.

### 9.1.3 보호 기법(기본 형태)
- **Base/Limit** 레지스터:  
  $$\text{물리주소} = \text{base} + \text{논리주소},\quad 0 \le \text{논리주소} < \text{limit}$$  
  단점: **연속 할당**만 가능 → **외부 단편화** 발생. 해결: **페이징**(9.3).

### 9.1.4 스와핑(개요)
- 메모리가 부족하면 프로세스를 **디스크로 스왑아웃** 후 나중에 **스왑인**.  
- 현대 일반 OS는 **페이지 단위** 스와핑(= **demand paging**)을 주로 사용.

---

## 9.2 Contiguous Memory Allocation

연속 할당은 **프로세스 전체**가 메모리에서 **연속한 블록**을 차지한다.

### 9.2.1 고정 분할 vs 가변 분할
- **Fixed partition**: 메모리를 고정 크기 파티션으로 나눔 → 내부 단편화↑.
- **Variable partition**: 요청 시 필요한 크기만큼 블록을 할당 → **외부 단편화**가 핵심 문제.

### 9.2.2 단편화
- **내부 단편화**: 블록 크기 − 실제 사용량  
  $$\text{Internal} = \sum_i (\text{allocated}_i - \text{requested}_i)$$
- **외부 단편화**: 총 여유는 충분하지만 **연속한** 큰 블록이 없음.  
  경험적 법칙: 가변 분할에서 평균적으로 **외부 단편화 ≈ 할당량의 1/3** 수준으로 수렴(엄밀 공식 아님, 직관 가이드).

### 9.2.3 배치(placement) 알고리즘
- **First-fit**: 처음 맞는 빈 블록. 빠름, 단편화 중간.
- **Best-fit**: 가장 작은 맞춤 블록. 쪼개진 작은 조각이 많이 남을 수 있음.
- **Worst-fit**: 가장 큰 블록. 큰 조각을 더 잘 보존할 때 의미가 있으나 대체로 효과 미지수.
- **Next-fit**: last-fit 위치부터 검색 → 탐색 편향 완화.

#### (실습) 연속 할당 시뮬레이터 (Python)
```python
# contiguous_allocator.py
from dataclasses import dataclass
from typing import List, Tuple, Optional

@dataclass
class Hole:
    start: int
    size: int

class ContiguousAllocator:
    def __init__(self, mem_size: int):
        self.mem_size = mem_size
        self.holes: List[Hole] = [Hole(0, mem_size)]
        self.allocs = {}  # pid -> (start, size)

    def _find_first_fit(self, size)->Optional[int]:
        for i,h in enumerate(self.holes):
            if h.size >= size:
                return i
        return None

    def _find_best_fit(self, size)->Optional[int]:
        cand = [(i,h.size) for i,h in enumerate(self.holes) if h.size >= size]
        return min(cand, key=lambda x:x[1])[0] if cand else None

    def _find_worst_fit(self, size)->Optional[int]:
        cand = [(i,h.size) for i,h in enumerate(self.holes) if h.size >= size]
        return max(cand, key=lambda x:x[1])[0] if cand else None

    def alloc(self, pid:int, size:int, policy="first")->Optional[Tuple[int,int]]:
        idx = {"first":self._find_first_fit,
               "best":self._find_best_fit,
               "worst":self._find_worst_fit}[policy](size)
        if idx is None: return None
        h = self.holes[idx]
        start = h.start
        self.allocs[pid] = (start, size)
        # split hole
        h.start += size
        h.size  -= size
        if h.size == 0: self.holes.pop(idx)
        return start, size

    def free(self, pid:int):
        if pid not in self.allocs: return
        start,size = self.allocs.pop(pid)
        self.holes.append(Hole(start,size))
        self._coalesce()

    def _coalesce(self):
        self.holes.sort(key=lambda h:h.start)
        merged = []
        for h in self.holes:
            if not merged or merged[-1].start+merged[-1].size < h.start:
                merged.append(h)
            else:
                merged[-1].size += h.size
        self.holes = merged

    def external_fragmentation(self)->int:
        # 총 홀 크기 - 최댓값(=가장 큰 연속 블록)
        if not self.holes: return 0
        total = sum(h.size for h in self.holes)
        largest = max(h.size for h in self.holes)
        return total - largest

# demo
if __name__ == "__main__":
    ca = ContiguousAllocator(1024)
    ca.alloc(1, 100, "first")
    ca.alloc(2, 300, "first")
    ca.alloc(3, 50,  "first")
    ca.free(2)
    ca.alloc(4, 120, "best")
    print("holes:", ca.holes)
    print("external frag:", ca.external_fragmentation())
```

**해설**  
- `external_fragmentation()`은 **총 빈 공간 − 가장 큰 연속 블록**으로 간단 근사.  
- `coalesce`로 인접 홀 병합 → **압축(compaction)** 의 소프트 대체(하드웨어/OS 레벨의 실제 compaction은 페이지 이동 필요).

### 9.2.4 Compaction(압축)
- **외부 단편화**를 줄이기 위해 **메모리 내 블록들을 이동**해 홀을 합친다.  
- **실행 중 재배치**가 필요 → 순수 연속 할당 체계에서는 **비용 큼**.  
- 해결: **페이징**으로 논리적 연속성을 **물리적 비연속성**으로 대체(9.3).

---

## 9.3 Paging

페이징은 **고정 크기** 단위(페이지/프레임)로 **가상 주소 공간**을 **물리 메모리**에 매핑한다.

### 9.3.1 용어
- **Page**: 가상 메모리의 고정 크기 블록(예: 4 KiB, 16 KiB, 64 KiB …).
- **Frame**: 물리 메모리의 같은 크기 블록.
- **Page Table**: **VPN → PFN**(page frame number) 매핑 테이블.
- **TLB**: 최근 주소 변환을 캐시하는 **소형 고속 캐시**.

### 9.3.2 주소 분해
가상 주소 `VA`를 **상위 비트(VPN)** 와 **하위 비트(offset)** 로 분할:

- 페이지 크기가 \(2^k\) 이면  
  $$\text{offset} = VA \ \&\ (2^k-1),\quad VPN = VA \gg k$$
- 물리 주소:  
  $$PA = (PFN \ll k) \ \vert \ \text{offset}$$

#### (예제) 주소 변환 계산
- 페이지 크기 = 4 KiB → \(k=12\)  
- `VA = 0x12345` → `VPN = 0x12345 >> 12 = 0x12`(18), `offset = 0x345`  
- PageTable[18] = PFN= `0x77` → `PA = (0x77<<12) | 0x345`.

### 9.3.3 내부 단편화(페이징)
- 요청이 페이지 경계를 넘지 않더라도 **마지막 페이지의 남는 공간**은 사용하지 못함.  
  평균 내부 단편화는 **페이지 크기의 절반** 수준으로 근사.

### 9.3.4 페이지 크기 트레이드오프
- **크게**: 페이지 테이블 작아짐, TLB 커버리지↑, 내부 단편화↑, I/O 한 번당 전송량↑.
- **작게**: 내부 단편화↓, 세밀한 보호/공유, 페이지 테이블↑, TLB 미스↑ 가능.

### 9.3.5 TLB와 EAT
- TLB hit rate: \(h\), 메모리 접근 시간: \(m\), TLB 접근 시간: \(t\).  
  **유효 접근 시간(EAT)** 근사:
  $$EAT \approx h\cdot (t + m) + (1-h)\cdot (t + m + m)$$
  (미스 시 **PTE 읽기** + **데이터 접근**으로 메모리 2회. 멀티레벨이면 더 큼.)

### 9.3.6 공유와 COW
- **공유 텍스트**: 여러 프로세스가 **읽기 전용** 코드 페이지 공유.
- **Copy-on-Write**: `fork()` 등에서 부모/자식이 페이지를 공유하다가 **쓰기 시에만 복사**.

#### (실습) 간단 페이징 + TLB 시뮬 (Python)
```python
# paging_tlb_sim.py
from collections import OrderedDict

class LRUCache(OrderedDict):
    def __init__(self, cap): super().__init__(); self.cap=cap
    def get(self, k):
        if k in self:
            self.move_to_end(k)
            return self[k]
        return None
    def put(self, k, v):
        if k in self: self.move_to_end(k)
        self[k]=v
        if len(self)>self.cap: self.popitem(last=False)

class Pager:
    def __init__(self, page_bits=12, tlb_entries=16):
        self.k = page_bits
        self.pt = {}       # VPN -> PFN
        self.tlb = LRUCache(tlb_entries)
        self.next_pfn = 0  # free list 생략

    def map(self, vpn, pfn=None):
        if pfn is None: pfn=self.next_pfn; self.next_pfn+=1
        self.pt[vpn]=pfn

    def translate(self, va):
        vpn = va >> self.k
        off = va & ((1<<self.k)-1)
        pfn = self.tlb.get(vpn)
        hit = True
        if pfn is None:
            hit = False
            pfn = self.pt.get(vpn)
            if pfn is None: raise KeyError("page fault")
            self.tlb.put(vpn, pfn)
        pa = (pfn<<self.k) | off
        return pa, hit

# demo
if __name__=="__main__":
    pager = Pager(page_bits=12, tlb_entries=4)
    for vpn in range(8): pager.map(vpn)      # 간단 매핑
    addrs = [0x1234, 0x1ABC, 0x2234, 0x1235, 0x3FFF, 0x4234, 0x5234, 0x1236]
    hits=0
    for a in addrs:
        pa, hit = pager.translate(a)
        hits += hit
    print("TLB hit rate:", hits/len(addrs))
```

---

## 9.4 Structure of the Page Table

현대 OS는 **페이지 테이블**을 다양한 구조로 구현한다. 핵심 이슈는 **메모리 오버헤드**·**변환 비용**·**TLB 상호작용**이다.

### 9.4.1 PTE(Page Table Entry) 구성
일반적인 PTE 필드(아키텍처마다 다름):

- **PFN**: 페이지 프레임 번호
- **V/Present**: 유효/메모리에 존재
- **R/W/X**: 접근 권한(읽기/쓰기/실행)
- **U/S**: 사용자/커널 접근
- **A(Accessed)/Referenced**: 참조 비트
- **D(Dirty)**: 쓰기 발생
- **G(Global)**: 컨텍스트 불변 페이지
- **NX/XD**: 실행 금지(DEP)
- **Software bits**: OS가 임의로 쓰는 비트(예: COW 표시)

#### (예제) PTE 비트필드 (C, 개념적)
```c
// pte_bits.c — 개념적 비트필드 (실제 아키텍처와 다를 수 있음)
#include <stdint.h>
typedef struct {
    uint64_t present : 1;   // V
    uint64_t rw      : 1;   // R/W
    uint64_t us      : 1;   // U/S
    uint64_t pwt     : 1;   // write-through
    uint64_t pcd     : 1;   // cache disable
    uint64_t a       : 1;   // accessed
    uint64_t d       : 1;   // dirty
    uint64_t pat     : 1;   // page attribute table
    uint64_t g       : 1;   // global
    uint64_t ign     : 3;   // ignored
    uint64_t pfn     : 36;  // PFN (가정)
    uint64_t sw      : 7;   // OS software bits
    uint64_t protkey : 4;   // protection key
    uint64_t nx      : 1;   // no-execute
} pte_t;
```

### 9.4.2 선형(단일 레벨) 페이지 테이블
- **장점**: 변환이 단순.  
- **단점**: 주소 공간이 크면 테이블이 **매우 큼**(예: 48-bit VA, 4 KiB 페이지 → 2^36 엔트리 잠재).

### 9.4.3 다단계(계층적) 페이지 테이블
**아이디어**: 사용하지 않는 주소 범위의 **하위 테이블을 아예 만들지 않음**(sparse-friendly).

- 2-레벨 예(32-bit, 4 KiB 페이지, 10/10/12 분할):  
  $$VA = \underbrace{\text{Dir}}_{10} \ \underbrace{\text{Tbl}}_{10} \ \underbrace{\text{Offset}}_{12}$$  
  변환: **디렉터리 엔트리(PDE)** → **테이블 엔트리(PTE)** → PFN.

- 3-레벨/4-레벨(현대 x86-64): PML4→PDPT→PD→PT→오프셋 (4-level), 혹은 5레벨까지.

#### (실습) 2-레벨 변환 시뮬 (Python)
```python
# two_level_pt.py — 10/10/12 분할 시뮬
PAGE_BITS = 12
L1_BITS   = 10
L2_BITS   = 10

class TwoLevelPT:
    def __init__(self):
        self.dir = {}  # L1 index -> L2 dict
        self.next_pfn = 0

    def map(self, va, pfn=None):
        vpn = va >> PAGE_BITS
        l1 = (vpn >> L2_BITS) & ((1<<L1_BITS)-1)
        l2 = vpn & ((1<<L2_BITS)-1)
        if l1 not in self.dir: self.dir[l1] = {}
        if pfn is None: pfn = self.next_pfn; self.next_pfn += 1
        self.dir[l1][l2] = pfn

    def translate(self, va):
        off = va & ((1<<PAGE_BITS)-1)
        vpn = va >> PAGE_BITS
        l1 = (vpn >> L2_BITS) & ((1<<L1_BITS)-1)
        l2 = vpn & ((1<<L2_BITS)-1)
        if l1 not in self.dir or l2 not in self.dir[l1]:
            raise KeyError("page fault")
        pfn = self.dir[l1][l2]
        return (pfn<<PAGE_BITS)|off

# demo
if __name__=="__main__":
    pt = TwoLevelPT()
    for va in (0x00401234, 0x01405678, 0x80400000):
        pt.map(va)
        print(hex(pt.translate(va)))
```

**장점**: 실제 사용 영역만 테이블을 생성 → **테이블 메모리 절약**.  
**단점**: TLB 미스 시 **메모리 접근이 계층 수만큼** 증가.

### 9.4.4 해시/역(inverted) 페이지 테이블

#### Hashed Page Table (주로 64-bit, HP-UX 등 전통)
- **키**: \( (ASID, VPN) \) → **해시 체인**으로 PFN 찾기.  
- **장점**: **거대한 VA**에 대해 테이블 크기 절약.  
- **단점**: 충돌 처리(체인), 해시 비용.

#### Inverted Page Table (PowerPC/AIX 등)
- **프레임 수** 만큼만 엔트리를 둠(= 물리 메모리 크기에 비례).  
- 각 엔트리는 “이 프레임을 소유한 (PID/ASID, VPN)” 정보.  
- 변환은 \( (ASID, VPN) \)으로 **탐색**(해시) → PFN.  
- **장점**: 주소 공간 크기와 무관하게 **프레임 수**에 비례.  
- **단점**: 탐색/충돌 처리 필요 → TLB 의존도↑.

#### (실습) 단순 Inverted PT 스케치 (Python)
```python
# inverted_pt.py — 개념적
from collections import defaultdict

class InvertedPT:
    def __init__(self, nframes:int):
        self.nf = nframes
        self.table = [None]*nframes  # (asid, vpn)
        self.hash = defaultdict(list) # simple chaining: key -> list of frame idx
        self.next = 0

    def map(self, asid:int, vpn:int):
        f = self.next % self.nf; self.next += 1
        self.table[f] = (asid, vpn)
        self.hash[(asid, vpn)].append(f)
        return f

    def translate(self, asid:int, va:int, page_bits=12):
        vpn = va >> page_bits; off = va & ((1<<page_bits)-1)
        frames = self.hash.get((asid, vpn), [])
        if not frames: raise KeyError("page fault")
        # 여러 프레임이 걸려있을 일은 정상에선 없음(여기선 단순화)
        pfn = frames[0]
        return (pfn<<page_bits)|off
```

### 9.4.5 프레임 테이블 & 교체 연계
- **Frame Table**: 각 물리 프레임의 상태(참조/더티/소유자/핀 등) 기록.
- 페이징 **교체 알고리즘**(LRU/Clock)은 **참조 비트** 등과 강하게 연동(다음 장, 메모리 관리 심화에서 상세).

### 9.4.6 대페이지/슈퍼페이지(Transparent Huge Pages)
- 2 MiB/1 GiB(아키텍처별) 같은 **큰 페이지** 지원.  
- **TLB 커버리지** 크게 증가 → HPC/DB/GC 등에서 성능 유리.  
- 단점: 내부 단편화↑, 메모리 압력/스왑 시 비용↑.

---

## 보충: 실습 과제 & 체크리스트

### 과제 A — First/Best/Worst-fit의 외부 단편화 비교
1) `contiguous_allocator.py`로 랜덤 요청(지수/균일 분포) 생성.  
2) 정책별 **외부 단편화** 및 **평균 탐색 길이** 비교.  
3) compaction(강제 coalesce) 유무에 따른 차이 관측.

### 과제 B — 페이지 크기에 따른 EAT 비교
1) `paging_tlb_sim.py`에서 \(k\)를 12/16/21로 바꾸며 워크셋 접근.  
2) TLB 엔트리 수를 16/64/256으로 스윕.  
3) **TLB hit rate**·**EAT 근사** 비교 후 페이지 크기 trade-off 정리.

### 과제 C — 2-레벨 vs 선형 PT 메모리 오버헤드
1) `two_level_pt.py`로 희소/밀집 VA를 랜덤 생성 후, 생성된 L2 테이블 수 기록.  
2) 선형 PT 대비 **오버헤드 절감률** 계산.

---

## 핵심 요약

- **9.1 배경**: 실행 시점 주소 변환(MMU), 보호·공유·재배치가 핵심.  
- **9.2 연속 할당**: 간단하지만 **외부 단편화**가 본질. compaction 비용 큼.  
- **9.3 페이징**: **비연속 물리 매핑**으로 외부 단편화 제거, 대신 **TLB/EAT** 관리가 성능 포인트.  
- **9.4 페이지 테이블 구조**: 선형은 단순하지만 크고, **다단계/해시/역 PT**로 오버헤드 절감. TLB 미스 비용과의 균형이 관건.

---

## 부록: 수식 모음

- **주소 분해**  
  $$\text{offset} = VA \bmod 2^k,\quad VPN = \left\lfloor \frac{VA}{2^k}\right\rfloor$$
- **EAT 근사(단일 레벨 PT)**  
  $$EAT \approx h(t+m) + (1-h)(t+2m)$$
- **내부 단편화(평균)**  
  $$E[\text{internal}] \approx \frac{\text{page\_size}}{2}$$