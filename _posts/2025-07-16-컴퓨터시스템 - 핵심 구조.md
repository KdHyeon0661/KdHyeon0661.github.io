---
layout: post
title: 컴퓨터시스템 - 핵심 구조
date: 2025-07-16 17:20:23 +0900
category: 컴퓨터시스템
---
# 컴퓨터 시스템의 핵심 구조: 캐시, 저장장치, 운영체제, 그리고 네트워크

## 0. 개요 — 층위가 만드는 성능의 질서

현대 컴퓨터 시스템은 **시간·공간·비용**의 타협 위에 서 있다.

- 시간(지연·대역폭): L1 캐시는 수 ns, NVMe는 수십 μs, 네트워크 RTT는 ms.
- 공간(용량): 레지스터 ≪ 캐시 ≪ DRAM ≪ SSD/HDD ≪ 오브젝트 스토리지.
- 비용/GB: 반대로 커질수록 싸진다.

이 글은 네 축을 촘촘히 잇는다.

1. **캐시**: 지역성, 연관도, 라인/셋, 일관성, TLB, NUMA, 거짓 공유, 사전 인출(prefetch).
2. **저장장치**: DRAM↔SSD↔HDD, NVMe 큐, 파일시스템/저널링, 페이지 캐시, FIO로 측정.
3. **운영체제**: 프로세스/스레드/스케줄러, 가상메모리, COW, 시스템콜, `mmap`, 동기화.
4. **네트워크**: TCP/UDP/QUIC, 혼잡제어, BDP, 소켓 버퍼, Nagle, `epoll`, 간단 서버/클라.

마지막에는 **엔드-투-엔드 튜닝 시나리오**로 마무리한다.

---

## 1. 캐시 — 지역성과 레이아웃이 지연을 지배한다

### 1.1 캐시 기본: 라인, 셋, 연관도

- **캐시 라인(cache line)**: 보통 64B 단위 전송/저장.
- **셋-연관도**: Set-Associative(예: 8-way). 인덱스로 셋을 고르고 그 안에서 태그 매칭.
- **쓰기 정책**: write-back + write-allocate가 일반적.

**평균 메모리 접근 시간(AMAT)**

$$
\text{AMAT}
= \text{HitTime}_{L1}
+ \text{MissRate}_{L1}\big(
  \text{HitTime}_{L2}
  + \text{MissRate}_{L2}\big(
    \text{HitTime}_{L3}
    + \text{MissRate}_{L3}\cdot \text{MemLatency}
  \big)
\big)
$$

핵심은 **MissRate를 구조적으로 낮추는 레이아웃**이다.

### 1.2 지역성의 두 얼굴: 시간·공간

- **시간 지역성**: 같은 데이터 재접근이 잦다(카운터, 루프 불변값).
- **공간 지역성**: 인접 데이터도 곧 접근한다(배열 순회).

#### 예제 A — 행우선 vs 열우선 순회 (C)

캐시 라인과 행렬 레이아웃(행렬은 행-연속 저장)의 충돌을 눈으로 보자.

```c
// gcc -O2 stride.c -o stride && /usr/bin/time -f "%E %MKB" ./stride
#include <stdio.h>
#include <stdlib.h>
#include <stdint.h>
#include <time.h>

#define N 4096
static int a[N][N];

static inline double now() {
    struct timespec ts; clock_gettime(CLOCK_MONOTONIC, &ts);
    return ts.tv_sec + ts.tv_nsec*1e-9;
}

int main(){
    for(int i=0;i<N;i++) for(int j=0;j<N;j++) a[i][j]=i+j;

    volatile long long sum=0;
    double t=now();
    // 행우선 접근: 공간 지역성 ↑
    for(int i=0;i<N;i++)
        for(int j=0;j<N;j++)
            sum += a[i][j];
    double t1=now();

    // 열우선 접근: 캐시 미스 폭증
    for(int j=0;j<N;j++)
        for(int i=0;i<N;i++)
            sum += a[i][j];
    double t2=now();

    printf("row-major: %.3f s, col-major: %.3f s, sum=%lld\n",
        t1 - t, t2 - t1, sum);
    return 0;
}
```

**관찰 포인트**

- 같은 산술량이라도 **메모리 접근 패턴**이 시간을 좌우한다.
- `col-major`는 라인마다 새로운 페이지/라인을 건드려 **TLB 미스**까지 유발.

### 1.3 TLB — 주소 변환의 캐시

가상주소→물리주소 변환용 **TLB(Translation Lookaside Buffer)** 도 계층적이다(L1/L2 TLB).  
**페이지 크기**(4KB, 2MB hugepage 등)는 TLB 히트율에 결정적이다.

- 대규모 배열 스트라이드 접근 → **TLB 스로싱** 가능.
- 해결책: **연속·큰 페이지**, **데이터 레이아웃 재설계**, **타일링(blocking)**.

#### 예제 B — 타일링으로 TLB/캐시 동시 최적화

```c
// 간단한 타일링 매트릭스 덧셈
#define BS 64
for (int ii=0; ii<N; ii+=BS)
  for (int jj=0; jj<N; jj+=BS)
    for (int i=ii; i<ii+BS; ++i)
      for (int j=jj; j<jj+BS; ++j)
        C[i][j] = A[i][j] + B[i][j];
```

- BS는 L1/L2 용량, 라인 크기, 연관도를 감안해 **실험**으로 찾는다.

### 1.4 멀티코어와 캐시 일관성, 그리고 거짓 공유

- **MESI** 계열 프로토콜로 라인 수준 일관성을 유지.
- **거짓 공유(false sharing)**: 서로 다른 스레드가 **같은 캐시 라인**의 서로 다른 변수를 갱신 → 불필요한 invalidation 핑퐁.

#### 예제 C — 거짓 공유와 패딩(64B 정렬)

```c
// gcc -O2 -pthread false_share.c -o fs && ./fs
#include <pthread.h>
#include <stdalign.h>
#include <stdio.h>

#define N 100000000
typedef struct { alignas(64) long long v; } padded;

padded counters[2]; // 각 원소가 다른 라인에 놓이도록

void* t0(void* p){ for(int i=0;i<N;i++) counters[0].v++; return NULL; }
void* t1(void* p){ for(int i=0;i<N;i++) counters[1].v++; return NULL; }

int main(){
    pthread_t a,b;
    pthread_create(&a,NULL,t0,NULL);
    pthread_create(&b,NULL,t1,NULL);
    pthread_join(a,NULL); pthread_join(b,NULL);
    printf("%lld %lld\n", counters[0].v, counters[1].v);
}
```

- `alignas(64)` 패딩으로 **라인 분리** → 스케일링 회복.

### 1.5 프리패처, 분기 예측, 구조적 최적화

- **하드웨어 프리패처**는 선형·규칙적 패턴에 강하다. 링크드리스트는 약하다 → **배열화**가 유리.
- **분기 예측 실패**도 파이프라인 플러시로 큰 손실. **분기 없는 코드**(bit trick, LUT)가 유리할 때가 많다.

---

## 2. 저장장치 — DRAM·SSD·HDD와 파일시스템의 만남

### 2.1 계층과 특성

| 계층 | 대략 지연 | 대역폭 | 랜덤 IOPS | 비고 |
|---|---:|---:|---:|---|
| DRAM | ~100 ns | 10~100 GB/s | – | 휘발성 |
| NVMe SSD | 70–150 μs | 2–7 GB/s | 100k–1M | 병렬 큐/딥 |
| SATA SSD | ~100 μs | 0.5–0.6 GB/s | ~100k | AHCI |
| HDD | 4–12 ms | 100–250 MB/s | 수백 | 탐색·회전 지연 |
| 원격 객체 | ms–수백ms | – | – | 대용량/저비용 |

**NVMe 큐(pair)**가 높은 IOPS의 비결. 병렬 제출/완료 큐로 커널/디바이스 협업.

### 2.2 페이지 캐시와 Direct I/O

- **페이지 캐시**: 파일 데이터를 DRAM에 캐시, read hit 시 SSD 미접근.
- **Direct I/O**: 캐시 우회를 통해 이중복제 방지/일관 레이턴시, 대용량 DB에서 유용.

#### 예제 D — `mmap` vs `read`

```c
// 파일을 메모리맵으로 스캔
#include <sys/mman.h>
#include <sys/stat.h>
#include <fcntl.h>
#include <unistd.h>
#include <stdint.h>
#include <stdio.h>

int main(int argc,char**argv){
    int fd=open(argv[1],O_RDONLY);
    struct stat st; fstat(fd,&st);
    uint8_t* p=mmap(NULL,st.st_size,PROT_READ,MAP_PRIVATE,fd,0);
    long long sum=0;
    for(off_t i=0;i<st.st_size;i++) sum+=p[i];
    printf("%lld\n",sum);
    munmap(p, st.st_size); close(fd);
}
```

- `mmap`는 **page fault** 기반 지연 로딩. 순차 스캔에서 커널 프리패처 + read-ahead의 도움을 받음.

### 2.3 파일시스템·저널링·동시성

- Ext4/XFS/Btrfs 등은 **저널링**으로 메타데이터 일관성 보장.
- **쓰기 증폭(write amplification)**: 작은 랜덤 쓰기를 내부적으로 큰 단위로 쓰며 증폭.  
  SSD는 FTL(Flash Translation Layer)과 GC 때문에 더 민감 → **정렬(align)**, **배치 쓰기**가 유리.

$$
\text{WriteAmp} \approx \frac{\text{NAND 쓰기 총량}}{\text{호스트 쓰기 총량}} \ge 1
$$

### 2.4 FIO로 성능 측정(재현 실험)

#### 예제 E — 랜덤/순차 측정 (fio jobfile)

```ini
; fio --name=seqread --filename=/data/testfile --size=4G --rw=read --bs=1M --iodepth=32 --numjobs=1 --direct=1
; fio --name=randread --filename=/data/testfile --size=4G --rw=randread --bs=4k --iodepth=64 --numjobs=4 --direct=1
[global]
ioengine=libaio
runtime=30
time_based=1
numjobs=1
direct=1

[seqread]
rw=read
bs=1M
iodepth=32
size=4G

[randread]
rw=randread
bs=4k
iodepth=64
numjobs=4
size=4G
```

- **해석 요령**: MB/s(순차), kIOPS·p99(랜덤), `clat`/`slat` 분해, CPU%.

### 2.5 LSM vs B-Tree (KV 스토어 설계 관점)

- **B-Tree**: 읽기 빠름, 랜덤 쓰기 비용 큼.
- **LSM(Log-Structured Merge)**: 쓰기 집약 워크로드에 유리, 컴팩션으로 읽기 앰프 발생.  
  시스템 요구에 따라 자료구조 선택이 성능을 좌우한다.

---

## 3. 운영체제 — 추상화·격리·스케줄링

### 3.1 프로세스·스레드·컨텍스트 스위치

- **프로세스**: 독립 주소공간 + 리소스.  
- **스레드**: 주소공간 공유, 스케줄링 단위.  
- **컨텍스트 스위치 비용**: 레지스터/PC/스택 교체 + TLB flush (상황에 따라).

### 3.2 가상메모리·COW·페이지 폴트

- **페이지 폴트**: 접근 시점에 실제 페이지 매핑/로딩.
- **COW(Copy-on-Write)**: `fork()` 직후 페이지 공유, 쓰기 시 복제 → 빠른 프로세스 생성.

#### 예제 F — `fork`/`exec`와 COW

```c
#include <unistd.h>
#include <stdio.h>
#include <sys/wait.h>
#include <string.h>

int main(){
    char msg[]="hello";
    pid_t pid=fork();
    if(pid==0){
        msg[0]='H'; // 쓰기 시 COW 발생
        execlp("echo","echo",msg,NULL);
    } else {
        wait(NULL);
        printf("parent sees: %s\n", msg); // "hello"
    }
}
```

### 3.3 시스템 콜 비용과 배치

- **유저↔커널 모드 전환**은 저렴하지 않다.  
  → **배치(batch)**, **비동기(urings, aio)**, **파이프라인**으로 amortize.

### 3.4 동기화 — 뮤텍스·원자적 연산·경합 회피

#### 예제 G — 경쟁 조건과 해결

```c
// -pthread 필요
#include <pthread.h>
#include <stdio.h>

long long counter=0;
pthread_mutex_t mtx = PTHREAD_MUTEX_INITIALIZER;

void* worker(void*){
    for(int i=0;i<1000000;i++){
        pthread_mutex_lock(&mtx);
        counter++;
        pthread_mutex_unlock(&mtx);
    }
    return NULL;
}

int main(){
    pthread_t t1,t2;
    pthread_create(&t1,NULL,worker,NULL);
    pthread_create(&t2,NULL,worker,NULL);
    pthread_join(t1,NULL); pthread_join(t2,NULL);
    printf("%lld\n", counter);
}
```

- **핫스팟 보호 범위 최소화**, **sharding**, **lock-free**(CAS) 등 구조적 회피가 더 강력하다.

### 3.5 `mmap`/페이지 캐시/버퍼 캐시의 상호작용

- 같은 파일을 `read()` vs `mmap()`하면 **페이지 캐시**를 공유.  
- `msync()`, `O_DIRECT`, `posix_fadvise()`로 I/O 힌트를 전달 가능.

---

## 4. 네트워크 — 레이턴시·대역폭·프로토콜 스택 다루기

### 4.1 TCP 수립·흐름제어·혼잡제어·BDP

- 3-way handshake → RTT 소모.
- **혼잡제어**: Reno/CUBIC/BBR 등. 스루풋은 경로 특성에 좌우.

**BDP(Bandwidth-Delay Product)**

$$
\text{BDP} = \text{대역폭} \times \text{RTT}
$$

윈도우가 BDP보다 작으면 링크를 **가득 채우지 못한다**.  
→ **소켓 버퍼/`tcp_rmem`/`tcp_wmem`** 조정, **호출 배치**로 효율↑.

### 4.2 Nagle, Delayed ACK, TIME_WAIT

- **Nagle**: 작은 패킷 합치기 → 지연 vs 효율. 지연 민감이면 `TCP_NODELAY`.
- **TIME_WAIT**: 종단 정리 상태. 고연결 서비스는 **포트 고갈** 대비 튜닝 필요.

### 4.3 UDP와 QUIC

- UDP는 경량·무연결. 재전송/순서/흐름제어는 애플리케이션 몫.
- QUIC(UDP 위): **1-RTT 핸드셰이크**, 헤드-오브-라인 차단 완화, 연결 마이그레이션.

### 4.4 소켓 프로그래밍 실습

#### 예제 H — 최소 HTTP 클라이언트 (Python)

```python
import socket, ssl

host = "example.org"; port = 443
ctx = ssl.create_default_context()
with socket.create_connection((host, port)) as raw:
    with ctx.wrap_socket(raw, server_hostname=host) as s:
        req = f"GET / HTTP/1.1\r\nHost: {host}\r\nConnection: close\r\n\r\n"
        s.sendall(req.encode())
        buf = bytearray()
        while True:
            chunk = s.recv(4096)
            if not chunk: break
            buf.extend(chunk)
print(buf.decode(errors="ignore").split("\r\n\r\n",1)[0])
```

#### 예제 I — `epoll` 기반 에코 서버 (C, 요지)

```c
// gcc -O2 ep.c -o ep && sudo ./ep 9000
// 연결이 많아도 1 스레드에서 이벤트로 처리
#include <sys/epoll.h> // ... 생략: 소켓 생성, non-block, bind/listen
// 핵심 루프 개요:
int ep = epoll_create1(0);
struct epoll_event ev, evs[1024];
ev.events = EPOLLIN; ev.data.fd = listen_fd;
epoll_ctl(ep, EPOLL_CTL_ADD, listen_fd, &ev);
for(;;){
    int n = epoll_wait(ep, evs, 1024, -1);
    for(int i=0;i<n;i++){
        if(evs[i].data.fd == listen_fd){
            // accept loop; EPOLLET인 경우 drain
        }else{
            // recv → send (에코); EAGAIN 처리
        }
    }
}
```

- **논블로킹**, **엣지 트리거(EPOLLET)**, **버퍼 관리**가 핵심.

---

## 5. 엔드-투-엔드: “로그 집계 서비스” 성능 올리기(사례)

요구: 에이전트가 로그를 보내면 수집기가 파싱·저장. 초당 수십만 라인 처리.

### 5.1 병목 가설 수립

1) **네트워크**: RTT/BDP 부족, 작은 write 폭탄 → Nagle/ACK 상호작용.  
2) **OS**: syscalls 과다, 작은 read/write, 컨텍스트 스위치 폭증.  
3) **저장장치**: 랜덤 쓰기 난립, 저널 sync, fsync 폭주.  
4) **캐시/메모리**: 파서가 포인터 난사, 스팬/슬라이스 지역성 박살, TLB 미스.

### 5.2 구조적 해결

- **네트워크**: 에이전트는 **배치 전송**(frames), 서버는 `epoll` + 큰 SO_RCVBUF/SNDBUF, `TCP_NODELAY` 여부 실험, 압축(옵션).
- **OS**: **io_uring**/비동기, syscalls 묶기, `sendfile`/`splice`로 zero-copy.
- **저장장치**: **append log** + 주기적 batch flush, **Direct I/O**(DB), WAL로 내구성 분리.
- **캐시**: 파싱은 **단일 pass**, **구조체 AoS → SoA** 변환, **타일링**으로 hot set 유지.

### 5.3 체크리스트(핵심 계측 지표)

- p50/p95/p99 end-to-end 레이턴시, 큐 길이.
- CPU 프로파일(소프트/하드 미스, 브랜치 미스).
- 소켓 큐드롭/재전송, RTO, cwnd/RTT.
- fs `clat`/`slat`, IOPS, WAF, dirty page 비율, `vm.dirty_*`.

---

## 6. 실전 팁 — 코드·시스템 디자인 원칙

1) **데이터가 왕**: 연산보다 **이동**이 비싸다. 먼저 레이아웃을 설계하라.  
2) **큰 덩어리(batch)**: 캐시·TLB·시스템콜·I/O 모두 배치로 유리.  
3) **스트림화**: 한 번에 읽고 한 번에 처리. 역참조 최소화.  
4) **측정으로 결론**: 벤치 없이 추측 금지. FIO/`perf`/`pidstat`/`ss`/`ebpf`.  
5) **단순성 유지**: 복잡한 최적화는 회귀를 낳는다. 병목 하나씩.

---

## 부록 A) 라틴시/대역폭 치트시트(대략치)

| 리소스 | 지연 | 대역폭 |
|---|---:|---:|
| L1 hit | ~1 ns | – |
| L2 hit | ~3–5 ns | – |
| L3 hit | ~10–20 ns | – |
| DRAM | ~80–120 ns | 10–100 GB/s |
| NVMe | ~70–150 μs | 2–7 GB/s |
| HDD | ~4–12 ms | 100–250 MB/s |
| 동일 AZ 네트워크 RTT | ~0.1–1 ms | 10–100 Gbps |

> 수치는 플랫폼에 따라 달라진다. **자체 측정**으로 교체할 것.

---

## 부록 B) 수식 모음

**AMAT (재기재)**

$$
\text{AMAT}
= \text{HitTime}_{L1}
+ \text{MissRate}_{L1} \cdot \text{MissPenalty}_{L1}
$$

**네트워크 BDP**

$$
\text{BDP (bytes)} = \text{Bandwidth (bytes/s)} \times \text{RTT (s)}
$$

**RAID 5 유효 용량**

$$
C_{\text{eff}} = (N-1)\times C_{\text{disk}}
$$

---

## 부록 C) “성능 회귀” 디버깅 루틴

1) **재현 스크립트**를 만든다(고정 입력·고정 seed).  
2) **바이너리 탐색**으로 문제 릴리스 영역 좁히기.  
3) **상관계수 ≠ 인과**: 단일 변수 통제.  
4) **히스토그램**으로 tail 확인(p99↑가 전체 p50에 작은 영향일 수 있음).  
5) **rollback 기준**과 **교훈 기록**.

---

## 부록 D) 학습·실험 TODO

- 같은 알고리즘을 **AoS vs SoA**로 구현하고 L1D miss 비교.  
- `mmap` 파일 스캔 vs `read` 반복 vs `sendfile`로 카피 비용 비교.  
- `TCP_NODELAY` on/off, `SO_SNDBUF` 크기 변화로 p50/p99 비교.  
- FIO로 4KB 랜덤, 1MB 순차를 장치별 그래프화.  
- HugePage on/off로 TLB miss와 시간 비교.

---

## 결론

- **캐시**는 지역성이 먹여 살린다: 레이아웃과 패턴이 지연을 결정한다.  
- **저장장치**는 순차/랜덤의 전장이며, 파일시스템/페이지 캐시가 승부처다.  
- **운영체제**는 추상화의 대가로 전환비용을 요구한다: 배치·비동기로 줄여라.  
- **네트워크**는 BDP·혼잡제어의 게임: 윈도우와 버퍼·배치가 핵심이다.  

이 네 층위를 **동시에** 보며 설계를 반복하면, 같은 코드도 **배** 이상 빨라진다.  
성능은 우연이 아니라 **구조**와 **측정**의 결과다.