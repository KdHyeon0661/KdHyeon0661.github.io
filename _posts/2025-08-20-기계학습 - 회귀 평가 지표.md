---
layout: post
title: 기계학습 - 회귀 평가 지표
date: 2025-08-20 14:25:23 +0900
category: 기계학습
---
# 회귀 평가 지표: MSE, RMSE, MAE 완전 정리

회귀(regression) 모델의 예측 품질은 **오차(error)** 를 어떻게 요약하느냐로 평가됩니다.  
가장 널리 쓰이는 세 지표는 **MSE**, **RMSE**, **MAE**이며, 각기 다른 장단점과 해석을 가집니다.

---

## 1) 정의와 수식

데이터 \(\{(x_i, y_i)\}_{i=1}^n\), 예측 \(\hat{y}_i\)라 할 때, 잔차 \(e_i = y_i - \hat{y}_i\).

### • MSE (Mean Squared Error, 평균제곱오차)
- **큰 오차에 강한 패널티(L2)** 를 주는 지표
\[
\mathrm{MSE}=\frac{1}{n}\sum_{i=1}^n (y_i-\hat{y}_i)^2=\frac{1}{n}\sum_{i=1}^n e_i^2
\]

### • RMSE (Root Mean Squared Error, 평균제곱근오차)
- MSE의 **제곱근**. 단위가 \(y\)와 **동일**하여 해석이 쉽다.
\[
\mathrm{RMSE}=\sqrt{\frac{1}{n}\sum_{i=1}^n (y_i-\hat{y}_i)^2}=\sqrt{\mathrm{MSE}}
\]

### • MAE (Mean Absolute Error, 평균절대오차)
- **절대오차(L1)** 의 평균. **이상치(outlier)에 강건**하다.
\[
\mathrm{MAE}=\frac{1}{n}\sum_{i=1}^n |y_i-\hat{y}_i|=\frac{1}{n}\sum_{i=1}^n |e_i|
\]

---

## 2) 직관과 해석 포인트

- **MSE/RMSE**: 오차를 제곱하므로 **큰 오차를 과하게 벌**줍니다. 안전·규제·금전적 손실처럼 **큰 실수가 특히 위험**한 문제에 적합.  
- **RMSE vs MSE**: 같은 정보를 담지만 RMSE는 **원 단위**라 크기를 직감적으로 해석하기 쉽습니다. (예: “RMSE=2°C”)
- **MAE**: 모든 오차를 **선형**으로 취급. 이상치가 많거나 라벨에 노이즈가 두꺼운 꼬리(heavy tail)일 때 더 **안정적**입니다.

> **부등식**: \(\mathrm{RMSE}\ge \mathrm{MAE}\) (RMS–AM 부등식, \( |e_i|\ge 0 \))  
> 같아지는 경우는 모든 \(|e_i|\)가 동일할 때뿐.

---

## 3) 통계적 관점 (노이즈 가정과 최적화)

- **MSE 최소화**는 잔차가 **정규분포(가우시안) 노이즈**라는 가정하에서 **최대우도추정(MLE)** 에 해당합니다.  
  - 이때 **조건부 평균** \( \mathbb{E}[Y|X=x] \)을 잘 맞추는 모델이 최적.
- **MAE 최소화**는 잔차가 **라플라스(Laplace)** 분포 노이즈라는 가정에서 MLE이며,  
  - **조건부 중앙값** \( \mathrm{median}(Y|X=x) \)을 추정하도록 유도합니다.

> **Baseline**: MSE를 최소화하는 상수 예측은 **평균**, MAE를 최소화하는 상수 예측은 **중앙값**.

---

## 4) 미분(학습 시 그래디언트)

모델 출력 \(\hat{y}_i\)에 대한 미분(배치 평균 기준):

- **MSE**  
\[
\frac{\partial \mathrm{MSE}}{\partial \hat{y}_i}=\frac{2}{n}(\hat{y}_i-y_i)=-\frac{2}{n}e_i
\]

- **RMSE** (RMSE \(>0\) 가정)  
\[
\frac{\partial \mathrm{RMSE}}{\partial \hat{y}_i}=\frac{\hat{y}_i-y_i}{n\cdot \mathrm{RMSE}}=-\frac{e_i}{n\cdot \mathrm{RMSE}}
\]
  (RMSE가 0이면 기울기를 0으로 두는 구현이 일반적)

- **MAE** (0에서 미분불능 → **아아-서브그래디언트** 사용)  
\[
\frac{\partial \mathrm{MAE}}{\partial \hat{y}_i}\in \frac{1}{n}\cdot
\begin{cases}
\{+1\} & (\hat{y}_i>y_i)\\
[-1,+1] & (\hat{y}_i=y_i)\\
\{-1\} & (\hat{y}_i<y_i)
\end{cases}
\]
→ 딥러닝에서는 미분 가능 근사(예: **Huber** 또는 **Pseudo-Huber** 손실)를 자주 사용.

---

## 5) 이상치와 강건성(robustness)

- **MSE/RMSE**: \(\,e^2\) 때문에 **이상치 영향이 급격히 커짐** → 잘못된 라벨/센서 오류에 취약.  
- **MAE**: 선형 패널티 → **이상치의 영향이 제한적**.  
- **折衷**: Huber 손실  
\[
L_\delta(e)=
\begin{cases}
\frac{1}{2}e^2,& |e|\le \delta\\
\delta|e|-\frac{1}{2}\delta^2,& |e|>\delta
\end{cases}
\]
작은 오차는 MSE처럼, 큰 오차는 MAE처럼 처리.

---

## 6) 스케일, 단위, 가중

- **RMSE/MAE**는 **원 단위**로 해석 용이. MSE는 제곱 단위라 크기가 과장.  
- 피처/타깃의 스케일이 크면 지표도 커지므로, **표준화/정규화** 및 **상대 지표(RMSE/σ 등)** 병행을 고려.  
- **가중 MSE/MAE**로 관측 중요도를 반영할 수 있음:
\[
\mathrm{WMSE}=\frac{\sum w_i e_i^2}{\sum w_i},\quad
\mathrm{WMAE}=\frac{\sum w_i |e_i|}{\sum w_i}
\]

---

## 7) 언제 무엇을 쓸까?

| 상황 | 권장 지표 | 이유 |
|---|---|---|
| 큰 실수를 특히 피해야 함(안전·비용 급증) | **RMSE** | 큰 오차에 가중 페널티 |
| 라벨 노이즈/이상치가 많음 | **MAE** | 강건성 우수 |
| 가우시안 노이즈 가정·최적화 편의 | **MSE/RMSE** | 매끄러운 미분, 해석 용이 |
| 경영/현업 해석 쉬운 숫자 필요 | **RMSE/MAE** | 원 단위로 직관적 |

> 실무 팁: 튜닝·학습에는 MSE(RMSE)를 쓰되, **리포트에는 MAE도 함께** 제시하면 해석이 좋아집니다.

---

## 8) 간단 예시 (이상치 효과 비교)

데이터 \(y=[10,11,9,10,\mathbf{200}]\), 예측 \(\hat{y}=[10,10,10,10,10]\)

- 잔차 \(e=[0,1,-1,0,190]\)

\[
\begin{aligned}
\mathrm{MAE}&=\frac{1}{5}(0+1+1+0+190)=38.4\\
\mathrm{MSE}&=\frac{1}{5}(0^2+1^2+(-1)^2+0^2+190^2)=\frac{36102}{5}=7220.4\\
\mathrm{RMSE}&=\sqrt{7220.4}\approx 84.95
\end{aligned}
\]

→ **한 개의 이상치**가 RMSE/MSE를 크게 끌어올리는 반면, **MAE는 상대적으로 덜 증가**.

---

## 9) 구현 스니펫 (NumPy / scikit-learn)

```python
import numpy as np
from sklearn.metrics import mean_squared_error, mean_absolute_error

y_true = np.array([10, 11, 9, 10, 200])
y_pred = np.array([10, 10, 10, 10, 10])

mse  = mean_squared_error(y_true, y_pred)
rmse = mean_squared_error(y_true, y_pred, squared=False)  # RMSE
mae  = mean_absolute_error(y_true, y_pred)

print(f"MSE={mse:.2f}, RMSE={rmse:.2f}, MAE={mae:.2f}")
```

---

## 10) 한 걸음 더: Bias–Variance 관점

(모델 \(\hat{f}\)가 진실 함수 \(f\)를 추정한다고 할 때)
\[
\mathbb{E}[(\hat{f}(x)-y)^2]=\underbrace{(\mathbb{E}[\hat{f}(x)]-f(x))^2}_{\text{Bias}^2}+\underbrace{\mathbb{V}[\hat{f}(x)]}_{\text{Variance}}+\underbrace{\sigma^2}_{\text{Noise}}
\]
- **MSE/RMSE**는 이 합을 직접 측정 → **과적합(분산 ↑)** 과 **과소적합(바이어스 ↑)** 균형을 보는 데 유용.

---

### ✅ 요약
- **MSE**: 제곱 패널티(L2), 학습·최적화에 편리하나 **이상치 민감**  
- **RMSE**: MSE의 제곱근, **원 단위** 해석, **큰 오차 강조**  
- **MAE**: 절대오차(L1), **이상치에 강건**, 중앙값 추정과 연결  
- 선택은 **데이터 노이즈 특성**, **비즈니스 리스크**, **해석 편의**에 맞춰!