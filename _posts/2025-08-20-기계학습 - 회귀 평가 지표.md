---
layout: post
title: 기계학습 - 회귀 평가 지표
date: 2025-08-20 14:25:23 +0900
category: 기계학습
---
# 회귀 평가 지표: MSE, RMSE, MAE

## 1. 정의와 표기(Notation)

데이터 \( \{(x_i, y_i)\}_{i=1}^n \), 예측 \( \hat{y}_i=\hat{f}(x_i) \), 잔차 \( e_i = y_i - \hat{y}_i \)라 하자.

### • MSE (Mean Squared Error, 평균제곱오차)
$$
\mathrm{MSE} \;=\; \frac{1}{n}\sum_{i=1}^n (y_i-\hat{y}_i)^2 \;=\; \frac{1}{n}\sum_{i=1}^n e_i^2
$$

### • RMSE (Root Mean Squared Error, 평균제곱근오차)
$$
\mathrm{RMSE} \;=\; \sqrt{\frac{1}{n}\sum_{i=1}^n (y_i-\hat{y}_i)^2} \;=\; \sqrt{\mathrm{MSE}}
$$
- **원 단위**로 해석 가능(온도·가격 등 대상 변수의 단위와 동일).

### • MAE (Mean Absolute Error, 평균절대오차)
$$
\mathrm{MAE} \;=\; \frac{1}{n}\sum_{i=1}^n |y_i-\hat{y}_i| \;=\; \frac{1}{n}\sum_{i=1}^n |e_i|
$$
- 절대값 패널티(L1). **이상치(outlier)에 강건**.

> 벡터 표기(선형대수): \( \mathbf{e} = \mathbf{y}-\hat{\mathbf{y}} \).
> \( \mathrm{MSE}=\|\mathbf{e}\|_2^2/n,\;\; \mathrm{RMSE}=\|\mathbf{e}\|_2/\sqrt{n},\;\; \mathrm{MAE}=\|\mathbf{e}\|_1/n \).

---

## 2. 직관: 패널티 형상과 해석

- **MSE/RMSE = L2 패널티**
  - 오차를 제곱 → **큰 오차에 과도한 벌점**. 안전/품질/규제처럼 큰 실수가 특히 비싼 문제에 적합.
  - 등고선이 원형(유클리드 거리). 미분이 매끄러워 **최적화가 안정**.
- **MAE = L1 패널티**
  - 모든 오차에 **선형 패널티** → 이상치 영향 제한. 라벨 노이즈가 크거나 heavy tail일 때 유리.
  - 등고선이 다이아몬드(맨해튼 거리). 0에서 미분불능 → **서브그래디언트** 사용.

> **RMS–AM 부등식**으로 \( \mathrm{RMSE}\ge \mathrm{MAE} \).
> 모든 \(|e_i|\)가 같을 때에만 equality.

---

## 3. 통계적 관점(가정과 최적 추정치)

- **MSE 최소화 ↔ 가우시안(정규) 노이즈 MLE**
  - 이때 최적 예측은 **조건부 평균** \( \mathbb{E}[Y\mid X=x] \).
- **MAE 최소화 ↔ 라플라스 노이즈 MLE**
  - 이때 최적 예측은 **조건부 중앙값** \( \mathrm{median}(Y\mid X=x) \).

**상수모형 baseline**
- \( \hat{y}\equiv c \)일 때 MSE 최소 \( c=\bar{y} \) (평균), MAE 최소 \( c=\tilde{y} \) (중앙값).

---

## 4. 최적화: 미분/서브그래디언트

배치 평균 기준, 각 샘플 \(i\)에 대해:

- **MSE**
$$
\frac{\partial\,\mathrm{MSE}}{\partial \hat{y}_i} \;=\; \frac{2}{n}(\hat{y}_i - y_i) \;=\; -\frac{2}{n}e_i
$$

- **RMSE** (RMSE \(>0\) 가정)
$$
\frac{\partial\,\mathrm{RMSE}}{\partial \hat{y}_i}
\;=\; \frac{\hat{y}_i - y_i}{n\cdot \mathrm{RMSE}}
\;=\; -\frac{e_i}{n\cdot \mathrm{RMSE}}
$$

- **MAE** (0에서 미분불능 → **서브그래디언트**)
$$
\frac{\partial\,\mathrm{MAE}}{\partial \hat{y}_i}
\in \frac{1}{n}\cdot
\begin{cases}
\{+1\}, & \hat{y}_i>y_i \\
[-1,+1], & \hat{y}_i=y_i \\
\{-1\}, & \hat{y}_i<y_i
\end{cases}
$$

**Huber 손실(절충)**
작은 오차는 L2, 큰 오차는 L1로 다루는 매끄러운 대안:
$$
L_\delta(e)=
\begin{cases}
\frac{1}{2}e^2, & |e|\le \delta\\
\delta|e|-\frac{1}{2}\delta^2, & |e|>\delta
\end{cases}
$$

---

## 5. 이상치/Heavy-tail에서의 거동

예: \( y=[10,11,9,10,\mathbf{200}],\;\hat{y}=[10,10,10,10,10] \Rightarrow e=[0,1,-1,0,190] \)

$$
\begin{aligned}
\mathrm{MAE}&=\tfrac{1}{5}(0+1+1+0+190)=38.4 \\
\mathrm{MSE}&=\tfrac{1}{5}(0^2+1^2+(-1)^2+0^2+190^2)=7220.4 \\
\mathrm{RMSE}&=\sqrt{7220.4}\approx 84.95
\end{aligned}
$$

- **한 개의 이상치**로 MSE/RMSE가 폭증, MAE는 상대적으로 덜 증가.
- **권장**: 라벨 노이즈/센서 이상 가능성이 크면 **MAE/Huber**, 아니면 **RMSE**.

---

## 6. 스케일/단위/정규화와 변형

- **RMSE/MAE는 원 단위**라 해석이 직관적, MSE는 제곱 단위라 크기가 과장.
- **정규화 지표**:
  - NRMSE(범위/표준편차로 나눔), NMAE, RRMSE(평균으로 나눔) 등으로 **상대 비교** 가능.
- **로그 스케일**
  - **RMSLE**(RMSE on log target) 또는 **타깃 로그 변환 후 RMSE**: 비음수·장꼬리 분포에서 상대오차 관점에 유리.
  - **주의**: 0/음수, 단위 해석의 변경.

---

## 7. 가중치/이질분산(heteroscedasticity)

관측 중요도 또는 분산이 샘플마다 다르면 **가중 지표** 사용:

$$
\mathrm{WMSE}=\frac{\sum_{i} w_i e_i^2}{\sum_i w_i},\quad
\mathrm{WMAE}=\frac{\sum_{i} w_i |e_i|}{\sum_i w_i}
$$

- **가중치 설정 예**: 신뢰도, 샘플 빈도, 최근성, 비용(오차 비용)
- 모델 학습도 **가중 최소제곱(Weighted LS)** 로 정합성 맞추기.

---

## 8. 예측-업무 연결: 언제 무엇을 쓸까?

| 상황 | 1차 지표 | 보조 지표/메모 |
|---|---|---|
| 큰 실수의 비용이 급격히 증가 | **RMSE** | 상위 백분위 오차도 점검(P95) |
| 라벨 노이즈/이상치 많음 | **MAE** | Huber/Quantile도 고려 |
| 가우시안 노이즈 가정, 최적화 편의 | **RMSE(MSE)** | 미분이 매끄러움 |
| 경영 보고(직관) | **RMSE/MAE** | 원 단위라 전달 용이 |
| 그룹 공정성/세그먼트별 품질 | **그룹별 RMSE/MAE** | 가중 평균뿐 아니라 분산도 확인 |

> **실무 팁**: 학습/튜닝에는 RMSE, 리포트에는 **RMSE+MAE 동시** 제시가 안전합니다.

---

## 9. 모델 선택/튜닝에서의 실수 방지

- **scikit-learn scoring 주의**: `neg_mean_squared_error`처럼 **음수로 반환**되는 스코어가 있음(최대화 일관성). RMSE는 `neg_root_mean_squared_error`.
- **CV 밖 전처리 금지**: 스케일링/인코딩은 반드시 **`Pipeline`** 에 포함해 CV 내부에서 `fit`.
- **시계열**: `TimeSeriesSplit` 사용(셔플 X).
- **다중 출력**: `multioutput="uniform_average"/"raw_values"` 옵션으로 집계 방식 명시.

---

## 10. 코드 스니펫

### 10.1 NumPy로 직접 계산
```python
import numpy as np

def mse(y, yhat):  return np.mean((y - yhat)**2)
def rmse(y, yhat): return np.sqrt(mse(y, yhat))
def mae(y, yhat):  return np.mean(np.abs(y - yhat))

y  = np.array([10,11,9,10,200])
yh = np.array([10,10,10,10,10])
print(mse(y,yh), rmse(y,yh), mae(y,yh))
```

### 10.2 scikit-learn: CV로 RMSE/MAE 함께 보고
```python
from sklearn.datasets import fetch_california_housing
from sklearn.model_selection import KFold, cross_validate
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import StandardScaler
from sklearn.impute import SimpleImputer
from sklearn.metrics import make_scorer
from sklearn.ensemble import HistGradientBoostingRegressor
import numpy as np, pandas as pd

data = fetch_california_housing(as_frame=True)
X, y = data.data, data.target  # 단위: $100,000s

num_cols = X.columns.tolist()
prep = ColumnTransformer([
    ("num", Pipeline([("imp", SimpleImputer(strategy="median")),
                      ("sc", StandardScaler())]), num_cols)
])

model = Pipeline([
    ("prep", prep),
    ("reg", HistGradientBoostingRegressor(random_state=42))
])

cv = KFold(n_splits=5, shuffle=True, random_state=42)
scores = cross_validate(
    model, X, y, cv=cv, n_jobs=-1,
    scoring={
        "rmse": "neg_root_mean_squared_error",
        "mae": "neg_mean_absolute_error",
        "r2": "r2"
    }
)

rmse = -scores["test_rmse"]
mae  = -scores["test_mae"]
print(f"RMSE: {rmse.mean():.4f} ± {rmse.std():.4f}")
print(f"MAE : {mae.mean():.4f} ± {mae.std():.4f}")
print(f"R^2 : {scores['test_r2'].mean():.4f}")
```

### 10.3 가중 지표/샘플 가중치
```python
from sklearn.metrics import mean_squared_error, mean_absolute_error
# sample_weight로 WMSE/WMAE 계산
wmse = mean_squared_error(y_true, y_pred, sample_weight=w)  # 평균 아닌 합/가중치합 처리 주의
wmae = mean_absolute_error(y_true, y_pred, sample_weight=w)
```

### 10.4 Quantile/Huber (강건 회귀)
```python
from sklearn.linear_model import HuberRegressor, QuantileRegressor

huber = HuberRegressor(epsilon=1.35)  # 큰 오차 L1, 작은 오차 L2
huber.fit(X, y)

qreg = QuantileRegressor(quantile=0.5, alpha=1e-4)  # 0.5=중앙값 회귀(≈MAE)
qreg.fit(X, y)
```

### 10.5 PyTorch: RMSE/MAE 커스텀 손실
```python
import torch, torch.nn as nn

class RMSELoss(nn.Module):
    def __init__(self, eps=1e-8):
        super().__init__(); self.eps = eps
    def forward(self, yhat, y):
        return torch.sqrt(torch.mean((yhat - y)**2) + self.eps)

class MAELoss(nn.Module):
    def forward(self, yhat, y):
        return torch.mean(torch.abs(yhat - y))

rmse_loss, mae_loss = RMSELoss(), MAELoss()
# 사용: loss = rmse_loss(pred, target)
```

### 10.6 부트스트랩 신뢰구간(95% CI)
```python
import numpy as np

def bootstrap_ci(y, yhat, metric_fn, B=2000, alpha=0.05, rng=np.random.default_rng(42)):
    n = len(y); stats=[]
    for _ in range(B):
        idx = rng.integers(0, n, n)
        stats.append(metric_fn(y[idx], yhat[idx]))
    lo, hi = np.quantile(stats, [alpha/2, 1-alpha/2])
    return lo, hi

# 예: rmse
metric = lambda a,b: np.sqrt(np.mean((a-b)**2))
lo, hi = bootstrap_ci(y_true, y_pred, metric_fn=metric)
print("RMSE 95% CI:", (lo, hi))
```

---

## 11. 실무 체크리스트

- [ ] **지표 정의**: RMSE/MAE 중 문제 특성(비용·노이즈·해석)에 맞는 주지표 선정
- [ ] **CV 전략**: (Stratified) K-Fold / TimeSeriesSplit / GroupKFold 적합성 검토
- [ ] **전처리 파이프라인**: 누수 방지(모든 변환을 `Pipeline` 내부)
- [ ] **이상치 대책**: 라벨 검증·클리핑·Huber/Quantile 보조
- [ ] **가중치 정책**: 중요 관측/세그먼트 반영 시 WMSE/WMAE
- [ ] **보고**: RMSE(해석) + MAE(강건성) + R²(설명력) 병기, 분포(잔차/상자그림) 제시
- [ ] **모니터링**: 배포 후 **지표 드리프트** 감시(주기·세그먼트별)

---

## 12. 흔한 함정과 대응

| 함정 | 증상 | 대응 |
|---|---|---|
| 불균일 분산(heteroscedastic) 무시 | 특정 구간에서 큰 잔차 | **가중 회귀**·변수 변환·세그먼트 모델 |
| 이상치에 끌리는 RMSE | 과도한 모델 복잡도/왜곡 | **MAE/Huber** 병행, 라벨 정제 |
| 단위/스케일 혼동 | 성능 비교 불가 | **NRMSE/NMAE** 병행, 표준화 |
| 시계열 셔플 CV | 리크/낙관적 성능 | **TimeSeriesSplit** |
| scoring 이름 혼동 | 음수 스코어 해석 오류 | `neg_` 접두 이해, 부호 반전 |

---

## 13. Bias–Variance 분해(요약)

모형 \(\hat{f}\)와 진실 \(f\), 노이즈 분산 \(\sigma^2\)에 대해:
$$
\mathbb{E}\big[(\hat{f}(x)-y)^2\big] \;=\;
\underbrace{\big(\mathbb{E}[\hat{f}(x)]-f(x)\big)^2}_{\text{Bias}^2}
+\underbrace{\mathbb{V}[\hat{f}(x)]}_{\text{Variance}}
+\underbrace{\sigma^2}_{\text{Irreducible Noise}}
$$
**MSE/RMSE**는 이 합을 직접 반영 → **과소적합(바이어스↑)** vs **과적합(분산↑)** 균형 판단에 유용.

---

## 요약

- **MSE/RMSE**: L2 패널티. 큰 오차에 민감, 최적화/해석 용이, **RMSE는 원 단위**.
- **MAE**: L1 패널티. **이상치 강건**, 중앙값 추정과 연결.
- 노이즈/비용/해석 요구에 따라 **주지표**를 고르고, 리포트에는 **RMSE+MAE**를 함께 제시.
- 실무에서는 **Huber/Quantile**, **가중 지표**, **CV/부트스트랩**, **세그먼트별 진단**을 곁들여야 신뢰할 수 있는 평가가 됩니다.
