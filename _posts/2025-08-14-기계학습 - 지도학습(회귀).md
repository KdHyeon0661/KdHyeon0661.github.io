---
layout: post
title: 기계학습 - 지도학습(회귀)
date: 2025-08-14 22:20:23 +0900
category: 기계학습
---
# 지도학습(회귀, Regression)

**지도학습(Supervised Learning)**은 입력 데이터와 그에 대응하는 **정답(Label)**이 주어진 상태에서 모델을 학습시키는 방법입니다.  
그중 **회귀(Regression)**는 **연속적인 숫자 값을 예측하는 문제**를 다룹니다.

예를 들어, **주택 가격 예측, 온도 예측, 매출 예측** 등이 회귀 문제의 대표적인 예입니다.

---

## 1. 회귀의 개념

### (1) 정의
- **회귀(Regression)**: 입력값 \(X\)와 출력값 \(y\)의 관계를 추정하는 함수 \(f(X)\)를 찾는 것
- 수학적으로:
$$
y \approx f(X) + \epsilon
$$
- 여기서:
  - \(y\): 실제 값
  - \(f(X)\): 모델이 추정한 예측 값
  - \(\epsilon\): 오차(Noise)

---

### (2) 회귀와 분류의 차이

| 구분 | 회귀(Regression) | 분류(Classification) |
|------|------------------|----------------------|
| 출력 | 연속값 | 범주(클래스) |
| 예시 | 주가 예측, 온도 예측 | 스팸 메일 여부, 이미지 클래스 |
| 평가 지표 | MSE, MAE, RMSE, R² | Accuracy, F1-score, AUC |

---

## 2. 회귀의 종류

### (1) 단순 선형 회귀(Simple Linear Regression)
- 독립 변수 1개, 종속 변수 1개
- 모델:
$$
\hat{y} = w x + b
$$
- 최적화 목표: MSE 최소화
$$
MSE = \frac{1}{n} \sum_{i=1}^n (y_i - (w x_i + b))^2
$$

---

### (2) 다중 선형 회귀(Multiple Linear Regression)
- 독립 변수 여러 개
- 모델:
$$
\hat{y} = w_1 x_1 + w_2 x_2 + \dots + w_n x_n + b
$$

---

### (3) 다항 회귀(Polynomial Regression)
- 비선형 관계를 다항식으로 근사
- 예:
$$
\hat{y} = w_0 + w_1 x + w_2 x^2 + \dots + w_d x^d
$$

---

### (4) 정규화 회귀(Regularized Regression)
- 과적합 방지를 위해 **패널티(규제항)** 추가
- **릿지 회귀(Ridge Regression)**:
$$
\min_w \left[ MSE + \lambda \sum_{j=1}^n w_j^2 \right]
$$
- **라쏘 회귀(Lasso Regression)**:
$$
\min_w \left[ MSE + \lambda \sum_{j=1}^n |w_j| \right]
$$
- 릿지: 가중치 크기 감소  
- 라쏘: 불필요한 가중치 0으로 만들어 변수 선택 기능

---

### (5) 비선형 회귀(Non-linear Regression)
- 비선형 함수(지수, 로그, 시그모이드 등)를 이용해 모델링

---

## 3. 회귀 모델 학습 과정

1. **데이터 수집**
   - 입력(feature)와 정답(label) 확보
2. **데이터 전처리**
   - 결측치 처리, 스케일링, 원-핫 인코딩
3. **모델 선택**
   - 선형, 다항, 정규화 회귀 등
4. **손실 함수 정의**
   - 회귀에서는 MSE, MAE, RMSE 자주 사용
5. **최적화**
   - 경사하강법(Gradient Descent) 또는 정규방정식(Normal Equation)
6. **평가**
   - 테스트 데이터에서 성능 측정 (R² score 등)

---

## 4. 회귀 평가 지표

| 지표 | 공식 | 특징 |
|------|------|------|
| MSE (Mean Squared Error) | \(\frac{1}{n} \sum (y - \hat{y})^2\) | 큰 오차에 민감 |
| RMSE (Root MSE) | \(\sqrt{MSE}\) | 해석이 쉬움 (원 단위) |
| MAE (Mean Absolute Error) | \(\frac{1}{n} \sum |y - \hat{y}|\) | 이상치에 덜 민감 |
| R² (결정계수) | \(1 - \frac{\sum (y - \hat{y})^2}{\sum (y - \bar{y})^2}\) | 1에 가까울수록 좋음 |

---

## 5. 파이썬 예제 (단순 선형 회귀)
```python
import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression

# 데이터 생성
X = np.array([1, 2, 3, 4, 5]).reshape(-1, 1)
y = np.array([1.2, 1.9, 3.0, 3.9, 5.1])

# 모델 학습
model = LinearRegression()
model.fit(X, y)

# 예측
y_pred = model.predict(X)

# 결과 출력
print("기울기(w):", model.coef_)
print("절편(b):", model.intercept_)

# 시각화
plt.scatter(X, y, color="blue", label="Actual")
plt.plot(X, y_pred, color="red", label="Predicted")
plt.legend()
plt.show()
```

---

## 6. 머신 러닝에서 회귀의 활용 예시
- **가격 예측**: 주택, 자동차, 주식 등
- **수요 예측**: 판매량, 트래픽
- **신호 처리**: 센서 데이터의 연속값 예측
- **추천 시스템**: 평점 예측

---

## 📌 정리
- **회귀**는 지도학습의 한 형태로, 연속적인 수치를 예측
- 종류: 단순/다중 선형 회귀, 다항 회귀, 정규화 회귀 등
- 학습 과정: 데이터 수집 → 전처리 → 모델 선택 → 손실 함수 최소화 → 평가
- 평가 지표: MSE, MAE, RMSE, R²
- 실제 응용: 가격·수요·신호 등 연속값 예측 문제 전반에 활용