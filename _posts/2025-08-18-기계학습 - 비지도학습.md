---
layout: post
title: 기계학습 - 비지도학습
date: 2025-08-18 23:25:23 +0900
category: 기계학습
---
# 비지도학습(Unsupervised Learning)

## 1. 개념

**비지도학습(Unsupervised Learning)**은 **정답(label)**이 없는 데이터를 이용하여 숨겨진 패턴, 구조, 분포를 찾아내는 머신 러닝의 한 분야입니다.  
지도학습과 달리, 입력 데이터에 대한 **정답 정보가 제공되지 않으므로** 모델이 스스로 데이터의 특성을 학습하여 **군집화(Clustering)**, **차원 축소(Dimensionality Reduction)**, **이상치 탐지(Anomaly Detection)** 등의 작업을 수행합니다.

---

## 2. 지도학습과의 비교

| 구분 | 지도학습(Supervised Learning) | 비지도학습(Unsupervised Learning) |
|------|-------------------------------|-------------------------------------|
| 데이터 | 입력 + 정답(label) | 입력만 존재 |
| 목적 | 입력 → 출력 예측 | 패턴, 군집, 구조 발견 |
| 예시 | 스팸메일 분류, 가격 예측 | 고객 군집화, 토픽 모델링 |
| 대표 알고리즘 | Linear Regression, SVM | K-Means, PCA |

---

## 3. 비지도학습의 주요 목적

1. **데이터 군집화 (Clustering)**  
   유사한 특성을 가진 데이터를 그룹으로 묶어 패턴을 찾음.  
   예: 고객 행동 분석, 이미지 유사도 분류.
   
2. **차원 축소 (Dimensionality Reduction)**  
   데이터의 주요 특징을 유지하면서 변수(차원)의 수를 줄여 시각화 및 연산 효율을 향상.  
   예: 고차원 텍스트 데이터의 시각화.
   
3. **이상치 탐지 (Anomaly Detection)**  
   정상 데이터 분포와 크게 다른 데이터를 찾아냄.  
   예: 신용카드 부정 결제 탐지, 센서 이상 감지.

---

## 4. 비지도학습의 대표 알고리즘

### (1) 군집화(Clustering)

#### a. **K-평균 군집화(K-Means Clustering)**
- 데이터 집합을 **K개의 그룹**으로 나눔.
- 알고리즘:
  1. 임의로 K개의 중심점(centroid) 초기화.
  2. 각 데이터 포인트를 가장 가까운 중심점에 할당.
  3. 각 군집의 평균값으로 중심점 갱신.
  4. 수렴할 때까지 반복.
- 거리 계산:
  $$
  \text{dist}(x, \mu_k) = \sqrt{\sum_{i=1}^n (x_i - \mu_{k,i})^2}
  $$

#### b. **계층적 군집화(Hierarchical Clustering)**
- 군집 계층을 만들어 **덴드로그램(Dendrogram)**으로 표현.
- 상향식(Agglomerative) 또는 하향식(Divisive) 방식 존재.

---

### (2) 차원 축소(Dimensionality Reduction)

#### a. **주성분 분석(PCA, Principal Component Analysis)**
- 고차원 데이터를 선형 변환하여 **분산이 가장 큰 방향**의 축을 찾음.
- 수학적 정의:
  - 공분산 행렬 \(C = \frac{1}{n} X^\top X\)을 고유값 분해(Eigen Decomposition)하여  
    가장 큰 고유값에 해당하는 고유벡터를 새로운 축으로 사용.
- 목적: 정보 손실 최소화 + 데이터 시각화.

#### b. **t-SNE (t-Distributed Stochastic Neighbor Embedding)**
- 비선형 차원 축소 기법.
- 고차원 데이터의 국소 구조(local structure)를 잘 보존하며 2D/3D로 시각화 가능.

---

### (3) 이상치 탐지(Anomaly Detection)

#### a. **Isolation Forest**
- 랜덤하게 선택한 특징과 분할 값을 사용하여 데이터를 분리.
- 이상치는 평균적으로 적은 분할 단계에서 분리됨.

#### b. **DBSCAN (Density-Based Spatial Clustering of Applications with Noise)**
- 밀도 기반 클러스터링.
- 특정 반경(\(\epsilon\)) 내의 점 개수를 기준으로 군집 형성.
- 군집에 속하지 않는 점을 이상치로 분류 가능.

---

## 5. 수학적 기반

### (1) 데이터 표현
- 비지도학습에서는 데이터 \(X\)가 다음과 같이 주어집니다:
$$
X = \{x_1, x_2, \dots, x_n\}, \quad x_i \in \mathbb{R}^d
$$
- \(d\): 특성(feature) 수  
- \(n\): 샘플 개수

### (2) 목표 함수
- **군집화의 경우**:  
  K-Means 목적 함수
  $$
  J = \sum_{k=1}^K \sum_{x_i \in C_k} \| x_i - \mu_k \|^2
  $$
  여기서 \(\mu_k\)는 \(k\)번째 군집의 중심점.

- **PCA의 경우**:
  분산 최대화:
  $$
  \max_{w} \frac{w^\top S w}{w^\top w}
  $$
  여기서 \(S\)는 공분산 행렬.

---

## 6. 장단점

### 장점
- 레이블 없이도 데이터 패턴 파악 가능.
- 새로운 인사이트 발견 가능.
- 데이터 전처리 및 시각화에 유용.

### 단점
- 결과의 품질을 객관적으로 평가하기 어려움.
- 알고리즘 선택과 하이퍼파라미터 설정이 까다로움.
- 해석이 어려울 수 있음.

---

## 7. 파이썬 예제: K-Means 클러스터링
```python
from sklearn.datasets import make_blobs
from sklearn.cluster import KMeans
import matplotlib.pyplot as plt

# 샘플 데이터 생성
X, _ = make_blobs(n_samples=300, centers=4, cluster_std=0.6, random_state=0)

# K-Means 모델 학습
kmeans = KMeans(n_clusters=4)
kmeans.fit(X)

# 예측
y_kmeans = kmeans.predict(X)

# 시각화
plt.scatter(X[:, 0], X[:, 1], c=y_kmeans, cmap='viridis')
plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1],
            s=200, c='red', marker='X')
plt.show()
```

---

## 📌 정리
- 비지도학습은 레이블 없이 데이터의 숨겨진 구조를 학습.
- 주요 기법: **군집화, 차원 축소, 이상치 탐지**.
- 데이터 탐색, 전처리, 시각화, 패턴 분석에 강력한 도구.
- K-Means, PCA, DBSCAN 등 다양한 알고리즘이 존재.
- 수학적 기반은 거리 계산, 공분산 분석, 밀도 추정 등에 있음.