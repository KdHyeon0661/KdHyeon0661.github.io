---
layout: post
title: 확률과 통계 - 공변량 보정
date: 2025-09-20 18:25:23 +0900
category: 확률과 통계
---
# ― 분산 줄이고 n 절감하기

> **목표**
> - **CUPED**(Controlled-experiment Using Pre-Experiment Data) 아이디어와 공식: 사전 지표를 이용한 **잔차화(residualization)** 로 **분산 감소**.
> - **ANCOVA**(공분산분석): **처리(T)** + **공변량(X)** + (선택) **상호작용**을 선형/GLM으로 적합하여 **정밀도 향상**.
> - **표본 크기 절감**과 **MDE 축소** 계산: $$\text{VRR}=1-R^2$$, $$\text{MDE}^\*=\text{MDE}\cdot \sqrt{1-R^2}$$.
> - **실무 절차**: 설계→사전지표 선택→잔차화/모형화→강건 표준오차→검증·리포팅.
> - **함정**: **사후 공변량(처리 이후)** 사용 금지, **드리프트**(pre/post 분포 차), **누수**(label leakage), **랜덤화 단위** 오판, **오버피팅**.

---

## Hook — “같은 실험, 더 짧게 끝내려면?”

A/B를 하다 보면 **변동성** 때문에 **작은 효과**(예: +0.2pp)를 탐지하기 어려워요.
하지만 실험 시작 **이전(Pre)** 의 사용자 지표(예: **과거 ARPU, 세션 수, 클릭 성향**)가 **실험 기간 지표**와 **강한 상관**이 있다면?
그 **상관**을 이용해 **불필요한 변동**을 제거하면, **같은 파워**를 위해 필요한 **표본 n**을 크게 줄일 수 있습니다. 이것이 **CUPED/ANCOVA**의 핵심입니다.

---

## 배경: “분산을 줄이면 파워가 오른다”

### 표준 A/B 추정량(차이-의-평균)

처리표시 $$T_i\in\{0,1\}$$, 결과 $$Y_i$$(예: ARPU), **무작위화**가 올바르면
$$
\hat\tau_{\text{diff}}=\bar Y_1-\bar Y_0,\qquad
\mathrm{Var}(\hat\tau_{\text{diff}})\approx \frac{\sigma_1^2}{n_1}+\frac{\sigma_0^2}{n_0}.
$$

### 공변량으로 분산 감소(직관)

**처리 이전에 이미 존재**하고 **결과와 상관**이 높은 **$X$**를 사용하면
결과 $$Y$$를 **예측 가능한 부분**과 **예측 불가능한 잔차**로 분해할 수 있습니다:
$$
Y = f(X) + \varepsilon,\quad \text{Var}(Y)=\text{Var}(f(X))+\text{Var}(\varepsilon).
$$
**실험 효과**는 $$\varepsilon$$에만 남기고 **$f(X)$**를 제거하면,
**분산이 $\text{Var}(\varepsilon)$로 감소** → 더 작은 n으로 같은 파워 달성!

---

## CUPED: 단일 공변량(사전 지표)로 잔차화

### 공식과 직관

사전 지표(처리 전에 측정한) $$X_i$$ 가 실험 기간 결과 $$Y_i$$ 와 상관 $$\rho$$ 를 가진다고 하자.
**CUPED 조정 결과** $$Y_i^\*$$ 를
$$
Y_i^\* \equiv Y_i - \theta\,(X_i-\mu_X)
$$
로 정의합니다. 여기서
- $$\mu_X=E[X]$$(표본 평균으로 대체)
- $$\theta$$ 는 **최적 계수**:
  $$
  \theta^\star \equiv \frac{\mathrm{Cov}(Y,X)}{\mathrm{Var}(X)}.
  $$
이렇게 하면
$$
\mathrm{Var}(Y^\*) = \mathrm{Var}(Y)\cdot (1-\rho^2).
$$

> **Variance Reduction Ratio (VRR)**
> $$\boxed{\text{VRR} = \frac{\mathrm{Var}(Y^\*)}{\mathrm{Var}(Y)} = 1-\rho^2}$$
> 상관이 0.6이면 **분산 64%**→**36%로**. **MDE**는 **$\sqrt{1-\rho^2}$ 배**로 줄어듭니다.

### 추정 절차(실무)

1) **사전 기간**에서 사용자별 $$X_i$$(예: 이전 28일 ARPU) 집계.
2) 실험 기간 $$Y_i$$(이번 14일 ARPU) 산출.
3) **전체 표본**(또는 **컨트롤만**)에서 $$\theta^\star=\widehat{\mathrm{Cov}}(Y,X)/\widehat{\mathrm{Var}}(X)$$ 추정.
4) $$Y_i^\* = Y_i - \theta^\star(X_i-\bar X)$$ 계산.
5) **차이-의-평균**: $$\hat\tau_{\text{CUPED}}=\bar Y_1^\*-\bar Y_0^\*$$.
6) 표준오차는 **사용자(클러스터)-강건 SE** 또는 **부트스트랩**으로.

> **컨트롤만 vs 전체로 $\theta$ 추정?**
> 무작위화로 $$T\perp X$$ 이면 **전체 표본** 사용해도 **불편**입니다.
> **드리프트**(처리에 따른 분포이동) 걱정이 크면 **컨트롤만**으로 $\theta$ 를 구해도 됩니다.

### 여러 공변량으로 확장(다변량 CUPED)

벡터 $$X_i\in\mathbb{R}^p$$ 일 때,
$$
Y_i^\* = Y_i - (X_i-\bar X)^\top \theta,\quad
\theta^\star=\arg\min_\theta \mathrm{Var}\big(Y-(X-\bar X)^\top\theta\big).
$$
이는 **회귀(OLS)** 로 $$Y\sim X$$ 를 적합해 **예측값을 제거**하는 것과 같습니다.
고차원·상호작용이 많을 때는 **ridge/elastic-net** + **교차적합(cross-fitting)** 권장(§6).

---

## ANCOVA: 회귀로 공변량을 “동시에” 보정

### 선형 ANCOVA 모형

$$
Y_i = \alpha + \tau T_i + \gamma^\top Z_i + \delta^\top (T_i\cdot Z_i) + \varepsilon_i,
$$
- $$T_i$$: 처리(0/1), $$Z_i$$: 공변량(사전 지표 포함).
- **목표**: **처리 효과 $$\tau$$**.
- **권장**: **Lin(2013)** 방식 ― **공변량 표준화(센터링)** + **상호작용** 포함, **HC**(HC2/HC3) **강건 표준오차** 사용.
  - 이유: **모형이 틀려도**(비선형) **일치성** 유지 + **정밀도 상승**.

### 잔차화와의 등가성

**$Z$에 대한 잔차화**(CUPED) 후 **차이-의-평균** ≈ **ANCOVA에서 $$\tau$$** (동일 공변량·선형 가정 하).
즉, **CUPED은 ANCOVA의 특수형**입니다.

### GLM ANCOVA (이항/카운트)

- **로지스틱**:
  $$
  \operatorname{logit} \Pr(Y_i=1)=\alpha + \tau T_i + \gamma^\top Z_i + \delta^\top (T_i\cdot Z_i).
  $$
  보고는 **OR**·**AME**.
- **포아송/NB**(오프셋 포함):
  $$
  \log E[Y_i] = \alpha + \tau T_i + \gamma^\top Z_i + \delta^\top (T_i\cdot Z_i)+\log(\text{exposure}_i).
  $$
  보고는 **IRR**.
> **주의**: 비선형 GLM에서는 “잔차화 후 차이-의-평균”과 완전 등가가 아닙니다. 이항/카운트는 **GLM ANCOVA**로 직접 추정하세요.

---

## 예시 A — **CUPED으로 ARPU 분산 감소**

### 설정

- 사전 28일 **ARPU**: $$X_i$$
- 실험 14일 **ARPU**: $$Y_i$$
- 관찰 상관: $$\hat\rho=0.55$$ → 이론상 **VRR ≈ 1−0.55^2=0.6975** (약 **30% 감소**), **MDE는 0.84배**.

### 계산

1) $$\widehat\theta = \widehat{\mathrm{Cov}}(Y,X)/\widehat{\mathrm{Var}}(X)$$
2) $$Y_i^\* = Y_i - \widehat\theta (X_i-\bar X)$$
3) $$\hat\tau_{\text{CUPED}} = \bar Y_1^\*-\bar Y_0^\*$$
4) SE: 사용자 클러스터 부트스트랩(또는 HC3).

### 리포트 문장

> “CUPED(사전 ARPU 사용)로 **분산 ~30% 감소**, **MDE 16% 절감**. 조정 추정치 **+210원**[95% CI +90, +330], 미조정보다 CI가 **좁다**.”

---

## 예시 B — **ANCOVA(선형)**: `ARPU ~ T + sessions_pre + time_pre + country + T:country`

- 공변량: **사전 세션수**, **사전 체류시간**, **국가더미**
- 상호작용: **T×국가**(국가에 따라 처리효과 달라질 수 있음)
- 결과:
  - $$\hat\tau=+180원$$, HC3 SE=55 → **p=0.001**
  - **Adjusted R²↑**, deviance↓
  - 국가 A에서 **효과 더 큼**(T×국가A 양의 유의)

> “**Lin-스타일 ANCOVA**(센터링·상호작용·HC3)로 **정밀도 상승**. CUPED과 결론 일관.”

---

## CUPED 2.0 ― **CUPAC / ML-예측 + 교차적합**

### 아이디어

단일 사전지표 대신 **풍부한 특징**(기기, 지역, 과거 행동 벡터)으로
**사전기간 결과를 예측**하는 함수 $$\hat f(X)$$(**black-box** 가능).
그 다음 **예측값**을 **CUPED 공변량**으로 사용:
$$
Y_i^\* = Y_i - \theta\big(\hat f(X_i)-\overline{\hat f(X)}\big).
$$

### **교차적합(cross-fitting)** 필수

같은 데이터로 **학습**·**조정**을 동시에 하면 **오버피팅 바이어스** 위험.
- 데이터 K등분 → K-1로 **$\hat f$ 학습**, **남은 fold**에만 적용.
- $$\theta$$ 추정은 전체에서 가능(또는 fold별 평균).

### 왜 좋은가?

- 단일 상관 $$\rho$$ 대신 **설명력 $$R^2$$** 가 커짐 → **VRR=1-R^2**.
- 고차·비선형 패턴까지 흡수 → **분산 더 크게 감소**.

> **주의**: **사전** 특징만 사용하세요. **처리 이후 관측치**(예: 실험 중 클릭) 사용 금지(누수).

---

## 표본 크기 절감·MDE 계산

### VRR에서 파생

- 조정 전 분산: $$\sigma^2$$, 조정 후: $$\sigma^{\*2}=\sigma^2(1-R^2)$$.
- **MDE 축소**:
  $$
  \boxed{\text{MDE}^\*=\text{MDE}\cdot \sqrt{1-R^2}}
  $$
- **필요 표본**: 같은 MDE/파워를 원하면
  $$
  \boxed{n^\* = \frac{n}{1-R^2}}
  $$
  (팔당 대칭 설계, 근사)

### 예

- 사전지표로 $$R^2=0.36$$ → **MDE 0.8배**, **필요 n 1/(1-0.36)=1.56배 절감**(즉 현재 n의 64%만 필요).

---

## 비율·카운트 지표에서의 공변량 보정

### 로지스틱 ANCOVA

- $$\operatorname{logit}\Pr(\text{convert}=1) = \alpha + \tau T + \gamma^\top Z + \delta^\top (T\cdot Z).$$
- 보고: **OR**, **AME(∆p)**.
- **희귀사건**은 **Firth 로지스틱** 또는 **Poisson+robust**로 RR 근사.

### 포아송/NB ANCOVA(오프셋)

- $$\log E[\text{clicks}] = \alpha + \tau T + \gamma^\top Z + \delta^\top (T\cdot Z) + \log(\text{impr}).$$
- 보고: **IRR**. **과산포**면 NB/Quasi.

### 비율형 지표의 **선형 잔차화** 팁

- CVR 같이 **비율**은 **분모 변동**을 무시하면 편향 위험 → **로지스틱 GLM** 권장.
- 단, **사용자단위 이진 Y**를 **예측해 잔차화**(CUPAC) 후 **차이-의-평균**은 **직관적 효과**(∆p) 리포팅에 유용.

---

## 클러스터/블록/층화와 결합

- **클러스터 랜덤화**(예: 푸시 캠페인을 “사용자”가 아닌 “그룹/지역” 단위로):
  - 공변량을 **클러스터 수준**으로 포함(과거 지역 평균 매출 등).
  - **클러스터-강건 SE** 또는 **혼합모형**(랜덤효과) 사용.
- **층화/블록**: 블록 더미를 ANCOVA에 넣거나, 블록별 CUPED 후 **가중 평균**.

---

## 함정과 체커(필수)

1) **사후 공변량 사용 금지**: 처리 이후에 결정되는 변수(실험 중 클릭/노출)를 공변량에 넣으면 **효과가 제거**되어 **편향**.
2) **랜덤화 단위 불일치**: 사용자 무작위화인데 세션 단위로 회귀/부트스트랩 → **SE 과소**. **사용자 클러스터 SE**로.
3) **드리프트**: Pre와 Experiment 기간의 **분포 변화**(시즌성). **윈도우 안정화**·**동일 기간 매칭**으로 완화.
4) **극단값**: ARPU 꼬리 → **로그/윈저라이즈** + 강건 SE.
5) **오버피팅**(ML 공변량): **교차적합** 필수, 특징 수를 **보수적**으로.
6) **공변량 누락**: CUPED는 **사전 지표**가 핵심. 무관한 변수 다수는 **잡음 ↑**.
7) **의사결정 지연**: 분산 감소가 작을 때는 복잡성 > 편익. **VRR 사전 추정**으로 기대 이득을 확인.

---

## Python 예제(개념 코드)

> **주의**: 아래 코드는 **개념 검증**용입니다. 실무에선 **statsmodels**/**sklearn**의 검증된 구현과 **강건 SE/클러스터 SE**를 사용하세요.

```python
import numpy as np, pandas as pd
import statsmodels.api as sm
import statsmodels.formula.api as smf

# 시뮬레이션: 사전 ARPU(X)와 실험 ARPU(Y), 처리 T

rng = np.random.default_rng(0)
n = 100_000
T = rng.integers(0,2,size=n)                 # 0/1 treatment
X = rng.gamma(2.0, 3.0, size=n)              # pre ARPU-ish (heavy-tail)
eps = rng.normal(0, 2.0, size=n)
tau_true = 0.2                                # true ATE in ARPU units
Y = 0.5 + tau_true*T + 0.6*X + eps            # post ARPU (linear-ish)

df = pd.DataFrame({'Y':Y, 'T':T, 'X':X})
df['Xc'] = df['X'] - df['X'].mean()

# Naive difference-in-means

tau_naive = df.loc[df.T==1,'Y'].mean() - df.loc[df.T==0,'Y'].mean()

# CUPED

theta = np.cov(df['Y'], df['X'], bias=True)[0,1] / np.var(df['X'])
df['Y_cuped'] = df['Y'] - theta*df['Xc']
tau_cuped = df.loc[df.T==1,'Y_cuped'].mean() - df.loc[df.T==0,'Y_cuped'].mean()
vrr = 1 - np.corrcoef(df['Y'], df['X'])[0,1]**2

print(f"Naive ATE ~ {tau_naive:.4f}")
print(f"CUPED ATE ~ {tau_cuped:.4f}, VRR≈{vrr:.3f} (MDE x{np.sqrt(vrr):.3f})")

# ANCOVA (Lin-style: centered covariate + interaction, HC3 SE)

model = smf.ols('Y ~ T + Xc + T:Xc', data=df).fit(cov_type='HC3')
print(model.summary().tables[1])

# 처리효과 계수(상호작용 포함 모델에서 T의 계수 해석 주의: 평균 X에서의 효과)

tau_ancova = model.params['T']
print("ANCOVA tau @ mean X:", tau_ancova)

# 로지스틱 ANCOVA 예시(이진 전환)

p = 1/(1+np.exp(-(-3.5 + 0.4*T + 0.15*df['Xc'])))    # true logit
Ybin = rng.binomial(1, p, size=n)
df['Ybin'] = Ybin
logit = smf.glm('Ybin ~ T + Xc + T:Xc', data=df, family=sm.families.Binomial()).fit(cov_type='HC3')
print(logit.summary().tables[1])

# for T

marg = logit.get_margeff(at='overall', method='dydx', atexog={'T':1})
print(marg.summary())
```

---

## 보고 템플릿(선형/GLM 각각)

### 선형(CUPED + ANCOVA)

> **지표**: ARPU(원) — heavy-tail → 윈저 99.5% + HC3.
> **CUPED**: 사전 28일 ARPU로 조정(θ=0.62). **VRR ~ 0.62² → 분산 38% 감소**, MDE 0.78배.
> **추정치**: 미조정 +240원 [+80, +400] → **CUPED +180원 [ +90, +270 ]**.
> **ANCOVA**: `Y ~ T + Xc + T:Xc` (Lin 방식, HC3). **τ=+175원 [ +70, +280 ]** (CUPED과 일관).
> **진단**: 잔차 패턴 무, Cook 상위 0.5% 제외해도 결론 동일.
> **결론**: 처리로 **ARPU 상승**. CUPED/ANCOVA로 **신뢰 구간 대폭 축소**.

### GLM(로지스틱)

> **지표**: 전환(0/1), 사전 클릭성향 점수 포함.
> **모형**: `logit(P(convert)) ~ T + score_c + T:score_c` (HC3).
> **효과**: OR(T)=**1.09 [1.05, 1.13]**, AME=**+0.24pp [ +0.10, +0.38 ]**.
> **캘리브레이션**: Brier 0.082, 리라이어빌리티 양호.
> **결론**: 공변량 보정으로 **정밀도** 상승, 신규유저에서 효과 더 큼.

---

## 자주 묻는 질문(FAQ)

**Q1. 사전지표가 없으면 CUPED 못 하나요?**
A. **CUPAC**처럼 **사전 특징**으로 **사전기간 결과**를 예측해 **의사 사전지표**를 만들 수 있습니다. 단, **교차적합**으로 누수 방지.

**Q2. $\theta$ 는 컨트롤만으로 구해야 하나요?**
A. 무작위화하에 **전체 표본**에서도 **불편**. 다만 처리가 **$X$의 분포를 강하게 바꾸는** 경우 **컨트롤만** 추천.

**Q3. 로지스틱에서 CUPED은?**
A. “잔차화 후 차이-의-평균”은 **선형**에서 예쁘게 맞습니다. 이항/카운트는 **GLM ANCOVA**로 직접 추정하세요.

**Q4. 공변량을 너무 많이 쓰면?**
A. **VRR↑** 가능하지만 **오버피팅**·**불안정**. **교차적합/정규화**와 **강건 SE**를 사용하고, **해석 가능**한 핵심 공변량 위주로.

**Q5. 파워 계산에 어떻게 반영?**
A. 기존 MDE/표본계획을 $$\sqrt{1-R^2}$$ 배로 조정. 예: MDE 0.30pp, $$R^2=0.36$$ → **0.24pp**.

---

## 수학 부록

### 최적 $\theta^\star$ 도출

$$
\theta^\star = \arg\min_\theta \mathrm{Var}(Y - \theta(X-\mu_X)).
$$
미분하여 0:
$$
\frac{d}{d\theta}\mathrm{Var}(Y - \theta(X-\mu_X)) = -2\,\mathrm{Cov}(Y,X) + 2\theta\,\mathrm{Var}(X)=0
$$
$$
\Rightarrow\ \boxed{\theta^\star=\frac{\mathrm{Cov}(Y,X)}{\mathrm{Var}(X)}},\quad
\mathrm{Var}(Y^\*)=\mathrm{Var}(Y)(1-\rho^2).
$$

### 권고의 요지(스케치)

무작위화 하에서
$$
Y=\alpha+\tau T+\gamma^\top Z + \delta^\top (T\cdot Z)+\varepsilon
$$
을 **HC** 강건 SE로 적합하면, **모형이 틀려도** $$\hat\tau$$ 는 **일치**하고 **정밀**.
이는 **잔차화** 추정량과 1차 근사에서 동등.

---

## 체크리스트(출시 전)

- [ ] **사전지표/특징**이 **처리 이전**에 고정되는가? (누수 X)
- [ ] **랜덤화 단위**와 **분석/부트스트랩 단위** 일치(사용자 ID).
- [ ] **윈도우 선택** 합리성(시즌성·캠페인 영향 고려).
- [ ] **VRR 사전 추정**으로 기대 이득 확인(예: 상관/$$R^2$$).
- [ ] **HC3/클러스터 SE** 적용, heavy-tail은 **윈저·로그** 병행.
- [ ] GLM일 때 **오프셋/링크** 맞는지 점검.
- [ ] **교차적합**(CUPAC/ML) 적용 및 과적합 방지.
- [ ] **리포트**: 미조정 vs 조정치, CI 폭 비교, VRR/MDE 절감 수치 명시.

---

## TL;DR

- **CUPED**: $$Y^\*=Y-\theta(X-\bar X)$$, **$\theta=\mathrm{Cov}(Y,X)/\mathrm{Var}(X)$**, **VRR=1-ρ²**.
- **ANCOVA**: `Y ~ T + Z + T:Z`(**Lin-스타일** + **HC 강건 SE**)로 **정밀도↑**, 모형이 틀려도 **일치성**.
- **CUPAC/ML + 교차적합**으로 **$R^2$**를 키워 **MDE**를 더 줄일 수 있다.
- **항상**: 사후 공변량 금지, 랜덤화 단위 일치, 과적합/드리프트 주의.
