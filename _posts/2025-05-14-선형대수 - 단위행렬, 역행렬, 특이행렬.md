---
layout: post
title: 선형대수 - 단위행렬, 역행렬, 특이행렬
date: 2025-05-14 21:20:23 +0900
category: 선형대수
---
# 단위행렬, 역행렬, 특이행렬 — 선형 시스템의 핵심 도구들 (전면 개정)

## 표기(Notation)

- 정방행렬: $$\mathbf{A}\in\mathbb{R}^{n\times n}$$, 항등행렬: $$\mathbf{I}_n$$
- 전치: $$\mathbf{A}^\top$$, 역행렬: $$\mathbf{A}^{-1}$$, 행렬식: $$\det(\mathbf{A})$$
- 랭크: $$\operatorname{rank}(\mathbf{A})$$, 영공간: $$\mathcal{N}(\mathbf{A})=\{\mathbf{x}:\mathbf{A}\mathbf{x}=\mathbf{0}\}$$
- 노름: $$\lVert\cdot\rVert\equiv\lVert\cdot\rVert_2$$, 조건수: $$\kappa(\mathbf{A})=\lVert\mathbf{A}\rVert\,\lVert\mathbf{A}^{-1}\rVert$$

---

## 단위행렬(Identity Matrix)

### 정의와 예

$$
\mathbf{I}_n=\begin{bmatrix}
1&0&\cdots&0\\
0&1&\cdots&0\\
\vdots&\vdots&\ddots&\vdots\\
0&0&\cdots&1
\end{bmatrix},\qquad
\mathbf{A}\mathbf{I}_n=\mathbf{I}_n\mathbf{A}=\mathbf{A}.
$$

### 성질 요약

- $$\det(\mathbf{I}_n)=1,\ \ \mathbf{I}_n^{-1}=\mathbf{I}_n$$
- 모든 고유값이 1, 고유벡터는 표준기저(임의의 완전기저 가능)

---

## 역행렬(Inverse Matrix)

### 정의

정방행렬 $$\mathbf{A}$$ 에 대해
$$
\mathbf{A}\mathbf{A}^{-1}=\mathbf{A}^{-1}\mathbf{A}=\mathbf{I}_n
$$
를 만족하는 행렬 $$\mathbf{A}^{-1}$$ 이 존재하면, $$\mathbf{A}$$ 는 **가역**(invertible)입니다.

### 동치 조건(서로 동치)

다음은 모두 동치입니다.
$$
\det(\mathbf{A})\neq 0
\ \Longleftrightarrow\
\operatorname{rank}(\mathbf{A})=n
\ \Longleftrightarrow\
\mathcal{N}(\mathbf{A})=\{\mathbf{0}\}
\ \Longleftrightarrow\
\text{모든 고유값 }\lambda_i\neq 0
\ \Longleftrightarrow\
\mathbf{A}\text{는 전단사 선형사상}.
$$

### 기본 성질

$$
(\mathbf{A}^{-1})^{-1}=\mathbf{A},\quad
(\mathbf{A}^\top)^{-1}=(\mathbf{A}^{-1})^\top,\quad
(\mathbf{A}\mathbf{B})^{-1}=\mathbf{B}^{-1}\mathbf{A}^{-1}.
$$
직교행렬 $$\mathbf{Q}$$ 는 $$\mathbf{Q}^{-1}=\mathbf{Q}^\top$$.

### 닫힌형 공식(소규모)

- 2×2:
$$
\mathbf{A}=\begin{bmatrix}a&b\\c&d\end{bmatrix},\ \ \det(\mathbf{A})=ad-bc\neq 0
\Rightarrow
\mathbf{A}^{-1}=\frac{1}{ad-bc}\begin{bmatrix}d&-b\\-c&a\end{bmatrix}.
$$
- 일반 $$n$$: 수치적으로 adjugate 공식은 비실용적(불안정·고비용).

### 수치 해법과 권장사항

- **연립방정식** $$\mathbf{A}\mathbf{x}=\mathbf{b}$$ 에서 **직접 역행렬을 구하지 말고**
  $$\mathbf{x}=\mathbf{A}^{-1}\mathbf{b}$$ 대신
  **분해 기반 해법**을 쓰는 것이 표준입니다.
  - 일반: LU(+피벗) → forward/backward solve
  - 과결정 최소제곱: QR 또는 SVD
  - 대칭 양정치(SPD): Cholesky
- 이유: 안정성·성능·오차 증폭 최소화를 위해.

### 조건수와 악조건성

- $$\kappa(\mathbf{A})=\sigma_{\max}/\sigma_{\min}$$ (2-노름에서 SVD 특이값 비)
- $$\kappa$$ 가 클수록 해가 데이터·오차에 민감(거의 특이).
- 설계: 정규화, 재스케일링, 정규화항(릿지) 고려.

---

## 특이행렬(Singular Matrix)

### 정의와 동치

역행렬이 없으면 **특이**라 하고,
$$
\det(\mathbf{A})=0
\ \Longleftrightarrow\
\operatorname{rank}(\mathbf{A})<n
\ \Longleftrightarrow\
\exists\,\mathbf{x}\neq\mathbf{0}:\ \mathbf{A}\mathbf{x}=\mathbf{0}.
$$

### 기하·연산적 의미

- 선형사상이 일부 차원을 **붕괴**(예: 평면을 직선으로 압축).
- $$\mathbf{A}\mathbf{x}=\mathbf{b}$$ 는 **해가 없거나 무수히 많음**.
  - 일관성: $$\operatorname{rank}(\mathbf{A})=\operatorname{rank}([\mathbf{A}\mid\mathbf{b}])$$
  - 자유도: $$n-\operatorname{rank}(\mathbf{A})$$

---

## 의사역행렬(Moore–Penrose Pseudoinverse)과 정규화

### 의사역행렬

SVD $$\mathbf{A}=\mathbf{U}\mathbf{\Sigma}\mathbf{V}^\top$$ 에 대해
$$
\mathbf{A}^+=\mathbf{V}\mathbf{\Sigma}^+\mathbf{U}^\top,
$$
여기서 $$\mathbf{\Sigma}^+$$ 는 0이 아닌 특이값의 역으로 구성.
용도:
- 과결정 최소제곱 해 $$\mathbf{x}^\star=\mathbf{A}^+\mathbf{b}$$ (최소노름 해)
- 특이/랭크결핍 상황의 안정적 해

### 릿지(티호노프) 정규화

$$
(\mathbf{A}^\top\mathbf{A}+\lambda\mathbf{I})\mathbf{x}=\mathbf{A}^\top\mathbf{b},\quad \lambda>0.
$$
- $$\lambda\mathbf{I}$$ 로 **수치 안정성** 증대, 과적합 완화, $$\kappa$$ 개선.

---

## 분해 기반 실전 해법 요약

| 상황 | 권장 분해/해법 | 비고 |
|---|---|---|
| 정방, 일반 | LU(+피벗) | 안정적, 빠름 |
| SPD | Cholesky | 가장 빠르고 안정적 |
| 과결정 최소제곱 | QR 또는 SVD | SVD가 가장 견고 |
| 랭크 의심/노이즈 큼 | SVD/의사역 | 임계값으로 유효랭크 결정 |
| 특이 또는 근특이 | 의사역/릿지 | 정규화로 안정화 |

---

## PyTorch 예제

```python
import torch
torch.set_printoptions(precision=6, sci_mode=False)
dtype = torch.float64
```

### 단위행렬과 항등성

```python
I = torch.eye(3, dtype=dtype)
A = torch.tensor([[2., 1., 0.],
                  [0., 1., 3.],
                  [4., 0., 1.]], dtype=dtype)
print("AI - A =\n", A @ I - A)   # 영행렬
print("IA - A =\n", I @ A - A)
```

### 역행렬 계산과 검증(소규모)

```python
A2 = torch.tensor([[2., 1.],
                   [5., 3.]], dtype=dtype)
A2_inv = torch.linalg.inv(A2)
print("A2_inv =\n", A2_inv)
print("A2 @ A2_inv ≈ I =\n", A2 @ A2_inv)
```

### 연립방정식: inv 대신 solve

```python
A = torch.tensor([[3., 2.],
                  [1., 2.]], dtype=dtype)
b = torch.tensor([5., 5.], dtype=dtype)

# 권장

x_solve = torch.linalg.solve(A, b)
# 비권장(데모용)

x_inv = torch.linalg.inv(A) @ b

print("solve x =", x_solve)
print("inv  x =", x_inv)
print("잔차 =", torch.linalg.norm(A @ x_solve - b))
```

### 특이행렬 감지와 실패 사례

```python
B = torch.tensor([[1., 2.],
                  [2., 4.]], dtype=dtype)  # 행이 배수 → 랭크 1

detB = torch.linalg.det(B)
rankB = torch.linalg.matrix_rank(B)
print("det(B) =", detB.item(), " rank(B) =", int(rankB.item()))

try:
    torch.linalg.inv(B)
except RuntimeError as e:
    print("역행렬 실패(특이):", str(e).splitlines()[0])
```

### 의사역행렬로 최소제곱/최소노름 해

```python
# 과결정 예: 3x2

A_ls = torch.tensor([[1., 1.],
                     [1., 2.],
                     [1., 3.]], dtype=dtype)
b_ls = torch.tensor([2., 2., 4.], dtype=dtype)

x_pinv = torch.linalg.pinv(A_ls) @ b_ls          # 최소제곱-최소노름 해
x_lstsq = torch.linalg.lstsq(A_ls, b_ls).solution

print("pinv  해 =", x_pinv)
print("lstsq 해 =", x_lstsq)
print("잔차 노름 =", torch.linalg.norm(A_ls @ x_pinv - b_ls))
```

### SPD에서의 Cholesky 해법

```python
# SPD 예: A = M^T M

M = torch.tensor([[2., 0., 0.],
                  [1., 1., 0.],
                  [0., 1., 1.]], dtype=dtype)
A_spd = M.T @ M
b = torch.tensor([1., 0., 2.], dtype=dtype)

L = torch.linalg.cholesky(A_spd)           # A = L L^T
y = torch.cholesky_solve(b.unsqueeze(1), L)  # 직접 해 구하기 (b를 열벡터로)
x_chol = y.squeeze(1)
print("Cholesky 해 =", x_chol)

# 검증

print("잔차 =", torch.linalg.norm(A_spd @ x_chol - b))
```

### 조건수와 악조건성 예시

```python
# 근특이 행렬: 작은 eps로 열을 거의 평행하게 만들기

eps = 1e-8
C = torch.tensor([[1., 1.],
                  [1., 1.+eps]], dtype=dtype)
U, S, Vh = torch.linalg.svd(C)
cond2 = (S.max() / S.min()).item()
print("특이값 =", S.numpy(), "  cond2 ≈", cond2)

b = torch.tensor([2., 2.+eps], dtype=dtype)
x_solve = torch.linalg.solve(C, b)
print("해 x =", x_solve)  # eps 크기에 매우 민감
```

### 릿지 정규화로 안정화

```python
A = torch.tensor([[1., 1.],
                  [1., 1.+1e-8]], dtype=dtype)
b = torch.tensor([2., 2.+1e-8], dtype=dtype)

lam = 1e-3
x_ridge = torch.linalg.solve(A.T @ A + lam*torch.eye(2, dtype=dtype), A.T @ b)
print("릿지 해 =", x_ridge)
```

### 블록 역행렬(쉬우면서 유용한 형태)

2×2 블록
$$
\mathbf{A}=\begin{bmatrix}\mathbf{P}&\mathbf{Q}\\\mathbf{R}&\mathbf{S}\end{bmatrix}
$$
에서 $$\mathbf{P}$$ 가 가역이고 슈어 보충 $$\mathbf{S}-\mathbf{R}\mathbf{P}^{-1}\mathbf{Q}$$ 가 가역이면
$$
\mathbf{A}^{-1}=
\begin{bmatrix}
\mathbf{P}^{-1}+\mathbf{P}^{-1}\mathbf{Q}\mathbf{T}^{-1}\mathbf{R}\mathbf{P}^{-1} & -\mathbf{P}^{-1}\mathbf{Q}\mathbf{T}^{-1}\\
-\mathbf{T}^{-1}\mathbf{R}\mathbf{P}^{-1} & \mathbf{T}^{-1}
\end{bmatrix},
\quad
\mathbf{T}=\mathbf{S}-\mathbf{R}\mathbf{P}^{-1}\mathbf{Q}.
$$

```python
# 작은 블록 예시 검증

P = torch.tensor([[2., 0.],
                  [0., 3.]], dtype=dtype)
Q = torch.tensor([[1., 2.],
                  [0., 1.]], dtype=dtype)
R = torch.tensor([[0., 1.],
                  [1., 0.]], dtype=dtype)
S = torch.tensor([[4., 1.],
                  [1., 2.]], dtype=dtype)

Pinv = torch.linalg.inv(P)
T = S - R @ Pinv @ Q
A = torch.block_diag(P, S)
A[:2, 2:] = Q
A[2:, :2] = R

Ainv_block = torch.empty_like(A)
top_left  = Pinv + Pinv @ Q @ torch.linalg.inv(T) @ R @ Pinv
top_right = - Pinv @ Q @ torch.linalg.inv(T)
bot_left  = - torch.linalg.inv(T) @ R @ Pinv
bot_right = torch.linalg.inv(T)
Ainv_block[:2, :2] = top_left
Ainv_block[:2, 2:] = top_right
Ainv_block[2:, :2] = bot_left
Ainv_block[2:, 2:] = bot_right

Ainv_torch = torch.linalg.inv(A)
print("블록공식과 inv 비교 노름 =", torch.linalg.norm(Ainv_block - Ainv_torch))
```

---

## 해석적·실전적 요약

1) **역행렬 존재 조건**: $$\det\neq 0,\ \operatorname{rank}=n,\ \mathcal{N}=\{\mathbf{0}\},\ \lambda_i\neq 0$$ 는 모두 동치.
2) **직접 역행렬 금지**: 해 구할 땐 solve/분해 사용이 표준.
3) **특이/근특이**: 의사역행렬(또는 릿지)로 안정적 해를 구함.
4) **조건수 관리**: 표준화/스케일링, 정규화, 적절한 분해(SVD/QR/Cholesky).
5) **블록 행렬**: 슈어 보충으로 부분 역 연산 및 조건 개선을 활용.

---

## 연습문제(힌트 포함)

1) $$\mathbf{A}=\begin{bmatrix}1&2\\3&4\end{bmatrix}$$ 의 역행렬을 2×2 공식으로 구해 검증하라.
힌트: $$\det=-2,\ \mathbf{A}^{-1}=\frac{1}{-2}\begin{bmatrix}4&-2\\-3&1\end{bmatrix}$$.

2) $$\operatorname{rank}(\mathbf{A})<n$$ 이면 $$\mathbf{A}\mathbf{x}=\mathbf{b}$$ 가
i) 해가 없을 조건, ii) 무수히 많은 해가 있을 조건을 랭크로 서술하라.

3) $$\mathbf{A}$$ 가 SPD 일 때 Cholesky 가 LU 대비 유리한 이유(안정성·연산량)를 설명하고,
단계별로 $$\mathbf{A}\mathbf{x}=\mathbf{b}$$ 를 푸는 과정을 적어라.

4) SVD 로 의사역행렬을 정의할 때, 작은 특이값 절단의 의미와
데이터 노이즈 관점에서의 장단점을 논하라.

5) 슈어 보충을 이용해 블록 행렬의 역을 유도하고,
슈어 보충이 양정치임을 보이면 원 행렬의 양정치성과 어떤 관계가 있는지 설명하라.

---

## 결론

- **단위행렬**은 행렬곱의 항등원이며 모든 역연산의 기준점입니다.
- **역행렬**은 가역성의 표상으로, 존재 여부는 랭크·행렬식·영공간·고유값과 동치입니다.
- **특이행렬**은 차원을 붕괴시키며, 해가 유일하지 않습니다. 이때 **의사역행렬**과 **정규화**가 실전 해법입니다.
- 실제 계산에서는 **직접 역행렬을 피하고**, **분해 기반 해법**을 선택하는 것이 정확도와 성능을 모두 확보하는 길입니다.
