---
layout: post
title: 웹해킹 - 복잡도/속도 제한
date: 2025-10-15 15:25:23 +0900
category: 웹해킹
---
# 29. 복잡도/속도 제한: **GraphQL Depth/Cost, 파일 처리 제한**  
— **DoS/리소스 고갈**을 구조적으로 막는 설계: *쿼리 복잡도/깊이*, *요청/초(레이트)*, *파일 크기·해상도·압축율·디코딩 비용*, *큐·비동기 처리*, *프록시/웹서버 상한*까지

> 목적  
> 대규모 트래픽/악의적 요청/우발적 중복 클릭, 그리고 *이미지·동영상·압축파일* 같은 무거운 입력이 섞인 환경에서 **CPU·메모리·IO**를 예측가능한 한계 안으로 고정합니다.  
> 핵심은 **사전에 예산을 계산**(GraphQL *쿼리 비용*)하고, **요청을 등급화·속도제한**하며, **파일 디코딩·리샘플링·압축폭탄** 등의 *최악경로*를 **구조적으로 봉쇄**하는 것입니다.

---

## 0) 한눈에 보기(Executive Summary)

- **GraphQL**  
  - *Depth 제한*: 경로 깊이 상한(예: `maxDepth=10`).  
  - *Cost(복잡도) 제한*: 필드별 *가중치 × 예상 항목 수*를 누적해 상한(예: `maxCost=2e3`).  
  - *Persisted Query*: **화이트리스트 쿼리만** 허용해 동적 쿼리 면적 축소.  
  - *레이트 제한*: 사용자/토큰/IP별 **슬라이딩 윈도 또는 토큰 버킷**.
- **파일 처리**  
  - *HTTP 레벨 상한*: `client_max_body_size`/`maxRequestBodySize`.  
  - *Magic bytes* 기반 **MIME 검증**(확장자 불신).  
  - *이미지*: **메가픽셀 상한**, **최대 치수**, **재인코딩**, **압축폭탄(Decompression Bomb) 차단**.  
  - *ZIP/아카이브*: **총 해제 크기·파일 수·중첩 심도** 제한 + **Zip-Slip** 경로 정규화.  
  - *비디오*: **해상도·길이·비트레이트** 한도, **트랜스코딩 큐**(동기 금지).
- **운영**  
  - *에러 코드*: 400/413/422/429/503의 일관된 사용.  
  - *큐/비동기*: 무거운 처리는 202 + 폴링/웹훅.  
  - *지표*: 차단율, p95 비용, 업로드 거부 사유, 큐 대기시간.

---

## 1) 위협 모델

1) **GraphQL 폭발성**  
   - 중첩 필드, *alias*·*fragment*·*배열 곱셈* → **N×M×K** 폭.  
   - 페이징 미흡, “`first: 1000` × `edges.node { … }` × `subCollection`” 같은 곱셈.
2) **파일 기반 DoS**  
   - 30KB PNG → **1.2GB** 픽셀 버퍼(거대 해상도/악성 IHDR), **ZIP 폭탄**(해제 100GB), 잘못된 코덱 파싱.
3) **네트워크/재시도**  
   - 자동 재시도/다중 클릭으로 동일 처리 누적(→ 28장 Idempotency-Key와 연결).  
4) **다중 인스턴스**  
   - 동일 순간 유입 → 모든 인스턴스가 **동시에 무거운 일** 시작.

---

## 2) GraphQL 복잡도 모델: *깊이 + 비용(가중치)*

### 2.1 기본 공식
- **깊이(depth)**: 루트에서 리프까지 경로 길이.  
- **비용(cost)**: 필드별 비용을 다음처럼 누적:
  
  $$\text{cost} = \sum_{\text{field}\ i} w_i \times \prod \text{(증폭 인자)}$$

- **증폭 인자**: `first/limit`(목록 수), `width×height`(이미지 썸네일 생성 같은 변환), 하위 필드 fan-out.

### 2.2 경험적 상수
- `Query.user`: \( w=1 \)  
- `User.posts(first:n)`: \( w=2 \cdot \min(n, 50) \)  
- `Post.comments(first:m)`: \( w=3 \cdot \min(m, 50) \)  
- *합계가* `maxCost=2000`, *깊이가* `maxDepth=10`를 넘으면 거절(400).

---

## 3) 예제 스키마(전자상거래 간단화)

```graphql
type Query {
  me: User
  user(id: ID!): User
  search(term: String!, first: Int = 10): [Product!]!
}

type User {
  id: ID!
  name: String!
  orders(first: Int = 10): [Order!]!
}

type Order {
  id: ID!
  items(first: Int = 20): [OrderItem!]!
  total: Int!
}

type OrderItem {
  sku: String!
  product: Product!
  qty: Int!
}

type Product {
  id: ID!
  title: String!
  price: Int!
  images(first: Int = 5): [Image!]!
}

type Image {
  url: String!
  width: Int!
  height: Int!
}
```

---

## 4) **Apollo Server** 플러그인: *깊이/노드/비용* 동시 제한

> 외부 라이브러리 없이 **AST 방문**으로 구현(실무에서는 검증된 라이브러리 사용 가능).

```ts
// src/graphql/complexity.ts
import {
  parse, visit, Kind, DocumentNode, OperationDefinitionNode, FieldNode
} from 'graphql';

type Ctx = { vars: Record<string, number> };

const MAX_DEPTH = 10;
const MAX_NODES = 1500;
const MAX_COST  = 2000;

function argInt(node: FieldNode, name: string, ctx: Ctx, def = 0): number {
  const a = node.arguments?.find(a => a.name.value === name);
  if (!a) return def;
  if (a.value.kind === Kind.INT) return parseInt(a.value.value, 10);
  if (a.value.kind === Kind.VARIABLE) {
    const v = ctx.vars[a.value.name.value]; return typeof v === 'number' ? v : def;
  }
  return def;
}

export function analyze(doc: DocumentNode, variables: Record<string, any>) {
  let maxDepth = 0, nodes = 0, cost = 0;
  const ctx: Ctx = { vars: Object.fromEntries(Object.entries(variables ?? {}).map(([k,v]) => [k, Number(v)])) };

  function weight(fieldPath: string[], node: FieldNode): number {
    const name = node.name.value;
    const path = fieldPath.join('.');
    // 가중치 규칙(서비스 상황에 맞춰 조정)
    if (path === 'Query.search') {
      const first = Math.min(argInt(node,'first',ctx,10), 50);
      return 5 * first;
    }
    if (path.endsWith('.orders')) {
      const first = Math.min(argInt(node,'first',ctx,10), 50);
      return 2 * first;
    }
    if (path.endsWith('.items')) {
      const first = Math.min(argInt(node,'first',ctx,20), 50);
      return 3 * first;
    }
    if (path.endsWith('.images')) {
      const first = Math.min(argInt(node,'first',ctx,5), 10);
      return 1 * first;
    }
    return 1; // 기본
  }

  function visitSelection(selections: any[], path: string[], depth: number) {
    maxDepth = Math.max(maxDepth, depth);
    for (const sel of selections ?? []) {
      if (sel.kind === Kind.FIELD) {
        nodes++;
        const newPath = [...path, sel.name.value];
        cost += weight(newPath, sel);
        const sub = sel.selectionSet?.selections;
        if (sub) visitSelection(sub, newPath, depth + 1);
      } else if (sel.kind === Kind.INLINE_FRAGMENT) {
        visitSelection(sel.selectionSet?.selections, path, depth);
      } else if (sel.kind === Kind.FRAGMENT_SPREAD) {
        // 실제 프로덕션에서는 fragmentDefs를 맵에 담아 연결
      }
    }
  }

  for (const def of doc.definitions) {
    if (def.kind === Kind.OPERATION_DEFINITION) {
      visitSelection(def.selectionSet.selections, [def.operation], 1);
    }
  }
  return { maxDepth, nodes, cost };
}

export function ensureWithinLimits(q: string, variables: Record<string, any>) {
  const doc = parse(q);
  const { maxDepth, nodes, cost } = analyze(doc, variables ?? {});
  if (maxDepth > MAX_DEPTH) throw new Error(`Query depth ${maxDepth} exceeds ${MAX_DEPTH}`);
  if (nodes   > MAX_NODES)  throw new Error(`Query nodes ${nodes} exceeds ${MAX_NODES}`);
  if (cost    > MAX_COST)   throw new Error(`Query cost ${cost} exceeds ${MAX_COST}`);
  return { maxDepth, nodes, cost };
}
```

```ts
// src/graphql/server.ts
import { ApolloServer } from '@apollo/server';
import { startStandaloneServer } from '@apollo/server/standalone';
import type { ContextFunction } from '@apollo/server';
import { ensureWithinLimits } from './complexity';

const typeDefs = /* GraphQL */`…(위 스키마)…`;
const resolvers = { /* … */ };

const server = new ApolloServer({ typeDefs, resolvers });

await startStandaloneServer(server, {
  listen: { port: 4000 },
  context: async ({ req }) => {
    const q = (req as any).body?.query ?? '';
    const variables = (req as any).body?.variables ?? {};
    const metrics = ensureWithinLimits(q, variables);
    return { metrics, userId: req.headers['x-user-id'] };
  }
});
```

> **효과**: 쿼리 **수락 전에** 비용 산정 → 상한 초과 시 **즉시 거절(400)**.  
> **팁**: 필드별 *가중치*는 **실측 비용**(DB/캐시 조회수, 예상 레코드 수)로 **주기적 보정**.

---

## 5) Persisted Query(화이트리스트) + 인트로스펙션 정책

- **운영**: *동적 텍스트 쿼리* 대신 **사전 해시 등록 쿼리**만 허용.  
- **장점**:  
  - 방화벽/캐시에서 **쿼리 해시 기반** 제어 가능.  
  - **쿼리 변형 공격면** 축소(특히 alias/fragment 변형).  
- **정책**: 운영에서는 **인트로스펙션 비활성**(내부 툴·스테이징에서만 활성) + **Persisted만 허용**.

```ts
// 예시: 쿼리 해시 화이트리스트
const ALLOW = new Set([
  'b7b3a5…', // getMe
  '6a1c22…', // searchProducts
]);

function assertPersisted(req: any) {
  const hash = req.headers['x-gql-hash'] || req.body?.extensions?.persistedQuery?.sha256Hash;
  if (!hash || !ALLOW.has(hash)) throw new Error('Persisted query only');
}
```

---

## 6) 레이트 제한(토큰 버킷) — **복잡도 가중 레이트**

> 요청 1건 = 1토큰… 이 아니라 **“쿼리 비용”만큼 토큰 차감**하면 공격자가 *작은 간격의 무거운 쿼리*를 연속 날리기 어렵습니다.

### 6.1 Redis Lua (원자)

```lua
-- token_bucket.lua
-- KEYS[1] = bucket:{userId}
-- ARGV[1] = now_millis, ARGV[2] = fill_rate_per_sec, ARGV[3] = capacity, ARGV[4] = cost
local now   = tonumber(ARGV[1])
local rate  = tonumber(ARGV[2])
local cap   = tonumber(ARGV[3])
local cost  = tonumber(ARGV[4])

local last = redis.call('HGET', KEYS[1], 'ts')
local tokens = redis.call('HGET', KEYS[1], 'tok')
if not last then last = now; tokens = cap end
last = tonumber(last); tokens = tonumber(tokens)

local delta = (now - last) / 1000.0
tokens = math.min(cap, tokens + delta * rate)

if tokens < cost then
  redis.call('HSET', KEYS[1], 'ts', now, 'tok', tokens)
  redis.call('EXPIRE', KEYS[1], 3600)
  return {0, tokens} -- 거부
else
  tokens = tokens - cost
  redis.call('HSET', KEYS[1], 'ts', now, 'tok', tokens)
  redis.call('EXPIRE', KEYS[1], 3600)
  return {1, tokens} -- 허용
end
```

```ts
// 사용 (Node/Apollo context)
const cost = metrics.cost;              // 위 complexity 결과
const key  = `bucket:${userId || ip}`;
const [ok, remain] = await redis.evalsha(SHA, 1, key, Date.now(), 20 /*tps*/, 200 /*cap*/, cost);
if (!ok) throw new GraphQLError('Rate limit', { extensions: { code: 'RATE_LIMITED' }});
```

---

## 7) 파일 처리 제한 — **HTTP·MIME·픽셀·압축폭탄**

### 7.1 HTTP 레벨 상한

- **Nginx**
  ```nginx
  client_max_body_size 15m;      # 업로드 상한
  proxy_read_timeout  60s;
  proxy_send_timeout  60s;
  ```
- **Express**
  ```ts
  app.use(express.json({ limit: '1mb' }));
  app.use(express.urlencoded({ extended: false, limit: '1mb' }));
  ```

### 7.2 업로드 파이프라인(버스보이 + Magic bytes + 샤프)

```ts
// src/upload/image.ts
import Busboy from 'busboy';
import { fileTypeFromStream } from 'file-type';
import sharp from 'sharp';
import { createWriteStream } from 'node:fs';
import { tmpdir } from 'node:os';
import { join } from 'node:path';

const MAX_BYTES = 10 * 1024 * 1024; // 10MB
const MAX_MP    = 12;                // 메가픽셀 상한 (예: 12MP)
const MAX_W     = 6000, MAX_H = 6000;

export function handleImageUpload(req, res) {
  const bb = Busboy({ headers: req.headers, limits: { fileSize: MAX_BYTES, files: 1 } });
  let rejected = false;

  bb.on('file', async (name, stream, info) => {
    try {
      // 1) Magic bytes로 MIME 검증
      const ft = await fileTypeFromStream(stream);
      if (!ft || !['image/png','image/jpeg','image/webp','image/avif'].includes(ft.mime)) {
        rejected = true; stream.resume();
        return res.status(415).json({ error: 'unsupported_media_type' });
      }

      // 2) Sharp로 메타데이터만 우선 읽기(스트림을 복사하는 대신 temp로 흘리기)
      const temp = join(tmpdir(), `up_${Date.now()}.${ft.ext}`);
      const sink = createWriteStream(temp);
      stream.pipe(sink);
      await new Promise((ok,ko)=>sink.on('finish',ok).on('error',ko));

      const meta = await sharp(temp, { limitInputPixels: MAX_MP * 1_000_000 + 1 }) // 폭탄 방어
                      .metadata(); // width/height/exif

      if (!meta.width || !meta.height) {
        return res.status(422).json({ error: 'invalid_image' });
      }
      if (meta.width > MAX_W || meta.height > MAX_H) {
        return res.status(413).json({ error: 'too_large', width: meta.width, height: meta.height });
      }
      if ((meta.width * meta.height) > (MAX_MP * 1_000_000)) {
        return res.status(413).json({ error: 'too_many_pixels' });
      }

      // 3) 표준화(리사이즈+재인코딩) — EXIF 제거, WebP 재인코드
      const out = join(tmpdir(), `norm_${Date.now()}.webp`);
      await sharp(temp)
        .rotate() // EXIF 회전 보정
        .resize({ width: Math.min(meta.width, 4096), height: Math.min(meta.height, 4096), fit: 'inside', withoutEnlargement: true })
        .toFormat('webp', { quality: 82 })
        .toFile(out);

      // 4) 바이러스/정책 스캔(선택: ClamAV 등) → 저장소(S3 등)에 업로드
      return res.status(201).json({ ok: true, format: 'webp' });
    } catch (e) {
      if (!rejected) return res.status(422).json({ error: 'decode_failed' });
    }
  });

  bb.on('error', () => res.status(400).end());
  req.pipe(bb);
}
```

> **포인트**  
> - **Magic bytes**로 타입 확인(확장자 불신).  
> - `limitInputPixels`로 **디코딩 단계**에서 폭탄 차단.  
> - **리사이즈·재인코딩**으로 표준화(Exif 제거·퀄리티 제한).  
> - 413(Too Large)/422(Unprocessable Entity)/415(Unsupported) 구분.

### 7.3 ZIP/아카이브 제한(Zip-Slip·폭탄)

```ts
import unzipper from 'unzipper';
import { createWriteStream } from 'node:fs';
import { normalize, join } from 'node:path';

const MAX_ENTRIES = 500;
const MAX_TOTAL   = 200 * 1024 * 1024; // 200MB 해제 상한
const MAX_DEPTH   = 5;
const SAFE_DIR    = '/srv/uploads/unpacked';

function safeJoin(base: string, p: string) {
  const n = normalize('/' + p).replace(/^\/+/, ''); // 상대경로 정규화
  if (n.includes('..')) throw new Error('zip_slip');
  return join(base, n);
}

export async function handleZip(req, res) {
  let entries = 0, total = 0;
  req.pipe(unzipper.Parse())
    .on('entry', e => {
      entries++; if (entries > MAX_ENTRIES) { e.autodrain(); return; }
      const depth = e.path.split('/').length - 1;
      if (depth > MAX_DEPTH) { e.autodrain(); return; }

      const out = safeJoin(SAFE_DIR, e.path);
      if (e.type === 'Directory') { e.autodrain(); return; }
      const ws = createWriteStream(out);
      e.on('data', (buf) => {
        total += buf.length;
        if (total > MAX_TOTAL) { e.autodrain(); ws.close(); }
      });
      e.pipe(ws);
    })
    .on('close', () => {
      if (total > MAX_TOTAL || entries > MAX_ENTRIES) return res.status(413).json({ error: 'archive_too_big' });
      return res.status(201).json({ ok: true, entries, total });
    })
    .on('error', () => res.status(422).json({ error: 'bad_archive' }));
}
```

> **방어 포인트**  
> - **Zip-Slip**(상대 경로 탈출) 차단.  
> - **총 해제 크기/엔트리 수/폴더 깊이** 상한.  
> - 압축폭탄은 **해제 총량**으로 제한.

### 7.4 비디오 메타 검증(ffprobe)

- **해상도/길이/비트레이트** 상한만 선검증 → 트랜스코딩은 **큐**로 오프로딩.
- 결과 코덱/비트레이트 **프로파일** 강제(HLS/DASH 변환은 워커).

---

## 8) 무거운 처리 = **큐 + 202 Accepted**

> 대용량 이미지 변환/비디오 트랜스코딩/AI 추론 등은 **요청 스레드에서 절대 직접 처리하지 말고** 작업 큐에 넣습니다.

```
Client  ── POST /uploads → 202 + { jobId } ──▶ Queue ──▶ Worker(N개, 동시성 k) ──▶ Storage/DB
                      ▲                                          │
                      └─────────── GET /jobs/{id} (status) ◀─────┘
```

- **장점**: 요청 폭주 시 큐 길이가 늘어날 뿐, **웹 프로세스의 CPU/메모리**는 안정.  
- **스케일**: 워커 수·동시성으로 처리량을 제어(백프레셔).  
- **에러**: 재시도 정책(멱등 키와 결합), DLQ(사망 큐).

---

## 9) 프록시/에지 상한(Nginx/CloudFront)

- **Nginx**
  ```nginx
  client_max_body_size 15m;
  limit_req_zone $binary_remote_addr zone=gql:10m rate=10r/s;
  limit_req zone=gql burst=20 nodelay;  # GraphQL 엔드포인트
  proxy_read_timeout 60s;
  ```
- **CDN 캐시**: GraphQL은 보통 **캐시 어려움** → 대신 **WAF 규칙**(깊이/길이/문자열 시그니처) 적용.

---

## 10) 에러 코드/메시지 정책

| 상황 | 코드 | 예 |
|---|---:|---|
| GraphQL 깊이/비용 초과 | 400 | `{ "error": "query_cost_exceeded", "cost": 2137, "max": 2000 }` |
| 레이트 제한 | 429 | `Retry-After: 3` |
| 본문 크기 초과 | 413 | `client_max_body_size` 초과 |
| MIME/디코딩 실패 | 415/422 | `{ "error": "unsupported_media_type" }` |
| 큐 처리 중 | 202 | `{ "jobId": "…" }` |

---

## 11) 테스트 시나리오

1) **깊이 20짜리 쿼리** → 400.  
2) `first: 1000` 곱셈 유도 → 400(비용 초과).  
3) 동일 사용자 10req/s + 비용 300 → 약 2~3req/s로 자동 스로틀(429).  
4) 50MB 이미지 업로드 → 413.  
5) 10MP 제한 초과 이미지 → 413(`too_many_pixels`).  
6) ZIP 폭탄(해제 10GB) → 413(`archive_too_big`).  
7) 비디오 업로드 → 202 + 워커로 트랜스코딩.

---

## 12) 운영 지표

- **GraphQL**: 평균/95p **depth**, **cost**, **nodes**. 거절율(400), 429율.  
- **파일**: 업로드 성공률, 거부 사유 분포(415/413/422), 평균 처리시간.  
- **큐**: 대기시간, 처리율, 실패율, DLQ 수.  
- **호스트**: CPU/메모리/FD 수/GC 시간(스파이크 알람).

---

## 13) 수학적 직관: 비용 예산의 합계

- 게시물/댓글 쿼리의 예상 비용:
  $$
  \text{cost}
  = 2\cdot \min(n, 50) \times \bigl(1 + 3\cdot \min(m, 50)\bigr)
  $$
  예: `n=40, m=20`이면  
  $$2\cdot 40 \times (1 + 3\cdot 20) = 80 \times 61 = 4880 \ \Rightarrow\ \text{거부}$$
- **설계 포인트**: *상수*는 **실측 기반**으로 주기적 조정.

---

## 14) 체크리스트

- [ ] GraphQL **maxDepth / maxNodes / maxCost** 선검증  
- [ ] **Persisted Query** + 인트로스펙션 운영 비활성  
- [ ] **복잡도 가중 레이트 제한**(Redis 버킷)  
- [ ] 파일 업로드 **크기/MIME/픽셀/압축폭탄** 제한  
- [ ] 무거운 작업은 **큐 + 202**  
- [ ] 에지(Nginx/CDN) **body/rate** 상한  
- [ ] **표준 에러 코드/메시지** 일관성  
- [ ] 대시보드: 비용/거절/큐 대기시간/거부 사유

---

## 15) “복붙” 스타터 패키지(요약)

```ts
// 1) GraphQL 서버 띄우기 전: ensureWithinLimits(query, variables)
// 2) Redis 버킷: cost 기반 차감
// 3) 업로드 라우트: Magic bytes → meta → 표준화 → 저장
// 4) 무거운 건 즉시 202 + 큐
```