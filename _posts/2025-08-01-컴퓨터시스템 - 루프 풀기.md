---
layout: post
title: 컴퓨터시스템 - 루프 풀기
date: 2025-08-01 21:20:23 +0900
category: 컴퓨터시스템
---
# 루프 풀기(Loop Unrolling) — 성능 최적화 기법 심층 분석

루프 풀기(Loop Unrolling)는 **루프 반복 횟수를 줄이기 위해 루프 본문의 연산을 여러 번 복제**하여 한 번의 반복에 더 많은 작업을 수행하는 기법이다.  
Bryant & O’Hallaron의 *컴퓨터 시스템: 핵심 개념과 원리*에서도 루프 최적화의 중요한 전략 중 하나로 다룬다.

---

## 1. 개념 요약
- **정의**: 루프의 본문을 여러 번 복사하여, 반복문 제어(조건 비교, 분기)로 인한 오버헤드를 줄이고, 파이프라인 병렬성을 향상시키는 기법.
- **목적**
  1. 루프 제어 명령어 수 감소 → **분기 오버헤드 감소**
  2. 독립 연산 간 병렬 수행 가능성↑ → **파이프라인 활용도 증가**
  3. 메모리 접근 패턴 최적화 → **캐시 효율 향상 가능**

---

## 2. 기본 예제

### 2.1 원본 코드
```c
int sum_array(int *a, int n) {
    int sum = 0;
    for (int i = 0; i < n; i++) {
        sum += a[i];
    }
    return sum;
}
```

- 매 반복마다 `i < n` 비교, 분기, `i++` 수행
- **루프 제어 오버헤드**가 상대적으로 커짐

---

### 2.2 루프 4배 풀기(Unroll factor = 4)
```c
int sum_array_unrolled4(int *a, int n) {
    int sum = 0;
    int i = 0;

    // 4개씩 더함
    for (; i <= n - 4; i += 4) {
        sum += a[i] + a[i+1] + a[i+2] + a[i+3];
    }

    // 남은 원소 처리
    for (; i < n; i++) {
        sum += a[i];
    }

    return sum;
}
```
**변화점**:
- 루프 반복 횟수 = 약 `n/4` 로 감소
- 제어 명령어 수가 줄어 **분기 예측기 부담 완화**
- 연속된 메모리 접근으로 캐시 히트율↑

---

## 3. 어셈블리 관점에서의 이득
원본 루프:
```asm
.L1:
    cmp    %ecx, %eax   # i < n ?
    jge    .L2
    mov    (%rdi,%rax,4), %edx
    add    %edx, %ebx
    inc    %eax
    jmp    .L1
```

4배 풀기:
```asm
.L1:
    cmp    %ecx, %eax
    jg     .L2
    mov    (%rdi,%rax,4), %edx
    add    4(%rdi,%rax,4), %edx
    add    8(%rdi,%rax,4), %edx
    add    12(%rdi,%rax,4), %edx
    add    %edx, %ebx
    add    $4, %eax
    jmp    .L1
```
- 분기(조건 점프) 횟수가 4분의 1로 감소
- 연산 간 **데이터 의존성 최소화**로 파이프라인 활용도 향상 가능

---

## 4. 성능상의 이점
1. **분기 예측 실패 감소**  
   반복문에서 분기 예측기는 패턴을 잘 예측하지만, 여전히 비교·점프 명령 자체가 파이프라인 단계에서 비용이 든다.  
   반복 횟수를 줄이면 이 오버헤드가 비례해서 줄어든다.

2. **명령어 수준 병렬성(ILP) 증가**  
   독립적인 연산(예: a[i], a[i+1], a[i+2], a[i+3] 더하기)을 **레지스터에 병렬로 로드**하고, CPU가 파이프라인에 동시에 투입 가능.

3. **캐시 지역성**  
   연속된 메모리 접근으로 **하드웨어 프리패처**가 효율적으로 동작, L1/L2 캐시 히트율 증가.

---

## 5. 단점 및 주의사항
- **코드 크기 증가**: 언롤링 팩터가 크면 명령어 메모리 사용량이 늘어 I-cache 미스 가능성↑
- **레지스터 압박**: 한 번에 여러 개의 루프 변수를 저장하므로 레지스터 부족 → 스필(spill) 발생 가능
- **남은 요소 처리 필요**: n이 언롤링 배수로 나누어떨어지지 않으면 잔여 부분 처리 루프 필요
- **컴파일러 최적화 중복**: 최신 컴파일러(`-O3`)는 자동 언롤링을 수행하므로 수동 언롤링 이득이 제한적일 수 있음

---

## 6. 고급 기법: 루프 언롤링 + 벡터화
루프 언롤링은 **SIMD(vectorization)** 와 결합하면 더 큰 효과를 낼 수 있다.

예: AVX2 벡터화 + 언롤링
```c
#include <immintrin.h>

int sum_array_avx_unrolled(int *a, int n) {
    __m256i vsum = _mm256_setzero_si256();
    int i = 0;

    for (; i <= n - 8; i += 8) {
        __m256i v = _mm256_loadu_si256((__m256i*)&a[i]);
        vsum = _mm256_add_epi32(vsum, v);
    }

    // 벡터 합을 스칼라로 변환
    int temp[8];
    _mm256_storeu_si256((__m256i*)temp, vsum);
    int sum = temp[0] + temp[1] + temp[2] + temp[3]
            + temp[4] + temp[5] + temp[6] + temp[7];

    // 남은 요소
    for (; i < n; i++) {
        sum += a[i];
    }

    return sum;
}
```
- 한 번에 8개 int 로드/연산
- 루프 언롤링과 벡터화를 결합해 **분기 감소 + 병렬 처리 + 대역폭 활용** 효과

---

## 7. 적용 시점
- **핵심 루프**(핫 루프)에 적용 — 전체 실행 시간의 대부분을 차지하는 부분
- 데이터가 메모리보다 CPU 연산이 병목인 경우  
- 컴파일러 자동 최적화 결과를 분석(`-fno-unroll-loops`로 비교)

---

## 8. 정리
| 장점 | 단점 |
|------|------|
| 분기 오버헤드 감소 | 코드 크기 증가 |
| ILP 증가 | 레지스터 압박 |
| 캐시 효율 향상 | 남은 요소 처리 필요 |
| 벡터화 시 효과 극대화 | 최신 컴파일러와 중복 가능 |

---

💡 **팁**:  
루프 언롤링은 ‘무조건’ 빠른 것이 아니라, **데이터 크기, 메모리 대역폭, 레지스터 개수, 캐시 구조**를 고려해 적용해야 한다.  
특히 최신 CPU는 자동 벡터화와 동적 분기 예측이 뛰어나므로, 실제 **성능 측정**(`perf`, `VTune`)으로 효과를 검증하는 것이 필수다.
