---
layout: post
title: 컴퓨터시스템 - 루프 풀기
date: 2025-08-01 21:20:23 +0900
category: 컴퓨터시스템
---
# 루프 풀기(Loop Unrolling)

## 개요 — 왜 루프 언롤링인가?

### 정의

- 루프 언롤링(unrolling)은 **반복문의 본문을 여러 번 복제**해, 한 번의 반복에서 더 많은 일을 처리함으로써 **루프 제어 오버헤드(비교/분기/증감)** 를 줄이고, **명령어 수준 병렬성(ILP)** 을 키우는 기법이다.

### 목표

- **분기/루프 제어 감소** → 분기 예측기 부담과 분기 자체의 파이프라인 비용 감소
- **ILP 증가** → 독립 연산을 동시에 발사(issue)하여 파이프라인/포트 활용도 향상
- **메모리 접근 패턴 정돈** → 선형 접근을 강화해 하드웨어 프리패처/캐시 효율 개선

### 성능 모델(간단)

- 루프당 분기·제어 오버헤드가 \(b\) 사이클, 언롤링 팩터가 \(u\)일 때(균등 분배 가정) 오버헤드 기여는 대략
$$
\Delta \text{CPE} \approx b\left(1-\frac{1}{u}\right)
$$
- **ILP** 및 **명령 스케줄링** 개선은 마이크로아키텍처(실행 포트/파이프/의존성)에 따라 추가 이득을 준다(정량화는 측정이 필수).

---

## 가장 단순한 예 — 합계(reduction)

### 원본

```c
int sum_array(const int *a, int n) {
    int s = 0;
    for (int i = 0; i < n; ++i)
        s += a[i];
    return s;
}
```

### 4배 언롤(핵심 루프 + 잔여 처리)

```c
int sum_array_unroll4(const int *a, int n) {
    int s0 = 0, s1 = 0, s2 = 0, s3 = 0; // 다중 축적기 → 의존 길이 단축
    int i = 0;

    for (; i + 3 < n; i += 4) {
        s0 += a[i + 0];
        s1 += a[i + 1];
        s2 += a[i + 2];
        s3 += a[i + 3];
    }
    int s = (s0 + s1) + (s2 + s3);

    for (; i < n; ++i) s += a[i]; // 꼬리 처리
    return s;
}
```
**포인트**
- **다중 축적기**: 의존 체인을 1→4개로 분기해 ALU 파이프 의존 지연을 완화(ILP↑).
- **잔여 처리(peeling/epilogue)**: \(n \bmod 4\) 요소를 스칼라로 마무리.

---

## 어셈블리 관점(개략) — 분기/의존성 감소

### 단순 루프(개념적)

```asm
.Lloop:
    cmp   %ecx, %eax      # i < n?
    jge   .Ldone
    add   (%rdi,%rax,4), %ebx
    inc   %eax
    jmp   .Lloop
```

### 4× 언롤(개념적)

```asm
.Lloop:
    cmp   %ecx, %eax
    jg    .Ldone
    mov   (%rdi,%rax,4),    %r8d
    add   4(%rdi,%rax,4),   %r9d
    add   8(%rdi,%rax,4),   %r10d
    add   12(%rdi,%rax,4),  %r11d
    lea   (%r8d,%r9d),      %r8d
    lea   (%r10d,%r11d),    %r9d
    add   %r9d, %r8d
    add   %r8d, %ebx
    add   $4, %eax
    jmp   .Lloop
```
- 분기 빈도 1/4.
- 레지스터 축적 사용으로 의존 체인 단축.

---

## 언롤링 패턴과 구현 디테일

### 정수/실수 합(accumulation) — 다중 축적기

```c
double dot_unroll4(const double* restrict x,
                   const double* restrict y, int n){
    double s0=0, s1=0, s2=0, s3=0;
    int i=0;
    for (; i+3<n; i+=4) {
        s0 += x[i+0]*y[i+0];
        s1 += x[i+1]*y[i+1];
        s2 += x[i+2]*y[i+2];
        s3 += x[i+3]*y[i+3];
    }
    double s=(s0+s1)+(s2+s3);
    for (; i<n; ++i) s += x[i]*y[i];
    return s;
}
```
- **FMA** 가능 시(플랫폼·컴파일러) 더 큰 이익.
- FP 재배열로 미세한 오차 차이 발생 가능(테스트로 허용 오차 관리).

### 메모리 복사/채우기(언롤링 + 비분기)

```c
void fill_unroll8(int *dst, int n, int v){
    int i=0;
    for(; i+7<n; i+=8){
        dst[i+0]=v; dst[i+1]=v; dst[i+2]=v; dst[i+3]=v;
        dst[i+4]=v; dst[i+5]=v; dst[i+6]=v; dst[i+7]=v;
    }
    for(; i<n; ++i) dst[i]=v;
}
```
- 대형 반복에 **non-temporal store**(스트리밍 저장)도 고려(플랫폼 인트린식).

### 분기 제거와 결합

```c
// before
for (int i=0;i<n;++i) out[i] = (in[i]>0)?in[i]:0;

// after (branchless + unroll4)
for (int i=0;i+3<n; i+=4){
    int x0=in[i], x1=in[i+1], x2=in[i+2], x3=in[i+3];
    out[i+0] = x0 & -(x0>0);
    out[i+1] = x1 & -(x1>0);
    out[i+2] = x2 & -(x2>0);
    out[i+3] = x3 & -(x3>0);
}
for (int i=(n&~3); i<n; ++i) out[i] = in[i] & -(in[i]>0);
```
- **분기 예측 미스**가 잦은 루프에 효과적.

### Duff’s Device — switch 기반 언롤링(핵심 아이디어 예시)

```c
void copy_duff(char* dst, const char* src, int n){
    int cnt = (n+7)/8;
    switch (n % 8){
    case 0: do { *dst++ = *src++;
    case 7:      *dst++ = *src++;
    case 6:      *dst++ = *src++;
    case 5:      *dst++ = *src++;
    case 4:      *dst++ = *src++;
    case 3:      *dst++ = *src++;
    case 2:      *dst++ = *src++;
    case 1:      *dst++ = *src++;
             } while(--cnt>0);
    }
}
```
- **현대 컴파일러/CPU**에서는 가독성 대비 이점이 작을 수 있음(교육 목적 예시).

### Unroll-and-Jam(이중 루프)

- 외부 루프를 언롤 → **내부 루프 본문**끼리 결합해 **재사용/캐시 효율**과 ILP를 동시에 노림.
- 행렬/컨볼루션에서 자주 쓰임(타일링과 병행).

---

## 언롤 팩터 선택 — 수학/자원/코드 크기 균형

### 분기 오버헤드 기여(근사)

- 반복 제어 비용이 반복마다 \(b\), 언롤 팩터 \(u\):
$$
\text{CPE}_\text{new} \approx \text{CPE}_\text{old} - b\left(1-\frac{1}{u}\right)
$$
- **수익 체감**: \(u\)가 커질수록 추가 이득은 작아진다.

### 레지스터 압력 모델(대략)

- 필요 레지스터 수 \(\approx\) (축적기 수) + (포인터/인덱스/상수) + (프리페치/임시).
- x86-64:
  - **GPR**: 16개
  - **XMM/ymm**: 16개(AVX2), **zmm**: 32개(AVX-512, 일부 플랫폼)
- **언롤 팩터가 커지면 스필 위험**(L1↔스택 이동) → 성능 역행.

### 코드 크기/아이캐시

- 언롤로 코드 크기 ↑ → **I-cache/ITLB 미스** 위험.
- 긴 핫루프가 다수이면 작은 언롤이 낫다.

---

## 자동 언롤링 vs 수동 언롤링

### 컴파일러 옵션/지시어

- GCC/Clang: `-O3`, `-funroll-loops`, `#pragma unroll N`, `#pragma clang loop unroll(enable)`, `#pragma GCC unroll N`
- MSVC: `#pragma loop(no_vector)`, `#pragma loop(ivdep)`, `#pragma loop(unroll)`

### 언제 수동으로?

- **복잡한 의존성/별칭**으로 자동 벡터화/언롤이 막힐 때
- **도메인 지식**(정렬/배수/경계조건)을 활용해 더 나은 스케줄 가능할 때
- **프로파일 기반**으로 특정 루프만 외과적으로 조정할 때

---

## 벡터화(SIMD)와의 결합 — 시너지 극대화

### AVX2 예: 8개 정수 합 + 언롤

```c
#include <immintrin.h>

int sum_avx2_unroll(const int *a, int n){
    __m256i vs0=_mm256_setzero_si256();
    __m256i vs1=_mm256_setzero_si256();
    int i=0;
    // 2×언롤: 16개/반복
    for (; i+15<n; i+=16){
        __m256i v0=_mm256_loadu_si256((const __m256i*)&a[i+0]);
        __m256i v1=_mm256_loadu_si256((const __m256i*)&a[i+8]);
        vs0=_mm256_add_epi32(vs0, v0);
        vs1=_mm256_add_epi32(vs1, v1);
    }
    vs0=_mm256_add_epi32(vs0, vs1);
    alignas(32) int tmp[8];
    _mm256_store_si256((__m256i*)tmp, vs0);
    int s = tmp[0]+tmp[1]+tmp[2]+tmp[3]+tmp[4]+tmp[5]+tmp[6]+tmp[7];
    for (; i<n; ++i) s += a[i];
    return s;
}
```
- 언롤로 **로드 대기**를 겹치고, **두 축적 레지스터**로 의존 체인을 단축.
- **정렬**/프리페치/NT-store 등은 데이터 패턴에 맞춰 선택.

### 자동 벡터화 지원 힌트

- `restrict`로 별칭 제거, `#pragma omp simd` 혹은 `#pragma ivdep`.
- 정렬된 포인터 사용(가능 시 `aligned_alloc`/`posix_memalign`).

---

## 메모리 바운드와 언롤링 — 언제 이득이 제한되나?

- 루프가 명확히 **메모리 대역폭 제한**이면, **분기 오버헤드/ILP 개선**의 이득은 상한이 작다.
- 그래도 **언롤**로 얻는 이점:
  - **로드 미세 병렬화**(상위 레벨 캐시 히트 지연 겹치기)
  - **분기 비용 감소**
- 그러나 Roofline 상 **AI 한계**가 낮다면 언롤만으로 큰 폭의 향상은 기대하기 어렵다 → **타일링/데이터 재사용**을 우선.

---

## 실전 패턴(도메인)

### 1D 컨볼루션(고정 커널) — 언롤 + 상수전개

```c
// 커널 길이 5 (k[-2..2]), 경계는 생략
void conv5_unroll(const float* x, float* y, int n,
                  float k0,float k1,float k2,float k3,float k4){
    for (int i=2;i+5<n; i+=4){ // 4× 언롤
        float x0=x[i-2], x1=x[i-1], x2=x[i],   x3=x[i+1], x4=x[i+2];
        float x5=x[i+3], x6=x[i+4];

        y[i+0]=k0*x0 + k1*x1 + k2*x2 + k3*x3 + k4*x4;
        y[i+1]=k0*x1 + k1*x2 + k2*x3 + k3*x4 + k4*x5;
        y[i+2]=k0*x2 + k1*x3 + k2*x4 + k3*x5 + k4*x6;

        // 다음 반복에서 일부 재사용 가능(소프트웨어 파이프라이닝/슬라이딩 윈도)
        y[i+3]=k0*x3 + k1*x4 + k2*x5 + k3*x6 + k4*x[i+5];
    }
    // 잔여 처리...
}
```
- **슬라이딩 윈도우** 재사용을 노리되, 레지스터/코드 크기 균형.

### 히스토그램 — 경쟁·분기 완화 + 언롤

```c
void hist_unroll(const unsigned char* a,int n, unsigned* hist){
    unsigned local[256]={0};
    int i=0;
    for (; i+3<n; i+=4){
        ++local[a[i+0]];
        ++local[a[i+1]];
        ++local[a[i+2]];
        ++local[a[i+3]];
    }
    for (; i<n; ++i) ++local[a[i]];
    for (int b=0;b<256;++b) hist[b]+=local[b];
}
```
- 스레드 병렬 시 **스레드 로컬**과 병합 단계로 스케일 확보.

---

## 벤치마크/검증 스캐폴딩

### CPE/속도 비교 골격

```c
#include <time.h>
#include <stdio.h>
#include <stdlib.h>

static inline double now(){
    struct timespec t;
    clock_gettime(CLOCK_MONOTONIC,&t);
    return t.tv_sec + t.tv_nsec*1e-9;
}

int sum_scalar(const int* a, int n){
    int s=0; for(int i=0;i<n;++i) s+=a[i]; return s;
}

int sum_unroll4(const int* a, int n){
    int s0=0,s1=0,s2=0,s3=0, i=0;
    for (; i+3<n; i+=4){
        s0+=a[i+0]; s1+=a[i+1]; s2+=a[i+2]; s3+=a[i+3];
    }
    int s=(s0+s1)+(s2+s3);
    for (; i<n; ++i) s+=a[i];
    return s;
}

int main(){
    const int n=1<<26;
    int* a = (int*)aligned_alloc(64, n*sizeof(int));
    for(int i=0;i<n;++i) a[i]=i&1023;

    double t0=now(); volatile int s0=sum_scalar(a,n); double t1=now();
    double t2=now(); volatile int s1=sum_unroll4(a,n); double t3=now();

    printf("scalar:  %.3f s  | unroll4: %.3f s | speedup: %.2fx  (sum=%d/%d)\n",
           t1-t0, t3-t2, (t1-t0)/(t3-t2), s0, s1);
    free(a);
}
```
- 동일 결과 확인(DCE 방지 위해 `volatile` 사용).
- `perf stat -r 5 ./a.out` 로 IPC/branch-miss/cache-miss 비교.

---

## 컴파일러 힌트/리포트로 언롤링 확인

- Clang: `-Rpass=loop-unroll -Rpass-missed=loop-unroll -Rpass-analysis=loop-unroll`
- GCC: `-fopt-info-optimized-optimized-vec-missed=stderr`
- MSVC: `/Qvec-report:2` (벡터화 리포트) + 어셈 확인

**실무 팁**
- 자동 언롤 실패 시: 별칭 제거(`restrict`), 경계 명확화, 반복 수 정적 추론 가능하도록 상수화.
- 과도 언롤 시: `#pragma nounroll` 로 억제해 I-cache/스필 역효과 방지.

---

## 언어/런타임별 고려

- **C/C++**: 수동 언롤/인트린식 자유도 높음. UB(정수 오버플로/미정렬 접근)에 주의.
- **.NET/C#**: JIT가 제한적 자동 언롤을 함. 핫경로는 **Span<T>**, `Unsafe.Add`, `AggressiveInlining` 등과 함께 **수동 부분 언롤**로 이득 사례 존재(측정 필수).
- **Java**: JIT C2가 언롤/벡터화 시도. **range check elimination** 패턴을 충족하도록 작성.
- **Python**: CPython 루프 언롤의 이득은 작음 → **NumPy/Numba/Cython**로 옮겨 벡터화/네이티브 루프를 사용.

---

## 안전성/정확성/유지보수 체크

- **FP 결합/순서 바뀜**: 오차 모델 정의, 테스트에서 상대/절대 오차 허용.
- **별칭/정렬**: `restrict` 남용 금지(증명 가능한 경우만), misaligned 접근 주의.
- **레지스터 압력/코드 크기**: 스필/아이캐시 악화 시 팩터 축소.
- **가독성**: 프로파일로 **핫루프 한정** 적용, 주석/테스트 케이스 필수.

---

## 빠른 의사결정 체크리스트

- [ ] 이 루프가 **핫스팟**인가(프로파일)?
- [ ] 언롤로 **분기 비용/의존 길이**를 줄일 여지가 있는가?
- [ ] **레지스터 예산** 내에서 축적기/주소 변수 수용 가능한가(스필 없음)?
- [ ] **I-cache** 증가가 허용 가능한가(핫루프 다중 공존 여부)?
- [ ] 자동 언롤/벡터화가 실패하는 이유는 무엇인가(별칭/경계/함수호출)?
- [ ] 개선 후 **CPE/IPC/미스율**로 이득을 확인했는가? 다양한 **n**에서 **안정적**인가?

---

## 요약

| 항목 | 핵심 |
|---|---|
| 장점 | 분기 오버헤드↓, ILP↑, 캐시/프리패처 친화 패턴 유도 |
| 한계 | 레지스터 압력↑ → 스필 위험, 코드 크기↑ → I-cache 압박 |
| 메모리 바운드 | 언롤만으로 한계, **타일링/데이터 재사용**을 병행 |
| 실무 태도 | **프로파일 주도** 적용, 컴파일러 리포트/어셈 확인, 과유불급 |

언롤링은 **만능이 아니지만**, 적절한 팩터·축적기·데이터 레이아웃·벡터화와 결합하면 **짧고 뜨거운 루프의 실제 성능을 크게 끌어올리는** 실전 무기다. 항상 **측정 → 원인 → 적용 → 재측정**의 과학적 루틴으로 접근하자.
