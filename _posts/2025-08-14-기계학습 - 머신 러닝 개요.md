---
layout: post
title: 기계학습 - 머신 러닝 개요
date: 2025-08-14 14:20:23 +0900
category: 기계학습
---
# 머신 러닝 개요

## 1. 머신 러닝이란 무엇인가?
**데이터에서 일반화 가능한 규칙(모델)을 학습**하여 보지 못한 입력에 대해 **예측/결정**을 수행하는 방법론이다.

전통적 프로그래밍:
```plaintext
데이터 + 규칙(사람이 작성) → 결과
```
머신 러닝:
```plaintext
데이터 + 결과(라벨) → 규칙(모델)
```

---

## 2. 인공지능 vs 머신 러닝 vs 딥러닝

| 구분 | AI | ML | DL |
|---|---|---|---|
| 정의 | 지능적 행동 전반 | 데이터에서 패턴 학습 | 다층 신경망으로 표현학습 |
| 특징 | 규칙기반 포함 | 통계·최적화 중심 | 대규모 데이터/가속기 |
| 예 | 전문가시스템 | SVM/트리/GBM | CNN/RNN/Transformer |
| 필요 데이터 | 적~중 | 중 | 많음(대개) |

---

## 3. 지도학습·비지도학습·강화학습

### 지도학습
- 라벨 \(y\)가 있는 데이터 \((x,y)\)로 \(f_\theta(x)\) 학습.
- 분류/회귀.
$$
\theta^*=\arg\min_\theta \ \mathcal{L}(y,f_\theta(x))
$$

### 비지도학습
- 라벨 없이 구조 찾기(군집/차원축소).
$$
g: X \to Z \quad (\text{잠재표현 } Z)
$$

### 강화학습
- 보상 최대화 정책 \(\pi\) 학습.
$$
\pi^*=\arg\max_\pi \mathbb{E}\left[\sum_{t=0}^{\infty}\gamma^t r_t\right]
$$

---

## 4. 프로젝트 전체 흐름(End-to-End)

1) **수집**: 로그/DB/센서/Kaggle 등
2) **탐색/전처리**: 결측/이상치/스케일링/인코딩
3) **특성공학**: 도메인 파생변수, 교호작용
4) **모델링**: 베이스라인→고급(트리 앙상블/신경망)
5) **검증**: 적절한 CV, 누수 방지, 올바른 지표
6) **튜닝**: 규제/하이퍼파라미터 탐색
7) **배포**: API/배치/스트리밍
8) **운영**: 모니터링(드리프트, 성능), 재학습, 버저닝

---

## 5. 수학적 기초(압축)

### 5.1 ERM(경험적 위험 최소화)
$$
R(\theta)=\mathbb{E}[\ell(Y, f_\theta(X))] \approx \frac{1}{n}\sum_{i=1}^n \ell(y_i, f_\theta(x_i))
$$

### 5.2 정규화(과적합 억제)
- L2(릿지): \( \lambda \|\theta\|_2^2 \)
- L1(라쏘): \( \lambda \|\theta\|_1 \)

### 5.3 경사하강
$$
\theta \leftarrow \theta - \eta \nabla_\theta \mathcal{L}(\theta)
$$

### 5.4 편향-분산 분해(직관)
$$
\mathbb{E}\big[(\hat f(x)-f(x))^2\big] = \underbrace{\text{Bias}^2}_{\text{과소적합}} + \underbrace{\text{Var}}_{\text{불안정}} + \sigma^2
$$

---

## 6. 지도학습 분류 예제: 파이프라인 + ROC/AUC

```python
# 분류: 유방암 데이터셋 (sklearn)
import numpy as np
from sklearn.datasets import load_breast_cancer
from sklearn.model_selection import StratifiedKFold, cross_validate
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import roc_auc_score, RocCurveDisplay, confusion_matrix, classification_report
import matplotlib.pyplot as plt

X, y = load_breast_cancer(return_X_y=True, as_frame=False)

pipe = Pipeline([
    ("scaler", StandardScaler()),
    ("clf", LogisticRegression(max_iter=500, class_weight="balanced"))
])

cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
scores = cross_validate(pipe, X, y, cv=cv, scoring=["roc_auc","accuracy","f1"], return_estimator=True)
print({k: np.mean(v) for k,v in scores.items() if "test" in k})

# 한 폴드 모델로 ROC 그리기
est = scores["estimator"][0].fit(X, y)
y_score = est.predict_proba(X)[:,1]
RocCurveDisplay.from_predictions(y, y_score)
plt.title("ROC Curve (train for demo)")
plt.show()

y_pred = est.predict(X)
print(confusion_matrix(y, y_pred))
print(classification_report(y, y_pred))
```

**로지스틱 회귀 수식**
$$
P(Y=1\mid x)=\sigma(w^\top x + b)=\frac{1}{1+e^{-(w^\top x+b)}}
$$
손실(로그우도 음수):
$$
\mathcal{L}(w,b) = -\sum_{i=1}^n \{y_i\log \hat p_i + (1-y_i)\log(1-\hat p_i)\} + \lambda\|w\|_2^2
$$

---

## 7. 지도학습 회귀 예제: 캘리포니아 주택가격 + 규제

```python
from sklearn.datasets import fetch_california_housing
from sklearn.model_selection import KFold, GridSearchCV
from sklearn.linear_model import Ridge, Lasso
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.pipeline import Pipeline
from sklearn.metrics import mean_squared_error, r2_score
import numpy as np

data = fetch_california_housing(as_frame=True)
df = data.frame.copy()

num_cols = df.columns.drop("MedHouseVal")
pre = ColumnTransformer([
    ("num", StandardScaler(), num_cols)
])

pipe = Pipeline([
    ("pre", pre),
    ("model", Ridge())
])

param_grid = {
    "model": [Ridge(), Lasso(max_iter=5000)],
    "model__alpha": [0.01, 0.1, 1.0, 10.0]
}

cv = KFold(n_splits=5, shuffle=True, random_state=42)
g = GridSearchCV(pipe, param_grid, cv=cv, scoring="neg_root_mean_squared_error", n_jobs=-1)
g.fit(df[num_cols], df["MedHouseVal"])

best = g.best_estimator_
pred = best.predict(df[num_cols])
rmse = np.sqrt(mean_squared_error(df["MedHouseVal"], pred))
r2 = r2_score(df["MedHouseVal"], pred)
print("Best", g.best_params_, "RMSE", rmse, "R2", r2)
```

**회귀 지표**
$$
\text{RMSE}=\sqrt{\frac{1}{n}\sum_i (y_i-\hat y_i)^2},\quad
R^2=1-\frac{\sum_i (y_i-\hat y_i)^2}{\sum_i(y_i-\bar y)^2}
$$

---

## 8. 비지도학습 예제: K-Means + 실루엣 + PCA

```python
from sklearn.datasets import make_blobs
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score
from sklearn.decomposition import PCA
import matplotlib.pyplot as plt

X, _ = make_blobs(n_samples=800, centers=4, cluster_std=1.20, random_state=42)

scores = []
for k in range(2,9):
    km = KMeans(n_clusters=k, n_init="auto", random_state=42)
    labels = km.fit_predict(X)
    scores.append((k, silhouette_score(X, labels)))
print(scores)  # k 선택 참고

best_k = max(scores, key=lambda t: t[1])[0]
km = KMeans(n_clusters=best_k, n_init="auto", random_state=42)
labels = km.fit_predict(X)

pca = PCA(n_components=2)
X2 = pca.fit_transform(X)
plt.scatter(X2[:,0], X2[:,1], c=labels, s=8)
plt.title(f"KMeans (k={best_k}) on PCA(2)")
plt.show()
```

**실루엣 스코어**(직관):
$$
s(i)=\frac{b(i)-a(i)}{\max\{a(i),b(i)\}}
$$
\(a(i)\): 같은 군집 평균거리, \(b(i)\): 가장 가까운 다른 군집 평균거리.

---

## 9. 딥러닝 한 눈에: MLP 학습 루프(파이토치)

```python
# 간단 MLP (PyTorch) - 개념용
import torch, torch.nn as nn, torch.optim as optim
from sklearn.datasets import load_breast_cancer
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

X, y = load_breast_cancer(return_X_y=True)
sc = StandardScaler().fit(X)
X = sc.transform(X)

Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

Xtr = torch.tensor(Xtr, dtype=torch.float32)
ytr = torch.tensor(ytr, dtype=torch.float32).unsqueeze(1)
Xte = torch.tensor(Xte, dtype=torch.float32)
yte = torch.tensor(yte, dtype=torch.float32).unsqueeze(1)

model = nn.Sequential(
    nn.Linear(Xtr.shape[1], 32), nn.ReLU(),
    nn.Linear(32, 16), nn.ReLU(),
    nn.Linear(16, 1), nn.Sigmoid()
)
crit = nn.BCELoss()
opt = optim.Adam(model.parameters(), lr=1e-3)

for epoch in range(50):
    model.train()
    opt.zero_grad()
    pred = model(Xtr)
    loss = crit(pred, ytr)
    loss.backward()
    opt.step()

with torch.no_grad():
    prob = model(Xte)
    acc = ((prob>0.5).float()==yte).float().mean().item()
print("Test Acc:", acc)
```

**팁:** 초기화(Xavier/He), 정규화(BN/Dropout), 최적화(AdamW, CosineAnneal), **조기종료**와 **검증셋**을 항상 유지.

---

## 10. 강화학습 미니예제: 멀티암드 밴딧(ε-탐욕)

```python
import numpy as np

np.random.seed(42)
true_means = np.array([0.2, 0.5, 0.6, 0.4])  # 각 슬롯머신의 진짜 기대보상
n_actions = len(true_means)

Q = np.zeros(n_actions)  # 추정 보상
N = np.zeros(n_actions)  # 선택 횟수
eps = 0.1
T = 2000

rewards = []
for t in range(T):
    if np.random.rand() < eps:
        a = np.random.randint(n_actions)       # 탐색
    else:
        a = np.argmax(Q)                        # 이용
    r = np.random.rand() < true_means[a]        # 베르누이 보상
    N[a] += 1
    Q[a] += (r - Q[a]) / N[a]                   # 점진적 평균(학습률 1/N)
    rewards.append(r)

print("추정 Q:", Q, "평균보상:", np.mean(rewards))
```

---

## 11. 특성공학·전처리·파이프라인 설계

- **스케일링**: 표준화 \( z=(x-\mu)/\sigma \) 혹은 정규화 \([0,1]\)
- **범주형 인코딩**: 원-핫, 타겟 인코딩(누수 주의)
- **결측치**: 단순/모델 기반 임퓨테이션
- **파이프라인**: 변환과 모델을 **원자적으로 묶어 재현성** 확보

```python
from sklearn.impute import SimpleImputer
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder
from sklearn.linear_model import LogisticRegression

num_pipe = Pipeline([("imp", SimpleImputer(strategy="median")),
                     ("sc", StandardScaler())])
cat_pipe = Pipeline([("imp", SimpleImputer(strategy="most_frequent")),
                     ("oh", OneHotEncoder(handle_unknown="ignore"))])

pre = ColumnTransformer([("num", num_pipe, [0,1,2]),
                         ("cat", cat_pipe, [3,4])])

clf = Pipeline([("pre", pre),
                ("lr", LogisticRegression(max_iter=1000))])
```

---

## 12. 성능평가 & 불균형 데이터

### 분류 지표
$$
\text{Precision}=\frac{TP}{TP+FP},\quad
\text{Recall}=\frac{TP}{TP+FN},\quad
F1=2\cdot\frac{PR}{P+R}
$$
- ROC-AUC, PR-AUC(불균형일 때 더 유용)

### 회귀 지표
RMSE, MAE, \(R^2\) (위 참조)

### 불균형 대응
- **class_weight** / 임곗값 튜닝 / **언더·오버샘플링(SMOTE)**

```python
from imblearn.over_sampling import SMOTE
from imblearn.pipeline import Pipeline
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import StratifiedKFold, cross_val_score

pipe = Pipeline([
    ("sm", SMOTE(random_state=42)),
    ("lr", LogisticRegression(max_iter=500))
])
cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
print(cross_val_score(pipe, X, y, cv=cv, scoring="f1"))
```

---

## 13. 데이터 리스크: 누수, 시간 분리, 재현성

- **누수(Leakage)**: 학습 시점에 사용할 수 없는 정보를 모델에 노출하는 실수(타겟 인코딩을 전체에 적용, 미래 피처 사용 등).
- **시간 분리**: 시계열은 **과거→미래** 순서 유지(split by time).
- **재현성**: 난수 고정, 패키지 버전 고정, 데이터 버저닝(DVC/MLflow)

```python
import numpy as np
import random, os
def seed_all(seed=42):
    random.seed(seed); np.random.seed(seed); os.environ["PYTHONHASHSEED"]=str(seed)
seed_all(42)
```

---

## 14. 모델 해석: 중요도/Permutation/PDP

```python
from sklearn.inspection import permutation_importance, PartialDependenceDisplay
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split

Xtr, Xte, ytr, yte = train_test_split(X, y, stratify=y, random_state=42)
rf = RandomForestClassifier(n_estimators=300, random_state=42).fit(Xtr, ytr)

r = permutation_importance(rf, Xte, yte, scoring="roc_auc", n_repeats=10, random_state=42)
idx = r.importances_mean.argsort()[::-1][:10]
print("Top-10 features by permutation:", idx)

PartialDependenceDisplay.from_estimator(rf, Xte, [idx[0]])
```

- **Permutation Importance**: 모델 불가지론적, 일반화된 중요도.
- **PDP/ICE**: 피처 변화에 따른 예측 반응 곡선(단, 상호작용 주의).

---

## 15. 배포 & MLOps: 서빙, 모니터링, 재학습

### 15.1 모델 저장/로딩
```python
import joblib
joblib.dump(best, "model.joblib")
m = joblib.load("model.joblib")
```

### 15.2 FastAPI 서빙(간단)
```python
# uvicorn app:api --reload
from fastapi import FastAPI
import joblib
import numpy as np

api = FastAPI()
model = joblib.load("model.joblib")

@api.post("/predict")
def predict(payload: dict):
    X = np.array(payload["features"])  # [[...], [...]]
    yhat = model.predict(X).tolist()
    return {"pred": yhat}
```

### 15.3 모니터링 개념
- **데이터 드리프트**: 입력 분포 변화(PSI/KS-test),
- **성능 드리프트**: 실제 라벨 도착 시 AUC/RMSE 추적,
- **경보/롤백/재학습 파이프라인**(스케줄 기반 or 데이터 이벤트 기반)

---

## 16. 윤리·공정성·프라이버시(간단 가이드)
- **공정성**: 그룹간 성능 차이(EO, DP) 점검
- **프라이버시**: 최소수집, 가명화, 접근제어, 필요 시 **DP-SGD**·연합학습(Federated) 고려
- **설명가능성**: 높은 위험 도메인(의료/금융)은 해석 가능 모델 또는 충실한 사후 설명 도구 구축

---

## 17. 체크리스트(현업용)

- [ ] 문제정의: **비즈니스 지표 ↔ ML 지표** 정렬
- [ ] 데이터 파이프: 결측/이상치 정책, **누수 금지**
- [ ] 검증전략: IID? 시계열? 그룹? **올바른 CV** 채택
- [ ] 기준선: 단순모델(로지스틱/선형/작은 트리) 성능 확보
- [ ] 하이퍼서치: 공간/예산/조기중지 설정
- [ ] 모델해석: 중요도/부분의존/샘플 설명
- [ ] 배포형태: 실시간/배치/온디바이스
- [ ] 모니터링: 데이터/성능 드리프트, SLA/알람
- [ ] 버저닝: 데이터/코드/모델(MLflow/DVC)
- [ ] 보안/윤리: 접근통제, 감사로그, 공정성 점검

---

## 18. 요약
- 머신 러닝은 **데이터 기반 일반화**로 의사결정을 자동화한다.
- 학습 유형(지도/비지도/강화)에 맞는 **지표·검증·전처리**가 핵심.
- **파이프라인화/재현성/누수 방지**는 성능만큼 중요하다.
- 배포 이후에는 **드리프트·성능 모니터링**과 **주기적 재학습**으로 수명 주기를 운영한다.
