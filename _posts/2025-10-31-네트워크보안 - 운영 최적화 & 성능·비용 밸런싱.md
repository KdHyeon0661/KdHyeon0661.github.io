---
layout: post
title: 네트워크보안 - 운영 최적화 & 성능·비용 밸런싱
date: 2025-10-31 20:25:23 +0900
category: 네트워크보안
---
# 25. 운영 최적화 & 성능·비용 밸런싱

> 목표
> - **L2/L3 데이터패스 튜닝(XDP/DPDK)**의 핵심 포인트를 이해하고, **운영 현실**에서 무엇을 선택/포기해야 하는지 정리한다.
> - **CDN/캐시/Keep-Alive/커넥션 풀**로 백엔드 부하를 구조적으로 낮추고, **오토스케일/캐시 적중률/지연** 간의 상호작용을 수치로 보자.
> - **운영 리스크 vs 성능 트레이드오프**를 의사결정 표/플레이북으로 정리해 “왜 지금은 이 수준만 한다”를 설명 가능하게 만든다.
> - **실습**: L7 캐싱(리버스 프록시)으로 **백엔드 보호** 파이프라인을 구성하고, **워밍/무효화/헤더 설계/성능 측정**을 통해 효과를 숫자로 확인한다.

---

## 25.1 XDP/DPDK 개념, 튜닝 포인트

### 25.1.1 XDP (eXpress Data Path)
- **커널 가장 앞단(NIC 드라이버 RX)**에서 eBPF 프로그램으로 패킷을 처리하는 경량 데이터패스.
- **장점**: 드롭/리다이렉트/헤더 검사 같은 **간단한 L2/L3/L4 필터/샘플링**을 초저지연으로 처리(수 Mpps 가능).
- **활용**:
  - **L3/L4 조기 드롭**(bogon, 스캐너, SYN flood 선별),
  - **샘플링 기반 텔레메트리**(N s 중 1),
  - **NIC 큐 리다이렉트**(RSS 보정), **AF_XDP**로 사용자 공간 전달.

**XDP 드롭 샘플 (C/eBPF, *개념용*)**
```c
// xdp_drop_syn.c — 특정 포트의 SYN 폭주를 조기 드롭 (데모)
#include <linux/bpf.h>
#include <linux/ip.h>
#include <linux/tcp.h>
#include "bpf_helpers.h"

SEC("xdp")
int xdp_syn_guard(struct xdp_md *ctx) {
    void *data = (void *)(long)ctx->data;
    void *end  = (void *)(long)ctx->data_end;
    struct ethhdr *eth = data;
    if ((void*)(eth+1) > end) return XDP_PASS;
    if (eth->h_proto != __constant_htons(ETH_P_IP)) return XDP_PASS;

    struct iphdr *ip = (void*)(eth+1);
    if ((void*)(ip+1) > end || ip->protocol != IPPROTO_TCP) return XDP_PASS;

    struct tcphdr *tcp = (void*)ip + ip->ihl*4;
    if ((void*)(tcp+1) > end) return XDP_PASS;

    if (tcp->dest == __constant_htons(443) && tcp->syn && !tcp->ack) {
        // 간단 정책: 443으로 오는 순수 SYN은 드롭 (데모)
        return XDP_DROP;
    }
    return XDP_PASS;
}
char _license[] SEC("license") = "GPL";
```

**XDP 튜닝 포인트**
- **NIC 드라이버/펌웨어**: XDP 지원 모드 확인(드라이버 native vs generic).
- **RSS/큐 수**: CPU 코어마다 RX 큐 매핑, **RPS/XPS** 보정.
- **메모리**: **ring buffer size**, **page-pool** 리사이클, **busy_poll**(낮은 지연), **NAPI weight**.
- **프로그램 로직**: *fast-path first* (필터 조건 → 빠른 return), **bpf map** 조회 최소화.
- **관측**: `bpftool prog`, **XDP drop/pass 통계**, pps/latency 히스토그램.

> **운영 현실**: XDP로 **조기 드롭/샘플링**을 하고, L7 로직은 상위(프록시/애플리케이션)에서 처리.
> 고급 L7 처리는 XDP 범위 밖이므로 **분리 설계**가 안전하다.

---

### 25.1.2 DPDK (Data Plane Development Kit)
- **폴링 기반의 유저 공간 데이터패스**(커널 스택 우회).
- **장점**: 초고속 패킷 처리, **고정 지연(variance↓)**, 멀티큐/NUMA 최적화에 유리.
- **단점**:
  - 폴링으로 **CPU 계속 소비**(전력↑),
  - 커널 스택과의 **연동/관측**이 어려움 → 운영 도구/드라이버 호환성 고려 필요.

**DPDK 튜닝 포인트**
- **HugePages**(ex. 1G hugepage) 확보, **NUMA 노드**와 **NIC 큐** 코어 고정(pin)
- **LRO/GRO/TSO** 오프로딩 전략(바이패스/활용)
- **mbuf 캐시**, **burst size**, **rx/tx queue depth**
- **IRQ 제거(폴링)**, OS 스케줄러 간섭 최소화(전용 코어)
- **telemetry**: pps, drop, queue fill level, cache miss 비율

> **운영 판단**:
> - **일반 웹/API 트래픽**: XDP + 커널 네트워킹 + 프록시(L7) 조합이 비용/관리 우수.
> - **고정 지연형, 초고속 L4/L7 프록시**: DPDK 기반 제품/솔루션 고려(네이티브 구현은 유지보수 난이도↑).

---

### 25.1.3 커널 네트워킹 기본 튜닝(현실적 체크리스트)
- **conntrack 해시/버킷**: 대규모 NAT/프록시 시 `nf_conntrack_max`, hashsize 조정
- **TCP**:
  - `tcp_tw_reuse=1` (현대 커널 기준), `tcp_fin_timeout`(과도 축소 주의),
  - **BBR** 또는 Cubic 선택, `tcp_fastopen`(환경별)
  - `somaxconn`, `tcp_max_syn_backlog`, `netdev_max_backlog`
- **IRQ balance**: NIC 큐와 CPU 코어 affinity 고정, **RSS 스프레드**
- **Busy poll**: `net.core.busy_poll=50` 등 저지연 트레이드오프
- **관측**: `ss -s`, `netstat -s`, drop counters, **eBPF** 프로파일/히트맵

---

## 25.2 CDN/캐시/Keep-Alive/커넥션 풀

### 25.2.1 CDN/에지 캐시 전략
- **정적**: 이미지/CSS/JS, 장기 캐시(`Cache-Control: public, max-age=31536000, immutable`)
- **준동적**: 템플릿 조각/카테고리 목록 → **짧은 TTL + 배경 리프레시**
- **개인화**: 쿠키/토큰/Geo/UA에 따라 **변형(Vary)** → 캐시 파편화 조심
- **오리진 보호**: **캐시 미스 제한**(request collapsing), **prefetch/프리워밍**, **오리진 건강도 기반 throttling**

**HTTP 캐시 헤더 Best (정적 버전 리소스)**
```
Cache-Control: public, max-age=31536000, immutable
ETag: "hash"
```

### 25.2.2 리버스 프록시 캐시(Nginx) — 핵심 스니펫
```nginx
proxy_cache_path /var/cache/nginx levels=1:2 keys_zone=api_cache:512m
                 inactive=10m max_size=50g use_temp_path=off;

map $http_authorization $cache_bypass {
  default 1;             # 인증 있으면 기본 우회
  "" 0;                  # 인증 없음 → 캐시 후보
}
map $request_method $cache_method_bypass {
  default 1; GET 0; HEAD 0;   # GET/HEAD만 캐시
}

server {
  listen 443 ssl;
  location /api/public/ {
    proxy_cache           api_cache;
    proxy_cache_bypass    $cache_bypass$cache_method_bypass;
    proxy_cache_valid     200 302 10s;
    proxy_cache_valid     404 1s;
    proxy_cache_key       "$scheme$request_method$host$request_uri";
    proxy_ignore_headers  Set-Cookie; # 퍼블릭 응답에 쿠키 제거 (원 서버 유의)
    add_header X-Cache-Status $upstream_cache_status;
    proxy_pass http://backend;
  }
}
```
- **키 설계**: `Host + URI + (선택) 쿼리정규화 + Vary 헤더`.
- **안전장치**: 인증/개인화 응답은 **캐시 금지**, `Vary` 오남용 주의(파편화↑).
- **워밍/프리패치**: 배포 직후 **핫 경로** 선요청.

### 25.2.3 Keep-Alive/커넥션 풀
- **클라이언트→프록시**: `keepalive_timeout`을 **적절히 길게**(예: 30–120s) — handshake 비용↓
- **프록시→백엔드 풀**:
  - 연결 재사용(`keepalive`), **최대 연결 수**로 백엔드 보호
  - HTTP/1.1 vs HTTP/2: H2는 **멀티플렉싱**으로 *same-origin*에서 연결 수 절감
- **DB/외부 API**: **풀링 라이브러리**(최소/최대 크기, idle timeout), **서킷브레이커** 필수.

**Node.js 예 (HTTP/HTTPS keep-alive 에이전트)**
```js
const http  = require('http');
const https = require('https');
const agent = new http.Agent({ keepAlive: true, maxSockets: 200 });
const sagent= new https.Agent({ keepAlive: true, maxSockets: 200 });

require('axios').create({
  httpAgent: agent, httpsAgent: sagent, timeout: 5000
});
```

**Python aiohttp 예 (커넥션 풀)**
```python
import aiohttp, asyncio

async def main():
    conn = aiohttp.TCPConnector(limit=200, limit_per_host=100, ttl_dns_cache=300)
    async with aiohttp.ClientSession(connector=conn) as session:
        async with session.get("https://api.example.com/data") as r:
            print(await r.text())

asyncio.run(main())
```

---

## 25.3 운영 리스크 vs 성능 트레이드오프

### 25.3.1 의사결정 매트릭스(예)

| 선택 | 이득 | 리스크/비용 | 완화책 |
|---|---|---|---|
| **XDP 조기 드롭** | PPS↑, 커널부하↓ | 코드/검증 복잡, 디버깅 난도 | 단순 룰만, 캔어리, 메트릭 필수 |
| **DPDK 프록시** | 지연/분산 안정 | 개발·운영 난도↑, 전력↑ | 제품 사용, 전용 코어, 텔레메트리 |
| **L7 캐시 확대** | 오리진 보호 | 갱신/정합성 이슈 | 단기 TTL+배경 리프레시+무효화 API |
| **Keep-Alive↑** | CPU↓, 핸드셰이크↓ | 연결 고갈/큐 적체 | per-client 상한, idle timeout |
| **H2/H3 도입** | 멀티플렉싱, 지연↓ | 구현/프록시 체인 호환 | 구간별 점진 전환, 다운그레이드 경로 |
| **Aggressive Timeout↓** | 느린 클라 보호 | 오탐/합법 트래픽 차단 | 경계값 A/B, 로그로 튜닝 |
| **CDN 헤더 강화** | 에지 오프로드 | 캐시 파편화/잘못된 개인정보 캐시 | Vary 설계, 인증 응답 no-store |

### 25.3.2 운영 관점 규칙
- **관측→가설→실험→릴리스**: 성능 변경은 항상 **카나리 + 롤백** 준비.
- **SLO 연계**: p50/p95 지연, 에러율, 캐시 적중률, 오리진 rps, 비용(노드/트래픽) **함께** 본다.
- **비용–성능 곡선**: 캐시 히트 1%p↑가 **몇 rps** 절감인지 환산 → **ROI**로 의사결정.
- **운영 매뉴얼**: 장애시 “캐시 TTL 임시 증가/미스 상한/백엔드 릴리트” 같은 **버튼화**.

---

## 25.4 실습: L7 캐싱으로 백엔드 보호

> **목표**: 리버스 프록시 캐시(예: Nginx/Envoy/Varnish)로 **준동적 API**에 **짧은 TTL 캐시**를 적용하고,
> **워밍/무효화/리밋**까지 구성하여 **백엔드 rps/cpu**를 낮춘다. *운영 가이드까지 포함*.

### 25.4.1 실습 구성

```
[wrk] → [Nginx (L7 캐시)] → [App (Flask/FastAPI)] → [DB/Upstream (모의)]
           └→ Redis (선택: 캐시 키-밸류)
```

- **프록시 캐시**: Nginx 내장 또는 Varnish.
- **백엔드**: 간단한 FastAPI(랜덤 50ms 지연)로 CPU소모 시뮬레이트.
- **벤치**: `wrk -t8 -c200 -d60s https://proxy/api/public/items?page=1`

### 25.4.2 백엔드 앱(예: FastAPI)
```python
# app.py
from fastapi import FastAPI, Request
import random, asyncio
app = FastAPI()

@app.get("/api/public/items")
async def items(page:int=1):
    await asyncio.sleep(0.05 + random.random()*0.02)  # 50~70ms
    return {"page":page, "items":[{"id":i} for i in range(10)]}
```

### 25.4.3 Nginx 캐시 구성(요점)
```nginx
proxy_cache_path /var/cache/nginx keys_zone=api:256m max_size=10g inactive=60s;
map $arg_page $kpage { default:$arg_page; "":"1"; }
map $request_uri $norm { default $uri$is_args$kpage; }  # 쿼리 정규화

server {
  listen 443 ssl;
  location /api/public/ {
    proxy_cache api;
    proxy_cache_key "$scheme$host$norm";
    proxy_cache_valid 200 1s;             # 짧은 TTL(데모)
    proxy_cache_lock on;                   # request collapsing
    proxy_http_version 1.1;
    proxy_set_header Connection "";
    proxy_pass http://127.0.0.1:8000;
    add_header X-Cache $upstream_cache_status;
  }
}
```

- **짧은 TTL(1s)**: 최신성 요구가 높을 때 안전한 선택.
- **`proxy_cache_lock`**: 캐시 미스 동시 몰림 방지 → 오리진 보호.
- **정규화 키**: 의미 없는 쿼리/순서 차이 제거.

### 25.4.4 캐시 워밍/프리패치 스크립트
```bash
#!/usr/bin/env bash
set -e
HOST="https://proxy"
hot=(
  "/api/public/items?page=1"
  "/api/public/items?page=2"
  "/api/public/items?page=3"
)
for p in "${hot[@]}"; do
  curl -sk -o /dev/null -w "%{http_code} $p\n" "$HOST$p"
done
```

### 25.4.5 캐시 무효화(엔드포인트/키 기반)
- **키 규칙**을 문서화해야 안전히 무효화 가능.
- Nginx는 기본적으로 PURGE 미제공 → **경로 버전닝**(`…?v=hash`) 또는
  **파일명 해시**(정적) 사용. Varnish/Envoy/Cloud-CDN은 **API PURGE** 지원.

**Varnish 예 (VCL, 태그 purge)**
```vcl
sub vcl_recv {
  if (req.method == "PURGE" && client.ip ~ purge_acl) {
    ban("obj.http.X-Cache-Tag ~ " + req.http.X-Purge-Tag);
    return(synth(200,"Purged"));
  }
}
sub vcl_backend_response {
  set beresp.http.X-Cache-Tag = "items";
}
```

### 25.4.6 오리진 보호: 레이트/동시성 제한
```nginx
# 동시 오리진 연결 제한 (백엔드 보호)
limit_conn_zone $server_name zone=conn:10m;

server {
  location /api/public/ {
    limit_conn conn 200;              # 오리진 연결 상한
    proxy_connect_timeout 1s;
    proxy_read_timeout 2s;
    # 캐시 설정은 위와 동일
  }
}
```

### 25.4.7 성능 측정(벤치마크 시나리오)
1) **캐시 OFF**: `proxy_cache off;` 상태에서 `wrk -t8 -c200 -d60s`
   - 기록: `RPS`, `p50/p95`, 백엔드 CPU/메모리, 에러율.
2) **캐시 ON (TTL=1s)**: 동일 워크로드 측정, **백엔드 호출 수** 비교.
3) **워밍+Lock**: 배포 직후 워밍 후 측정 → **p95 안정성** 개선 확인.
4) **인증/개인화 요청 혼재**: 캐시 가능한 경로와 아닌 경로 rps 분리 보기.

**wrk 명령 예**
```bash
wrk -t8 -c200 -d60s --latency https://proxy/api/public/items?page=1
```

**기대 결과(예시 수치)**
- 캐시 OFF: 4k rps, p95 120ms, 오리진 rps=4k
- 캐시 ON: 20k rps, p95 40ms, 오리진 rps=0.8k (캐시 적중률 ~80%)
- 워밍+Lock: 스파이크 구간의 p95 변동폭 ↓

> **핵심 해석**: **적중률 1%p 증가**가 오리진 rps를 **얼마나 줄였는지**를 **환산**하여
> 캐시 공간/노드 비용과 비교 → **ROI**로 의사결정.

### 25.4.8 실패/장애 플레이북
- **증상**: 캐시 미스 폭증, 오리진 5xx 증가, 큐 적체
- **즉시 조치**
  1) **TTL 일시 연장**(예: 1s→10s)
  2) **캐시 키/락 재검토**(파편화/락 비활성)
  3) **미스 상한**: request collapsing 강제, 백엔드 연결 수 상한 축소
- **사후**:
  - **Vary/쿠키 검사**(개인화가 캐시 파괴?),
  - **정규화**(쿼리 파편화 제거),
  - **워밍 커버리지** 확대.

---

## 부록 A. 비용–성능 모델(간단)

**변수**
- `H` = 캐시 적중률
- `R_total` = 총 요청 rps
- `R_origin = R_total * (1 - H)`
- `Cost_origin = a * R_origin` (오리진 노드/CPU 비용 단순화)
- `Cost_cache = b * Size_cache + c * egress_cd n`

**목표**: `Cost_total = Cost_origin + Cost_cache` 최소화
→ `dCost/dH` 음수 구간까지 **H(정책/워밍/정규화)**를 올리되, **정합성 리스크**를 고려한 제한.

---

## 부록 B. 체크리스트

- [ ] **캐시 키**: 경로/쿼리 정규화, 인증/개인화 분리, `Vary` 최소화
- [ ] **TTL/무효화**: 짧은 TTL + 배경 리프레시 + 명확한 퍼지 전략
- [ ] **오리진 보호**: request collapsing, 오리진 동시성 상한, 서킷브레이커
- [ ] **관측**: 적중률, 미스 사유(키 미스/Bypass), 오리진 rps, p95, 에러율
- [ ] **릴리스**: 배포 후 **워밍**, 카나리, 롤백 버튼(캐시 비활성/TTL 확대)
- [ ] **보안**: 개인화/PII 응답 `no-store`, `Set-Cookie` 정리, 헤더 검증
- [ ] **네트워킹**: NIC 큐/RSS/IRQ, conntrack, TCP backlog, keep-alive

---

## 요약
- **XDP/DPDK**는 **데이터패스 레벨**에서 성능을 다루지만 **운영 복잡도**가 다르다. 대부분의 웹/API 워크로드는 **XDP(간단 룰) + 커널 네트워킹 + L7 프록시/캐시** 조합이 **비용·유지보수** 측면에서 유리하다.
- **CDN/캐시/Keep-Alive/풀링**은 오리진 부하를 **구조적으로** 감소시킨다. 특히 **캐시 키/TTL/락/워밍**이 실효를 가른다.
- **트레이드오프**는 “성능↔정합성/운영 리스크”의 균형이다. **숫자(적중률→오리진 rps)**로 설명 가능한 **ROI 모델**을 유지하라.
- **실습**의 L7 캐시 파이프라인과 벤치마크를 통해, **p95 개선**과 **오리진 보호** 효과를 바로 확인할 수 있다.
- 다음 단계: **Envoy/Varnish/Redis 캐시** 비교, **H2/H3** 전환 실험, **에지 컴퓨팅(Workers/Functions)** 기반 **Near-origin 규칙**으로 확장.
