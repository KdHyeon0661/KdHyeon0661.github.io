---
layout: post
title: 영상처리 - 영상 처리의 개요와 디지털 영상의 이해 (C#)
date: 2025-12-10 14:30:23 +0900
category: 영상처리
---
# 영상 처리의 개요와 디지털 영상의 이해

## 아날로그 영상과 디지털 영상

### 아날로그 영상의 특성
현실 세계의 영상은 연속적인 공간에서 정의된 연속 함수입니다.

$$
f_a(x, y) : \mathbb{R}^2 \rightarrow \mathbb{R}^+
$$

여기서 $(x, y)$는 실수 좌표, $$f_a(x, y)$$는 해당 점의 밝기 값입니다.

**특징:**
- 좌표계: 연속적인 실수 공간
- 값의 범위: 연속적인 밝기 값
- 저장: 물리적 매체(필름, 아날로그 신호)

### 디지털 영상의 특성

컴퓨터가 처리할 수 있는 이산적 표현입니다.

$$
f_d[m, n] : \mathbb{Z}^2 \rightarrow \{0, 1, \dots, 255\}
$$

여기서 $$[m, n]$$은 정수 인덱스, $$f_d[m, n]$$은 0~255의 정수 값입니다.

**특징:**
- 좌표계: 이산적인 격자(grid) 시스템
- 값의 범위: 양자화된 정수 값
- 저장: 디지털 메모리(바이트 배열)

## 샘플링과 양자화

### 샘플링: 공간의 이산화
연속 공간에서 이산적인 점들을 선택하는 과정입니다.

**샘플링 수식:**
$$
x = m \cdot \Delta x, \quad y = n \cdot \Delta y
$$
$$
f_d[m, n] = f_a(m\Delta x, n\Delta y)
$$

여기서 $$\Delta x$$, $$\Delta y$$는 샘플링 간격으로, 이 값이 작을수록 고해상도 영상이 됩니다.

**샘플링 밀도에 따른 결과:**
```
고해상도 (밀집 샘플링)        저해상도 (희소 샘플링)
● ● ● ● ● ● ●              ●   ●   ●   ●
● ● ● ● ● ● ●              ●   ●   ●   ●  
● ● ● ● ● ● ●              ●   ●   ●   ●
● ● ● ● ● ● ●              ●   ●   ●   ●
세부적인 표현 가능              정보 손실 발생
```

### 양자화: 값의 이산화
연속적인 밝기 값을 유한한 수의 레벨로 근사화하는 과정입니다.

**양자화 수식:**
$$
Q = \frac{\text{Max Value}}{L - 1}
$$
$$
f_q[m, n] = \left\lfloor \frac{f_d[m, n]}{Q} \right\rfloor \times Q
$$

여기서 $$L$$은 양자화 레벨 수입니다. 8비트 영상의 경우 $$L = 256$$입니다.

**비트 깊이별 표현력:**
| 비트 수 | 레벨 수 | 용도 |
|---------|---------|------|
| 1비트 | 2 | 흑백 영상, 마스크 |
| 8비트 | 256 | 일반 그레이스케일 영상 |
| 16비트 | 65,536 | 의료 영상, 과학 데이터 |
| 24비트 | 16,777,216 | 트루컬러(RGB 각 8비트) |

## 영상의 수학적 표현

### 2차원 함수로서의 영상
디지털 영상은 행(row)과 열(column)로 구성된 2차원 함수입니다.

$$
I : \mathbb{Z}^2 \rightarrow \mathbb{Z}
$$

**4×3 영상의 행렬 표현:**
```
수학적 표현:           메모리 인덱싱:
I(0,0) I(1,0) I(2,0) I(3,0)    [0]  [1]  [2]  [3]
I(0,1) I(1,1) I(2,1) I(3,1)    [4]  [5]  [6]  [7]  
I(0,2) I(1,2) I(2,2) I(3,2)    [8]  [9] [10] [11]
```

**픽셀 좌표계:**
```
(0,0) ----> x(너비)
|
|
y(높이)
```

## C#에서의 영상 표현과 메모리 레이아웃

### 고수준 접근: OpenCvSharp 사용

OpenCvSharp은 영상 처리를 위한 고수준 API를 제공합니다.

```csharp
using OpenCvSharp;

public class ImageProcessingHighLevel
{
    public void ProcessImageWithOpenCV()
    {
        // 1. 영상 로드 (고수준 API)
        Mat image = Cv2.ImRead("image.jpg", ImreadModes.Grayscale);
        
        // 2. 영상 정보 확인
        int width = image.Width;      // 너비 (열 수)
        int height = image.Height;    // 높이 (행 수)
        int channels = image.Channels(); // 채널 수 (그레이스케일: 1, RGB: 3)
        
        // 3. 기본 영상 처리 연산
        // 가우시안 블러 적용
        Mat blurred = new Mat();
        Cv2.GaussianBlur(image, blurred, new Size(5, 5), 1.5);
        
        // 에지 검출
        Mat edges = new Mat();
        Cv2.Canny(blurred, edges, 50, 150);
        
        // 4. 영상 저장
        Cv2.ImWrite("processed.jpg", edges);
        
        // 5. 리소스 해제
        image.Dispose();
        blurred.Dispose();
        edges.Dispose();
    }
}
```

### 저수준 동작 원리 분석

OpenCvSharp의 `ImRead` 함수 내부에서는 다음과 같은 과정이 일어납니다:

```csharp
// 의사 코드: Cv2.ImRead의 내부 동작
internal static Mat ImReadInternal(string filename, ImreadModes flags)
{
    // 1. 파일 읽기
    byte[] fileData = File.ReadAllBytes(filename);
    
    // 2. 파일 형식 판별 (JPEG, PNG 등)
    ImageFormat format = DetectImageFormat(fileData);
    
    // 3. 디코딩 (형식에 따른 처리)
    switch (format)
    {
        case ImageFormat.Jpeg:
            return DecodeJpeg(fileData, flags);
        case ImageFormat.Png:
            return DecodePng(fileData, flags);
        // ... 다른 형식들
    }
}

private static Mat DecodeJpeg(byte[] compressedData, ImreadModes flags)
{
    // JPEG 디코딩 (libjpeg-turbo 라이브러리 사용)
    // 1. 헤더 파싱
    JpegHeader header = ParseJpegHeader(compressedData);
    
    // 2. 허프만 테이블 로드
    HuffmanTable huffmanTable = LoadHuffmanTables(compressedData);
    
    // 3. MCU(Minimum Coded Unit) 디코딩
    byte[] mcuData = DecodeMCUs(compressedData, huffmanTable);
    
    // 4. 색상 공간 변환 (YCbCr → RGB)
    byte[] rgbData = ConvertYCbCrToRgb(mcuData);
    
    // 5. Mat 객체 생성
    Mat mat = new Mat(header.Height, header.Width, 
                     MatType.CV_8UC3, rgbData);
    
    return mat;
}
```

### C#에서의 메모리 레이아웃 이해

#### 1. 논리적 표현 vs 물리적 저장

**논리적 (2차원 배열):**
```csharp
byte[,] image2D = new byte[height, width];
// 접근: byte pixel = image2D[y, x];
```

**문제점:** 메모리 상에서 연속적이지 않아 캐시 효율이 낮습니다.

**물리적 (1차원 배열):**
```csharp
byte[] image1D = new byte[height * width];
// 접근: byte pixel = image1D[y * width + x];
```

#### 2. Stride의 개념과 중요성

Stride는 한 행(row)의 바이트 수로, 너비와 다를 수 있습니다.

```csharp
public class ImageBuffer
{
    private byte[] _data;
    private int _width;
    private int _height;
    private int _stride;
    
    public ImageBuffer(int width, int height)
    {
        _width = width;
        _height = height;
        
        // 메모리 정렬을 위한 stride 계산 (4바이트 정렬)
        _stride = ((width + 3) / 4) * 4;
        
        _data = new byte[_stride * height];
    }
    
    // 픽셀 접근 메서드
    public byte GetPixel(int x, int y)
    {
        // stride를 사용한 인덱스 계산
        int index = y * _stride + x;
        return _data[index];
    }
    
    public void SetPixel(int x, int y, byte value)
    {
        int index = y * _stride + x;
        _data[index] = value;
    }
}
```

**Stride가 필요한 이유:**
1. **메모리 정렬**: CPU가 효율적으로 접근하기 위해
2. **GPU 요구사항**: 그래픽 카드의 메모리 정렬 규칙
3. **이미지 파일 형식**: BMP, TIFF 등에서 패딩 사용

#### 3. 실제 메모리 레이아웃 예시

**가상의 3×4 영상 (너비=4, stride=4):**
```
물리적 메모리: [행0][행1][행2]

행0: [P00][P01][P02][P03]
행1: [P10][P11][P12][P13]  
행2: [P20][P21][P22][P23]

선형 배열: [P00][P01][P02][P03][P10][P11][P12][P13][P20][P21][P22][P23]
```

**패딩이 있는 경우 (너비=3, stride=4):**
```
물리적 메모리: [행0][패딩][행1][패딩][행2][패딩]

행0: [P00][P01][P02][  패딩  ]
행1: [P10][P11][P12][  패딩  ]
행2: [P20][P21][P22][  패딩  ]

선형 배열: [P00][P01][P02][패딩][P10][P11][P12][패딩][P20][P21][P22][패딩]
```

### 고수준과 저수준의 연결: 실제 구현 예제

#### OpenCvSharp의 Mat 클래스 내부 구조

```csharp
// Mat 클래스의 핵심 멤버 (의사 코드)
public class Mat : IDisposable
{
    // 네이티브 포인터 (C++ OpenCV 객체 참조)
    private IntPtr _ptr;
    
    // 메타데이터
    private int _rows;     // 높이
    private int _cols;     // 너비
    private int _type;     // 데이터 타입 (CV_8UC1, CV_8UC3 등)
    private int _step;     // stride (한 행의 바이트 수)
    
    // 데이터 접근 메서드
    public unsafe byte* DataPointer
    {
        get
        {
            // 네이티브 객체에서 데이터 포인터 얻기
            return (byte*)NativeMethods.core_Mat_data(_ptr);
        }
    }
    
    // 픽셀 접근 (저수준)
    public unsafe byte GetPixelValue(int row, int col, int channel = 0)
    {
        // 메모리 계산: 행 시작 주소 + 열 오프셋 + 채널 오프셋
        byte* rowPtr = DataPointer + (row * _step);
        int pixelOffset = col * Channels() + channel;
        return rowPtr[pixelOffset];
    }
}
```

#### 직접 구현하는 영상 클래스

```csharp
public unsafe class DirectBitmap : IDisposable
{
    private byte* _scan0;
    private int _stride;
    private Bitmap _bitmap;
    private BitmapData _bitmapData;
    
    public int Width { get; }
    public int Height { get; }
    
    public DirectBitmap(int width, int height)
    {
        Width = width;
        Height = height;
        
        // Bitmap 생성 (Format32bppArgb: BGRA 순서)
        _bitmap = new Bitmap(width, height, PixelFormat.Format32bppArgb);
        
        // 메모리 잠금 (LockBits)
        _bitmapData = _bitmap.LockBits(
            new Rectangle(0, 0, width, height),
            ImageLockMode.ReadWrite,
            PixelFormat.Format32bppArgb
        );
        
        // 스캔 라인 시작 주소
        _scan0 = (byte*)_bitmapData.Scan0;
        _stride = _bitmapData.Stride;
    }
    
    // 픽셀 설정 (BGRA 형식)
    public void SetPixel(int x, int y, byte b, byte g, byte r, byte a = 255)
    {
        // 행 시작 주소 계산
        byte* row = _scan0 + (y * _stride);
        
        // 픽셀 오프셋 (4바이트 per pixel: B,G,R,A)
        int pixelOffset = x * 4;
        
        row[pixelOffset] = b;     // Blue
        row[pixelOffset + 1] = g; // Green
        row[pixelOffset + 2] = r; // Red
        row[pixelOffset + 3] = a; // Alpha
    }
    
    // 그레이스케일 변환 (저수준 최적화)
    public void ConvertToGrayscale()
    {
        for (int y = 0; y < Height; y++)
        {
            byte* row = _scan0 + (y * _stride);
            
            for (int x = 0; x < Width; x++)
            {
                int pixelOffset = x * 4;
                
                // BGR 값을 읽어서 그레이스케일 계산
                byte b = row[pixelOffset];
                byte g = row[pixelOffset + 1];
                byte r = row[pixelOffset + 2];
                
                // 그레이스케일 값 계산 (가중치 평균)
                byte gray = (byte)((r * 0.299 + g * 0.587 + b * 0.114));
                
                // BGR 모두 같은 값으로 설정
                row[pixelOffset] = gray;     // Blue
                row[pixelOffset + 1] = gray; // Green  
                row[pixelOffset + 2] = gray; // Red
                // Alpha는 변경하지 않음
            }
        }
    }
    
    public void Dispose()
    {
        if (_bitmapData != null)
        {
            _bitmap.UnlockBits(_bitmapData);
            _bitmapData = null;
        }
        _bitmap?.Dispose();
    }
}
```

### 샘플링과 양자화의 실제 구현

```csharp
public class SamplingAndQuantization
{
    // 아날로그 함수 (연속 함수) - 예시: 2D 사인파
    private double AnalogFunction(double x, double y)
    {
        return 0.5 * (1 + Math.Sin(x * 0.1) * Math.Cos(y * 0.1));
    }
    
    // 샘플링: 연속 공간 → 이산 격자
    public double[,] SampleAnalogFunction(double startX, double startY, 
                                         double deltaX, double deltaY,
                                         int samplesX, int samplesY)
    {
        double[,] sampled = new double[samplesY, samplesX];
        
        for (int i = 0; i < samplesY; i++)
        {
            double y = startY + i * deltaY;
            for (int j = 0; j < samplesX; j++)
            {
                double x = startX + j * deltaX;
                sampled[i, j] = AnalogFunction(x, y);
            }
        }
        
        return sampled;
    }
    
    // 양자화: 연속 값 → 이산 레벨
    public byte[,] Quantize(double[,] continuousValues, int bits)
    {
        int levels = 1 << bits; // 2^bits
        double maxValue = 1.0; // 최대 밝기 값 (정규화)
        
        int height = continuousValues.GetLength(0);
        int width = continuousValues.GetLength(1);
        byte[,] quantized = new byte[height, width];
        
        for (int y = 0; y < height; y++)
        {
            for (int x = 0; x < width; x++)
            {
                // [0, 1] 범위를 [0, levels-1] 범위로 매핑
                double normalized = continuousValues[y, x];
                int quantizedValue = (int)(normalized * (levels - 1) + 0.5);
                
                // 클리핑 (범위 제한)
                if (quantizedValue < 0) quantizedValue = 0;
                if (quantizedValue > levels - 1) quantizedValue = levels - 1;
                
                quantized[y, x] = (byte)quantizedValue;
            }
        }
        
        return quantized;
    }
    
    // 샘플링 레이트에 따른 품질 비교
    public void CompareSamplingRates()
    {
        // 고해상도 샘플링
        double[,] highRes = SampleAnalogFunction(0, 0, 0.1, 0.1, 100, 100);
        
        // 저해상도 샘플링  
        double[,] lowRes = SampleAnalogFunction(0, 0, 0.5, 0.5, 20, 20);
        
        // 양자화 비교
        byte[,] highRes8bit = Quantize(highRes, 8);  // 256 레벨
        byte[,] lowRes4bit = Quantize(lowRes, 4);    // 16 레벨
        byte[,] lowRes2bit = Quantize(lowRes, 2);    // 4 레벨
        
        Console.WriteLine($"고해상도 (100x100, 8비트): {highRes8bit.Length} 바이트");
        Console.WriteLine($"저해상도 (20x20, 4비트): {lowRes4bit.Length} 바이트");
        Console.WriteLine($"정보 손실 있지만 용량은 1/{(highRes8bit.Length / (double)lowRes4bit.Length):F1}배");
    }
}
```

## 실전 예제: 간단한 영상 처리 파이프라인

```csharp
public class CompleteImagePipeline
{
    // 1. 영상 생성 (수학적 함수로부터)
    public byte[,] GenerateImageFromFunction(int width, int height)
    {
        byte[,] image = new byte[height, width];
        
        for (int y = 0; y < height; y++)
        {
            for (int x = 0; x < width; x++)
            {
                // 원형 그라디언트 생성
                double centerX = width / 2.0;
                double centerY = height / 2.0;
                
                double distance = Math.Sqrt(
                    Math.Pow(x - centerX, 2) + 
                    Math.Pow(y - centerY, 2)
                );
                
                double maxDistance = Math.Sqrt(
                    Math.Pow(centerX, 2) + 
                    Math.Pow(centerY, 2)
                );
                
                double normalized = distance / maxDistance;
                image[y, x] = (byte)(normalized * 255);
            }
        }
        
        return image;
    }
    
    // 2. 2D 배열을 1D 배열로 변환 (메모리 레이아웃)
    public byte[] ConvertTo1DArray(byte[,] image2D, int stride)
    {
        int height = image2D.GetLength(0);
        int width = image2D.GetLength(1);
        
        byte[] image1D = new byte[height * stride];
        
        for (int y = 0; y < height; y++)
        {
            for (int x = 0; x < width; x++)
            {
                int srcIndex = y * width + x;
                int dstIndex = y * stride + x;
                image1D[dstIndex] = image2D[y, x];
            }
            // 패딩 영역은 0으로 채움
            for (int x = width; x < stride; x++)
            {
                image1D[y * stride + x] = 0;
            }
        }
        
        return image1D;
    }
    
    // 3. OpenCvSharp으로 처리
    public void ProcessWithOpenCV(byte[] imageData, int width, int height, int stride)
    {
        using (Mat mat = new Mat(height, width, MatType.CV_8UC1, imageData))
        {
            // 히스토그램 평활화
            Mat equalized = new Mat();
            Cv2.EqualizeHist(mat, equalized);
            
            // 임계값 처리
            Mat thresholded = new Mat();
            Cv2.Threshold(equalized, thresholded, 128, 255, ThresholdTypes.Binary);
            
            // 윤곽선 검출
            Point[][] contours;
            HierarchyIndex[] hierarchy;
            Cv2.FindContours(
                thresholded, 
                out contours, 
                out hierarchy, 
                RetrievalModes.Tree,
                ContourApproximationModes.ApproxSimple
            );
            
            Console.WriteLine($"검출된 윤곽선 수: {contours.Length}");
        }
    }
    
    // 4. 저수준 직접 처리
    public unsafe void ProcessDirectly(byte* imageData, int width, int height, int stride)
    {
        // 간단한 커널 적용 (평균 필터)
        byte[] tempBuffer = new byte[height * stride];
        fixed (byte* tempPtr = tempBuffer)
        {
            // 행 단위 처리
            for (int y = 1; y < height - 1; y++)
            {
                byte* prevRow = imageData + ((y - 1) * stride);
                byte* currRow = imageData + (y * stride);
                byte* nextRow = imageData + ((y + 1) * stride);
                byte* dstRow = tempPtr + (y * stride);
                
                for (int x = 1; x < width - 1; x++)
                {
                    // 3×3 평균 필터
                    int sum = 0;
                    sum += prevRow[x - 1] + prevRow[x] + prevRow[x + 1];
                    sum += currRow[x - 1] + currRow[x] + currRow[x + 1];
                    sum += nextRow[x - 1] + nextRow[x] + nextRow[x + 1];
                    
                    dstRow[x] = (byte)(sum / 9);
                }
            }
            
            // 결과 복사
            Buffer.MemoryCopy(tempPtr, imageData, height * stride, height * stride);
        }
    }
}
```

## 핵심 개념 정리

### 영상 표현의 계층 구조
```
1. 현실 세계: 연속 함수 f(x,y) (아날로그)
2. 샘플링: 격자점 선택 → 이산 좌표 [m,n]
3. 양자화: 연속 값 → 정수 레벨 (0-255)
4. 메모리: 1차원 바이트 배열 + stride
5. 프레임버퍼: 디스플레이 출력
```

### 성능 고려사항

```
// 성능 비교 (1000×1000 영상 기준)
// 2차원 배열 접근: ~50ms
// 1차원 배열 접근: ~20ms  
// 포인터 직접 접근: ~5ms
// SIMD 최적화: ~1ms (최대 50배 향상)
```

### 실용적 조언
1. **교육/프로토타이핑**: OpenCvSharp 사용 (생산성 ↑)
2. **실시간 처리**: 직접 메모리 관리 + unsafe 코드 (성능 ↑)
3. **메모리 레이아웃**: stride 이해 필수 (호환성 ↑)
4. **처리 파이프라인**: 영상 → 전처리 → 특징 추출 → 분석
