---
layout: post
title: 확률과 통계 - 연속 분포와 정규세계
date: 2025-09-19 17:25:23 +0900
category: 확률과 통계
---
# 연속 분포와 정규세계

> **목표**
> - **균등·지수·감마·카이제곱·정규**의 역할과 상호관계를 이해한다.
> - **대기시간(지수/감마)**, **집계 지표의 정규 근사**(CLT·델타법)의 적용 한계를 실무 예제로 파악한다.
> - **체류시간(heavy-tail)** 같은 분포에서 **평균·표준편차만**으로 보고하는 위험을 진단하고 대안을 제시한다.

---

## 0. Hook — “정규성은 공짜가 아니다”

실무에서 자주 듣는 말:

> “일별 평균이면 대충 정규 분포로 보죠.”

문제는 **원자료의 분포가 어떤지 모른 채** 이 말을 쓰는 순간이다.

- 사이트 **체류시간**이나 **거래금액**처럼 **꼬리가 두꺼운 분포(heavy-tail)** 에서는  
  - 표본 크기가 커도  
  - 일별 평균의 분포가 우리가 기대하는 것보다 **훨씬 요동**칠 수 있고  
  - **평균 ± 1.96·표준오차**로 그린 신뢰구간이 **엉뚱하게 좁거나 비대칭적**일 수 있다.
- “평균 120초, 표준편차 300초”라는 한 줄 요약은  
  - **상위 1% 사용자의 1시간 체류**  
  - **극단적인 장기 세션**을 전혀 드러내지 못한다.

핵심 메시지:

1. 먼저 **단일 사용자 수준 분포**(원분포)의 모양을 보고  
2. 그 위에서 **지수·감마·로그정규·파레토** 후보를 검토하고  
3. 집계 지표(일별 평균, 분당 평균 등)을 정규 근사할지 말지 결정해야 한다.
4. 보고서는 **평균·표준편차**만이 아니라  
   - **중앙값**  
   - **IQR(사분위 범위)**  
   - **상위 분위(90p, 95p, 99p)**  
   - 필요하면 **로그척도 요약값**까지 함께 적어서 “꼬리”를 드러내야 한다.

이 글은 이런 판단을 위해 필요한 연속 분포들을 **역할 중심**으로 엮어 본다.

---

## 1. 균등 분포 — “모른다는 것의 공식”

### 1.1 정의와 기본 성질

균등 분포는 “**a와 b 사이 어디든 똑같이 가능**”이라는 아주 단순한 가정이다.

- 정의  
  $$X \sim \mathrm{Unif}(a,b)$$
- PDF(확률밀도함수)  
  $$
  f_X(x)=
  \begin{cases}
  \dfrac{1}{b-a}, & a \le x \le b \\
  0, & \text{otherwise}
  \end{cases}
  $$
- CDF(누적분포함수)  
  $$
  F_X(x)=P(X \le x) =
  \begin{cases}
  0, & x < a \\
  \dfrac{x-a}{b-a}, & a \le x \le b \\
  1, & x > b
  \end{cases}
  $$
- 기대값·분산  
  $$
  E[X]=\frac{a+b}{2},\quad
  \mathrm{Var}(X)=\frac{(b-a)^2}{12}
  $$

#### 직관

- **이외 정보가 없을 때의 기본 모형**  
  “a와 b 사이인 건 확실하지만 어디에 몰려 있는지는 전혀 모른다” → 균등은 일종의 “**모른다는 것의 공식화**”.
- 일단 균등으로 시작해 시뮬레이션을 돌린 뒤, 실제 데이터가 쌓이면  
  - 다른 분포(삼각, 베타, 정규 등)로 바꾸는 경우가 많다.

### 1.2 웹/앱 직관 — “실험 구간 내 최초 방문 시각”

실험을 0분부터 60분까지 진행한다고 하자.

- 가정:
  - 실험 전반에 걸쳐 **트래픽 유입이 거의 일정**하고
  - 사용자에게 나중에 들어올 이유/초기에 들어올 이유가 크게 없다면
- **최초 방문 시각 T**는  
  $$T \sim \mathrm{Unif}(0, 60\text{ 분})$$  
  정도로 근사할 수 있다.

이 가정이 깨지는 신호:

- “초반에 이벤트가 몰린다” → 초반 핫타임, 마케팅 푸시
- “후반에 몰린다” → 퇴근 시간 집중, 특정 시간대 알림
- 이럴 땐 **균등 대신** 삼각 분포나 베타 분포, 혹은 경험분포를 쓰는 편이 더 낫다.

### 1.3 간단 시뮬레이션 코드

```python
import random
import statistics

def sample_uniform(a, b, n=100000):
    xs = [random.uniform(a, b) for _ in range(n)]
    mean = statistics.mean(xs)
    var = statistics.pvariance(xs)
    return mean, var

if __name__ == "__main__":
    m, v = sample_uniform(0, 60)
    print("sample mean:", m)
    print("sample var :", v, "(theoretical:", (60-0)**2/12, ")")
```

- 이 코드를 여러 번 실행하면
  - 평균이 약 30,
  - 분산이 약 300에 수렴하는 것을 확인할 수 있다.

---

## 2. 지수 분포 — “기다림과 기억 없음”

### 2.1 정의와 핵심 성질

지수 분포는 “**다음 사건까지의 대기시간**”의 기본 모형이다.

- 정의  
  $$T \sim \mathrm{Exp}(\lambda)$$
- PDF  
  $$
  f_T(t) = \lambda e^{-\lambda t},\quad t \ge 0
  $$
- CDF  
  $$
  F_T(t) = P(T \le t) = 1 - e^{-\lambda t}
  $$
- 기대값·분산  
  $$
  E[T] = \frac{1}{\lambda}, \quad
  \mathrm{Var}(T) = \frac{1}{\lambda^2}
  $$

#### 기억 없음 (memorylessness)

지수 분포의 상징적인 성질:

$$
P(T > s+t \mid T > s) = P(T > t)
$$

설명:

- 이미 s초를 기다렸더라도, **앞으로 더 기다려야 할 시간의 분포**는 처음과 같다.
- “지금까지 기다린 것”이 **앞으로의 남은 시간에 영향을 주지 않는다**.

실무 해석:

- 어떤 시스템의 이벤트 발생이 정말 지수라면  
  - “오래 아무 일이 없었으니 이제 곧 일어나겠지?”는 **착각**이다.
- 현실 시스템은
  - 장비 노후,
  - 사용자 피로도,
  - 시간대 효과 등으로
  - **기억 없음이 어긋나는 경우가 많다** → 감마/로그정규/파레토 등으로 확장해야 한다.

### 2.2 포아송 과정과의 연결

**포아송 과정(Poisson process)**:

- “단위 시간당 평균 λ건 발생”하는 사건 흐름.
- 전형적인 가정:
  - 서로 다른 구간에서 사건 수는 **독립**.
  - 아주 작은 시간 간격에서는 한 건 이상 발생할 확률이 극히 작다.

결과:

- 이 과정에서 **연속 두 사건 사이 대기시간**은  
  $$T \sim \mathrm{Exp}(\lambda)$$
- 또한 **시간 t까지 발생 건수 N(t)**는  
  $$N(t) \sim \mathrm{Poisson}(\lambda t)$$

즉,

- “한 번에 몇 건?” → 포아송 분포
- “다음 건까지 얼마나 기다리나?” → 지수 분포

### 2.3 실무 예 — 푸시 알림 후 첫 클릭까지 대기시간

가정:

- 어떤 캠페인 알림을 보냈고,
- 각 사용자에 대해 “첫 클릭까지 대기시간 T”가 Exp(λ)라고 하자.

그러면,

- **10초 이내 클릭 확률**:
  $$
  P(T \le 10) = 1 - e^{-\lambda \cdot 10}
  $$
- **중앙값**:
  $$
  \mathrm{med}(T) = \frac{\ln 2}{\lambda} \approx 0.693 \cdot \frac{1}{\lambda}
  $$
  - 평균이 1/λ이므로
  - **지수에서 중앙값은 항상 평균보다 작다**.

보고할 때:

- “평균 대기시간 5초”보다  
- “**중앙값 3.5초, 90퍼센타일 11초**”처럼 요약하면
  - **대부분의 사용자 vs 아주 느린 사용자**를 명확하게 보여줄 수 있다.

### 2.4 Python 시뮬레이션 — 지수 대기시간 분포

```python
import random
import math
import statistics

def exp_sample(lam):
    # inverse transform sampling
    u = random.random()
    return -math.log(1 - u) / lam

def simulate_exp(lam=0.2, n=100000):
    xs = [exp_sample(lam) for _ in range(n)]
    mean = statistics.mean(xs)
    var = statistics.pvariance(xs)
    xs_sorted = sorted(xs)
    def quantile(p):
        k = int(p * n)
        return xs_sorted[k]
    return {
        "mean": mean,
        "var": var,
        "q50": quantile(0.5),
        "q90": quantile(0.9),
        "q95": quantile(0.95),
    }

if __name__ == "__main__":
    stats = simulate_exp(lam=0.2)
    for k, v in stats.items():
        print(k, "=", v)
```

- 이 예에서는 λ=0.2 (평균 5초)일 때
  - q50 ≈ 3.47,
  - q90 ≈ 11.51,
  - q95 ≈ 14.98 정도가 나올 것이다.
- 같은 평균이라도 **꼬리 쪽 사용자는 훨씬 오래 기다린다**는 것을 숫자로 체감할 수 있다.

---

## 3. 감마와 Erlang — “지수 k개 합 = Erlang”

### 3.1 정의(형상 k, 척도 θ)

감마 분포는 “양수 축 위에 정의된 연속 분포”의 매우 일반적인 패밀리다.

- 정의  
  $$T \sim \mathrm{Gamma}(k,\theta)$$  (k>0, θ>0)
- PDF  
  $$
  f_T(t) = \frac{1}{\Gamma(k)\theta^k} t^{k-1} e^{-t/\theta},\quad t \ge 0
  $$
- 기대값·분산  
  $$
  E[T] = k\theta,\quad
  \mathrm{Var}(T) = k\theta^2
  $$
- 변동계수(CV, coefficient of variation)  
  $$
  \mathrm{CV} = \frac{\sqrt{\mathrm{Var}(T)}}{E[T]} = \frac{1}{\sqrt{k}}
  $$

해석:

- k가 커질수록 **CV가 감소** → 상대적인 변동성이 줄어든다.
- 즉, 감마는
  - k : “**단계 수/형상**”
  - θ : “**단계당 평균 시간(척도)**”
  - 로 생각하면 직관적이다.

### 3.2 포아송 과정 관점 — “k번째 사건까지의 시간”

포아송 과정에서:

- 사건 간 간격은 **지수(λ)**.
- **k번째 사건까지의 누적 대기시간**은  
  $$T_k = \sum_{i=1}^k X_i,\quad X_i \sim \mathrm{Exp}(\lambda)$$
- 이 합 T_k는  
  $$T_k \sim \mathrm{Gamma}\left(k, \theta=\frac{1}{\lambda}\right)$$

특별히 **k가 양의 정수**일 때:

- 이를 **Erlang(k, λ)** 분포라고 부른다.

직관:

- 하나의 이벤트가 일어나기까지 여러 **잠복 단계**가 있고,
- 각 단계가 지수적인 대기시간을 가진다면
- 전체 대기시간은 감마(Erlang)로 모델링하기 좋다.

### 3.3 웹/앱에서의 감마 직관

예: **전환 퍼널**

1. 알림 도착 → 읽기
2. 읽기 → 상세 페이지 진입
3. 상세 페이지 → 결제 완료

각 단계가 지수 대기시간을 가진다고 가정하면,

- 알림 도착 시점을 기준으로 “**최종 전환까지 걸리는 시간**”은  
  $$T \sim \mathrm{Gamma}(k=3, \theta)$$  
  꼴이 된다.

또 다른 예: **이탈 위험률(hazard)의 변화**

- 지수 분포: 위험률이 시간에 대해 **상수**
- 감마 분포(k>1): 위험률이 **증가**하다가 plateau  
  - “머무를수록 떠날 확률이 달라지는” 현상 표현 가능

따라서,

- 체류시간/세션 길이 데이터를 보면,
  - 초반에는 이탈이 많고
  - 오래 머무는 사용자일수록 계속 남아 있는 경향이 있다면
- 순수 지수보다 감마/Erlang, 로그정규를 쓰는 편이 더 타당하다.

### 3.4 감마 분포 시뮬레이션 코드 (단순 Erlang 버전)

```python
import random
import math
import statistics

def exp_sample(lam):
    u = random.random()
    return -math.log(1 - u) / lam

def erlang_sample(k, lam):
    return sum(exp_sample(lam) for _ in range(k))

def simulate_erlang(k=3, lam=0.2, n=100000):
    xs = [erlang_sample(k, lam) for _ in range(n)]
    mean = statistics.mean(xs)
    var = statistics.pvariance(xs)
    xs_sorted = sorted(xs)
    def q(p):
        return xs_sorted[int(p * n)]
    return {
        "mean": mean,
        "var": var,
        "q50": q(0.5),
        "q90": q(0.9),
        "q95": q(0.95),
    }

if __name__ == "__main__":
    stats = simulate_erlang()
    for k, v in stats.items():
        print(k, "=", v)
```

- λ=0.2, k=3이면
  - 이론적으로 평균 E[T]=k/λ=15초,
  - Var[T]=k/λ²=75.
- 지수(평균=5초)와 비교하면,
  - **같은 평균(단계당)**이더라도
  - 세 단계 합산은 “더 안정적인” 분포를 만든다는 것을 확인할 수 있다.

---

## 4. 카이제곱(χ²) 분포 — “정규제곱의 합”

### 4.1 정의와 감마와의 연결

정규 분포와 감마 분포 사이에 있는 핵심 연결 고리:

- $$Z_i \sim \mathcal{N}(0,1),\ i=1,\dots,\nu$$ (독립)
- $$Q = \sum_{i=1}^\nu Z_i^2 \sim \chi^2_\nu$$ (자유도 ν)

이때,

$$
\chi^2_\nu \equiv \mathrm{Gamma}\left(k=\frac{\nu}{2},\ \theta=2\right)
$$

즉, 카이제곱 분포는 **감마의 특수한 경우**다.

### 4.2 정규모집단에서의 분산 추정

정규모집단에서,

- $$X_i \stackrel{i.i.d.}{\sim} \mathcal{N}(\mu,\sigma^2)$$
- 표본분산:
  $$
  S^2 = \frac{1}{n-1} \sum_{i=1}^n (X_i - \bar X)^2
  $$

그러면,

$$
\frac{(n-1)S^2}{\sigma^2} \sim \chi^2_{n-1}
$$

이 결과로 인해:

- 분산에 대한 **정확한 신뢰구간**을 χ² 분포로 만들 수 있다.
- 예를 들어, 신뢰수준 1-α에서
  $$
  P\left(
    \chi^2_{1-\alpha/2} \le \frac{(n-1)S^2}{\sigma^2} \le \chi^2_{\alpha/2}
  \right) = 1-\alpha
  $$
  이므로
  $$
  \left(
    \frac{(n-1)S^2}{\chi^2_{1-\alpha/2}},
    \ \frac{(n-1)S^2}{\chi^2_{\alpha/2}}
  \right)
  $$
  가 σ²의 신뢰구간이 된다.

정규 가정이 무너지면:

- 이 χ² 기반 CI는 **정확도가 떨어진다**.
- Heavy-tail 데이터에서는
  - S² 자체가 극단값에 매우 민감하고
  - χ² 근사도 깨지므로
  - **부트스트랩 신뢰구간**(재표본화 기반)을 함께 보는 것이 바람직하다.

### 4.3 회귀·적합도 검정에서의 역할

- 선형회귀에서
  - 잔차제곱합(SSE)을 적당히 표준화하면
  - χ² 분포를 따른다고 보는 가정이 들어간다.
- 카이제곱 적합도·독립성 검정에서
  - **셀별 기대빈도** 조건(통상 5 이상)을 만족해야
  - χ² 근사가 신뢰할 만하다.

---

## 5. 정규 분포 — “합/평균의 자연한 끝”

### 5.1 정의와 기본 성질

- 정의  
  $$X \sim \mathcal{N}(\mu,\sigma^2)$$
- PDF  
  $$
  f_X(x) = \frac{1}{\sqrt{2\pi}\sigma}
  \exp\left(-\frac{(x-\mu)^2}{2\sigma^2}\right)
  $$
- 표준화  
  $$
  Z = \frac{X-\mu}{\sigma} \sim \mathcal{N}(0,1)
  $$

정규 분포의 특징:

- **합/평균의 한계 분포**라는 점에서 중요하다.
- 또한 **선형 변환에 대해 닫혀 있음**:
  - aX+b도 정규.

### 5.2 중심극한정리(CL T) — 합/평균의 정규 근사

중심극한정리(가장 단순한 형태):

- $$X_1, X_2, \dots$$ 서로 독립, 동일분포(i.i.d.)
- 평균 μ, 분산 σ²(유한)를 갖는다고 하자.
- 표본평균:
  $$
  \bar X_n = \frac{1}{n} \sum_{i=1}^n X_i
  $$
- 그러면
  $$
  \frac{\bar X_n - \mu}{\sigma/\sqrt{n}} \xrightarrow{d} \mathcal{N}(0,1)
  \quad (n\to\infty)
  $$

의미:

- n이 충분히 크면,
  - **원분포가 정규가 아니더라도**
  - 표본평균은 정규분포와 거의 비슷해진다.

단, 중요한 전제:

1. 분산이 **유한**이어야 한다.
2. 극단적으로 지배적인 꼬리가 없어야 한다.
3. 독립성·동일분포 가정이 크게 깨지지 않아야 한다.

### 5.3 Berry–Esseen 부류 결과 — “얼마나 빨리 수렴하는가”

CLT는 “**언젠가** 정규에 가까워진다”만 말해준다.  
**Berry–Esseen 정리**는 “**얼마나 빨리** 가까워지는지”를 알려준다.

핵심 아이디어:

- $$X_i$$에 대해 3차 모멘트(왜도 관련)가 유한하면,
- 분포 함수의 최대 차이
  $$
  \sup_x \left| P\left(\frac{\bar X_n - \mu}{\sigma/\sqrt{n}} \le x\right) - \Phi(x) \right|
  $$
  가 대략
  $$
  \le \frac{C\cdot E[|X_i-\mu|^3]}{\sigma^3 \sqrt{n}}
  $$
  으로 제어된다 (어떤 상수 C).

직관:

- **꼬리가 두껍고 왜도가 크면** (3차 모멘트가 크면)
  - 수렴 속도가 느려진다.
- heavy-tail에 가까운 분포는
  - **n=수만 명**이어도
  - 일별 평균의 분포가 우리가 기대하는 것보다 정규에서 많이 벗어날 수 있다.

### 5.4 이산→정규 근사와 연속성 보정

대표적인 예: **이항 분포의 정규 근사**

- $$X \sim \mathrm{Bin}(n,p)$$
- 평균 np, 분산 np(1-p)
- n이 충분히 크고 p가 0이나 1에 너무 가깝지 않으면
  $$
  X \approx \mathcal{N}(np, np(1-p))
  $$

이때 **연속성 보정**:

- 이산 분포(정수) X에 대해
  $$
  P(X \le k) \approx P\left(
    \mathcal{N}(np, np(1-p)) \le k + 0.5
  \right)
  $$
- “+0.5”는 **정수 경계**를 연속축 위에서 보정해주는 역할을 한다.

CTR/클릭수 등 바이너리 집계에 대한 정규 근사에서도  
이 연속성 보정을 쓰면 **꼬리 확률** 근사 정확도가 좋아진다.

---

## 6. 집계 지표의 정규 근사 — 평균의 세계

### 6.1 일별 평균 체류시간의 근사

사용자별 체류시간 $$T_i$$ (i=1,…,n):

- i.i.d.라고 가정하고
- 평균 μ, 분산 σ²(유한)를 가진다고 하자.

일별 평균:

$$
\bar T = \frac{1}{n} \sum_{i=1}^n T_i
$$

CLT에 의해

$$
\bar T \approx \mathcal{N}\left(\mu,\ \frac{\sigma^2}{n}\right)
$$

실제 계산에서는 σ²를 모르기 때문에 **표본분산** $$S_T^2$$로 추정한다.

#### 신뢰구간

표본 크기가 크면:

$$
\bar T \pm z_{1-\alpha/2} \cdot \frac{S_T}{\sqrt{n}}
$$

- z_{0.975} ≈ 1.96 등.

표본 크기가 작으면:

$$
\bar T \pm t_{1-\alpha/2,\ n-1} \cdot \frac{S_T}{\sqrt{n}}
$$

- 여기서 $$t_{p,\nu}$$는 자유도 ν를 갖는 t 분포의 분위수.

**주의**:

- heavy-tail, 로그정규 등에서
  - S_T 자체가 극단값에 민감하고
  - 분산 추정이 불안정 → 신뢰구간 폭이 매우 변동적.
- 이럴 때는
  - **부트스트랩 CI** (재표본화)
  - **로그 변환 후 CI** 등을 의무적으로 함께 보는 것이 안전하다.

### 6.2 CTR·CVR 평균의 근사와 델타법

CTR(Click-Through Rate) 예:

- 하루 동안
  - 노출수: N
  - 클릭수: C
- CTR:
  $$
  \hat\theta = \frac{C}{N}
  $$

단순 이항 모델:

- $$C \sim \mathrm{Bin}(N,p)$$, p가 진짜 CTR
- $$E[\hat\theta] = p$$
- $$\mathrm{Var}(\hat\theta) = \frac{p(1-p)}{N}$$

정규 근사:

- N이 충분히 크고 p가 0,1에 너무 가깝지 않으면
  $$
  \hat\theta \approx \mathcal{N}\left(p,\ \frac{p(1-p)}{N}\right)
  $$

실무에서는 p를 모른다 → $$p \approx \hat\theta$$로 대체.

**신뢰구간**:

$$
\hat\theta \pm z_{1-\alpha/2} \sqrt{\frac{\hat\theta(1-\hat\theta)}{N}}
$$

#### 델타법(Delta Method) 한 줄 요약

좀 더 복잡한 함수형 추정량:

- 예: 두 CTR의 비율, 로그 비율, 전환율의 로그오즈 등

$$
\hat\phi = g(\hat\theta)
$$

델타법:

- $$\hat\theta$$가 정규근사 $$\mathcal{N}(\theta, \sigma^2)$$를 가진다면,
- 1차 테일러 전개로
  $$
  \hat\phi \approx \mathcal{N}(g(\theta),\ [g'(\theta)]^2 \sigma^2)
  $$

예:

- 로그 비율: $$\hat\phi = \log \hat\theta$$
- 그러면
  $$
  g'(\theta) = \frac{1}{\theta}
  $$
  이므로 분산 근사는
  $$
  \mathrm{Var}(\hat\phi) \approx \left(\frac{1}{\theta}\right)^2 \sigma^2
  $$

CTR가 매우 작을 때는

- 원척도(그냥 비율)보다
- **로그 스케일**에서 비교했을 때
  - 분포가 더 대칭에 가깝고
  - 선형 모델링이 안정적인 경우가 많다.

---

## 7. Heavy-tail 분포 — 로그정규·파레토·Lomax

### 7.1 Heavy-tail이란?

**heavy-tail(두꺼운 꼬리)**:

- 직관적으로
  - “**극단적인 큰 값이 꽤 자주 나오는 분포**”.
- 지수 분포보다 꼬리가 천천히 떨어지는 경우를 가리키는 경우가 많다.

정의(한 가지 관점):

- 꼬리확률 $$P(X > x)$$가
  - $$\exp(-cx)$$보다 천천히 감소하거나
  - $$x^{-\alpha}$$ 꼴로 감소하는 경우 등.

이런 분포에서는:

- 평균값, 분산 등 **요약값이 극단값에 매우 민감**하다.
- 샘플 크기를 계속 늘려도
  - **평균이 안정되는데 매우 긴 시간이 걸린다.**

### 7.2 로그정규(Lognormal) 분포

정의:

- $$\log T \sim \mathcal{N}(\mu,\sigma^2)$$이면
- $$T$$는 로그정규 분포라 하고
  $$T \sim \mathrm{Lognormal}(\mu,\sigma^2)$$

PDF:

$$
f_T(t) = \frac{1}{t\sigma\sqrt{2\pi}}
\exp\left(-\frac{(\log t - \mu)^2}{2\sigma^2}\right),\quad t>0
$$

중요한 요약값:

- 평균  
  $$
  E[T] = \exp\left(\mu + \frac{\sigma^2}{2}\right)
  $$
- 중앙값  
  $$
  \mathrm{med}(T) = \exp(\mu)
  $$
- 모드(최빈값)  
  $$
  \mathrm{mode}(T) = \exp(\mu - \sigma^2)
  $$

즉,

- $$\sigma^2$$가 커질수록
  - **mean > median > mode**의 간격이 크게 벌어진다.
- “평균 60초”라고 해도
  - **대부분의 사용자는 60초보다 훨씬 짧게 머무르지만**
  - 극단적으로 오래 머무는 극소수 때문에 평균이 끌려 올라가는 상황이 흔하다.

### 7.3 파레토(Pareto)·Lomax 분포

파레토 분포(가장 단순한 heavy-tail 모형):

- $$X \sim \mathrm{Pareto}(x_m, \alpha)$$, x ≥ x_m > 0
- PDF:
  $$
  f_X(x) = \alpha x_m^{\alpha} x^{-(\alpha+1)},\quad x \ge x_m
  $$
- 꼬리확률:
  $$
  P(X > x) = \left(\frac{x_m}{x}\right)^{\alpha}
  $$

모멘트 존재 여부:

- $$\alpha \le 1$$ → 평균도 무한
- $$1 < \alpha \le 2$$ → 평균은 유한, 분산은 무한
- $$\alpha > 2$$ → 평균·분산 모두 유한

**Lomax(파레토 Type II)**:

- 파레토를 x≥0부터 시작하도록 옮긴 버전.
- 대기시간, 수명 데이터에서 자주 쓰인다.

실무 해석:

- 파레토 계열처럼 **아주 긴 꼬리**를 가진 분포에서는
  - 분산이 아예 **무한하거나 거의 무한에 가까운 수준**일 수 있다.
  - 이런 경우 CLT의 가정 (분산 유한)이 깨지므로
    - 평균의 정규근사가 **잘 성립하지 않는다**.
  - 합이나 평균은 정규가 아니라 **안정분포(Stable distribution)** 류로 수렴하는 것이 더 적절한 모델이 된다.

### 7.4 실무 증상 — Heavy-tail을 의심해야 할 때

대략 다음과 같은 현상이 보이면 heavy-tail 후보를 의심해야 한다.

1. **일별 평균**이
   - 하루는 60초,
   - 다음날은 110초,
   - 그 다음날은 65초...
   - 식으로 **불규칙하게 튀는데**,
   - 일별 사용자 수는 늘 **수만 명 이상**이다.
2. **상위 1% 사용자의 체류시간 합**이
   - 총 체류시간의 엄청난 비율(예: 30~50%)을 차지한다.
3. 히스토그램을 그려보면
   - 대부분 값은 0~2분 사이 몰려 있지만,
   - x축을 길게 늘리면 1시간 이상, 몇 시간짜리 세션이 수두룩하다.

이럴 때

- “평균 120초, 표준편차 300초”만 보고 의사결정을 하면
  - **대부분의 사용자 경험**을 완전히 왜곡하게 된다.

### 7.5 대안 리포팅

Heavy-tail 의심 상황에서 권장되는 리포팅 방식:

1. **중앙값·IQR(사분위 범위)**:
   - “중앙값 45초, IQR=[18, 120]”
2. **상위 분위(90p, 95p, 99p)**:
   - “95p 280초, 99p 1200초”
3. **로그척도(log1p) 요약값**:
   - log1p(체류시간)에 대한 평균·표준편차 제시
4. **분포형태 요약**:
   - “로그정규 추정 μ,σ”
   - 또는 파레토/Lomax tail index 추정 결과

이런 요약들이 함께 있으면,

- PM/디자이너/운영자는
  - “**대부분 사용자에게는 어떤 경험인지**”
  - “**극단적인 몇몇 사용자가 시스템에 어떤 부담을 주는지**”
  를 한눈에 볼 수 있다.

---

## 8. 통합 사례 — 지수 vs 감마 vs 로그정규, 그리고 정규근사

### 8.1 예제 1 — 체류시간: 지수 vs 감마 vs 로그정규 비교

#### 설정

평균이 대략 비슷한 세 가지 시나리오를 비교한다.

- 시나리오 A (지수):
  - $$T_A \sim \mathrm{Exp}(\lambda = 1/60)$$  
    (평균 60초)
- 시나리오 B (감마):
  - $$T_B \sim \mathrm{Gamma}(k=3, \theta=20)$$  
    (평균 3×20=60초, 변동성 감소)
- 시나리오 C (로그정규):
  - $$T_C \sim \mathrm{Lognormal}(\mu=3.8, \sigma=1.0)$$  
    평균:
    $$
    E[T_C] = \exp(3.8 + 0.5) = \exp(4.3) \approx 73.7\text{초}
    $$

#### 지수(시나리오 A)의 분위수

$$
q_{0.95} = F^{-1}(0.95)
= -\frac{1}{\lambda} \ln(1-0.95)
= 60 \cdot (-\ln 0.05) \approx 179.2\text{초}
$$

- 평균 60초이어도
  - 상위 5% 사용자는 3분 가까이 머무른다.

#### 감마(k=3, θ=20)의 분위수

감마의 95p는 닫힌형이 없으므로 수치적으로 구한다(시뮬레이션이나 수치적분).

- 일반적으로 **지수보다 꼬리가 짧다**.
- 이유: k>1인 감마는
  - 초반 hazard가 증가하는 형태 → 매우 긴 체류시간이 나올 확률이 줄어든다.

#### 로그정규(시나리오 C)의 꼬리

로그정규(μ=3.8, σ=1.0):

- 중앙값: exp(3.8) ≈ 44.7초
- 평균: ≈ 73.7초
- 95p:
  $$
  q_{0.95} = \exp(\mu + \sigma z_{0.95})
  \approx \exp(3.8 + 1.0 \cdot 1.645)
  = \exp(5.445) \approx 231.5\text{초}
  $$

비교:

- A(지수): 평균=60, 95p≈179
- B(감마): 평균=60, 95p < 179 (더 짧음)
- C(로그정규): 평균≈74, 95p≈232 (가장 길다)

즉, **평균만 보면 A/B/C를 구분할 수 없거나 오히려 C가 좋아 보이지만**,  
**95p를 보면 C가 가장 긴 꼬리를 가진다는 것**을 알 수 있다.

#### Python 시뮬레이션 코드

```python
import random, math, statistics

def exp_sample(lam):
    u = random.random()
    return -math.log(1-u)/lam

def gamma_erlang_sample(k, theta):
    # k는 정수라고 가정 (Erlang)
    lam = 1.0/theta
    return sum(exp_sample(lam) for _ in range(k))

def lognorm_sample(mu, sigma):
    z = random.gauss(0,1)
    return math.exp(mu + sigma*z)

def summary(draw_fn, n=200000):
    xs = [draw_fn() for _ in range(n)]
    xs.sort()
    def q(p):
        return xs[int(p*n)]
    return {
        "mean": statistics.mean(xs),
        "std": statistics.pstdev(xs),
        "q50": q(0.5),
        "q90": q(0.9),
        "q95": q(0.95),
        "q99": q(0.99),
    }

if __name__ == "__main__":
    A = summary(lambda: exp_sample(1/60))
    B = summary(lambda: gamma_erlang_sample(3, 20))
    C = summary(lambda: lognorm_sample(3.8, 1.0))
    print("Exp:", A)
    print("Gamma:", B)
    print("Lognorm:", C)
```

보고시:

- “평균 60초”로만 보고하는 대신
- “Exp: 95p 180초, Gamma: 150초, Lognormal: 230초”처럼 비교하면
  - **꼬리의 차이**가 선명해진다.

### 8.2 예제 2 — 일별 평균 체류시간의 정규 근사 검증

#### 설정

- 팀 A: 사용자 50,000명, 로그정규(μ=3.8, σ=0.9)
- 팀 B: 사용자 50,000명, 로그정규(μ=3.85, σ=0.9)

각 팀의 일별 평균을

$$
\bar T_A,\ \bar T_B
$$

라고 하자.

CLT 관점:

- 사용자 수가 매우 크므로
  - $$\bar T_A, \bar T_B$$는 상당히 정규에 가까워진다.
- 하지만
  - σ가 큰 로그정규면
  - **일별 평균의 분산 자체가 매우 크고**
  - n이 커도 생각보다 늦게 안정된다.

#### 시뮬레이션 코드 (일별 평균 분포 보기)

```python
import random, math, statistics

def lognorm_sample(mu, sigma):
    return math.exp(random.gauss(mu, sigma))

def daily_mean(mu, sigma, n_users=50000):
    xs = [lognorm_sample(mu, sigma) for _ in range(n_users)]
    return statistics.mean(xs)

def simulate_days(mu, sigma, n_users=50000, days=365):
    means = [daily_mean(mu, sigma, n_users) for _ in range(days)]
    means.sort()
    def q(p):
        return means[int(p*days)]
    return {
        "mean_of_means": statistics.mean(means),
        "std_of_means": statistics.pstdev(means),
        "q5": q(0.05),
        "q50": q(0.5),
        "q95": q(0.95),
    }

if __name__ == "__main__":
    A = simulate_days(3.8, 0.9)
    B = simulate_days(3.85, 0.9)
    print("Team A daily mean stats:", A)
    print("Team B daily mean stats:", B)
```

- 팀 B의 평균은 팀 A보다 약간 크지만,
- **일별 변동성**이 워낙 크면
  - 두 팀의 **일별 평균 시계열만 보고는 차이를 구분하기 어렵다.**
- 이럴 때는
  - **t-검정, 부트스트랩** 등으로
  - 장기간 평균의 신뢰구간을 직접 계산해 비교하는 것이 필요하다.

### 8.3 예제 3 — 카이제곱과 분산 CI

정규 모집단으로 가정되는 품질 측정 데이터:

- 하루에 50개 샘플을 뽑아 어떤 품질 지표 X를 측정,
- X가 대략 정규라고 알려져 있다고 하자.

표본분산 $$S^2$$을 이용해 σ²의 신뢰구간을 만들고 싶다.

Python 예:

```python
import random, statistics
from math import sqrt
from statistics import mean, pstdev

# 가상의 정규모집단
TRUE_SIGMA = 2.0
TRUE_MU = 10.0

def sample_normal(mu, sigma, n=50):
    return [random.gauss(mu, sigma) for _ in range(n)]

def chi_square_var_ci(xs, alpha=0.05):
    import mpmath as mp  # mpmath를 쓴다고 가정
    n = len(xs)
    s2 = statistics.pvariance(xs)
    df = n - 1
    # 카이제곱 분위수 (역 CDF)
    chi2_lower = mp.gammaincinv(df/2, 1 - alpha/2) * 2
    chi2_upper = mp.gammaincinv(df/2, alpha/2) * 2
    lower = (df * s2) / chi2_lower
    upper = (df * s2) / chi2_upper
    return lower, upper

# 실제 실행 환경에서 mpmath 설치 필요
```

실무에서는:

- 정규성에 대한 확신이 충분하지 않다면
  - 이 카이제곱 CI 대신
  - **부트스트랩으로 분산 CI**를 구해 함께 제시하는 것이 좋다.

### 8.4 예제 4 — 지수/감마로 “재방문까지의 시간” 모델

#### D1 리텐션과 대기시간

D1 리텐션은 단순히 “다음날 다시 오는 비율”이지만,

- 실제로는 “**재방문까지의 시간**”을 가진 연속 변수다.

푸시 정책에 따라:

- 하루 1회 푸시:  
  $$\lambda_A = 1/36\text{ h}^{-1}$$
- 하루 2회 푸시:  
  $$\lambda_B = 1/24\text{ h}^{-1}$$

단순하게 지수 모델로 가정하면,

- 24시간 이내 재방문 확률:
  $$
  P(T \le 24) = 1 - e^{-\lambda \cdot 24}
  $$

정책 A vs B 비교:

- A:
  $$
  1 - e^{-(1/36)\cdot 24} = 1 - e^{-2/3}
  $$
- B:
  $$
  1 - e^{-(1/24)\cdot 24} = 1 - e^{-1}
  $$

B가 이론상 더 크다.  
그러나 현실에서는:

- 너무 자주 푸시를 보내면 사용자가 싫어하여
  - 실제 λ가 **오히려 감소**할 수 있다.
- 이런 현상까지 포함하려면
  - λ를 “푸시 빈도의 함수”로 잡고
  - 실험으로 λ를 추정해야 한다.

보다 정교하게는

- “열어보는 데까지의 시간 (T₁)”,
- “열어본 후 다시 돌아오는 시간 (T₂)”,
- “주기적으로 돌아오는 시간 (T₃)” 등
- 여러 단계를 감마/Erlang 모형으로 묶어볼 수 있다.

---

## 9. 정규성 진단 — “검정”보다 “그림+요약치”

### 9.1 QQ-plot 사고법

정규성 진단에서 가장 직관적인 도구가 **QQ-plot**이다.

- x축: 이론적 정규분포의 분위수
- y축: 데이터의 분위수

특징:

- 점들이 거의 직선에 있으면
  - 정규 근사가 양호.
- 상위 꼬리가 위로 휘면 heavy-tail,
- 하위 꼬리가 아래로 휘면 왼쪽 꼬리가 두꺼운 경우.

### 9.2 Shapiro–Wilk, Anderson–Darling 등 검정

통계적 정규성 검정들:

- Shapiro–Wilk
- Anderson–Darling
- Kolmogorov–Smirnov 등

문제:

- 표본이 크면
  - **사소한 일탈**에도 p-value가 극단적으로 작게 나온다.
- “p < 0.001 → 정규 아님”이라고 해도,
  - 실무 관점에서는 충분히 정규 근사를 써도 되는 경우가 많다.

따라서:

- 검정 결과는
  - “**심각한 왜곡이 있는지**”를 보는 참고자료 정도로 사용.
- 의사결정에는
  - QQ-plot,
  - 분위수 리포팅,
  - 정규 근사 사용/비사용에 따른 **민감도 분석**이 더 중요하다.

### 9.3 Python으로 QQ-plot 그리기 예시

```python
import numpy as np
import scipy.stats as st
import matplotlib.pyplot as plt

def qq_plot(data, title="QQ-plot"):
    osm, osr = st.probplot(data, dist="norm", plot=None)
    theoretical_q = osm[0]
    sample_q = osr
    plt.scatter(theoretical_q, sample_q, s=5)
    # 대각선
    min_val = min(min(theoretical_q), min(sample_q))
    max_val = max(max(theoretical_q), max(sample_q))
    plt.plot([min_val, max_val], [min_val, max_val])
    plt.xlabel("Theoretical Quantiles (Normal)")
    plt.ylabel("Sample Quantiles")
    plt.title(title)
    plt.show()

# 로그정규 샘플에 대한 QQ-plot 예시
if __name__ == "__main__":
    rng = np.random.default_rng(0)
    lognorm_sample = np.exp(rng.normal(3.8, 1.0, size=10000))
    qq_plot(lognorm_sample, title="Lognormal vs Normal QQ-plot")
```

- 로그정규 데이터에 대해 이 QQ-plot을 그리면
  - 양쪽 꼬리가 크게 휘는 형태를 볼 수 있다.
- 같은 데이터의 로그를 취해
  - `np.log(lognorm_sample)`으로 QQ-plot을 그리면
  - 매우 직선에 가까워진다 → “로그정규”라는 이름의 이유.

---

## 10. 변환 — log1p와 Box–Cox

### 10.1 log1p 변환의 실무성

체류시간, 금액 데이터에는 **0이 포함되는 경우**가 많다.

- 예:
  - “즉시 이탈(0초)”,
  - “무료 사용(금액 0)” 등.

로그 변환을 직접 쓰면:

- $$\log 0$$는 정의되지 않는다.

그래서 자주 쓰는 것이:

$$
\mathrm{log1p}(x) = \log(1+x)
$$

특징:

- x=0 → log1p(0)=0
- x가 커지면
  - log1p(x) ≈ log(x)

실무 사용법:

1. 원데이터 X에 대해 Y=log1p(X)를 만든다.
2. Y에 대해
   - 정규성 진단,
   - 선형 회귀,
   - 분산 분석을 수행한다.
3. 결과를 해석할 때는
   - 다시 원척도(X)로 역변환하여 설명한다.

### 10.2 Box–Cox 변환

Box–Cox 변환:

$$
g_\lambda(x) =
\begin{cases}
\dfrac{x^\lambda - 1}{\lambda}, & \lambda \ne 0 \\
\log x, & \lambda = 0
\end{cases}
$$

특징:

- λ 파라미터를 데이터에서 추정하여
  - 변환된 데이터가 **가장 정규에 가깝도록** 만든다.
- x>0이어야 하므로,
  - 0이 많으면 **shift + Box–Cox** 등을 고려해야 한다.

실무 팁:

- Box–Cox를 적용한 뒤에도
  - QQ-plot, 분위수 등을 꼭 확인.
- 변환 후 모델의 결과를
  - “**원척도**로 어떻게 보여줄지”를 미리 생각해야 한다.
  - 예: 예측값에 역변환 적용, 신뢰구간 역변환 등.

---

## 11. 실무 리포트 템플릿(연속형 지표)

다음은 heavy-tail 가능성이 있는 연속 지표의 권장 보고 템플릿 예시다.

### 11.1 체류시간 보고 예

> 체류시간 T (초 단위)
> - 중앙값: 45s  
> - IQR: [18s, 120s]  
> - 95p: 280s  
> - log1p(T)의 평균·표준편차: 3.5 ± 0.7  
> - 평균: 68s (heavy-tail 특성으로 인해 극단값에 민감)

설명:

- 중앙값/IQR: “**전형적인 사용자**”의 경험
- 95p: SLA, UX 상위 사용자 관리를 위한 지표
- log1p 평균·표준편차: 모델링·통계 분석에 사용하는 스케일
- 평균: **참고용** (heavy-tail 경고와 함께)

### 11.2 대기시간(알림 응답) 보고 예

> 알림 후 첫 클릭까지 대기시간 T
> - 감마(k=2.7, θ=22s)로 추정  
> - 평균: 59s  
> - 90p: 110s  
> - hazard: 시간 경과에 따라 감소(초반에 안 누르면 이후 누를 확률 빠르게 감소)

여기서:

- 감마 파라미터 k, θ는
  - 최대우도추정(MLE) 등으로 얻은 값.
- hazard 형태가 증가형/감소형인지에 따라
  - “훈련형(머무를수록 더 오래 남는다)” vs
  - “피로형(처음 반응 없으면 이후 반응 거의 없다)” 등의 해석이 가능하다.

### 11.3 일별 평균(집계 지표) 보고 예

> 일별 평균 체류시간 비교 (실험군 B vs 대조군 A)
> - 추정 차이: +3.2s  
> - 95% t-신뢰구간: [+1.5s, +4.9s]  
> - 부트스트랩 CI 유사 (±0.2s 수준 차이)  
> - heavy-tail 특성으로 인해 상위 1% 세션의 영향이 큼 → 위 결과는 이러한 꼬리까지 포함한 차이를 반영

---

## 12. 체크리스트 — 연속분포·정규세계 사용 전 점검

정리 차원에서, 모델링·리포팅·추론 전에 확인해야 할 체크리스트를 모아보면:

1. **데이터 타입 확인**
   - 시간/양수형(체류시간, 대기시간, 금액)이면
     - 지수·감마·로그정규·파레토·Lomax 후보를 먼저 본다.
2. **기억 없음 가정**
   - “기다린 시간과 상관없이 앞으로 남은 시간이 같다”라고 말할 수 있는가?
     - 그렇다면 지수 모델이 합리적.
     - 아니라면 감마/로그정규/파레토 등으로 넘어간다.
3. **단계 합성 여부**
   - 여러 단계(읽기→고민→전환)가 겹쳐진 대기시간이라면
     - 감마(Erlang) 모델이 자연스럽다.
4. **꼬리 진단**
   - 히스토그램, 로그-로그 플롯, QQ-plot으로
     - 꼬리가 지수보다 두껍게 보이는지 확인.
5. **리포팅 관행 점검**
   - “평균·표준편차”만 보고하지 말고
     - 중앙값, IQR, 상위 분위(90p, 95p, 99p)를 기본으로 포함.
6. **정규근사 적용 범위**
   - 합/평균 같은 집계 지표에만 정규근사를 쓸 것.
   - **개별 데이터**의 분포를 정규로 가정하는 것은 전혀 다른 이야기다.
7. **분산·신뢰구간 추론**
   - 정규 가정에 기반한 χ², t-분포 CI를 쓸 때
     - 정규성 위배 가능성이 크면
     - 부트스트랩 CI를 병행해 결과의 민감도를 확인.
8. **변환 활용**
   - 로그 변환(log, log1p)이나 Box–Cox 변환을 사용해
     - 분포를 대칭에 가깝게 만들고,
     - 그 위에서 정규 기반 기법을 쓰는 전략을 적극적으로 고려.
9. **모형의 해석 가능성**
   - 변환된 공간에서 얻은 결과를
     - 실제 의사결정 언어(초, 원, 회수 등)로 어떻게 다시 번역할지까지 계획.
10. **카이제곱 검정 요건**
    - 기대빈도, 자유도 계산, 카이제곱 근사의 적절성을 항상 명확히 해 둘 것.

---

## 13. 연습문제와 풀이 스케치

### [1] 지수 분포의 중앙값 vs 평균

**문제**

- $$T \sim \mathrm{Exp}(\lambda)$$에서
  - 중앙값과 평균의 관계를 구하고,
  - 어떤 의미를 가지는지 설명하라.

**풀이 스케치**

1. 중앙값 m은
   $$
   P(T \le m) = 0.5
   $$
   를 만족.
2. CDF:
   $$
   F_T(t) = 1 - e^{-\lambda t}
   $$
   이므로
   $$
   1 - e^{-\lambda m} = 0.5
   \Rightarrow e^{-\lambda m} = 0.5
   \Rightarrow m = \frac{\ln 2}{\lambda}
   $$
3. 평균은
   $$
   E[T] = \frac{1}{\lambda}
   $$
4. 따라서
   $$
   \mathrm{med}(T) = (\ln 2)\cdot E[T] \approx 0.693 \cdot E[T]
   $$

의미:

- 지수 분포에서는
  - 평균보다 **중앙값이 항상 작다**.
- 사용자 대기시간이 지수라고 가정하면
  - “평균 10초”라고 할 때,
  - 절반 이상의 사용자는 6.93초 이내에 응답한다.

---

### [2] Erlang 대기시간의 평균·분산

**문제**

- 포아송율 λ=0.1/s (10초에 평균 1건 발생).
- 3번째 이벤트까지 대기시간 T의 평균·분산을 구하라.

**풀이 스케치**

1. 포아송 과정에서
   - k번째 사건까지 대기시간은
     $$T \sim \mathrm{Gamma}(k, \theta=1/\lambda)$$
2. 여기서는
   - k=3,
   - λ=0.1,
   - θ=1/λ = 10.
3. 평균:
   $$
   E[T] = k\theta = 3 \times 10 = 30\text{초}
   $$
4. 분산:
   $$
   \mathrm{Var}(T) = k\theta^2 = 3 \times 10^2 = 300\text{초}^2
   $$

---

### [3] heavy-tail 리포팅 전략

**문제**

- 로그정규(μ=3.5, σ=1.1) 체류시간 T에 대해
  - 평균, 중앙값, 95p를 개념적으로 비교하고,
  - 어떤 지표들을 리포트할지 제안하라.

**풀이 스케치**

1. 중앙값:
   $$
   \mathrm{med}(T) = \exp(\mu) = \exp(3.5)
   $$
2. 평균:
   $$
   E[T] = \exp\left(\mu + \frac{\sigma^2}{2}\right)
   = \exp\left(3.5 + \frac{1.21}{2}\right)
   = \exp(4.105)
   $$
3. 95p:
   $$
   q_{0.95} = \exp(\mu + \sigma z_{0.95})
   = \exp(3.5 + 1.1 \cdot 1.645)
   $$
   - 중앙값보다 훨씬 크다.
4. 관계:
   - mean > median,
   - 95p ≫ median.
   - σ가 크므로 이 차이가 극적으로 벌어진다.
5. 리포팅 제안:
   - “중앙값, IQR, 90p/95p”를 기본으로 보고
   - 평균은 “heavy-tail로 인해 극단값에 민감”하다는 경고와 함께 참고용으로만 보여준다.
   - 필요하다면 log1p(T)에 대한 평균·표준편차도 함께 제공.

---

### [4] 파레토에서 CLT 한계

**문제**

- 파레토 분포의 모수 α가 2 이하일 때
  - 평균의 정규근사가 왜 깨지는지 설명하라.

**풀이 스케치**

1. 파레토(α≤2)에서는
   - α≤1: 평균 무한
   - 1<α≤2: 평균은 유한, 분산은 무한
2. CLT의 기본 가정:
   - 분산 σ²가 유한해야 한다.
3. 분산이 무한하면
   - 표본평균의 스케일이
     - √n이 아니라
     - n^{1/α} 등의 다른 스케일로 성장한다.
   - 따라서
     - 정규분포가 아니라
     - **안정분포(Levy α-stable)** 같은 다른 한계분포로 수렴하게 된다.
4. 결과적으로
   - “평균 ± 1.96·표준오차” 같은 정규 기반 신뢰구간은
     - 이론적 근거가 없고
     - 실무적으로도 엉뚱한 값을 줄 수 있다.

---

## 14. TL;DR — 요약

- **균등**:
  - “추가 정보가 없다”는 것을 수학적으로 표현하는 기본 모형.
- **지수**:
  - 포아송 과정의 사건 간 간격,
  - **기억 없음**으로 특징지어지는 간단한 대기시간 모형.
- **감마(Erlang)**:
  - 지수의 합,
  - k단계 퍼널, 누적 대기시간, hazard 형태 변화를 표현하는 데 유용.
- **카이제곱(χ²)**:
  - 정규제곱의 합 = 감마(ν/2, 2),
  - 분산 추정, 회귀, 적합도 검정의 기본 구성요소.
- **정규**:
  - 합/평균의 자연스러운 한계 분포(중심극한정리),
  - 그러나 **분산 유한·꼬리 온건**이라는 조건이 있다.
- **Heavy-tail (로그정규·파레토 등)**:
  - 체류시간, 금액, 트래픽, 사용자 활동량 등에서 흔하다.
  - 평균·표준편차만으론 극단값과 꼬리를 숨긴다.
- **실무 리포팅**:
  - 항상 **중앙값, IQR, 상위 분위(90p/95p/99p)**를 함께 보고
  - 필요하면 **로그척도 요약값**과 **분포형태(로그정규/감마)**를 병기하라.
  - 집계 지표의 정규근사는
    - **합/평균**에서만 조심스럽게 쓰고,
    - heavy-tail에서는 부트스트랩·변환 기반 분석을 병행하라.