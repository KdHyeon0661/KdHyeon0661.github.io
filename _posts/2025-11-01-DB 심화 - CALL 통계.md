---
layout: post
title: DB 심화 - CALL 통계
date: 2025-11-01 16:25:23 +0900
category: DB 심화
---
# Oracle CALL 통계 해석과 튜닝

> **핵심 요약**
> Oracle의 **CALL 통계**는 SQL 실행의 **Parse/Execute/Fetch** 각 단계별로 **CPU/경과시간/디스크 I/O/논리적 읽기/처리 행 수**를 정량화한 표입니다. TKPROF나 SQL Trace를 통해 이 표를 읽을 수 있으면, 성능 병목의 정확한 위치(파싱 과다, 인덱스 미사용, 랜덤 I/O 폭증, 과도한 Fetch 등)를 빠르게 특정하고 해결할 수 있습니다.

---

## CALL 통계란 무엇인가?

### TKPROF의 핵심 출력

SQL Trace로 수집한 원시 트레이스 파일을 TKPROF로 변환하면 아래와 같은 **CALL 통계 표**를 얻을 수 있습니다. 이 표는 SQL 실행의 생명주기를 세 단계로 나누고, 각 단계별 자원 소모를 측정합니다.

```
call     count  cpu     elapsed     disk    query   current  rows
------- ------ -------  --------  -------  -------  -------  ----
Parse        1   0.03      0.05        0        2        0     0
Execute      1   0.12      0.20      120    10500      130     1
Fetch       10   0.09      0.15       10     9500       20   100
```

**행(단계)**
- **Parse**: SQL 문장을 파싱(하드 또는 소프트), 권한 검사, 실행 계획 생성 및 최적화, 커서 확보.
- **Execute**: SQL을 실행. DML(INSERT/UPDATE/DELETE)의 경우 실제 데이터 변경이 발생하며, SELECT의 경우 서버가 실행 계획에 따라 데이터 스캔과 조인을 시작합니다.
- **Fetch**: SELECT 문의 결과를 클라이언트 애플리케이션으로 전송하는 단계. 여러 번의 배치 단위로 수행될 수 있습니다.

**열(지표)**
- **count**: 해당 단계가 수행된 횟수.
- **cpu**: CPU를 사용한 시간(초).
- **elapsed**: 총 경과 시간(초). 대기 시간을 포함합니다.
- **disk**: 디스크에서 발생한 물리적 읽기 블록 수.
- **query**: 일관된 읽기 모드(Consistent Read, CR)에서 발생한 논리적 읽기 블록 수. 주로 SELECT용.
- **current**: 현재 모드(Current Mode)에서 발생한 논리적 읽기 블록 수. 주로 DML용.
- **rows**: 해당 단계에서 처리되거나 반환된 행의 수.

> **핵심 포인트**
> - SELECT 문의 경우, 실제 데이터 스캔은 `Execute` 단계에서 시작되지만, 클라이언트로의 결과 전송은 `Fetch` 단계에서 이루어집니다.
> - `Fetch`의 **배치 크기**(array size)가 작으면 `Fetch count`가 불필요하게 많아져 `elapsed`와 `CPU` 시간이 크게 증가할 수 있습니다.

---

## 각 지표 해석법: 높은 수치가 시사하는 문제

| 지표 | 의미 | 수치가 높을 때의 해석과 대응 방향 |
|---|---|---|
| **count** | 단계 호출 횟수 | **Parse**: 커서 재사용 부족, 바인드 변수 미사용. **Fetch**: Fetch Array Size가 너무 작음. |
| **cpu** | CPU 사용 시간 | **Parse**: 하드 파싱, 복잡한 최적화. **Execute/Fetch**: 대량 조인/정렬/함수 처리. |
| **elapsed** | 총 응답 시간 | CPU 시간 대비 크다면 대기(디스크 I/O, 락/래치, 네트워크)가 많다는 신호. |
| **disk** | 물리적 읽기 | 버퍼 캐시 적중률 낮음, 인덱스 미사용 또는 대량 테이블 풀 스캔. |
| **query** | CR 모드 논리적 읽기 | 읽기 작업량. 과다하면 불필요한 테이블/인덱스 스캔이나 비효율적인 조인 순서 가능성. |
| **current** | Current 모드 논리적 읽기 | DML 작업량. 비효율적인 인덱스 설계나 과도한 커밋, 체크포인트 영향 가능성. |
| **rows** | 처리/반환 행 수 | **SELECT**: `Fetch rows` 합계가 최종 반환 건수. **DML**: `Execute rows`가 실제 변경 건수. |

**추가 진단 정보**
TKPROF 출력에는 `misses in library cache during parse` 같은 추가 정보가 포함될 수 있습니다. 이 값이 높으면 하드 파싱이 빈번히 발생하고 있음을 의미합니다.

---

## 실습: SQL Trace와 TKPROF로 CALL 통계 수집하기

### 1. 세션 트레이스 활성화

```sql
-- 정확한 통계 수준 설정
ALTER SESSION SET statistics_level = ALL;

-- 레벨 8 트레이스 시작 (바인드 변수 값은 제외, 대기 이벤트 포함)
ALTER SESSION SET events '10046 trace name context forever, level 8';
```

### 2. 테스트 워크로드 실행

```sql
-- 샘플 테이블 생성
DROP TABLE t_call PURGE;
CREATE TABLE t_call AS
SELECT level AS id,
       CASE MOD(level,3) WHEN 0 THEN 'APAC' WHEN 1 THEN 'EMEA' ELSE 'AMER' END region,
       TRUNC(SYSDATE) - MOD(level, 1000) AS dte,
       ROUND(DBMS_RANDOM.VALUE(10, 1000), 2) amt
FROM dual CONNECT BY level <= 1000000;

CREATE INDEX ix_call_region_dte ON t_call(region, dte);
BEGIN
  DBMS_STATS.GATHER_TABLE_STATS(USER,'T_CALL',cascade=>TRUE,
    method_opt=>'FOR COLUMNS SIZE 75 region SIZE 1 dte');
END;
/

-- 바인드 변수를 사용한 쿼리 실행 (의도적인 여러 호출)
VAR rgn VARCHAR2(10);
EXEC :rgn := 'APAC';

SELECT /* call-demo */ SUM(amt)
FROM   t_call
WHERE  region = :rgn
AND    dte >= TRUNC(SYSDATE) - 30
AND    dte <  TRUNC(SYSDATE);

-- 커서 공유를 테스트하기 위한 반복 실행 (의도적 예시)
DECLARE
  l_dummy NUMBER;
BEGIN
  FOR i IN 1..100 LOOP
    EXECUTE IMMEDIATE
      'SELECT /* call-demo */ COUNT(*) FROM t_call WHERE region=:b AND dte>=TRUNC(SYSDATE)-30 AND dte<TRUNC(SYSDATE)'
    INTO l_dummy
    USING 'APAC';
  END LOOP;
END;
/
```

### 3. 트레이스 종료 및 파일 위치 확인

```sql
ALTER SESSION SET events '10046 trace name context off';

-- 트레이스 파일 위치 확인 (관리자 권한 필요 시)
SELECT value FROM v$diag_info WHERE name = 'Default Trace File';
```

### 4. TKPROF로 변환 (OS 쉘에서 실행)

```bash
tkprof /u01/app/oracle/diag/.../trace/your_sid_ora_12345.trc call_stats.out sys=no sort=exeela,fchela
```

- **`sort=exeela,fchela`**: Execute와 Fetch 단계의 경과 시간(elapsed) 기준으로 정렬합니다.
- **`sys=no`**: SYS 사용자가 실행한 SQL을 제외하여 분석에 방해되는 노이즈를 줄입니다.

---

## CALL 통계 해석: 실제 문제 진단 케이스

### 케이스 1: 하드 파싱 과다

```
call     count  cpu   elapsed  disk  query current rows
Parse     1000  0.90    1.50     0      50       0    0
Execute   1000  0.20    0.30     0     500      10    0
Fetch     1000  0.10    0.20     0     300       5 1000
misses in library cache during parse: 1000
```

**진단**
- `Parse count`와 `misses in library cache during parse`가 모두 높습니다.
- 동일한 SQL이 매번 새로 파싱되고 있습니다(하드 파싱).

**원인**
- 애플리케이션에서 바인드 변수를 사용하지 않고 리터럴 값을 직접 SQL 텍스트에 삽입.
- SQL 문장이 실행될 때마다 미묘하게 변경됨(주석, 공백, 힌트 등).
- 세션 설정(NLS 파라미터 등)이 달라 커서를 공유할 수 없음.

**해결 방안**
- 애플리케이션 코드를 수정하여 **바인드 변수**를 필수적으로 사용하도록 합니다.
- SQL 템플릿을 표준화하여 문장 자체의 변화를 제거합니다.
- `SESSION_CACHED_CURSORS` 파라미터 값을 증가시키고, 클라이언트 드라이버의 Statement Caching 기능을 활성화합니다.

### 케이스 2: 비효율적 실행 계획으로 인한 I/O 폭증

```
call     count  cpu   elapsed  disk    query current rows
Parse        1  0.01     0.02     0        2       0    0
Execute      1  1.20     3.50 50000   120000    3000    1
Fetch       10  0.10     0.40    50    20000      50  100
```

**진단**
- `Execute` 단계의 `disk`(물리 읽기)와 `query`(논리 읽기)가 매우 큽니다.
- 적은 수의 행(100행)을 가져오기 위해 과도한 I/O가 발생하고 있습니다.

**원인**
- 적절한 인덱스를 사용하지 않은 풀 테이블 스캔.
- 잘못된 조인 순서 또는 조인 방법.
- 통계 정보가 부정확하거나 히스토그램이 없어 옵티마이저가 잘못된 카디널리티 예측.

**해결 방안**
- WHERE 절과 JOIN 조건에 사용된 컬럼에 적합한 **인덱스를 생성 또는 수정**합니다.
- **DBMS_STATS**를 이용해 최신의 정확한 통계 정보와 컬럼 히스토그램을 수집합니다.
- 필요하다면 **SQL 프로파일**, **SQL 플랜 관리자(SPM)**, **SQL 베이스라인**을 사용하여 안정적인 최적의 실행 계획을 고정시킵니다.

### 케이스 3: 작은 Fetch Array Size로 인한 네트워크 오버헤드

```
call     count  cpu   elapsed  disk query current rows
Parse        1  0.00     0.00     0     2       0    0
Execute      1  0.05     0.10    10  1500      10    0
Fetch     1000  0.40     1.80   100 50000     500 10000
```

**진단**
- `Fetch count`가 결과 행 수(`rows`)에 비해 극단적으로 많습니다(1000번 Fetch로 10000행).
- `Fetch` 단계의 `elapsed` 시간이 `Execute`보다 훨씬 깁니다.

**원인**
- 클라이언트 드라이버의 기본 Fetch Array Size가 너무 작게 설정되어 있습니다(예: 10).
- 많은 행을 가져올 때 네트워크 왕복 횟수가 불필요하게 증가합니다.

**해결 방안**
- 애플리케이션 코드에서 데이터를 가져오기 전에 **Fetch Array Size를 증가**시킵니다. 일반적으로 100 ~ 1000 사이가 좋은 시작점입니다.
- 단, 한 번에 가져오는 데이터 양이 너무 크면 클라이언트 측 메모리 부하를 유발할 수 있으므로 적절한 트레이드오프가 필요합니다.

---

## SELECT와 DML의 CALL 통계 차이

CALL 통계를 해석할 때는 SQL의 유형에 따라 각 단계의 의미가 다르다는 점을 이해해야 합니다.

**SELECT 문**
- **Execute**: 실행 계획을 따라 데이터 소스를 읽기 시작합니다. `rows`는 일반적으로 0입니다.
- **Fetch**: 클라이언트로 결과 행을 전송합니다. 최종 반환된 행 수는 `Fetch rows`의 합계입니다.
- 성능 병목은 `Execute`(실행 계획) 또는 `Fetch`(네트워크/배치 크기) 중 하나에서 발생할 수 있습니다.

**INSERT/UPDATE/DELETE 문**
- **Execute**: 실제 데이터의 삽입, 갱신, 삭제 작업이 발생합니다. 처리된 행 수는 `Execute rows`에 반영됩니다.
- **Fetch**: 일반적으로 존재하지 않거나(`count` 0), `rows`가 0입니다(단, RETURNING INTO 구문 사용 시 예외).
- 성능 병목은 거의 항상 `Execute` 단계에서 발생하며, `current` 모드 읽기와 디스크 I/O가 주요 관찰 대상입니다.

---

## 시스템 뷰와의 연계 분석

CALL 통계의 각 지표는 Oracle 동적 성능 뷰(V$ 뷰)의 통계와 직접적으로 연결되어 있습니다. 이를 통해 세션 또는 시스템 전체의 관점에서 문제를 확인할 수 있습니다.

- **`query`(consistent gets)** ↔ `V$SESSTAT` 내 `'consistent gets'` 통계.
- **`current`(db block gets)** ↔ `V$SESSTAT` 내 `'db block gets'` 통계.
- **`disk`(physical reads)** ↔ `V$SESSTAT` 내 `'physical reads'` 통계.
- **파싱 활동** ↔ `V$SESSTAT` 내 `'parse count (total)'`, `'parse count (hard)'`, `'session cursor cache hits'` 통계.

```sql
-- 현재 세션의 핵심 성능 통계 확인
SELECT sn.name, ss.value
FROM   v$sesstat ss
       JOIN v$statname sn ON sn.statistic# = ss.statistic#
WHERE  ss.sid = SYS_CONTEXT('USERENV', 'SID')
  AND  sn.name IN ('consistent gets',
                   'db block gets',
                   'physical reads',
                   'parse count (total)',
                   'parse count (hard)',
                   'session cursor cache hits');
```

CALL 통계의 `elapsed` 시간 중 대기 부분을 이해하려면 Active Session History(ASH)를 확인하는 것이 필수적입니다.

```sql
-- 최근 15분 동안 내 세션이 경험한 주요 대기 이벤트
SELECT event, COUNT(*) AS wait_count
FROM   v$active_session_history
WHERE  session_id = SYS_CONTEXT('USERENV', 'SID')
  AND  sample_time > SYSDATE - (15/1440) -- 15분 전
GROUP BY event
ORDER BY wait_count DESC;
```

---

## 실전 튜닝 워크플로우: CALL 통계 중심 접근법

1.  **문제 SQL 특정**: AWR 리포트, V$SQL 뷰 등을 통해 응답 시간이 느리거나 자원을 많이 소모하는 SQL을 식별합니다.
2.  **상세 트레이스 수집**: 해당 SQL을 실행하는 세션에 대해 SQL Trace(10046)를 활성화하고 워크로드를 재현한 후 트레이스를 중지합니다.
3.  **TKPROF 변환 및 CALL 통계 분석**: 트레이스 파일을 TKPROF로 변환하여 CALL 통계 표를 확인합니다.
    - **Parse 단계의 `elapsed`와 `cpu`가 높은가?** → 커서 공유 문제, 하드 파싱 의심.
    - **Execute 단계의 `disk`, `query`, `current`가 높은가?** → 비효율적인 실행 계획, 인덱스 문제 의심.
    - **Fetch 단계의 `count`가 높고 `elapsed`가 큰가?** → Fetch Array Size 문제 의심.
4.  **대기 이벤트 확인**: TKPROF 출력 하단의 대기 이벤트 목록이나 ASH 데이터를 확인하여 `elapsed` 시간을 구성하는 주요 대기 원인(`db file sequential read`, `log file sync` 등)을 파악합니다.
5.  **근본 원인 도출 및 해결 실행**:
    - 파싱 문제 → 바인드 변수 적용, 커서 캐시 설정 조정.
    - 실행 계획 문제 → 인덱스 생성/수정, 통계 갱신, 힌트 또는 SQL 프로파일 적용.
    - Fetch 문제 → 클라이언트 애플리케이션의 Fetch Array Size 증가.
6.  **개선 효과 검증**: 변경 사항 적용 후, 동일한 조건에서 다시 트레이스를 수집하고 CALL 통계를 비교하여 개선 효과를 수치적으로 입증합니다.

---

## 언어별 Fetch Array Size 튜닝 가이드

네트워크 왕복 횟수를 줄이고 Fetch 성능을 개선하는 가장 효과적인 방법은 Fetch Array Size(또는 Batch Size)를 적절히 조정하는 것입니다.

**Java (JDBC)**
```java
// Statement 또는 PreparedStatement에 설정
PreparedStatement pstmt = connection.prepareStatement("SELECT ...");
pstmt.setFetchSize(1000); // 기본값은 보통 10. 500~2000 사이로 조정 권장.
ResultSet rs = pstmt.executeQuery();
```

**.NET (ODP.NET)**
```csharp
// OracleCommand 객체에 설정 (바이트 단위)
OracleCommand cmd = new OracleCommand("SELECT ...", connection);
cmd.FetchSize = cmd.RowSize * 500; // 행당 크기를 고려해 약 500행 분량으로 설정.
OracleDataReader reader = cmd.ExecuteReader();
```

**Python (python-oracledb)**
```python
# 커서 객체에 설정
cursor = connection.cursor()
cursor.arraysize = 1000  # 기본값은 100.
cursor.execute("SELECT ...")
for row in cursor:
    process(row)
```

**효과**: 증가된 Array Size는 `Fetch count`를 감소시키고, 네트워크 지연이 큰 환경일수록 `Fetch elapsed` 시간을 획기적으로 단축시킵니다.

---

## 진단의 완성: CALL 통계와 대기 이벤트의 통합 분석

CALL 통계는 **무엇이** 시간을 소비했는지 보여주지만, **왜** 소비되었는지 설명해주지는 않습니다. `elapsed` 시간이 `cpu` 시간보다 훨씬 크다면, 그 차이는 바로 **대기 시간**입니다.

$$ \text{대기 시간 (Wait Time)} \approx \text{Elapsed Time} - \text{CPU Time} $$

TKPROF 출력의 마지막 부분에는 `Elapsed times include waiting on following events:`라는 섹션이 있어, 각 대기 이벤트별로 소요된 시간을 확인할 수 있습니다.

- **`db file sequential read`**: 인덱스를 이용한 랜덤 I/O 대기. 인덱스 조회가 많거나 넓은 범위를 스캔할 때 발생합니다.
- **`db file scattered read`**: 풀 테이블 스캔이나 인덱스 풀 스캔 시 발생하는 멀티블록 I/O 대기.
- **`log file sync`**: 커밋 시 로그 버퍼의 내용을 디스크의 리두 로그 파일에 기록하기를 기다리는 대기.
- **`enq: TX - row lock contention`**: 다른 트랜잭션에 의해 특정 행이 잠겨 있어 발생하는 대기.

이러한 대기 이벤트 정보와 CALL 통계의 I/O 지표(`disk`, `query`, `current`)를 함께 분석하면, 예를 들어 "`Execute`의 `elapsed`가 높은 이유는 `db file sequential read` 대기가 주를 이루고, 이는 `query` 수치가 매우 높기 때문이다"와 같은 구조적인 진단이 가능해집니다.

---

## 종합 예제: 느린 리포트 쿼리 개선 과정

**문제 상황**
매일 아침 실행되는 관리자 리포트 쿼리가 점점 느려져 10분 이상 소요됩니다.

**초기 CALL 통계 (TKPROF)**
```
call     count  cpu   elapsed   disk     query current rows
Parse        1  0.10     0.15       0       100       0    0
Execute      1 25.50   610.20  450000   8500000   15000    1
Fetch      500  2.10    15.50    1000    200000    1000 50000
```
*`Execute`의 `elapsed`가 압도적으로 높고, `disk`와 `query` 논리적 읽기가 매우 큽니다.*

**분석 및 조치**
1.  **실행 계획 확인**: 실행 계획을 확인해보니, 큰 두 테이블의 조인 순서가 잘못되어 비효율적인 네스티드 루프 조인이 발생하고, 결합 인덱스가 누락된 컬럼으로 범위 스캔이 진행되고 있었습니다.
2.  **개선 실행**:
    - 누락된 결합 인덱스를 `(dept_id, status, created_date)` 순서로 생성합니다.
    - 옵티마이저 힌트(`/*+ LEADING(t1 t2) USE_NL(t2) */`)를 사용하여 조인 순서와 방법을 유도합니다.
    - 리포트 툴의 연결 설정에서 Fetch Array Size를 50에서 1000으로 증가시킵니다.

**개선 후 CALL 통계**
```
call     count  cpu   elapsed   disk    query current rows
Parse        1  0.10     0.15       0      100       0    0
Execute      1  1.80     3.50    5000   120000    1000    1
Fetch       50  0.55     1.20     100    20000     100 50000
```
*`Execute`의 `elapsed`가 610초에서 3.5초로 급감했고, I/O(`disk`, `query`)도 크게 줄었습니다. `Fetch count`가 500에서 50으로 줄어 해당 단계의 성능도 개선되었습니다.*

---

## 마무리: CALL 통계 분석의 핵심 가치

Oracle CALL 통계는 SQL 성능 튜닝의 **강력한 현미경**입니다. 단순히 '느리다'는 감정적인 판단을 넘어, **파싱, 실행, 데이터 전송 중 어느 단계에서, 어떤 자원(CPU/I/O)을, 얼마나 소모했는지**를 명확한 수치로 제시합니다.

가장 효과적인 튜닝은 이러한 데이터에 기반합니다.
- `Parse` 비중이 높다면, 커서 공유와 애플리케이션 설계를 점검하세요.
- `Execute`의 I/O가 높다면, 인덱스와 실행 계획에 집중하세요.
- `Fetch` 횟수가 너무 많다면, 클라이언트 애플리케이션의 데이터 접근 방식을 재고하세요.

항상 트레이스 전과 후의 CALL 통계를 비교하여, 당신의 튜닝이 실제로 어떤 수치적 개선을 가져왔는지 측정하십시오. 이것이 과학적이고 지속 가능한 성능 관리의 시작입니다.