---
layout: post
title: DB 심화 - CALL 통계
date: 2025-11-01 16:25:23 +0900
category: DB 심화
---
# CALL 통계(Call Statistics) 완전 가이드

> **핵심 한 줄**
> Oracle의 **CALL 통계**는 한 SQL에 대해 **Parse / Execute / Fetch** 단계별로
> **CPU / Elapsed / Disk / Query / Current / Rows**를 정량화한 표다.
> TKPROF·SQL Trace에서 이 표를 읽을 줄 알면, **파싱 과다/인덱스 미사용/랜덤 I/O 폭증/과도한 페치** 같은
> **병목 지점**을 빠르게 특정할 수 있다.

---

## 1. CALL 통계란 무엇인가?

### 1.1 TKPROF의 핵심 표
SQL Trace로 수집한 원시 트레이스를 TKPROF로 가공하면 아래와 같은 **CALL 통계 표**가 나온다.

```
call     count  cpu     elapsed     disk    query   current  rows
------- ------ -------  --------  -------  -------  -------  ----
Parse        1   0.03      0.05        0        2        0     0
Execute      1   0.12      0.20      120    10500      130     1
Fetch       10   0.09      0.15       10     9500       20   100
```

- **행(ROW)**: `Parse / Execute / Fetch` (세 단계)
- **열(COLUMN)**:
  - **count**: 해당 단계가 호출된 횟수
  - **cpu**: CPU 사용 시간(초)
  - **elapsed**: 경과 시간(초) — 대기 포함
  - **disk**: 디스크 물리 읽기 블록 수
  - **query**: **consistent gets**(일관 읽기: CR 블록 논리 읽기)
  - **current**: **db block gets**(커런트 모드 논리 읽기)
  - **rows**: 해당 단계에서 **생산된 로우 수**

> **용어 매핑**
> - **query** ↔ `V$SESSTAT`의 `consistent gets`
> - **current** ↔ `V$SESSTAT`의 `db block gets`
> - **disk** ↔ `physical reads`

### 1.2 Parse/Execute/Fetch의 의미
- **Parse**: SQL 파싱(하드·소프트), 권한 검사, 최적화, 커서 확보
- **Execute**: SQL을 실행(INSERT/UPDATE/DELETE는 여기서 **rows** 증가). SELECT의 경우 서버가 실행 계획대로 스캔/조인 수행
- **Fetch**: SELECT 결과를 **클라이언트로 가져오는 단계** (배치 단위로 여러 번 수행될 수 있음)

> **중요**: SELECT는 보통 `Execute`에서 실제 스캔을 시작하고, **실제 레코드 전송은 Fetch에서 이뤄진다**.
> **배치 크기**(fetch array size)가 작으면 **Fetch count**가 불필요하게 커져 **elapsed**와 **CPU**가 증가한다.

---

## 2. 각 지표 해석법 — 무엇을 보면 무엇을 의심할까?

| 컬럼 | 의미 | 높을 때 해석/대응 |
|---|---|---|
| **count** | 단계 호출 횟수 | Parse count↑ → 커서 재사용 부족/바인드 미사용. Fetch count↑ → Fetch array size가 너무 작다. |
| **cpu** | CPU 소비 시간(초) | 파싱 CPU↑ → 공유 실패·하드 파싱·복잡한 최적화. Execute/Fetch CPU↑ → 대량 조인/정렬/함수 호출. |
| **elapsed** | 응답 시간(대기 포함) | 대기 이벤트 확인(디스크 I/O, 락/래치, 네트워크 등). CPU 대비 Elapsed가 크면 **대기**가 많다. |
| **disk** | 물리 읽기 블록 수 | 버퍼 캐시 미스/인덱스 미사용/대량 테이블 스캔. SQL·인덱스·통계 점검. |
| **query** | CR 논리 읽기 | 읽기 작업량(일관 읽기). 과다하면 불필요 스캔/조인 순서 문제 가능. |
| **current** | CUR 논리 읽기 | DML/체크포인트 영향 또는 비효율적인 커런트 읽기. UPDATE/DELETE 조인 키/인덱스 설계 점검. |
| **rows** | 처리/전송된 로우 | SELECT: Fetch 합계가 최종 row 수. DML: Execute 단계 rows에 반영. |

> **추가** — TKPROF 부가 정보
> - `misses in library cache during parse`: 파싱 시 라이브러리 캐시 미스 → **하드 파싱** 시사
> - `rows` 대비 `fetch count`가 이상하게 큰 경우 → **Array Size** 튜닝 필요

---

## 3. 실습: SQL Trace + TKPROF로 CALL 통계 얻기

### 3.1 트레이스 켜기(자기 세션)
```sql
ALTER SESSION SET statistics_level = ALL;

-- 10046 level 8: 바인드 제외 대기 포함, 12 이상은 SQL Monitor도 고려
ALTER SESSION SET events '10046 trace name context forever, level 8';
```

### 3.2 테스트 워크로드 예시
```sql
-- 예제 테이블
DROP TABLE t_call PURGE;
CREATE TABLE t_call AS
SELECT level AS id,
       CASE MOD(level,3) WHEN 0 THEN 'APAC' WHEN 1 THEN 'EMEA' ELSE 'AMER' END region,
       TRUNC(SYSDATE) - MOD(level, 1000) AS dte,
       ROUND(DBMS_RANDOM.VALUE(10, 1000), 2) amt
FROM dual CONNECT BY level <= 1000000;

CREATE INDEX ix_call_region_dte ON t_call(region, dte);
BEGIN
  DBMS_STATS.GATHER_TABLE_STATS(USER,'T_CALL',cascade=>TRUE,
    method_opt=>'FOR COLUMNS SIZE 75 region SIZE 1 dte');
END;
/

-- 바인드 기반 SELECT(다회 호출)
VAR rgn VARCHAR2(10); EXEC :rgn := 'APAC';
SELECT /* call-demo */ SUM(amt)
FROM   t_call
WHERE  region = :rgn
AND    dte >= TRUNC(SYSDATE) - 30
AND    dte <  TRUNC(SYSDATE);

-- 같은 문장을 반복 호출(간단 예)
BEGIN
  FOR i IN 1..100 LOOP
    EXECUTE IMMEDIATE
      'SELECT /* call-demo */ COUNT(*) FROM t_call WHERE region=:b AND dte>=TRUNC(SYSDATE)-30 AND dte<TRUNC(SYSDATE)'
    INTO  :rgn  -- 실수: INTO에 바인드 변수를 잘못 사용한 예 (의도적)
    USING 'APAC';
  END LOOP;
END;
/
```

> **주의**: 위의 PL/SQL 블록은 설명 목적의 샘플이며, 실제로는 `INTO`에는 결과를 받을 **스칼라 변수**를 써야 한다.
> (고의로 “나쁜 예”를 섞어, 트레이스 캡처 시 파싱/바인드가 어떻게 보이는지 관찰하도록 함.)

### 3.3 트레이스 끄기
```sql
ALTER SESSION SET events '10046 trace name context off';
```

### 3.4 TKPROF 실행(서버 OS 쉘)
```bash
tkprof /u01/app/oracle/diag/.../trace/your_sid_ora_12345.trc out.tkprof sys=no sort=exeela,fchela
```

- **`sort` 팩터**: `exeela`(Execute Elapsed), `fchela`(Fetch Elapsed) 등으로 정렬
- **`sys=no`**: SYS 소유 SQL 제외(노이즈 감소)

---

## 4. CALL 표 읽기 — 케이스별 해석

### 4.1 **Hard Parse 과다형**
```
call     count  cpu   elapsed  disk  query current rows
Parse     1000  0.90    1.50     0      50       0    0
Execute   1000  0.20    0.30     0     500      10    0
Fetch     1000  0.10    0.20     0     300       5 1000
misses in library cache during parse: 1000
```
- **징후**: Parse count와 `misses in library cache during parse`가 모두 높다 → **하드 파싱 난발**
- **원인 후보**: 바인드 미사용(리터럴 남발), 텍스트 변형(주석/공백/힌트 랜덤화), 세션 상태 불일치(NLS, ROLE)
- **처방**: **바인드 변수** 도입, 텍스트 템플릿 고정, 세션 표준화, `SESSION_CACHED_CURSORS`/드라이버 Statement Cache

### 4.2 **랜덤 I/O 폭증형(인덱스 미스매치/카디널리티 오류)**
```
Execute     1   1.20  3.50  50000  120000   3000   1
Fetch      10   0.10  0.40     50   20000     50 100
```
- **징후**: `disk`(물리 읽기)와 `query/current`(논리 읽기)가 매우 큼
- **원인 후보**: 인덱스 미사용/부적절한 조인 순서, 히스토그램 부재로 카디널리티 오류, 바인드 피킹
- **처방**: 적절한 **인덱스**, **히스토그램**, **ACS(Adaptive Cursor Sharing)** 활성, 필요시 **SPM**으로 플랜 고정

### 4.3 **Fetch Overhead형(배치 크기 문제)**
```
Fetch     1000  0.40  1.80    100   50000    500 10000
```
- **징후**: Fetch **count**가 많고 `elapsed`도 Fetch에서 크게 발생
- **원인 후보**: 드라이버 Fetch Array Size가 너무 작음(예: 10~20)
- **처방**: **Array Size 확대**(JDBC: `setFetchSize`, ODP.NET: `FetchSize`, Python: `arraysize`)
  → 왕복 횟수↓, Fetch 단계의 `elapsed`↓, 동일 rows 대비 효율↑

### 4.4 **DML Current Gets 과다형**
```
Execute   1  0.50  1.00   200   1000  20000 100000
```
- **징후**: `current`가 크고 `rows`도 큰 대량 UPDATE/DELETE
- **원인 후보**: ROWID 접근 비효율, 인덱스/파티션 설계 미스, 불필요한 반복 변경
- **처방**: 배치 사이즈 조절, 인덱스/파티션(세그먼트 지역성) 재검토, Merge 사용 고려

---

## 5. SELECT vs DML — CALL 통계 차이를 제대로 이해하자

| 유형 | Parse | Execute | Fetch | rows |
|---|---|---|---|---|
| **SELECT** | 파싱 | 실행(계획 수행 시작) | **결과 전송** | **Fetch 합계**가 결과 건수 |
| **INSERT/UPDATE/DELETE** | 파싱 | **실제 변경이 Execute에 반영** | 보통 0(리턴 없음) | **Execute rows**가 반영 건수 |

> **오해 방지**: SELECT에서 `Execute rows`가 0이어도 정상이다. 결과는 **Fetch rows**로 본다.

---

## 6. CALL 통계 ↔ 세션/시스템 통계 매핑

- **`query`** ↔ `V$SESSTAT.name='consistent gets'`
- **`current`** ↔ `V$SESSTAT.name='db block gets'`
- **`disk`** ↔ `V$SESSTAT.name IN ('physical reads','physical read total bytes' 등)`
- **파싱/하드파싱** ↔ `parse count (total/hard)`, `session cursor cache hits`
- **대기** ↔ `V$ACTIVE_SESSION_HISTORY`, `wait_class`, `event`

### 점검 스니펫
```sql
-- 내 세션의 핵심 통계
SELECT sn.name, ss.value
FROM   v$sesstat ss JOIN v$statname sn ON sn.statistic#=ss.statistic#
WHERE  ss.sid = SYS_CONTEXT('USERENV','SID')
AND    sn.name IN ('consistent gets','db block gets','physical reads',
                   'parse count (total)','parse count (hard)','session cursor cache hits');

-- 최근 15분 대기 이벤트 샘플 (ASH)
VAR t1 TIMESTAMP; VAR t2 TIMESTAMP;
EXEC :t1 := SYSTIMESTAMP - INTERVAL '15' MINUTE; EXEC :t2 := SYSTIMESTAMP;
SELECT event, COUNT(*)
FROM   v$active_session_history
WHERE  sample_time BETWEEN :t1 AND :t2
GROUP  BY event ORDER  BY 2 DESC FETCH FIRST 10 ROWS ONLY;
```

---

## 7. 실전 튜닝 루틴 — CALL 통계로 병목을 찾는 절차

1) **SQL Trace/TKPROF**로 문제 SQL의 CALL 표 확보
2) 단계별 `elapsed` 비중 확인
   - Parse↑ → **커서 공유**/바인드/세션 캐시
   - Execute↑ → **플랜/인덱스/카디널리티**
   - Fetch↑ → **Array Size/네트워크 왕복**
3) `disk/query/current`와 `rows`의 상관 분석
   - 적은 rows에 비해 I/O가 과다 → **불필요 스캔**
4) AWR/ASH로 **동시 대기 이벤트** 확인(디스크/락/뮤텍스/네트워크)
5) **수정**(힌트 말고 구조적 해결 우선: 바인드, 인덱스, 통계, SQL 재작성)
6) **재측정**. **CALL 통계**의 전/후 비교가 가장 명확한 개선 지표

---

## 8. 언어별 페치 튜닝(왕복 줄이기)

### 8.1 JDBC
```java
PreparedStatement ps = conn.prepareStatement(sql);
ps.setFetchSize(1000);    // 기본 10~50인 경우가 많다 → 500~2000 권장(메모리와 타협)
ResultSet rs = ps.executeQuery();
while (rs.next()) { /* consume */ }
```

### 8.2 ODP.NET
```csharp
cmd.FetchSize = 1024 * 1024 * 8; // 바이트 단위(행당 크기 고려하여 4~16MB 권장)
using var rdr = cmd.ExecuteReader();
while (rdr.Read()) { /* consume */ }
```

### 8.3 Python (oracledb)
```python
cur.arraysize = 1000
cur.execute(sql, ...)
for row in cur:
    pass
```

> **효과**: Fetch 단계 `count`↓, `elapsed`↓. 네트워크 왕복이 큰 환경일수록 효과가 크다.

---

## 9. 예제: 동일 SQL, 페치 사이즈만 바꾸어 CALL 통계 비교

### 9.1 테스트 쿼리
```sql
SELECT /* fetch-bench */ *
FROM   t_call
WHERE  region = :rgn
AND    dte >= TRUNC(SYSDATE) - 90
AND    dte <  TRUNC(SYSDATE);
```

### 9.2 시나리오
- **케이스 A**: 배열/페치 사이즈 **작게** (예: 50)
- **케이스 B**: 배열/페치 사이즈 **크게** (예: 1000)

> **기대 결과**
> - 두 케이스 모두 `Execute`의 I/O(논리/물리)는 유사할 수 있다(같은 스캔).
> - 하지만 **Fetch 단계 `count`와 `elapsed`**는 **B**가 훨씬 유리.

---

## 10. 고급 케이스: 대기-중심 응답시간 해석과의 결합

CALL 통계만으로도 많은 걸 알 수 있지만, **왜** `elapsed`가 큰지 알기 위해선 **대기 이벤트**를 결합한다.

- `elapsed - cpu ≈ waits`
  $$ \text{Wait Time} \approx \text{Elapsed} - \text{CPU} $$
- TKPROF 하단의 **`Elapsed times include waiting on following events`** 섹션 확인:
  - 예: `db file sequential read`(랜덤 읽기), `db file scattered read`(멀티블록 읽기),
    `log file sync`(커밋), `enq: TX - row lock contention`(행 락 대기) 등.

> **해석**
> - Execute `elapsed`의 대부분이 `db file scattered read` → **Full Scan** 의심(멀티블록 I/O)
> - Execute `elapsed`의 대부분이 `db file sequential read` → **인덱스 랜덤 I/O** 과다
> - Fetch `elapsed`에 `SQL*Net message from dblink` → DB 링크/네트워크 지연

---

## 11. CHECKLIST — CALL 통계 기반 튜닝 우선순위

- [ ] **Parse** 비중↑ → **바인드 변수**, 텍스트 템플릿 고정, `SESSION_CACHED_CURSORS`/Statement Cache
- [ ] **Execute** I/O↑ → 인덱스/플랜/카디널리티(히스토그램·ACS·SPM)
- [ ] **Fetch** 과다↑ → Array Size/네트워크/클라이언트 처리 병목
- [ ] `disk`↑ → 버퍼 캐시 미스/세그먼트 설계/물리 I/O 확인
- [ ] `current`↑(DML) → 인덱스·파티션 설계, 배치 크기, 잠금 충돌 여부
- [ ] `rows` 대비 I/O 불균형 → 불필요 스캔 제거(SQL 재작성)
- [ ] AWR/ASH로 대기 이벤트와 교차 검증

---

## 12. 작은 종합 예제 — “느린 조회”를 CALL 통계로 고치기

**상황**: 하루 수천 RPS API, 아래 조회가 간헐적으로 500ms+ 지연

1) TKPROF CALL 표 요약
```
call     count  cpu   elapsed   disk   query current rows
Parse       20  0.15    0.40       0     200       0    0
Execute     20  0.30    6.00    5000  120000    1000   20
Fetch       40  0.05    0.30      10    1000      20  400
misses in library cache during parse: 20
```
- **문제**: Parse↑(공유 실패), Execute I/O 폭증

2) 조치
- 애플리케이션: **바인드 변수** 도입, 텍스트 템플릿 고정
- 옵티마이저: `region,status` 히스토그램, 인덱스 `(region, dte)` 생성
- 클라이언트: `fetchSize=1000`

3) 개선 후 CALL
```
call     count  cpu   elapsed  disk   query current rows
Parse        1  0.01    0.02     0       2       0    0
Execute     20  0.05    0.15    20    3000     100   20
Fetch       20  0.02    0.08     2     800      10  400
```
- **결과**: 응답시간 안정화, CPU/IO 모두 감소

---

## 13. 결론

- **CALL 통계**는 한 SQL의 **수명 주기(파싱→실행→페치)** 를 숫자로 보여주는 **진단 나침반**이다.
- 표에서 **어느 단계의 `elapsed`**가 높은지, **I/O/논리 읽기/rows**의 상관을 보라.
- **바인드/커서 재사용**, **플랜·인덱스·카디널리티**, **배치/페치 사이즈** 조정만으로도
  대부분의 병목이 **빠르게** 개선된다.
- 항상 **트레이스 전/후** CALL 통계를 **같은 조건**에서 비교하여, **개선 효과**를 수치로 확인하라.

> **요약 체크**
> - Parse↑ → **바인드/커서 캐시**
> - Execute↑(disk/query/current↑) → **인덱스/플랜/통계**
> - Fetch↑ → **Array Size/네트워크**
> - CALL 통계 + 대기 이벤트(ASH/AWR) = **완성된 응답시간 분석**.
