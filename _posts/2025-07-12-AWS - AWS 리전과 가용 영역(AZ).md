---
layout: post
title: AWS - AWS 리전과 가용 영역(AZ)
date: 2025-07-12 19:20:23 +0900
category: AWS
---
# AWS 리전(Region)과 가용 영역(AZ)

## 0. 한눈에 보는 개념 맵

```
Global AWS
└─ Region (예: ap-northeast-2, us-east-1)
   ├─ Availability Zone (예: ap-northeast-2a/b/c)
   │  └─ 여러 물리 데이터센터(전력/냉각/네트워크 분리) + 초저지연 내부망
   └─ Regional Services (S3, IAM, CloudFront*는 Global, Route 53은 Global)
```

- **Region**: 지리적 단위. 데이터 주권/요금/지연/가용성에 영향
- **AZ**: 리전 내 장애 격리를 위한 **서로 독립된 데이터센터 그룹**
- **서비스 가시성**: 다수 서비스는 리전 범위로 **논리적 독립** (S3 버킷은 리전 귀속, EC2는 AZ에 실제로 배치)

---

## 1. 리전(Region) — 선택 기준과 운영 포인트

### 1.1 리전의 정의와 특징(확장)
- **지리적 독립성**: 한 리전 장애가 다른 리전에 직접 파급되지 않도록 설계
- **데이터 주권**: 규제가 강한 도메인(의료/금융)은 로컬 보관 요구 → **서울/도쿄/프랑크푸르트** 등 선택
- **요금·서비스 차이**: 리전별 단가/가용 서비스/용량이 다를 수 있음
- **옵트인 리전**: 활성화 전까지는 사용 불가(콘솔/Organizations 정책으로 제어)

### 1.2 리전 선택 체크리스트
- **지연(latency)**: 최종 사용자와 가까운가?
- **수요/용량**: 원하는 인스턴스/가속기(GPU 등) 재고가 충분한가?
- **규제/보안**: 데이터 국경(Residency) 요구 충족?
- **생태계**: 파트너, Direct Connect 로케이션, 기업 네트워크 경로
- **DR 전략**: 세컨더리 리전과의 거리/지연/비용 밸런스

### 1.3 지연 예산(간단 수식)
웹 요청의 총 지연을 다음과 같이 놓자:
$$
T_{\text{total}} = T_{\text{net}} + T_{\text{LB}} + T_{\text{app}} + T_{\text{db}}
$$
- **리전 선택**은 \(T_{\text{net}}\) 에 직접 영향.
- 엣지(CDN/캐시)를 쓰면 \(T_{\text{net}}\) 을 크게 낮출 수 있음.

---

## 2. 가용 영역(AZ) — 장애 격리와 내결함성의 핵심

### 2.1 AZ의 정의와 물리적 분리
- **전력/냉각/네트워크 라인의 물리적 분리**
- 리전 내 **초저지연** 백본으로 연결 (동기 복제/상호 헬스체크/로드밸런싱에 적합)

### 2.2 AZ 네이밍의 함정(중요)
- **`ap-northeast-2a` 같은 AZ 이름은 계정마다 다를 수 있다.**
  같은 실제 AZ라도 계정 A에선 `2a`, 계정 B에선 `2b` 로 보일 수 있음.
- **정확한 식별은 AZ ID(예: `apn2-az1`)** 로 한다.

**CLI로 확인**
```bash
aws ec2 describe-availability-zones --region ap-northeast-2 \
  --all-availability-zones \
  --query "AvailabilityZones[].{Name:ZoneName,Id:ZoneId,State:State}"
```
출력 예(의미):
```
[
  {"Name": "ap-northeast-2a", "Id": "apn2-az1", "State": "available"},
  {"Name": "ap-northeast-2b", "Id": "apn2-az2", "State": "available"},
  {"Name": "ap-northeast-2c", "Id": "apn2-az3", "State": "available"}
]
```

---

## 3. 리전·AZ 설계가 성능/안정성/비용에 미치는 영향

| 목적 | 설계 전략 | 비고 |
|---|---|---|
| 성능 | 사용자 근접 리전, 엣지(CF) 캐시, 전용회선(Direct Connect) | API 응답 지연 최적화 |
| HA | **다중 AZ** 배치(EC2/ASG/ALB/RDS Multi-AZ), 분산 서브넷 | 단일 AZ 장애 대응 |
| DR | **다중 리전** 복제(S3 CRR, Aurora Global, DDB Global) | 대규모 재해/리전 장애 대비 |
| 비용 | 필요한 AZ/리전만 활성, 데이터 전송/복제 비용 고려 | 교차 AZ/리전 송신 요금 |

---

## 4. 다중 AZ 가용성 모델 — 간단 확률 계산

AZ A, B의 가용성이 각각 \(A\), \(B\) 라고 할 때 **활성-활성(둘 중 하나라도 운영되면 OK)** 의 시스템 가용성은:
$$
A_{\text{dual}} = 1 - (1-A)(1-B)
$$
예: \(A=B=99.9\% = 0.999\) 이면,
$$
A_{\text{dual}} = 1 - (0.001)^2 = 0.999999 = 99.9999\%
$$
> 현실은 독립 가정이 완벽하진 않지만, **다중 AZ로 “한 자리수 이상” 가용성 상승**이 가능한 이유를 직관적으로 보여준다.

---

## 5. VPC·서브넷·라우팅 — AZ 인식형 네트워크 뼈대

### 5.1 기본 토폴로지(3-AZ 모범)
```
VPC 10.0.0.0/16
├─ Public Subnet A (10.0.1.0/24)  ─┐
│  └─ ALB, NAT GW                  │─ IGW
├─ Public Subnet B (10.0.2.0/24)  ─┘
├─ Private App Subnet A (10.0.11.0/24)
├─ Private App Subnet B (10.0.12.0/24)
├─ Private DB Subnet A  (10.0.21.0/24)
└─ Private DB Subnet B  (10.0.22.0/24)
```
- **각 AZ마다 Public/Private 서브넷을 짝수로 구성**
- **ALB** 는 Regional 리소스이지만 **Target은 AZ별로 분산**
- **RDS Multi-AZ**: 서로 다른 AZ의 DB 서브넷 필요

### 5.2 Terraform 예시(요약: 2-AZ Public/Private)
```hcl
variable "vpc_cidr" { default = "10.0.0.0/16" }
variable "az_names" { default = ["ap-northeast-2a", "ap-northeast-2b"] }

resource "aws_vpc" "main" {
  cidr_block           = var.vpc_cidr
  enable_dns_hostnames = true
  enable_dns_support   = true
}

resource "aws_subnet" "public" {
  count                   = length(var.az_names)
  vpc_id                  = aws_vpc.main.id
  cidr_block              = cidrsubnet(var.vpc_cidr, 8, count.index)
  availability_zone       = var.az_names[count.index]
  map_public_ip_on_launch = true
  tags = { "Tier" = "public" }
}

resource "aws_subnet" "private" {
  count             = length(var.az_names)
  vpc_id            = aws_vpc.main.id
  cidr_block        = cidrsubnet(var.vpc_cidr, 8, count.index + 10)
  availability_zone = var.az_names[count.index]
  tags = { "Tier" = "private" }
}
```

---

## 6. 컴퓨팅/로드밸런서 — AZ 분산과 상태검사

### 6.1 Auto Scaling Group(ASG)
- **다중 AZ** 서브넷을 걸어두면 **용량을 AZ 간 자동 분산**
- **헬스체크 실패 시 재생성** → AZ 장애 시 살아있는 AZ에 재배치

```bash
# 예시: ALB 타깃 그룹(HTTP 200 헬스체크)
aws elbv2 create-target-group \
  --name blog-tg \
  --protocol HTTP --port 80 \
  --vpc-id vpc-xxxx \
  --health-check-path /healthz
```

### 6.2 ALB vs NLB
- **ALB(L7)**: 경로/호스트 기반 라우팅, HTTP(S) 레벨, 쿠키 스티키
- **NLB(L4)**: **초고성능/고정 IP/EIP**, TCP/UDP, **Cross-Zone LB 옵션** 중요

> **Cross-Zone**: 대상이 특정 AZ에 몰려 있어도 요청을 모든 AZ로 분산.
> 전송 비용/요금 정책을 확인하고 켤 것.

---

## 7. 데이터베이스 — Multi-AZ와 다중 리전 복제

### 7.1 RDS Multi-AZ
- **동기** 복제(대부분 엔진)로 **AZ 장애 시 자동 승격**
- 여유 IP/엔드포인트가 **자동 전환**되므로 앱은 보통 커넥션 재시도만 필요

### 7.2 Aurora(리전 내) & Aurora Global Database(다중 리전)
- 스토리지 6중 복제(리전 내), 리더/라이터 분리
- **Global**: 세컨더리 리전에 **수 초 단위의 공용 지연 복제**, DR 또는 글로벌 근접성 제공

### 7.3 DynamoDB Global Table
- 멀티 리전 **활성-활성** 키-값 저장
- 충돌 해결(최종 쓰기 승리 등) 모델에 주의

---

## 8. 스토리지 — S3와 복제 전략

### 8.1 S3는 **리전 서비스** (AZ 바인딩 X)
- 버킷은 특정 리전에 귀속, 데이터는 내부적으로 다중 AZ 내구성 설계
- **CRR(교차 리전 복제)**, **SRR(동일 리전 복제)** 로 DR/거버넌스 충족

```bash
# S3 버킷 생성(서울)
aws s3api create-bucket \
  --bucket my-seoul-bucket-1234 \
  --create-bucket-configuration LocationConstraint=ap-northeast-2
```

**버전관리/암호화**는 기본값으로 켜둘 것.

---

## 9. 글로벌 트래픽 — Route 53, CloudFront, Global Accelerator

### 9.1 다중 리전 라우팅 전략
- **Failover**: 1차/2차(헬스체크 기반 자동 전환)
- **Latency-based**: 사용자 지연 최소 리전으로 라우팅
- **Geolocation/Geoproximity**: 지역/가중치 기반(정책적 요구)

**간단 Failover 정책(개념 JSON)**
```json
{
  "Type": "A",
  "SetIdentifier": "primary-seoul",
  "Failover": "PRIMARY",
  "HealthCheckId": "xxxx-primary-hc",
  "TTL": 30,
  "ResourceRecords": [{"Value": "203.0.113.10"}]
}
```
보조(SECONDARY)에 유사 레코드를 추가해 페일오버 구성.

### 9.2 CloudFront (Global Edge)
- S3/ALB/Custom Origin → 엣지 POP 캐시 → 전 세계 지연 감소
- **Origin Access Control(OAC)** 로 S3 프라이빗 접근

---

## 10. DR(재해복구) 패턴 — 비용 vs 복구시간의 트레이드오프

| 패턴 | 설명 | RTO/RPO | 비용 |
|---|---|---|---|
| 백업/복구 | 백업만 유지, 재해 시 복구 | 높음 | 낮음 |
| 파일럿 라이트 | 핵심 DB만 따뜻하게, 앱은 스케일아웃 | 중간 | 중간 |
| 웜 스탠바이 | 축소된 전체 스택 상시 대기 | 낮음 | 중간~높음 |
| 멀티사이트(A/A) | 여러 리전 활성-활성 | 매우 낮음 | 높음 |

**간단 모델**
$$
\text{월 비용} \approx C_{\text{primary}} + \alpha \cdot C_{\text{secondary}}
$$
- \(\alpha\) = 스탠바이 축소율(웜 스탠바이는 \(\alpha < 1\), 액티브-액티브는 \(\alpha \approx 1\))

---

## 11. IaC로 구현하는 다중 AZ 기초

### 11.1 CloudFormation: DB 서브넷 그룹(2-AZ)
```yaml
Resources:
  DbSubnetGroup:
    Type: AWS::RDS::DBSubnetGroup
    Properties:
      DBSubnetGroupDescription: "RDS for multi-AZ"
      SubnetIds:
        - subnet-azA-private
        - subnet-azB-private
```

### 11.2 Terraform: ALB + ASG를 2-AZ로
```hcl
resource "aws_lb" "app" {
  name               = "app-alb"
  load_balancer_type = "application"
  subnets            = [aws_subnet.public[0].id, aws_subnet.public[1].id]
}

resource "aws_autoscaling_group" "web" {
  vpc_zone_identifier = [aws_subnet.private[0].id, aws_subnet.private[1].id]
  desired_capacity    = 2
  min_size            = 2
  max_size            = 6
  # launch_template 등 생략
}
```

### 11.3 CDK(TypeScript): ALB + TargetGroup + 헬스체크
```ts
import * as cdk from 'aws-cdk-lib';
import * as ec2 from 'aws-cdk-lib/aws-ec2';
import * as elbv2 from 'aws-cdk-lib/aws-elasticloadbalancingv2';

export class AlbStack extends cdk.Stack {
  constructor(scope: cdk.App, id: string, props?: cdk.StackProps) {
    super(scope, id, props);
    const vpc = ec2.Vpc.fromLookup(this, 'Vpc', { isDefault: true });
    const alb = new elbv2.ApplicationLoadBalancer(this, 'ALB', {
      vpc, internetFacing: true
    });
    const listener = alb.addListener('Http', { port: 80, open: true });
    const tg = new elbv2.ApplicationTargetGroup(this, 'TG', {
      vpc, port: 80, protocol: elbv2.ApplicationProtocol.HTTP,
      healthCheck: { path: '/healthz', interval: cdk.Duration.seconds(30) }
    });
    listener.addTargetGroups('Attach', { targetGroups: [tg] });
  }
}
```

---

## 12. 실전 시나리오 — 서울 단일 리전, 다중 AZ 웹/DB

### 12.1 구성
```
Client → CloudFront → ALB(Regional)
           |            ├─ EC2/ECS in ap-northeast-2a
           |            └─ EC2/ECS in ap-northeast-2b
           └─ S3(정적)        |
                              └─ RDS Multi-AZ(2a/2b)
```

### 12.2 동작
- ALB가 **헬스체크**로 장애 인스턴스를 트래픽에서 제외
- ASG가 **살아있는 AZ** 에 신규 인스턴스를 보충
- RDS가 **스탠바이**를 프라이머리로 자동 승격

---

## 13. 실전 시나리오 — 서울↔프랑크푸르트 DR(파일럿 라이트)

### 13.1 구성
```
Primary: ap-northeast-2
  - ALB + ASG, RDS(Aurora Primary), S3
Secondary: eu-central-1
  - Aurora Global(리더), 최소 ASG 용량, S3 CRR
Route 53 Failover: PRIMARY=Seoul, SECONDARY=Frankfurt
```

### 13.2 절차
- 평시: 서울로 라우팅(지연 최소)
- 재해: 보조 리전으로 **DNS 자동 전환**, ASG 확장, Aurora 보조 승격

---

## 14. 비용과 데이터 전송 — 교차 AZ/리전 요금 고려

- **AZ 간 데이터 전송**: 일부 서비스/경로에서 과금 (내부 최적화 필요)
- **리전 간 전송**: CRR, Global DB, Global Table 사용 시 전송/요청 비용 반영
- **LB Cross-Zone**: 트래픽 패턴/요금 모델을 검토 후 활성

**간단 합계 모델**
$$
C_{\text{trans}} \approx \sum_{(i \to j)} v_{i \to j} \cdot p_{i \to j}
$$
- \(v_{i \to j}\): i→j 데이터량(GB)
- \(p_{i \to j}\): 단가(USD/GB)

---

## 15. 운영 체크리스트 — 실전 가드레일

- [ ] **AZ ID 기준**으로 용량/부하 분산 검증 (계정 간 `2a/2b` 매핑 혼선 방지)
- [ ] **서브넷/라우팅 테이블** 명명 규칙: `vpcX-azA-public`, `vpcX-azB-private`
- [ ] **ALB/NLB 헬스체크** 경로/코드 200 보장
- [ ] **ASG 용량**: 최소 2(각 AZ 1 이상), 예열/쿨다운 튜닝
- [ ] **RDS Multi-AZ**: DB Subnet Group 두 AZ 이상, 백업/보안그룹 분리
- [ ] **S3 버전관리/암호화/KMS** 기본값 활성
- [ ] **Route 53 헬스체크** 간격/타임아웃 최적화, Failover 정책 테스트
- [ ] **CloudWatch 알람**: 상태 검사, 5xx 비율, 지연, 오류율
- [ ] **테이블/큐(예: DDB/SQS)** 리전 귀속 인지, 글로벌 확장 설계

---

## 16. 흔한 함정과 해결

- **문제: AZ 이름 혼동** → **해결: ZoneId 사용/문서화**
- **문제: 단일 AZ에만 인스턴스 몰림** → **해결: ASG Subnet에 여러 AZ 지정, Capacity Rebalance 활성**
- **문제: LB 헬스체크 실패** → **해결: `/healthz` 구현/보안그룹 아웃바운드 허용**
- **문제: RDS Multi-AZ 오해(읽기 스케일 용도 아님)** → **해결: 읽기 부하는 **Read Replica**/Aurora 리더로 분리**
- **문제: 교차 AZ 전송 비용 폭증** → **해결: 데이터 로컬리티 설계(캐시, 파티셔닝, Cross-Zone 필요 최소화)**

---

## 17. 실습 가이드 — 20분에 끝내는 AZ 인지 배포

### 17.1 현재 계정의 AZ 매핑 파악
```bash
aws ec2 describe-availability-zones --region ap-northeast-2 \
  --query "AvailabilityZones[].{Name:ZoneName,Id:ZoneId}"
```

### 17.2 두 AZ에 퍼블릭/프라이빗 서브넷 만들기(요약 Terraform)
```hcl
# 위 5.2 예시 참고: 서브넷 2쌍 생성 후 값 출력
output "public_subnets"  { value = aws_subnet.public[*].id }
output "private_subnets" { value = aws_subnet.private[*].id }
```

### 17.3 ALB + ASG 생성, 헬스체크 `/healthz`
```bash
# ALB의 Target Group는 /healthz 200 응답을 기준으로 체크
# 애플리케이션에 /healthz 핸들러 구현 필수
```

### 17.4 RDS Multi-AZ 활성화
- 콘솔: RDS 생성 시 **Multi-AZ** 옵션 체크
- 또는 CFN/TF에서 `multi_az = true` / **DB Subnet Group** 에 두 AZ 서브넷을 넣는다

---

## 18. 부록 — 서비스별 리전/AZ 인식 요약

| 범주 | 서비스 | 리전/AZ 인식 |
|---|---|---|
| 컴퓨팅 | EC2 | **AZ 배치** |
| 컨테이너 | ECS Fargate/EKS | 노드/ENI가 AZ에 종속, 서비스는 Regional |
| LB | ALB/NLB | LB는 Regional, 대상 분산/헬스체크는 AZ 인식 |
| 스토리지 | S3 | Regional 서비스(내부 다중 AZ 내구성) |
| DB | RDS/Aurora | Multi-AZ/Global(옵션) |
| 키-값 | DynamoDB | Regional, Global Table로 다중 리전 |
| 엣지 | CloudFront | Global(POP) |
| DNS | Route 53 | Global, 정책 기반 라우팅 |
| 보안 | KMS | Regional 키, X-Region 공유는 별도 구성 |

---

## 19. 요약

- **Region** 은 **지리/규제/요금/지연**을 결정한다.
- **AZ** 는 **장애 격리**의 기본 단위로, **다중 AZ** 배치가 고가용성의 출발점이다.
- **설계 팁 핵심**: *AZ ID로 식별*, *각 AZ에 균형 배치*, *헬스체크/알람 철저*, *전송비 고려*, *DR 패턴 명확화*.

---

## 20. 빠른 명령/스니펫 모음

```bash
# AZ/ZoneId 조회
aws ec2 describe-availability-zones --region ap-northeast-2 \
  --query "AvailabilityZones[].{Name:ZoneName,Id:ZoneId}"

# ALB Target Group(헬스체크)
aws elbv2 create-target-group \
  --name web-tg --protocol HTTP --port 80 \
  --vpc-id vpc-xxxx --health-check-path /healthz

# 다중 AZ ASG(요약: 서브넷 2개 이상 지정)
aws autoscaling create-auto-scaling-group \
  --auto-scaling-group-name web-asg \
  --min-size 2 --max-size 6 --desired-capacity 2 \
  --vpc-zone-identifier "subnet-a,subnet-b" \
  --launch-template LaunchTemplateName=web-lt,Version='$Latest'

# RDS Multi-AZ (CLI는 엔진별 파라미터 상이, 콘솔/TF 권장)
```

```hcl
# Terraform: RDS Multi-AZ (예시)
resource "aws_db_instance" "db" {
  engine               = "mysql"
  instance_class       = "db.t3.micro"
  allocated_storage    = 20
  multi_az             = true
  db_subnet_group_name = aws_db_subnet_group.db.name
  vpc_security_group_ids = [aws_security_group.db.id]
}
```

---

## 21. 참고 ASCII 다이어그램(복습)

```
Region: ap-northeast-2
├─ AZ a
│  ├─ Public Subnet (ALB, NAT GW)
│  └─ Private Subnet (EC2/ECS)
├─ AZ b
│  ├─ Public Subnet (ALB)
│  └─ Private Subnet (EC2/ECS)
└─ DB Subnet Group (AZ a, AZ b) → RDS Multi-AZ
```

> 이 구조가 **단일 AZ 장애**에도 웹/DB 모두 **자동 회복**되는 기본 골격이다.
