---
layout: post
title: 컴퓨터시스템 - 최신 프로세서 이해하기
date: 2025-08-01 20:20:23 +0900
category: 컴퓨터시스템
---
# 최신 프로세서 이해하기 — 2025년판: 구조, 트렌드, 그리고 개발자가 당장 적용할 것

## 로드맵 스냅샷

| 플랫폼 | 핵심 포인트(요지) |
|---|---|
| **Apple M5(2025)** | 3nm 3세대, CPU/GPU/Neural Engine 전반 강화, 단일 다이·통합 메모리 아키텍처·높은 메모리 대역(153 GB/s) 지속. 컴퓨트/미디어/AI 워크로드 전반 대역 확충. |
| **Intel Core Ultra(Lunar Lake, 2024→2025 주력 모바일)** | 하이브리드(새 μarch P/E), **NPU(정수 INT8 기준 48 TOPS)**, 전성비 개선·온패키지 메모리·SoC 타일화. |
| **AMD Ryzen AI 300(2024→2025 모바일)** | Zen 5 + RDNA 3.5 iGPU + **NPU 최대 50 TOPS**, 3D V-Cache/칩렛 전략은 데스크톱/서버에서 병행. |
| **서버/데이터센터 공통** | CXL 3.1/3.2로 **메모리 패브릭/풀링** 본격화, HBM3E 채택 가속, PCIe 7.0(128 GT/s) **스펙 확정(2025)**. |

---

## ISA vs μarch, 그리고 “가속기” 동반 시대

- **ISA**는 x86-64/Armv9-A/RISC-V처럼 프로그래머가 보는 명령 집합.
- **μarch**는 *같은 ISA라도* 전혀 다른 내부(프론트엔드·백엔드·캐시·예측기·스케줄러·메모리)로 성능을 가르는 구현.
- **가속기 동반**: CPU 옆의 **벡터(SIMD)/텐서/행렬/NPU**가 정수·부동소수·행렬·추론을 분담.
- 2025년 세대 포인트
  - **Apple M5**: 3세대 3nm, 메모리 대역 153 GB/s, CPU/GPU/Neural Engine 동시 강화. 앱과 미디어·AI 파이프라인을 하나의 통합 메모리 공간에서 고대역으로 처리.
  - **Intel Lunar Lake**: P/E 하이브리드 재설계 + **NPU 48 TOPS(INT8)** → “온디바이스 AI” PC 기준을 충족.
  - **AMD Zen 5 파생(모바일 Ryzen AI 300)**: **NPU 50 TOPS**, CPU 전면 개편·전성비 개선·RDNA iGPU 강화.

---

## 코어 설계 트렌드: 프론트엔드·백엔드·하이브리드

- **프론트엔드**: 더 넓은 디코더·μop 캐시·고성능 브랜치 예측 → 백엔드로 안정적 uop 공급.
- **백엔드**: 더 넓은 실행 포트, 더 깊은 리오더 윈도우, 메모리 디스앰빅/프리패처 개선. (Zen 5는 파이프 확장·캐시 대역 강화 방향의 공식 기술 개요를 제시)
- **하이브리드(P/E)**: 저전력 배경 작업은 E-core, 레이턴시 민감·싱글스레드는 P-core로 밀어 **전성비** 최적화(노트북/모바일 SoC 표준화).

---

## 벡터·텐서·NPU: 무엇을 어떻게 쓸까?

- **벡터(SIMD)**
  - x86: AVX2/AVX-512, Arm: **SVE2**, (일부 Arm은 **SME/SME2**로 행렬연산 가속) — *데이터 병렬 코드를 먼저 만들면* 컴파일러가 자동 벡터화.
- **텐서/행렬 유닛**
  - x86 AMX, Arm SME, Apple/AMD/Intel의 행렬 코어: **GEMM/컨볼루션** 계열을 가속.
- **NPU**
  - **PC-NPU TOPS**는 INT8 기준. Intel Lunar Lake **48 TOPS**, AMD Ryzen AI 300 **50 TOPS**. 활용은 **ONNX Runtime/DirectML/Core ML/oneDNN** 등 경로로 연동.

---

## 메모리·캐시·패키징: 3D·칩렛·유니파이드

- **캐시/3D**: 3D V-Cache 등으로 L3를 수직 적층해 **히트율/지연 타협 최적화**(게임/과학연산 이득).
- **유니파이드 메모리/온패키지 메모리**: 노트북 SoC는 **통합 고대역 메모리**로 CPU/GPU/NPU 간 데이터 이동 비용을 줄임(Apple M 시리즈가 대표).
- **칩렛/3D 패키징**: 모바일·서버 모두 **타일/칩렛**으로 공정·수율·코스트 최적화.
- **CXL 3.x**: **3.1/3.2**에서 *메모리 풀링/패브릭* 강화 → 대규모 메모리 공간을 다수의 CPU/GPU/NPU가 공유하는 설계가 본격화. (3.1 공지·3.2 출시 시점 참고)

---

## I/O와 인터커넥트: PCIe 7.0, 그리고 그다음

- **PCIe 7.0**: **128 GT/s**(x16 기준 양방향 최대 수백 GB/s급) 스펙이 **2025년에 확정**. 실제 보급은 데이터센터·HPC → PC 순서로 점진.
- (참고) **PCIe 8.0 목표**도 2025년에 공개되기 시작(장기 로드맵) — 개발자는 *소프트웨어적으로는 비의존적 설계*를 유지.

---

## 2025년 개발자 실천 포인트(핵심만)

### Roofline으로 병목부터 확인

$$
\text{Attainable Perf}=\min(\text{Peak FLOPs},\; \text{AI}\times\text{Peak BW}),\quad
\text{AI}=\frac{\text{FLOPs}}{\text{Bytes moved}}
$$
- **AI(연산집약도)**를 올리려면: **블로킹/타일링**, **데이터 재사용**, **SoA 변환**.
- **메모리 바운드**면: 구조를 바꿔 **MLP/프리패치/동시 outstanding miss**를 늘려라.

### 잘 걸리게 쓰기

```c
// 벡터화/별칭 제거/정렬 힌트
void saxpy(int n, float *restrict x, float *restrict y, float a) {
  #pragma omp simd
  for (int i=0; i<n; ++i) y[i] += a * x[i];
}
```

- `restrict`로 별칭 제거, 분기는 마스크(브랜치리스), 경계는 peeling.
- x86은 `-mavx2/-mavx512f`, Arm은 `-msve-vector-bits=...` 등 **타깃 플래그**를 CI에 분리.

### NPU/행렬 가속 경로 추가(온디바이스 AI)

```c
// Pseudo: ONNX Runtime (DirectML/NPU 우선, 실패 시 CPU/GPU)
OrtSession* CreateSessionPreferNPU(const wchar_t* model) {
  OrtSessionOptions* opt = OrtCreateSessionOptions();
  // 1) NPU/DirectML 우선(플랫폼별 EP 등록)
  OrtSessionOptionsAppendExecutionProvider_DML(opt, /*deviceId=*/0);
  // 2) 실패하면 CPU EP로 폴백
  return OrtCreateSession(env, model, opt);
}
```

- **런타임 플러그가능 경로**(NPU → GPU → CPU).
- **양자화/배치**로 NPU 친화 모델 만들기(INT8/INT4, 동적 shape 최소화).

### 스레드/NUMA/온패키지 메모리

```c
// NUMA first-touch: 초기화 스레드=사용 스레드
#pragma omp parallel

{
  int tid = omp_get_thread_num();
  for (size_t i = chunk_start(tid); i < chunk_end(tid); ++i)
    a[i] = 0.0; // 이 스레드의 노드에 페이지가 할당됨
}
```

- **first-touch 정책**으로 스레드와 데이터의 **노드 일치**.
- **샤딩·TLS·리듀스 병합**으로 공유 상태(락 경합) 최소화.

### PGO/LTO로 핫패스에 최적화 “몰빵”

```bash
# 예: Clang/LLVM

clang -O3 -fprofile-generate ...
./train_inputs.sh
clang -O3 -fprofile-use=default.profdata -flto ...
```

- **LTO/ThinLTO + PGO**는 교차 TU 인라이닝/Devirt/레이아웃 최적화로 I-cache/분기/IPC 수치를 동시에 개선(2025년에도 여전히 ROI 최고).

---

## 체크리스트 (바로 적용)

- [ ] **데이터 레이아웃**: SoA/타일링/정렬/프리패치로 **AI↑**·**MLP↑**
- [ ] **벡터화**: `restrict`/마스크/경계처리로 자동 벡터화 유도
- [ ] **NPU 경로**: ONNX Runtime/Core ML/DirectML 등 **플러그형 경로** 마련
- [ ] **하이브리드 코어**: 백그라운드/포그라운드 **스레드 클래스 분리**
- [ ] **NUMA/온패키지 메모리**: first-touch·바인딩·스레드-데이터 일치
- [ ] **PGO/LTO**: 핫패스 집중 최적화(인라이닝·Devirt·ICache 레이आ웃)
- [ ] **계측**: `perf/VTune`로 IPC, L1/L2/L3-miss, branch-miss, BW, NPU 활용률

---

## 간단 벤치 스캐폴딩(측정 템플릿)

```c
#include <time.h>

double now_s() { struct timespec t; clock_gettime(CLOCK_MONOTONIC, &t);
  return t.tv_sec + t.tv_nsec*1e-9; }

void work(float* __restrict x, float* __restrict y, int n, float a);

int main() {
  const int n = 1<<26;
  // ... allocate & init x,y (aligned_alloc) ...
  double t0 = now_s();
  work(x,y,n,2.0f);
  double t1 = now_s();
  double gb = (double)n * sizeof(float) * 2 / (1<<30);
  printf("time=%.3fs, BW=%.1f GB/s\n", t1-t0, gb/(t1-t0));
}
```

- 필수 카운터: `cycles,instructions,branch-misses,L1-refs/L1-misses,LLC-misses,mem_bw`.

---

## “2025 기준”으로 알아둘 사실(요약)

1) **Apple M5** 세대: 3nm 3세대 공정·메모리 대역 153 GB/s·CPU/GPU/NE 강화, 통합 메모리로 워크플로 단순화.
2) **Intel Lunar Lake**: **NPU 48 TOPS**·하이브리드 코어·타일 SoC·전성비 지향.
3) **AMD Ryzen AI 300**: **NPU 50 TOPS**·Zen 5 계열·모바일 AI PC 최적화.
4) **CXL 3.1/3.2**: 메모리 패브릭·풀링·P2P 강화(대규모 메모리 가시화).
5) **PCIe 7.0(2025 스펙 확정)**: 차세대 가속기·스토리지·DPU 연결의 기반(보급은 점진).
