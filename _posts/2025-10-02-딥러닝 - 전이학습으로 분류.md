---
layout: post
title: 딥러닝 - 전이학습으로 분류
date: 2025-10-02 17:25:23 +0900
category: 딥러닝
---
# 전이학습으로 분류 시작하기  
**데이터 준비 · 클래스 불균형 · 레이블 품질(노이즈) · 전이학습 실전 레시피(코드 포함)**

## 0) 큰 그림(왜 전이학습인가?)
- **사전학습 백본(ResNet/EfficientNet/ViT 등)** 의 **일반 표현**을 활용 → **데이터가 적어도** 빠르게 수렴/일반화.
- 핵심 3축:
  1) **데이터**: 폴더 구조/전처리/증강/분할
  2) **클래스 불균형**: 샘플링/가중치/손실/임계값
  3) **레이블 품질**: 노이즈 탐지/완화/반자동 교정  
- 그리고 **학습 전략**: “**Linear Probe → 전층 미세튜닝**” + AMP, 적절한 스케줄링.

---

## 1) 데이터 준비: 구조·전처리·분할·EDA

### 1.1 디렉터리 구조(간단)
```
dataset/
  train/
    class_a/  img001.jpg ...
    class_b/  ...
    ...
  val/        (없으면 train에서 Stratified split)
  test/       (최종 보고용; 학습 중 절대 사용 금지)
```
- **`torchvision.datasets.ImageFolder`** 가 자동으로 라벨을 할당합니다(폴더명이 라벨).

### 1.2 전처리/증강(백본 스케일·정규화 일치)
- 사전학습 ImageNet 백본은 보통 **224×224**, **ImageNet 정규화** 사용:
  - `mean=[0.485,0.456,0.406]`, `std=[0.229,0.224,0.225]`

```python
from torchvision import transforms as T

IMG_SIZE = 224
train_tf = T.Compose([
    T.RandomResizedCrop(IMG_SIZE, scale=(0.6, 1.0), ratio=(3/4, 4/3)),
    T.RandomHorizontalFlip(p=0.5),
    T.ColorJitter(0.1,0.1,0.1,0.05),
    T.ToTensor(),
    T.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]),
])
val_tf = T.Compose([
    T.Resize(int(IMG_SIZE*1.14)), T.CenterCrop(IMG_SIZE),
    T.ToTensor(),
    T.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]),
])
```

> 팁: **라벨 보존형 증강**만 사용(분류). 잘라내기/색상변형/좌우반전은 안전, **라벨 바꾸는 증강**(큰 회전으로 숫자 뒤집힘 등)은 주의.

### 1.3 데이터셋/분할(Stratified)
```python
import torch, numpy as np
from torchvision.datasets import ImageFolder
from torch.utils.data import Subset, DataLoader
from sklearn.model_selection import StratifiedShuffleSplit

root = "dataset/train"   # val이 없으면 train에서 분할
full = ImageFolder(root, transform=train_tf)  # 임시로 train_tf
y = np.array([t for _, t in full.samples])

sss = StratifiedShuffleSplit(n_splits=1, test_size=0.15, random_state=42)
train_idx, val_idx = next(sss.split(np.zeros(len(y)), y))

train_ds = Subset(ImageFolder(root, transform=train_tf), train_idx)
val_ds   = Subset(ImageFolder(root, transform=val_tf),   val_idx)

BATCH=64
train_loader = DataLoader(train_ds, batch_size=BATCH, shuffle=True, num_workers=4, pin_memory=True)
val_loader   = DataLoader(val_ds,   batch_size=BATCH*2, shuffle=False, num_workers=4)
num_classes  = len(full.classes)
```
> 그룹(동일 사용자/상품/비디오 프레임 묶음)이 있으면 **GroupKFold/GroupShuffleSplit**으로 **누수 방지**.

### 1.4 데이터 품질 EDA(필수 체크)
- **이미지 손상**/채널수 상이 → 로딩 시 예외 처리 & 로그.
- **해상도/비율 분포**: 극단치(썸네일/초고해상도) 필터링 또는 다른 파이프라인.
- **중복/유사 이미지**: 학습/검증에 동시에 있으면 누수. (해시/특징 유사도로 제거)
- **클래스 분포**: 롱테일? (불균형 전략 3장에서 다룸)

```python
# 손상 파일 스캔(요약)
from PIL import Image
bad=[]
for p,_ in full.samples:
    try:
        Image.open(p).verify()
    except:
        bad.append(p)
print("broken images:", len(bad))
```

---

## 2) 전이학습(Transfer Learning) 전략

### 2.1 백본 선택 가이드(간단)
- **ResNet-50**: 튼튼한 기본기, 빠른 수렴, 파이프라인 가용성↑  
- **EfficientNet**: 파라미터 효율, 이미지 스케일 선택  
- **ViT**: 데이터 크면 강력, 적을 때는 **상당한 규제/증강** 필요

### 2.2 헤드 교체 & Linear Probe → 전층 미세튜닝
1) **헤드만 학습(Linear Probe)** 몇 epoch: 빠르게 안정화, 좋은 초기화 확보  
2) **상위 몇 개 block → 전층** 순차적으로 **Unfreeze**: 과적합 줄이고 수렴 안정

```python
import torch, torch.nn as nn
import torchvision.models as M

device = "cuda" if torch.cuda.is_available() else "cpu"
backbone = M.resnet50(weights=M.ResNet50_Weights.IMAGENET1K_V2)
in_dim = backbone.fc.in_features
backbone.fc = nn.Linear(in_dim, num_classes)
model = backbone.to(device)
```

#### (A) Linear Probe(백본 freeze)
```python
for p in model.parameters(): p.requires_grad = False
for p in model.fc.parameters(): p.requires_grad = True
```

#### (B) 점진적 Unfreeze + Discriminative LR
```python
# 상위 layer4만 풀기 → block별로 풀기
for p in model.layer4.parameters(): p.requires_grad = True
# 파라미터 그룹: 하위 레이어는 더 낮은 lr, 헤드는 높게
param_groups = [
    {"params": model.layer1.parameters(), "lr": 1e-5},
    {"params": model.layer2.parameters(), "lr": 2e-5},
    {"params": model.layer3.parameters(), "lr": 3e-5},
    {"params": model.layer4.parameters(), "lr": 5e-5},
    {"params": model.fc.parameters(),     "lr": 1e-4},
]
opt = torch.optim.AdamW(param_groups, weight_decay=1e-4)
```

### 2.3 학습 루프(AMP + Warmup+Cosine)
```python
import torch.nn.functional as F
from torch.cuda.amp import autocast, GradScaler

EPOCHS=20
scaler = GradScaler()

# 간단 Warmup+Cosine
steps_per_epoch = len(train_loader)
total_steps = EPOCHS * steps_per_epoch
warmup = int(0.1*total_steps)
scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(opt, T_max=(total_steps-warmup))

def get_lr(step):
    if step < warmup:
        for g in opt.param_groups:
            g["lr"] = g["lr"] * float(step+1)/warmup

global_step=0
best=0.0
for ep in range(EPOCHS):
    model.train()
    for xb, yb in train_loader:
        xb, yb = xb.to(device, non_blocking=True), torch.as_tensor(yb, device=device)
        opt.zero_grad(set_to_none=True)
        with autocast(dtype=torch.bfloat16 if torch.cuda.is_available() else torch.float32):
            logits = model(xb)
            loss = F.cross_entropy(logits, yb, label_smoothing=0.05)
        scaler.scale(loss).backward()
        scaler.unscale_(opt)
        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)
        scaler.step(opt); scaler.update()
        if global_step >= warmup: scheduler.step()
        else: get_lr(global_step)
        global_step += 1

    # 평가
    model.eval(); correct=total=0
    with torch.no_grad():
        for xb, yb in val_loader:
            xb, yb = xb.to(device), yb.to(device)
            pred = model(xb).argmax(1)
            correct += (pred==yb).sum().item(); total += yb.size(0)
    acc = correct/total
    print(f"[{ep+1:02d}] val acc={acc:.4f}")
    if acc>best:
        best=acc
        torch.save(model.state_dict(),"best.pt")
```

---

## 3) 클래스 불균형(롱테일) 다루기

### 3.1 먼저 “정확도(Accuracy) 함정” 피하기
- 불균형일수록 **Macro-F1**, **Balanced Accuracy**, **PR-AUC**를 보고합니다.
- **Balanced Acc**: 클래스별 Recall 평균  
  $$\mathrm{BACC}=\frac{1}{K}\sum_{c=1}^K \frac{TP_c}{TP_c+FN_c}$$

### 3.2 샘플링 vs 가중치 vs 손실

#### (A) **가중치**(CrossEntropy에 `weight=class_weights`)
```python
import numpy as np, torch

# class별 개수 계산
targets = [t for _, t in train_ds.dataset.samples]  # ImageFolder 원본에서 꺼내기
counts = np.bincount(np.array(targets)[train_idx], minlength=num_classes)
class_weights = torch.tensor((counts.sum()/np.clip(counts,1,None)), dtype=torch.float32).to(device)
criterion_w = torch.nn.CrossEntropyLoss(weight=class_weights)
```

#### (B) **WeightedRandomSampler**(소수 클래스 **오버샘플링**)
```python
from torch.utils.data.sampler import WeightedRandomSampler

sample_targets = np.array([train_ds.dataset.samples[i][1] for i in train_idx])
cls_counts = np.bincount(sample_targets, minlength=num_classes)
sample_weights = 1.0 / cls_counts[sample_targets]
sampler = WeightedRandomSampler(sample_weights, num_samples=len(sample_weights), replacement=True)
train_loader = DataLoader(train_ds, batch_size=BATCH, sampler=sampler, num_workers=4, pin_memory=True)
```

#### (C) **Focal Loss**(하드 예제에 더 집중)
$$
\mathrm{FL}(p_t)=-\alpha(1-p_t)^\gamma \log(p_t)
$$
```python
import torch.nn as nn
class FocalLoss(nn.Module):
    def __init__(self, alpha=None, gamma=2.0, reduction="mean"):
        super().__init__(); self.alpha=alpha; self.gamma=gamma; self.red=reduction
    def forward(self, logits, target):
        ce = F.cross_entropy(logits, target, weight=self.alpha, reduction='none')
        pt = torch.softmax(logits, -1).gather(1, target.view(-1,1)).squeeze(1).clamp_(1e-6,1-1e-6)
        loss = (1-pt).pow(self.gamma) * ce
        return loss.mean() if self.red=="mean" else loss.sum()
```

#### (D) **Class-Balanced Loss(Effective Number of Samples)**  
- 각 클래스 가중치:  
  $$w_c=\frac{1-\beta}{1-\beta^{n_c}},\ \ \beta\in[0.9,0.999]$$
```python
def class_balanced_weights(counts, beta=0.999):
    eff = (1 - np.power(beta, counts)) / (1 - beta)
    w = counts.sum() / (eff * len(counts))
    return torch.tensor(w, dtype=torch.float32)
```

> 권장 순서: **(1) 가중치/CB Loss** → **(2) 오버샘플링(혹은 Class-aware 샘플링)** → **(3) Focal**(특히 하드/희귀 클래스 민감 시)

### 3.3 데이터 레벨 전략
- **Minority만 증강 강하게**(색상/크롭 강도↑, CutMix/MixUp 사용)
- **Class-aware sampling**: 배치마다 각 클래스가 일정 수 포함되게(롱테일 완화)
- **Threshold 튜닝**(특정 클래스 리콜 중요 시): 비용 기반 임계값 조정

#### MixUp/CutMix(분류용)
```python
import random
def mixup(x, y, alpha=0.2):
    lam = np.random.beta(alpha, alpha)
    idx = torch.randperm(x.size(0), device=x.device)
    x2, y2 = x[idx], y[idx]
    x_mix = lam*x + (1-lam)*x2
    return x_mix, y, y2, lam

def mixup_criterion(crit, pred, y1, y2, lam):
    return lam*crit(pred,y1) + (1-lam)*crit(pred,y2)
```

사용:
```python
with autocast(dtype=torch.bfloat16):
    if random.random()<0.5:
        xb, y1, y2, lam = mixup(xb, yb, alpha=0.2)
        logits = model(xb)
        loss = mixup_criterion(criterion_w, logits, y1, y2, lam)
    else:
        logits = model(xb)
        loss = criterion_w(logits, yb)
```

---

## 4) 레이블 품질(노이즈) 다루기

### 4.1 왜 생기나?
- 크라우드소싱 오타, 웹스크래핑 자동 라벨, 클래스 경계 모호함, 중복/유사 클래스, 데이터 이동/매핑 오류.

### 4.2 빠른 진단(쉬운/효율적)
- **예측-라벨 불일치** 상위 샘플 살펴보기(고손실, 저확신).
- **에러 패턴**: 특정 클래스 쌍에서만 혼동? (컨퓨전 매트릭스)
- **중복 라벨**: 같은 이미지(또는 거의 동일)가 서로 다른 라벨을 가짐?

#### per-sample loss 로거(의심 샘플 추출)
```python
def collect_losses(model, loader, max_items=2000):
    model.eval(); rows=[]
    with torch.no_grad():
        for xb, yb in loader:
            xb, yb = xb.to(device), yb.to(device)
            logits = model(xb)
            loss = F.cross_entropy(logits, yb, reduction='none')
            probs = torch.softmax(logits, -1).max(1).values
            for i in range(xb.size(0)):
                rows.append((int(yb[i]), float(loss[i]), float(probs[i])))
            if len(rows) > max_items: break
    # 가장 손실↑이면서 확신↑(conflict)인 샘플이 오라클 후보
    rows.sort(key=lambda r: (r[1], -r[2]), reverse=True)
    return rows[:200]

suspects = collect_losses(model, val_loader)
print("top noisy candidates (y, loss, conf):", suspects[:10])
```

### 4.3 노이즈 견고 학습 기법

#### (A) Label Smoothing
- **원-핫을 부드럽게**: 정답 \(1-\epsilon\), 오답 \(\epsilon/(K-1)\)  
- 노이즈 적응/과신(overconfidence) 완화. (이미 위 CE에서 `label_smoothing=0.05` 사용)

#### (B) Bootstrapping Loss(soft/hard 혼합)
- **모델 예측**과 **원래 라벨**을 혼합
$$
\tilde{y} = (1-\lambda)\,y + \lambda\,\hat{p},\quad
\mathcal{L}=\mathrm{CE}(\hat{p},\tilde{y})
$$
```python
def bootstrapped_ce(logits, target, lmbd=0.1):
    with torch.no_grad():
        p = torch.softmax(logits, -1)
        y = torch.zeros_like(logits).scatter_(1, target.view(-1,1), 1.0)
        y_tilde = (1-lmbd)*y + lmbd*p
    logp = torch.log_softmax(logits, -1)
    return -(y_tilde*logp).sum(-1).mean()
```

#### (C) Self-Training(고확신 pseudo-label)
- **라벨 없는 데이터**/의심 데이터에 대해 **확신 ≥ τ**인 예측을 **새 라벨**로 사용.
```python
def pseudo_label_batch(model, xb, tau=0.9):
    with torch.no_grad():
        p = torch.softmax(model(xb), -1)
        conf, yhat = p.max(-1)
        mask = conf >= tau
    return xb[mask], yhat[mask], mask.sum().item()
```

#### (D) Ensemble/Co-teaching(아이디어)
- 다른 초기화/증강/아키텍처 **2개 모델**이 서로의 **손실 상위 샘플을 배제**하고 학습 → 노이즈 억제.

> 작업 흐름:  
> 1) 일단 전이학습으로 **베이스라인**  
> 2) **손실↑/확신↑** 샘플 **검수/수정**(작게라도)  
> 3) **Label Smoothing/Bootstrapping** 적용  
> 4) 여유가 있으면 **Self-Training**으로 데이터 확장

---

## 5) 평가·디버깅(현실적인 레포트 만들기)

### 5.1 지표(불균형 친화적)
```python
from sklearn.metrics import classification_report, confusion_matrix, balanced_accuracy_score, f1_score

def evaluate(model, loader, class_names):
    model.eval(); ys=[]; ps=[]
    with torch.no_grad():
        for xb, yb in loader:
            xb = xb.to(device)
            ys.append(yb.numpy())
            ps.append(model(xb).argmax(1).cpu().numpy())
    y = np.concatenate(ys); pred=np.concatenate(ps)
    print("Balanced Acc:", balanced_accuracy_score(y, pred))
    print("Macro-F1    :", f1_score(y, pred, average="macro"))
    print(classification_report(y, pred, target_names=class_names, digits=3))
    print("CM:\n", confusion_matrix(y, pred))
```

### 5.2 임계값 튜닝(특정 클래스 리콜/정밀 트레이드오프)
- Softmax 점수로 **클래스별 임계값**을 달리할 수 있음(특히 “기준치 이상이면 경보” 같은 업무).
- 비용 민감(오탐/미탐 비용)일 때 **코스트 최소화 임계값** 사용.

---

## 6) 엔드-투-엔드 미니 학습 스크립트(요약형)

> “불균형 + 라벨 노이즈가 살짝 있는” 다중분류를 가정

```python
import torch, torch.nn as nn, torch.nn.functional as F, numpy as np, random
from torch.cuda.amp import autocast, GradScaler
from torch.utils.data import DataLoader
import torchvision.models as M
from torchvision.datasets import ImageFolder
from torchvision import transforms as T
from sklearn.model_selection import StratifiedShuffleSplit
from sklearn.metrics import balanced_accuracy_score, f1_score

# 0) 세팅
seed=42
torch.manual_seed(seed); np.random.seed(seed); random.seed(seed)
device="cuda" if torch.cuda.is_available() else "cpu"
IMG=224; BATCH=64

train_tf = T.Compose([
    T.RandomResizedCrop(IMG, scale=(0.6,1.0), ratio=(3/4,4/3)),
    T.RandomHorizontalFlip(), T.ColorJitter(0.15,0.15,0.15,0.05),
    T.ToTensor(),
    T.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]),
])
val_tf = T.Compose([
    T.Resize(int(IMG*1.14)), T.CenterCrop(IMG),
    T.ToTensor(),
    T.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]),
])

root="dataset/train"; full = ImageFolder(root)
yall = np.array([t for _,t in full.samples])

sss = StratifiedShuffleSplit(n_splits=1, test_size=0.15, random_state=seed)
tr_idx, va_idx = next(sss.split(np.zeros(len(yall)), yall))
train_ds = torch.utils.data.Subset(ImageFolder(root, transform=train_tf), tr_idx)
val_ds   = torch.utils.data.Subset(ImageFolder(root, transform=val_tf),   va_idx)
num_classes = len(full.classes)

# class weights(가중 CE)
counts = np.bincount(yall[tr_idx], minlength=num_classes)
class_weights = torch.tensor(counts.sum()/np.clip(counts,1,None), dtype=torch.float32, device=device)

train_loader = DataLoader(train_ds, batch_size=BATCH, shuffle=True, num_workers=4, pin_memory=True)
val_loader   = DataLoader(val_ds,   batch_size=BATCH*2, shuffle=False, num_workers=4)

# 1) 모델
m = M.resnet50(weights=M.ResNet50_Weights.IMAGENET1K_V2)
m.fc = nn.Linear(m.fc.in_features, num_classes)
m = m.to(device)

# Linear probe 3epoch
for p in m.parameters(): p.requires_grad=False
for p in m.fc.parameters(): p.requires_grad=True
opt = torch.optim.AdamW(m.fc.parameters(), lr=1e-3, weight_decay=1e-4)
scaler=GradScaler()

def train_epoch(model, loader, criterion, opt):
    model.train(); loss_sum=0
    for xb, yb in loader:
        xb, yb = xb.to(device), yb.to(device)
        opt.zero_grad(set_to_none=True)
        with autocast(dtype=torch.bfloat16 if torch.cuda.is_available() else torch.float32):
            logits = model(xb)
            loss = criterion(logits, yb)
        scaler.scale(loss).backward()
        scaler.unscale_(opt)
        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)
        scaler.step(opt); scaler.update()
        loss_sum += loss.item()*xb.size(0)
    return loss_sum/len(loader.dataset)

def eval_epoch(model, loader):
    model.eval(); ys=[]; ps=[]
    with torch.no_grad():
        for xb, yb in loader:
            xs = xb.to(device)
            pred = m(xs).argmax(1).cpu().numpy()
            ys.append(yb.numpy()); ps.append(pred)
    y = np.concatenate(ys); p = np.concatenate(ps)
    return balanced_accuracy_score(y,p), f1_score(y,p,average="macro")

crit = nn.CrossEntropyLoss(weight=class_weights, label_smoothing=0.05)

for ep in range(3):
    tr = train_epoch(m, train_loader, crit, opt)
    bacc, f1 = eval_epoch(m, val_loader)
    print(f"[LP {ep+1}] loss={tr:.4f} bacc={bacc:.3f} f1={f1:.3f}")

# Unfreeze 상위 block → 전층
for p in m.layer4.parameters(): p.requires_grad=True
param_groups = [
    {"params": m.layer4.parameters(), "lr": 5e-5},
    {"params": m.fc.parameters(),     "lr": 1e-4},
]
opt = torch.optim.AdamW(param_groups, weight_decay=1e-4)

for ep in range(5):
    tr = train_epoch(m, train_loader, crit, opt)
    bacc, f1 = eval_epoch(m, val_loader)
    print(f"[FT1 {ep+1}] loss={tr:.4f} bacc={bacc:.3f} f1={f1:.3f}")

for p in m.parameters(): p.requires_grad=True
opt = torch.optim.AdamW(m.parameters(), lr=5e-5, weight_decay=1e-4)
for ep in range(7):
    tr = train_epoch(m, train_loader, crit, opt)
    bacc, f1 = eval_epoch(m, val_loader)
    print(f"[FT2 {ep+1}] loss={tr:.4f} bacc={bacc:.3f} f1={f1:.3f}")
```

> 이 스크립트는 **가중 CE + label smoothing + AMP**를 기본으로 하며,  
> 불균형이 심하면 **WeightedRandomSampler** / **FocalLoss** / **Class-Balanced Loss** 를 대체하여 넣으면 됩니다.

---

## 7) 시나리오별 플레이북

### 7.1 데이터가 매우 적다(클래스별 20장 이하)
- **강한 전이**: Linear probe → 극소수 파라미터만 Unfreeze  
- **증강↑**: RandAugment/ColorJitter 확대, CutMix/MixUp  
- **라벨 품질 확인**: 매 샘플 육안 검수(가능한 범위)

### 7.2 롱테일(상위 3개가 80%)
- **Class-balanced reweight** + **Class-aware sampling**  
- 희귀 클래스에 **증강 더 강하게**  
- 리포트는 **Macro-F1** 위주

### 7.3 웹 크롤링(노이즈 있음)
- 빠르게 전이 → **고손실/고확신** 샘플 검수  
- **Bootstrapping** + **Self-Training(τ=0.9)**  
- 점차 클린셋 확장(활용 가능한 라벨만)

### 7.4 도메인 쉬프트(학습·테스트 도메인 다름)
- 전처리/정규화 확인, **컬러/스타일** 증강 강화  
- **어댑테이션**(BN 통계 적응, 작은 unlabeled target set으로 TTA/BN적응)

---

## 8) 체크리스트(현업용)

### 데이터
- [ ] 폴더/라벨 매핑, 손상/중복 제거  
- [ ] Stratified(또는 Group) 분할, 누수 금지  
- [ ] 백본 정규화/해상도 일치, 증강 검토

### 학습
- [ ] Linear probe → 점진 Unfreeze → 전층  
- [ ] AMP, Clip, AdamW, Warmup+Cosine  
- [ ] 불균형: 가중치/샘플링/손실 적용

### 레이블 품질
- [ ] per-sample loss/확신으로 의심 샘플 추출  
- [ ] Label smoothing/Bootstrapping 적용  
- [ ] 가능시 pseudo-label로 데이터 확장

### 평가
- [ ] **Balanced Acc, Macro-F1, PR-AUC**  
- [ ] 컨퓨전 매트릭스/서브그룹 슬라이스  
- [ ] 임계값 튜닝(업무 비용 반영)

---

### 마무리
전이학습의 핵심은 **데이터 관리**(분할/증강/불균형/노이즈)와 **학습 절차**(freeze→unfreeze)의 조화입니다.  
여기 제공한 스니펫들을 그대로 조합하면 **작은 데이터·불균형·라벨 노이즈**가 섞인 현실 문제에서도 **견고한 베이스라인**을 빠르게 만들 수 있습니다.  
이후에는 모델/증강/손실을 하나씩 바꾸며 **수치 개선**을 체계적으로 누적하세요.
성능 리포트는 **Macro-F1/Balanced Acc** 중심으로, 라벨 품질은 **per-sample loss** 랭킹으로 지속 점검하는 것이 정석입니다.