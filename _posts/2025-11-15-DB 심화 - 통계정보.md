---
layout: post
title: DB 심화 - 통계정보
date: 2025-11-15 19:25:23 +0900
category: DB 심화
---
# Oracle 옵티마이저 통계정보: 데이터베이스 최적화의 기초

## 통계 정보가 실행 계획을 지배하는 이유

Oracle 옵티마이저(CBO)는 SQL 실행 계획을 수립할 때 일련의 논리적 계산 과정을 거칩니다. 이 과정에서 가장 중요한 입력값이 바로 통계 정보입니다. 통계는 옵티마이저에게 데이터의 분포, 크기, 특성에 대한 정확한 지도를 제공합니다. 이 지도가 왜곡되거나 불완전하면, 옵티마이저는 비록 완벽한 계산 논리를 가지고 있더라도 최적이 아닌 실행 계획을 선택하게 됩니다.

통계 정보의 핵심 역할을 이해하기 위해, 옵티마이저의 의사 결정 과정을 살펴보겠습니다:

1. **카디널리티 추정**: 각 단계에서 처리될 데이터 양을 예측합니다. 이는 선택도(Selectivity) 계산을 통해 이루어집니다.
2. **비용 계산**: 예상된 작업량을 처리하는 데 필요한 I/O와 CPU 비용을 산정합니다.
3. **대안 평가**: 가능한 모든 접근 경로, 조인 순서, 조인 방법을 비교합니다.
4. **최적 선택**: 가장 낮은 비용의 실행 계획을 선택합니다.

이 과정에서 통계 정보는 카디널리티 추정의 기초가 됩니다. 통계가 부정확하면, 모든 후속 결정이 잘못된 방향으로 흘러갈 수 있습니다. 이를 방지하기 위해 Oracle은 다양한 유형의 통계 정보를 제공하며, 각각 특정한 데이터 특성을 설명합니다.

## 통계 정보의 종류와 역할

Oracle 데이터베이스는 여러 층위의 통계 정보를 유지 관리합니다:

| 통계 유형 | 주요 내용 | 역할 | 딕셔너리 뷰 |
|---|---|---|---|
| **테이블 통계** | 행 수, 블록 수, 평균 행 길이 | 기본적인 데이터 크기 이해 | `USER_TAB_STATISTICS` |
| **컬럼 통계** | 고유값 수, NULL 비율, 값 범위 | 데이터 분포와 특성 파악 | `USER_TAB_COL_STATISTICS` |
| **히스토그램** | 값별 빈도 분포 | 편향된 데이터 분포 반영 | `USER_TAB_HISTOGRAMS` |
| **인덱스 통계** | 트리 깊이, 리프 블록 수, 클러스터링 팩터 | 인덱스 구조 효율성 평가 | `USER_INDEXES` |
| **확장 통계** | 컬럼 간 상관관계 | 복합 조건 선택도 정확화 | `USER_STAT_EXTENSIONS` |
| **시스템 통계** | I/O 속도, CPU 성능 | 하드웨어 특성 반영 | `SYS.AUX_STATS$` |

## 실습 환경 설정

통계 정보의 중요성을 직접 체험하기 위해 실습 환경을 구성해 보겠습니다:

```sql
-- 세션 설정
ALTER SESSION SET nls_date_format = 'YYYY-MM-DD';
ALTER SESSION SET statistics_level = ALL;

-- 테이블 생성
CREATE TABLE customers (
    customer_id NUMBER PRIMARY KEY,
    region      VARCHAR2(8) NOT NULL,  -- 지역: KOR, APAC, EMEA, AMER
    tier        VARCHAR2(8) NOT NULL,   -- 등급: VIP, GOLD, SILVER, GENERAL
    join_date   DATE NOT NULL
);

CREATE TABLE products (
    product_id  NUMBER PRIMARY KEY,
    category    VARCHAR2(12) NOT NULL,  -- 카테고리: ELEC, FOOD, TOY, HOME, FASH
    brand       VARCHAR2(12) NOT NULL,   -- 브랜드: B0(30%), B1-B49(나머지)
    price       NUMBER(10,2) NOT NULL
);

CREATE TABLE orders (
    order_id    NUMBER PRIMARY KEY,
    customer_id NUMBER NOT NULL,
    product_id  NUMBER NOT NULL,
    order_date  DATE NOT NULL,
    quantity    NUMBER NOT NULL,
    amount      NUMBER(12,2) NOT NULL
);

-- 인덱스 생성
CREATE INDEX idx_customers_region ON customers(region, customer_id);
CREATE INDEX idx_products_category ON products(category, product_id);
CREATE INDEX idx_orders_customer ON orders(customer_id);
CREATE INDEX idx_orders_product_date ON orders(product_id, order_date);

-- 샘플 데이터 삽입
DECLARE
    TYPE date_array IS TABLE OF DATE;
    v_dates date_array := date_array();
    v_start_date DATE := DATE '2023-01-01';
BEGIN
    -- 2년간의 날짜 배열 생성
    FOR i IN 0..730 LOOP
        v_dates.EXTEND;
        v_dates(i+1) := v_start_date + i;
    END LOOP;
    
    -- 고객 데이터 (50,000명)
    FOR i IN 1..50000 LOOP
        INSERT INTO customers VALUES (
            i,
            CASE MOD(i, 5) 
                WHEN 0 THEN 'KOR' 
                WHEN 1 THEN 'KOR'  -- KOR 비중 높임
                WHEN 2 THEN 'APAC'
                WHEN 3 THEN 'EMEA' 
                ELSE 'AMER' 
            END,
            CASE MOD(i, 4) 
                WHEN 0 THEN 'VIP' 
                WHEN 1 THEN 'GOLD'
                WHEN 2 THEN 'SILVER' 
                ELSE 'GENERAL' 
            END,
            v_dates(MOD(i, 731) + 1)
        );
    END LOOP;
    
    -- 제품 데이터 (12,000개)
    FOR i IN 1..12000 LOOP
        INSERT INTO products VALUES (
            i,
            CASE MOD(i, 5) 
                WHEN 0 THEN 'ELEC' 
                WHEN 1 THEN 'FOOD'
                WHEN 2 THEN 'TOY'  
                WHEN 3 THEN 'HOME' 
                ELSE 'FASH' 
            END,
            CASE 
                WHEN i <= 3600 THEN 'B0'  -- B0이 30% 차지 (편향)
                ELSE 'B' || TO_CHAR(MOD(i, 50) + 1)
            END,
            ROUND(DBMS_RANDOM.VALUE(1000, 100000), 2)
        );
    END LOOP;
    
    -- 주문 데이터 (200,000건)
    FOR i IN 1..200000 LOOP
        INSERT INTO orders VALUES (
            i,
            MOD(i, 50000) + 1,
            MOD(i, 12000) + 1,
            v_dates(MOD(i, 731) + 1),
            1 + MOD(i, 5),
            ROUND(DBMS_RANDOM.VALUE(1000, 50000), 2)
        );
    END LOOP;
    
    COMMIT;
    DBMS_OUTPUT.PUT_LINE('데이터 생성 완료');
END;
/
```

## 테이블 통계: 데이터의 기본 규모 이해

테이블 통계는 데이터의 물리적 크기와 구조에 대한 기본 정보를 제공합니다. 이러한 정보는 전체 테이블 스캔 비용 계산, 조인 순서 결정 등에 활용됩니다.

### 테이블 통계 수집 방법

```sql
-- 권장되는 기본 수집 방법
BEGIN
    DBMS_STATS.GATHER_TABLE_STATS(
        ownname          => USER,
        tabname          => 'ORDERS',
        estimate_percent => DBMS_STATS.AUTO_SAMPLE_SIZE,
        method_opt       => 'FOR ALL COLUMNS SIZE AUTO',
        cascade          => TRUE,  -- 인덱스 통계도 함께 수집
        degree           => DBMS_STATS.AUTO_DEGREE,
        granularity      => 'AUTO'
    );
END;
/
```

### AUTO_SAMPLE_SIZE의 중요성

Oracle 12c 이후부터는 `AUTO_SAMPLE_SIZE` 사용이 사실상 필수입니다. 이 설정은 Oracle이 내부 알고리즘을 통해 적절한 샘플 크기를 자동으로 결정하게 합니다. 특히 최빈값-빈도(Top-Frequency)와 하이브리드(Hybrid) 히스토그램 생성에는 `AUTO_SAMPLE_SIZE`가 필요합니다.

고정된 낮은 샘플링 비율(예: 1%)을 사용하면 데이터 편향(skew)이나 상관관계를 놓칠 위험이 큽니다. 이는 구조적인 카디널리티 오추정으로 이어집니다.

### 파티션 테이블과 증분 통계

대규모 파티션 테이블에서는 전체 통계 재수집이 비효율적일 수 있습니다. 증분 통계(Incremental Statistics) 기능을 사용하면 변경된 파티션만 통계를 수집하고, 글로벌 통계는 시놉시스(synopsis)를 통해 합성할 수 있습니다.

```sql
-- 증분 통계 활성화
BEGIN
    DBMS_STATS.SET_TABLE_PREFS(
        USER, 
        'LARGE_PARTITIONED_TABLE',
        'INCREMENTAL', 
        'TRUE'
    );
    DBMS_STATS.SET_TABLE_PREFS(
        USER, 
        'LARGE_PARTITIONED_TABLE',
        'GRANULARITY', 
        'AUTO'
    );
END;
/
```

이 방식은 파티션 교환 로드(Partition Exchange Load)가 빈번한 데이터 웨어하우스 환경에서 특히 유용합니다. 새 파티션의 통계만 수집하면 글로벌 통계가 자동으로 갱신됩니다.

### 통계 정보 조회

```sql
-- 테이블 통계 확인
SELECT 
    table_name,
    num_rows,
    blocks,
    avg_row_len,
    sample_size,
    last_analyzed,
    stale_stats
FROM user_tab_statistics 
WHERE table_name IN ('CUSTOMERS', 'PRODUCTS', 'ORDERS');

-- 파티션 통계 확인 (파티션 테이블인 경우)
SELECT 
    table_name,
    partition_name,
    num_rows,
    blocks,
    avg_row_len,
    last_analyzed
FROM user_tab_statistics 
WHERE table_name = 'PARTITIONED_TABLE'
AND partition_name IS NOT NULL
ORDER BY partition_name;
```

## 인덱스 통계: 접근 경로 효율성 평가

인덱스 통계는 옵티마이저가 인덱스 사용 여부와 효율성을 판단하는 데 중요한 정보를 제공합니다.

### 클러스터링 팩터: 인덱스 성능의 핵심 지표

클러스터링 팩터(Clustering Factor)는 인덱스 키의 논리적 순서와 테이블 행의 물리적 저장 순서가 얼마나 일치하는지를 나타내는 지표입니다. 이 값은 인덱스 범위 스캔과 중첩 루프 조인의 비용에 직접적인 영향을 미칩니다.

```sql
-- 인덱스 통계 확인
SELECT 
    index_name,
    blevel,           -- B-Tree 깊이
    leaf_blocks,      -- 리프 블록 수
    distinct_keys,    -- 고유 키 값 수
    clustering_factor, -- 클러스터링 팩터
    num_rows,
    last_analyzed
FROM user_indexes 
WHERE table_name = 'ORDERS';

-- 클러스터링 팩터 해석
-- CF ≈ 테이블 블록 수: 인덱스 순서와 물리적 순서가 잘 맞음 (효율적)
-- CF ≈ 테이블 행 수: 인덱스 순서와 물리적 순서가 맞지 않음 (비효율적)
```

클러스터링 팩터가 나쁘면(값이 클수록) 인덱스 스캔 시 랜덤 I/O가 증가하여 중첩 루프 조인의 비용이 급격히 상승합니다. 이 경우 옵티마이저는 해시 조인이나 정렬 병합 조인을 선호하게 됩니다.

### 클러스터링 팩터 개선 방법

1. **인덱스 조직 테이블(IOT) 사용**: 데이터 자체를 인덱스 구조로 저장
2. **정렬된 데이터 로드**: CTAS(Create Table As Select)와 ORDER BY를 사용한 재적재
3. **클러스터 테이블 사용**: 클러스터 키 기준으로 물리적 그룹화
4. **파티셔닝**: 파티션 단위로 데이터 정렬

## 히스토그램: 편향된 데이터 분포 반영

히스토그램은 컬럼 값의 분포 편향을 옵티마이저에게 알려주는 도구입니다. 균등 분포를 가정하는 기본 통계만으로는 'B0' 브랜드가 전체의 30%를 차지하는 현실을 반영할 수 없습니다.

### 히스토그램 유형

Oracle은 버전이 발전함에 따라 히스토그램 유형도 진화해 왔습니다:

| 유형 | 설명 | 생성 조건 |
|---|---|---|
| **Frequency** | 값별 정확한 빈도 저장 | 고유값 수 ≤ 버킷 수 |
| **Top-Frequency** | 최빈값만 정확히 기록 | AUTO_SAMPLE_SIZE 사용 시 |
| **Hybrid** | 최빈값 정확 + 나머지 근사 | AUTO_SAMPLE_SIZE 사용 시 |
| **Height-Balanced** | 구간 균형 분할 (레거시) | 이전 버전 호환성 |

### 히스토그램 생성 및 효과 확인

```sql
-- 히스토그램 없이 통계 수집
BEGIN
    DBMS_STATS.GATHER_TABLE_STATS(
        USER,
        'PRODUCTS',
        estimate_percent => DBMS_STATS.AUTO_SAMPLE_SIZE,
        method_opt => 'FOR COLUMNS SIZE 1 BRAND'  -- 히스토그램 제거
    );
END;
/

-- 히스토그램 생성 후 통계 수집
BEGIN
    DBMS_STATS.GATHER_TABLE_STATS(
        USER,
        'PRODUCTS',
        estimate_percent => DBMS_STATS.AUTO_SAMPLE_SIZE,
        method_opt => 'FOR COLUMNS SIZE 254 BRAND'  -- 히스토그램 생성
    );
END;
/

-- 히스토그램 정보 확인
SELECT 
    column_name,
    num_distinct,
    histogram,
    num_buckets,
    density,
    last_analyzed
FROM user_tab_col_statistics
WHERE table_name = 'PRODUCTS'
AND column_name = 'BRAND';
```

### 히스토그램 효과 실험

```sql
-- 히스토그램이 없을 때의 실행 계획
EXPLAIN PLAN FOR
SELECT COUNT(*) 
FROM products 
WHERE brand = 'B0';  -- 30% 차지

SELECT * FROM TABLE(DBMS_XPLAN.DISPLAY);

-- 히스토그램이 있을 때의 실행 계획
EXPLAIN PLAN FOR
SELECT COUNT(*) 
FROM products 
WHERE brand = 'B47';  -- 매우 드문 값

SELECT * FROM TABLE(DBMS_XPLAN.DISPLAY);
```

히스토그램이 있으면 옵티마이저는:
- 'B0' 같은 빈도 높은 값: 전체 테이블 스캔이나 빠른 전체 인덱스 스캔 선호
- 'B47' 같은 드문 값: 인덱스 범위 스캔 선호

히스토그램이 없으면 옵티마이저는 모든 값을 균등하게 분포된 것으로 가정하여 잘못된 접근 방식을 선택할 수 있습니다.

## 확장 통계: 컬럼 간 상관관계 반영

실제 비즈니스 데이터에서는 컬럼들이 서로 독립적이지 않는 경우가 많습니다. 예를 들어, 특정 지역의 고객들이 특정 등급에 집중되는 패턴이 있을 수 있습니다. 확장 통계(Extended Statistics)는 이러한 상관관계를 통계에 반영합니다.

### 확장 통계 생성

```sql
-- (지역, 등급) 조합에 대한 확장 통계 생성
BEGIN
    -- 확장 통계 생성
    DBMS_STATS.CREATE_EXTENDED_STATS(
        ownname    => USER,
        tabname    => 'CUSTOMERS',
        extension  => '(REGION, TIER)'
    );
    
    -- 통계 수집 (확장 통계 포함)
    DBMS_STATS.GATHER_TABLE_STATS(
        ownname    => USER,
        tabname    => 'CUSTOMERS',
        estimate_percent => DBMS_STATS.AUTO_SAMPLE_SIZE,
        method_opt => 'FOR ALL COLUMNS SIZE AUTO'
    );
END;
/

-- 생성된 확장 통계 확인
SELECT 
    extension_name,
    extension,
    creator,
    droppable
FROM user_stat_extensions
WHERE table_name = 'CUSTOMERS';
```

### 확장 통계 효과 실험

```sql
-- 확장 통계 없을 때
EXPLAIN PLAN FOR
SELECT COUNT(*) 
FROM customers 
WHERE region = 'KOR' AND tier = 'VIP';

SELECT * FROM TABLE(DBMS_XPLAN.DISPLAY);

-- 확장 통계 적용 후
EXPLAIN PLAN FOR
SELECT COUNT(*) 
FROM customers 
WHERE region = 'KOR' AND tier = 'VIP';

SELECT * FROM TABLE(DBMS_XPLAN.DISPLAY);

-- 조인 쿼리에서의 효과
EXPLAIN PLAN FOR
SELECT /*+ NO_EXTENDED_STATS */ 
       COUNT(*)
FROM customers c 
JOIN orders o ON o.customer_id = c.customer_id
WHERE c.region = 'KOR' AND c.tier = 'VIP';

EXPLAIN PLAN FOR
SELECT /*+ WITH_EXTENDED_STATS */ 
       COUNT(*)
FROM customers c 
JOIN orders o ON o.customer_id = c.customer_id
WHERE c.region = 'KOR' AND c.tier = 'VIP';

SELECT * FROM TABLE(DBMS_XPLAN.DISPLAY);
```

확장 통계가 있으면 옵티마이저는 독립 가정 대신 실제 조합 빈도를 사용하여 더 정확한 카디널리티를 추정합니다. 이는 조인 순서, 조인 방법, 접근 경로 선택에 긍정적인 영향을 미칩니다.

## SQL 계획 지시자: 자동 학습 메커니즘

SQL 계획 지시자(SQL Plan Directive, SPD)는 Oracle의 적응형 최적화 기능의 일부입니다. 옵티마이저가 반복적으로 카디널리티 오류를 감지하면 SPD를 생성하고, 다음 통계 수집 시점에 자동으로 확장 통계나 표현식 통계 생성을 유도합니다.

```sql
-- SPD 정보 확인
SELECT 
    directive_id,
    type,
    reason,
    state,
    created,
    last_modified
FROM dba_sql_plan_directives
WHERE owner = USER
AND table_name = 'CUSTOMERS';

-- SPD 기반 자동 생성 통계 확인
SELECT 
    extension_name,
    extension,
    creator
FROM user_stat_extensions
WHERE creator = 'SYS'
AND table_name = 'CUSTOMERS';
```

SPD는 편리한 기능이지만, 과도하게 생성되면 SYSAUX 테이블스페이스 관리 부담이 증가할 수 있습니다. 주기적인 점검과 불필요한 SPD 정리가 필요할 수 있습니다.

## 실시간 통계: 대량 데이터 변경에 대한 즉시 대응

전통적인 통계 수집은 배치 작업으로 이루어지기 때문에, 대량 데이터 로드 직후에는 통계가 현재 상태를 반영하지 못하는 '공백 시간'이 발생할 수 있습니다. 실시간 통계(Real-Time Statistics) 기능은 이 문제를 해결합니다.

실시간 통계는 대량 DML 작업 중에 실시간으로 생성되어, 옵티마이저가 최신 데이터 분포를 즉시 반영할 수 있게 합니다. 특히 ETL 작업 후 바로 해당 데이터를 조회하는 데이터 웨어하우스 환경에서 중요한 기능입니다.

```sql
-- 실시간 통계 활성화 확인
SELECT 
    table_name,
    notes
FROM user_tab_statistics
WHERE table_name = 'ORDERS'
AND notes LIKE '%REALTIME%';

-- 대량 데이터 로드 후 통계 확인
INSERT INTO orders 
SELECT * FROM orders_staging WHERE order_date > SYSDATE - 7;
-- 100만 건 삽입

COMMIT;

-- 실시간 통계가 자동으로 생성됨
EXPLAIN PLAN FOR
SELECT COUNT(*) 
FROM orders 
WHERE order_date > SYSDATE - 1;

SELECT * FROM TABLE(DBMS_XPLAN.DISPLAY);
```

## 시스템 통계: 하드웨어 특성 반영

시스템 통계는 데이터베이스 서버의 물리적 성능 특성을 옵티마이저에게 알려줍니다. 이를 통해 옵티마이저는 추상적인 비용 계산이 아닌, 실제 하드웨어에서의 실행 시간을 더 정확히 예측할 수 있습니다.

### 시스템 통계 수집 방법

```sql
-- NOWORKLOAD 방식 (기본)
BEGIN
    DBMS_STATS.GATHER_SYSTEM_STATS('NOWORKLOAD');
END;
/

-- WORKLOAD 방식 (정밀)
BEGIN
    -- 측정 시작
    DBMS_STATS.GATHER_SYSTEM_STATS('START');
    
    -- 대표적인 워크로드 실행 (운영 시간대)
    -- ...
    
    -- 측정 종료
    DBMS_STATS.GATHER_SYSTEM_STATS('STOP');
END;
/

-- 시스템 통계 확인
SELECT 
    pname,
    pval1,
    pval2
FROM sys.aux_stats$
WHERE sname = 'SYSSTATS_MAIN';
```

### 주요 시스템 통계 파라미터

- **CPUSPEED**: CPU 성능 (초당 표준 작업 수)
- **SREADTIM**: 단일 블록 읽기 평균 시간 (ms)
- **MREADTIM**: 다중 블록 읽기 평균 시간 (ms)
- **MBRC**: 다중 블록 읽기 시 평균 블록 수

이러한 값들은 비용 계산의 기준이 됩니다. 예를 들어 SSD 환경에서는 SREADTIM이 HDD에 비해 현저히 낮으므로, 옵티마이저는 인덱스 기반 랜덤 액세스를 더 선호하게 됩니다.

## 통계 관리의 고급 기법

### 대기 통계(Pending Statistics)

운영 환경에서는 통계 변경이 예상치 못한 성능 문제를 일으킬 수 있습니다. 대기 통계 기능을 사용하면 변경된 통계를 먼저 테스트한 후에만 프로덕션에 적용할 수 있습니다.

```sql
-- 대기 통계 모드로 통계 수집
BEGIN
    DBMS_STATS.SET_TABLE_PREFS(
        USER, 
        'ORDERS', 
        'PUBLISH', 
        'FALSE'
    );
    
    DBMS_STATS.GATHER_TABLE_STATS(
        USER,
        'ORDERS',
        estimate_percent => DBMS_STATS.AUTO_SAMPLE_SIZE
    );
END;
/

-- 대기 통계로 테스트
ALTER SESSION SET optimizer_use_pending_statistics = TRUE;

-- 테스트 쿼리 실행
EXPLAIN PLAN FOR
SELECT COUNT(*) FROM orders WHERE order_date > SYSDATE - 30;

SELECT * FROM TABLE(DBMS_XPLAN.DISPLAY);

-- 테스트 통과 시 프로덕션 적용
BEGIN
    DBMS_STATS.PUBLISH_PENDING_STATS(USER, 'ORDERS');
END;
/
```

### 통계 잠금(Locking Statistics)

중요한 테이블의 통계가 실수로 변경되는 것을 방지하기 위해 통계 잠금 기능을 사용할 수 있습니다.

```sql
-- 통계 잠금
BEGIN
    DBMS_STATS.LOCK_TABLE_STATS(USER, 'CRITICAL_TABLE');
END;
/

-- 통계 잠금 확인
SELECT 
    table_name,
    stattype_locked
FROM user_tab_statistics
WHERE table_name = 'CRITICAL_TABLE';

-- 통계 잠금 해제
BEGIN
    DBMS_STATS.UNLOCK_TABLE_STATS(USER, 'CRITICAL_TABLE');
END;
/
```

### 통계 백업 및 복원

통계 변경으로 인한 문제가 발생했을 때 빠르게 복구할 수 있도록 통계 백업을 정기적으로 수행하는 것이 좋습니다.

```sql
-- 통계 백업 테이블 생성
EXEC DBMS_STATS.CREATE_STAT_TABLE(USER, 'STATS_BACKUP');

-- 통계 내보내기
BEGIN
    DBMS_STATS.EXPORT_TABLE_STATS(
        ownname   => USER,
        tabname   => 'ORDERS',
        stattab   => 'STATS_BACKUP',
        statid    => 'BACKUP_202405'
    );
END;
/

-- 통계 가져오기 (복원)
BEGIN
    DBMS_STATS.IMPORT_TABLE_STATS(
        ownname   => USER,
        tabname   => 'ORDERS',
        stattab   => 'STATS_BACKUP',
        statid    => 'BACKUP_202405'
    );
END;
/

-- 특정 시점으로 통계 복원
BEGIN
    DBMS_STATS.RESTORE_TABLE_STATS(
        ownname   => USER,
        tabname   => 'ORDERS',
        as_of_timestamp => SYSTIMESTAMP - INTERVAL '1' HOUR
    );
END;
/
```

## 통계 문제 진단 프레임워크

통계 관련 문제를 체계적으로 진단하기 위한 접근법:

### 1단계: 실행 계획 분석

```sql
-- 상세 실행 계획 분석
SELECT *
FROM TABLE(DBMS_XPLAN.DISPLAY_CURSOR(
    sql_id => :problem_sql_id,
    format => 'ALLSTATS LAST +PREDICATE +NOTE +ALIAS'
));

-- 카디널리티 오류 식별
SELECT 
    operation,
    options,
    object_name,
    cardinality as estimated_rows,
    last_output_rows as actual_rows,
    ROUND((last_output_rows - cardinality) / 
          NULLIF(cardinality, 0) * 100, 2) as error_percent
FROM v$sql_plan_monitor
WHERE sql_id = :problem_sql_id
AND cardinality > 0
ORDER BY id;
```

### 2단계: 통계 상태 점검

```sql
-- 통계 최신성 확인
SELECT 
    table_name,
    num_rows,
    last_analyzed,
    stale_stats,
    ROUND((SYSDATE - last_analyzed), 2) as days_since_analyzed
FROM user_tab_statistics
WHERE last_analyzed IS NOT NULL
ORDER BY last_analyzed;

-- 히스토그램 존재 여부 확인
SELECT 
    table_name,
    column_name,
    histogram,
    num_buckets,
    last_analyzed
FROM user_tab_col_statistics
WHERE histogram != 'NONE'
ORDER BY table_name, column_name;

-- 확장 통계 확인
SELECT 
    table_name,
    extension_name,
    extension
FROM user_stat_extensions
ORDER BY table_name;
```

### 3단계: 데이터 분포 분석

```sql
-- 컬럼 값 분포 분석
SELECT 
    region,
    tier,
    COUNT(*) as count,
    ROUND(COUNT(*) * 100.0 / SUM(COUNT(*)) OVER(), 2) as percentage
FROM customers
GROUP BY region, tier
ORDER BY region, tier;

-- 조인 카디널리티 분석
SELECT 
    c.region,
    COUNT(DISTINCT o.order_id) as order_count,
    COUNT(*) as total_rows,
    AVG(o.amount) as avg_amount
FROM customers c
JOIN orders o ON o.customer_id = c.customer_id
GROUP BY c.region
ORDER BY order_count DESC;
```

## 결론: 통계 정보 관리의 종합적 접근법

Oracle 옵티마이저 통계 정보는 단순한 메타데이터가 아니라, 데이터베이스 최적화의 핵심 기반입니다. 효과적인 통계 관리 전략은 다음과 같은 원칙을 기반으로 해야 합니다:

### 1. 적절한 수집 전략 수립
- `AUTO_SAMPLE_SIZE`를 기본으로 사용하여 최신 히스토그램 유형 활용
- 데이터 변화 패턴에 맞는 수집 주기 설정 (STALE_PERCENT 조정)
- 대규모 파티션 테이블은 증분 통계 활용

### 2. 데이터 특성에 맞는 통계 구성
- 편향된 데이터 분포에는 히스토그램 필수 적용
- 상관관계가 있는 컬럼 조합은 확장 통계로 관리
- 인덱스 효율성 평가를 위한 클러스터링 팩터 모니터링

### 3. 안전한 운영 프레임워크 구축
- 대기 통계를 통한 변경 전 테스트
- 중요 테이블은 통계 잠금으로 보호
- 정기적인 통계 백업으로 복구 체계 마련

### 4. 지속적인 모니터링과 튜닝
- 실행 계획의 예상/실제 행 수 차이 모니터링
- SQL 계획 지시자 생성 패턴 분석
- 시스템 환경 변화에 따른 통계 재수집

통계 정보의 질은 옵티마이저의 결정 질을 직접적으로 결정합니다. 정확하고 시의적절한 통계는 복잡한 힌트나 강제적인 실행 계획 고정 없이도 최적의 성능을 달성할 수 있는 기반을 제공합니다. 반대로, 부정확한 통계는 아무리 정교한 튜닝 기법을 적용하더라도 근본적인 해결을 제공하지 못합니다.

데이터베이스 성능 최적화에서 통계 정보 관리의 우선순위를 높이고, 체계적인 접근법을 적용할 때, 예측 가능하고 지속 가능한 성능 개선을 달성할 수 있습니다. 통계는 옵티마이저의 눈과 귀입니다. 이 감각 기관을 정확하게 유지하는 것이 데이터베이스 전문가의 핵심 임무 중 하나입니다.