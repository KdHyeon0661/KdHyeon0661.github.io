---
layout: post
title: DB 심화 - ASH
date: 2025-10-24 21:25:23 +0900
category: DB 심화
---
# ASH와 AWR의 연계 활용: 장기 추적과 실시간 분석의 조화

## AWR과 ASH의 관계: 거시와 미시의 이중주

AWR(Automatic Workload Repository)과 ASH(Active Session History)는 성능 분석에서 **상호 보완적**인 관계입니다.

```
[실시간 현장]
    ↓ (1초 간격 샘플링)
    ASH (V$ACTIVE_SESSION_HISTORY)
    ↓ (1시간 간격 AWR 스냅샷)
    AWR (DBA_HIST_*)
    ↓ (요약 보관)
    DBA_HIST_ACTIVE_SESS_HISTORY
```

**핵심 차이점:**
- **AWR**: 1시간 단위의 **통계 요약**. '무엇이' 문제인지 방향성 제시.
- **ASH**: 1초 단위의 **활동 상세**. '왜', '언제', '어떻게' 문제가 발생했는지 증명.

---

## 실전 연계 분석 시나리오: 주간 성능 추적

### 단계 1: AWR로 문제 시간대 식별하기

매주 월요일 오전 10시에 성능 저하가 반복된다고 가정합니다.

```sql
-- 1. 최근 일주일 AWR 리포트 ID 찾기
SELECT snap_id,
       instance_number,
       TO_CHAR(begin_interval_time, 'YYYY-MM-DD HH24:MI') AS begin_time,
       TO_CHAR(end_interval_time, 'YYYY-MM-DD HH24:MI') AS end_time
FROM   dba_hist_snapshot
WHERE  begin_interval_time >= SYSDATE - 7
  AND  EXTRACT(HOUR FROM begin_interval_time) BETWEEN 9 AND 11  -- 오전 9-11시
  AND  TO_CHAR(begin_interval_time, 'DY', 'NLS_DATE_LANGUAGE=AMERICAN') = 'MON'
ORDER BY begin_interval_time DESC;

-- 2. 특정 AWR 구간 선택 (예: snap_id 1001~1002)
--    AWR 리포트 생성 또는 직접 쿼리
SELECT stat_name,
       value
FROM   dba_hist_sysstat
WHERE  snap_id BETWEEN 1001 AND 1002
  AND  stat_name IN ('DB time', 'CPU used by this session', 'user commits')
ORDER BY value DESC;
```

### 단계 2: AWR에서 발견된 문제를 ASH로 드릴다운

AWR에서 'DB Time'이 급증한 구간을 발견했다면, 해당 구간의 ASH 데이터를 상세 분석합니다.

```sql
-- AWR 스냅샷 시간을 ASH 분석 시간으로 변환
SELECT snap.begin_interval_time AS awr_start,
       snap.end_interval_time AS awr_end
FROM   dba_hist_snapshot snap
WHERE  snap.snap_id = 1001;

-- 해당 기간 ASH 데이터 분석 (히스토리 테이블 사용)
SELECT 
    TO_CHAR(TRUNC(ash.sample_time, 'MI'), 'HH24:MI') AS minute,
    ash.wait_class,
    ash.event,
    COUNT(*) AS sample_count,
    ROUND(100 * RATIO_TO_REPORT(COUNT(*)) OVER (PARTITION BY TRUNC(ash.sample_time, 'MI')), 1) AS pct_per_minute
FROM   dba_hist_active_sess_history ash
WHERE  ash.sample_time BETWEEN TO_DATE('2024-01-15 09:50:00', 'YYYY-MM-DD HH24:MI:SS')
                          AND TO_DATE('2024-01-15 10:10:00', 'YYYY-MM-DD HH24:MI:SS')
  AND  ash.session_type = 'FOREGROUND'
GROUP BY TRUNC(ash.sample_time, 'MI'), ash.wait_class, ash.event
HAVING COUNT(*) > 10  -- 의미 있는 샘플 수만
ORDER BY minute, sample_count DESC;
```

**실전 팁**: AWR에서 `Top 5 Timed Foreground Events`를 먼저 확인한 후, 그 이벤트를 중심으로 ASH를 분석하면 효율적입니다.

---

## SQL Monitor와 ASH의 연동: 실행 단계별 미시 분석

SQL Monitor는 실행 중인 SQL의 **실시간 진행 상황**을 보여줍니다. ASH와 결합하면 더 강력한 분석이 가능합니다.

### 사례: 느린 배치 작업 분석

```sql
-- 1. 현재 실행 중인 오래 걸리는 SQL 찾기 (SQL Monitor)
SELECT sql_id,
       sql_exec_id,
       sql_exec_start,
       elapsed_time / 1000000 AS elapsed_sec
FROM   v$sql_monitor
WHERE  status = 'EXECUTING'
  AND  elapsed_time / 1000000 > 300  -- 5분 이상 실행 중
ORDER BY elapsed_time DESC;

-- 2. 특정 SQL의 SQL Monitor 리포트 보기
SELECT dbms_sqltune.report_sql_monitor(
         sql_id => '&SQL_ID',
         sql_exec_id => &SQL_EXEC_ID,
         type => 'TEXT',
         report_level => 'ALL') AS monitor_report
FROM dual;
```

**SQL Monitor 리포트에서 주목할 부분:**
```
SQL Plan Monitoring Details (Plan Hash Value=3960770243)
===================================================================================================================================
| Id |        Operation         | Name |  Rows   | Cost |   Time    | Start  | Execs |   Rows   | Read | Read  | Activity | Activity Detail |
|    |                          |      | (Estim) |      | Active(s) | Active |       | (Actual) | Reqs | Bytes |   (%)    |   (# samples)   |
===================================================================================================================================
|  0 | SELECT STATEMENT         |      |         |      |       600 |     +0 |     1 |       0 |      |       |          |                 |
|  1 |   HASH JOIN              |      |      1M | 1234 |       600 |     +0 |     1 |       0 | 125k | 975MB |    85.0  | Cpu (35)        |
|    |                          |      |         |      |           |        |       |         |      |       |          | direct path read temp (210) |
|  2 |    TABLE ACCESS FULL     | T1   |    100K |  234 |       300 |     +0 |     1 |    100K |  50k | 390MB |    15.0  | Cpu (90)        |
|  3 |    TABLE ACCESS FULL     | T2   |     10M | 1000 |       300 |   +300 |     1 |     10M |  75k | 585MB |          |                 |
===================================================================================================================================
```

**여기서 ASH를 연결하면:**
- `direct path read temp (210 samples)` → ASH에서 해당 SQL의 `sql_plan_line_id=1` 구간을 필터링
- 210개 샘플이 **어느 정확한 시간대에** 집중되었는지 확인 가능

```sql
-- SQL Monitor에서 발견된 문제 라인의 ASH 상세 분석
SELECT 
    TO_CHAR(ash.sample_time, 'HH24:MI:SS') AS exact_time,
    ash.session_state,
    ash.event,
    ash.time_waited
FROM   v$active_session_history ash
WHERE  ash.sql_id = '&SQL_ID'
  AND  ash.sql_exec_id = &SQL_EXEC_ID
  AND  ash.sql_plan_line_id = 1  -- 문제 라인 ID
  AND  ash.sample_time > SYSTIMESTAMP - INTERVAL '10' MINUTE
ORDER BY ash.sample_time;
```

---

## RAC 환경에서의 ASH 분석: 인스턴스 간 경합 추적

RAC 환경에서는 `GV$` 글로벌 뷰를 사용하여 모든 인스턴스의 ASH 데이터를 통합 분석해야 합니다.

### 글로벌 핫 블록 식별

```sql
-- RAC 전체에서 가장 핫한 블록 찾기
SELECT 
    ash.instance_number,
    ash.current_obj#,
    ash.current_file#,
    ash.current_block#,
    COUNT(*) AS global_samples,
    -- 오브젝트 정보 조인
    obj.owner,
    obj.object_name,
    obj.object_type
FROM   gv$active_session_history ash
LEFT JOIN dba_objects obj 
       ON obj.object_id = ash.current_obj#
WHERE  ash.sample_time > SYSTIMESTAMP - INTERVAL '15' MINUTE
  AND  ash.session_type = 'FOREGROUND'
  AND  ash.current_obj# IS NOT NULL
GROUP BY ash.instance_number, ash.current_obj#, ash.current_file#, 
         ash.current_block#, obj.owner, obj.object_name, obj.object_type
HAVING COUNT(*) > 50  -- 충분히 높은 샘플 수
ORDER BY global_samples DESC
FETCH FIRST 20 ROWS ONLY;
```

### 인스턴스 간 로드 불균형 분석

```sql
-- 서비스별 인스턴스 부하 분포
WITH service_load AS (
    SELECT 
        ash.service_hash,
        ash.instance_number,
        COUNT(*) AS samples,
        SUM(CASE WHEN ash.event LIKE 'gc%' THEN 1 ELSE 0 END) AS gc_samples
    FROM   gv$active_session_history ash
    WHERE  ash.sample_time > SYSTIMESTAMP - INTERVAL '30' MINUTE
      AND  ash.session_type = 'FOREGROUND'
    GROUP BY ash.service_hash, ash.instance_number
)
SELECT 
    s.name AS service_name,
    sl.instance_number,
    sl.samples,
    sl.gc_samples,
    ROUND(100 * sl.gc_samples / NULLIF(sl.samples, 0), 1) AS gc_pct,
    ROUND(100 * RATIO_TO_REPORT(sl.samples) 
          OVER (PARTITION BY sl.service_hash), 1) AS distribution_pct
FROM   service_load sl
JOIN   v$active_services s 
       ON s.service_hash = sl.service_hash
WHERE  sl.samples > 100
ORDER BY sl.service_hash, sl.samples DESC;
```

**실전 인사이트**: 
- 특정 서비스가 한 인스턴스에 90% 이상 집중되고, `gc` 대기 비율이 높다면 → **서비스 어피니티(Service Affinity)** 설정 필요
- 모든 인스턴스에서 특정 블록에 대한 `gc buffer busy`가 높다면 → **핫 블록 분산** 필요 (파티셔닝, Reverse Key 등)

---

## 장기간 ASH 데이터 분석: 패턴과 트렌드 발견

`DBA_HIST_ACTIVE_SESS_HISTORY`는 보통 7-30일 동안의 상세 ASH 데이터를 보관합니다. 이를 활용한 트렌드 분석은 매우 가치 있습니다.

### 주간 패턴 분석

```sql
-- 지난 2주간 시간대별 대기 클래스 패턴
SELECT 
    TO_CHAR(TRUNC(ash.sample_time, 'HH24'), 'DAY') AS day_of_week,
    EXTRACT(HOUR FROM ash.sample_time) AS hour_of_day,
    ash.wait_class,
    COUNT(*) AS total_samples,
    ROUND(AVG(CASE WHEN ash.event LIKE 'gc%' THEN 1 ELSE 0 END) * 100, 1) AS avg_gc_pct
FROM   dba_hist_active_sess_history ash
WHERE  ash.sample_time >= TRUNC(SYSDATE) - 14
  AND  ash.sample_time < TRUNC(SYSDATE)
  AND  ash.session_type = 'FOREGROUND'
GROUP BY 
    TO_CHAR(TRUNC(ash.sample_time, 'HH24'), 'DAY'),
    EXTRACT(HOUR FROM ash.sample_time),
    ash.wait_class
HAVING COUNT(*) > 1000  -- 충분한 데이터가 있는 시간대만
ORDER BY 
    MIN(ash.sample_time),
    hour_of_day,
    total_samples DESC;
```

### 점진적 성능 저하 탐지 (성능 회귀 분석)

```sql
-- 같은 SQL의 실행 패턴이 시간에 따라 어떻게 변하는지
WITH sql_trend AS (
    SELECT 
        TRUNC(ash.sample_time, 'DD') AS day,
        ash.sql_id,
        ash.sql_plan_hash_value,
        COUNT(*) AS exec_samples,
        SUM(CASE WHEN ash.event = 'db file sequential read' THEN 1 ELSE 0 END) AS seq_read_samples,
        SUM(CASE WHEN ash.event = 'direct path read temp' THEN 1 ELSE 0 END) AS temp_read_samples
    FROM   dba_hist_active_sess_history ash
    WHERE  ash.sql_id = '&문제_SQL_ID'
      AND  ash.sample_time >= SYSDATE - 30
    GROUP BY TRUNC(ash.sample_time, 'DD'), ash.sql_id, ash.sql_plan_hash_value
)
SELECT 
    day,
    sql_plan_hash_value,
    exec_samples,
    seq_read_samples,
    temp_read_samples,
    ROUND(100 * seq_read_samples / NULLIF(exec_samples, 0), 1) AS seq_read_pct_day,
    ROUND(100 * temp_read_samples / NULLIF(exec_samples, 0), 1) AS temp_read_pct_day,
    -- 7일 이동 평균 (트렌드 확인)
    ROUND(AVG(100 * seq_read_samples / NULLIF(exec_samples, 0)) 
          OVER (ORDER BY day ROWS BETWEEN 6 PRECEDING AND CURRENT ROW), 1) AS seq_read_7d_avg
FROM   sql_trend
ORDER BY day DESC;
```

**이 분석으로 알 수 있는 것:**
- 실행 계획이 언제 변경되었는지(`sql_plan_hash_value` 변화)
- 특정 날짜부터 I/O 패턴이 어떻게 변했는지
- 성능 저하가 점진적인지 갑작스러운지

---

## 실제 사례 연구: 전자상거래 체크아웃 지연 문제

### 문제 상황
- 매일 오후 2시~4시 사이 체크아웃 응답 시간이 2초에서 15초로 증가
- AWR에서는 `enq: TX - row lock contention`이 1위 이벤트

### 분석 과정

**1단계: AWR로 문제 범위 좁히기**
```sql
-- 체크아웃 관련 서비스의 AWR 통계
SELECT stat_name, value
FROM   dba_hist_service_stat
WHERE  service_name = 'CHECKOUT_SVC'
  AND  snap_id IN (1005, 1006)  -- 문제 시간대 스냅샷
ORDER BY value DESC;
```

**2단계: ASH로 상세 패턴 분석**
```sql
-- 오후 2-4시 체크아웃 서비스의 상세 ASH
SELECT 
    EXTRACT(MINUTE FROM ash.sample_time) AS minute_mark,
    ash.event,
    ash.current_obj#,
    COUNT(*) AS lock_samples,
    -- 블로킹 관계 분석
    COUNT(DISTINCT ash.blocking_session) AS unique_blockers
FROM   dba_hist_active_sess_history ash
WHERE  ash.service_hash = (SELECT service_hash FROM v$active_services 
                           WHERE name = 'CHECKOUT_SVC')
  AND  ash.sample_time BETWEEN TO_DATE('2024-01-15 14:00:00', 'YYYY-MM-DD HH24:MI:SS')
                          AND TO_DATE('2024-01-15 16:00:00', 'YYYY-MM-DD HH24:MI:SS')
  AND  ash.event LIKE 'enq: TX%'
GROUP BY EXTRACT(MINUTE FROM ash.sample_time), ash.event, ash.current_obj#
ORDER BY minute_mark, lock_samples DESC;
```

**3단계: 문제 오브젝트 특정 및 근본 원인 분석**
```sql
-- 락이 발생한 오브젝트 확인
SELECT obj.owner, obj.object_name, obj.object_type
FROM   dba_objects obj
WHERE  obj.object_id IN (
    SELECT DISTINCT current_obj#
    FROM   dba_hist_active_sess_history
    WHERE  service_hash = (SELECT service_hash FROM v$active_services 
                           WHERE name = 'CHECKOUT_SVC')
      AND  event LIKE 'enq: TX%'
      AND  sample_time BETWEEN TO_DATE('2024-01-15 14:00:00', 'YYYY-MM-DD HH24:MI:SS')
                          AND TO_DATE('2024-01-15 16:00:00', 'YYYY-MM-DD HH24:MI:SS')
);

-- 해당 테이블의 인덱스 상태 확인 (FK 인덱스 부재 가능성)
SELECT table_name, constraint_name, constraint_type
FROM   user_constraints
WHERE  table_name = 'ORDERS'
  AND  constraint_type = 'R';  -- 외래 키 제약

-- 외래 키 인덱스 확인
SELECT index_name, column_name
FROM   user_ind_columns
WHERE  table_name = 'ORDERS'
ORDER BY index_name, column_position;
```

**4단계: 발견 및 해결**
- 발견: `ORDERS` 테이블의 `CUSTOMER_ID` 컬럼에 외래 키 제약은 있으나 인덱스가 없음
- 패턴: 오후 2시부터 대량의 주문 업데이트 시작 → `CUSTOMER_ID`로 조회/갱신 시 부모 테이블(`CUSTOMERS`)의 행에 대한 TM 락 발생
- 해결: `CUSTOMER_ID` 컬럼에 인덱스 생성
- 결과: 다음 날 같은 시간대 체크아웃 응답 시간이 15초에서 2.5초로 개선

---

## 고급 분석 기법: Machine Learning 준비 데이터 생성

ASH 데이터는 시간序列 데이터이므로 ML 모델 학습에도 활용할 수 있습니다.

### 성능 이상 탐지(Anomaly Detection)용 특징 추출

```sql
-- 시간대별 성능 특징 추출 (훈련 데이터 생성)
SELECT 
    TRUNC(sample_time, 'HH24') AS hour_bucket,
    -- 기본 통계
    COUNT(*) AS total_samples,
    SUM(CASE WHEN session_state = 'ON CPU' THEN 1 ELSE 0 END) AS cpu_samples,
    SUM(CASE WHEN wait_class = 'User I/O' THEN 1 ELSE 0 END) AS user_io_samples,
    SUM(CASE WHEN wait_class = 'Concurrency' THEN 1 ELSE 0 END) AS concurrency_samples,
    -- 대기 이벤트 다양성 (엔트로피)
    COUNT(DISTINCT event) AS unique_events,
    -- 블로킹 지표
    COUNT(DISTINCT blocking_session) AS active_blockers,
    SUM(CASE WHEN blocking_session IS NOT NULL THEN 1 ELSE 0 END) AS blocked_samples,
    -- SQL 다양성
    COUNT(DISTINCT sql_id) AS unique_sqls,
    -- 서비스 부하 분포
    COUNT(DISTINCT service_hash) AS active_services
FROM   dba_hist_active_sess_history
WHERE  sample_time >= SYSDATE - 90  -- 3개월 데이터
  AND  session_type = 'FOREGROUND'
GROUP BY TRUNC(sample_time, 'HH24')
ORDER BY hour_bucket;
```

### 실시간 이상 탐지 쿼리

```sql
-- 현재 시간대 패턴과 과거 평균 비교
WITH current_hour AS (
    SELECT 
        COUNT(*) AS curr_samples,
        SUM(CASE WHEN wait_class = 'Concurrency' THEN 1 ELSE 0 END) AS curr_concurrency,
        COUNT(DISTINCT sql_id) AS curr_unique_sqls
    FROM   v$active_session_history
    WHERE  sample_time > SYSDATE - INTERVAL '1' HOUR
      AND  session_type = 'FOREGROUND'
),
historical_avg AS (
    SELECT 
        AVG(total_samples) AS avg_samples,
        AVG(concurrency_samples) AS avg_concurrency,
        AVG(unique_sqls) AS avg_unique_sqls,
        STDDEV(total_samples) AS std_samples
    FROM   (
        SELECT 
            TRUNC(sample_time, 'HH24') AS hour_bucket,
            COUNT(*) AS total_samples,
            SUM(CASE WHEN wait_class = 'Concurrency' THEN 1 ELSE 0 END) AS concurrency_samples,
            COUNT(DISTINCT sql_id) AS unique_sqls
        FROM   dba_hist_active_sess_history
        WHERE  sample_time >= SYSDATE - 30
          AND  EXTRACT(HOUR FROM sample_time) = EXTRACT(HOUR FROM SYSDATE)  -- 같은 시간대
          AND  session_type = 'FOREGROUND'
        GROUP BY TRUNC(sample_time, 'HH24')
    )
)
SELECT 
    curr_samples,
    ROUND(avg_samples, 0) AS hist_avg_samples,
    ROUND((curr_samples - avg_samples) / NULLIF(std_samples, 0), 1) AS z_score,
    CASE 
        WHEN (curr_samples - avg_samples) / NULLIF(std_samples, 0) > 3 THEN '🚨 심각한 이상'
        WHEN (curr_samples - avg_samples) / NULLIF(std_samples, 0) > 2 THEN '⚠️ 주의 필요'
        ELSE '정상 범위'
    END AS anomaly_level
FROM   current_hour, historical_avg;
```

---

## 결론: ASH 마스터를 위한 실전 체크리스트

1. **정기적인 AWR-ASH 연계 분석** 수행
   - 주간 리포트에서 문제 지표 발견 → ASH로 드릴다운 분석

2. **기본 분석 패턴 확립**
   ```
   AWR Top Events → ASH 시간대 필터링 → Top SQL 식별 → 
   실행 계획 라인 확인 → 추가 차원(서비스/모듈) 분석
   ```

3. **RAC 환경에서는 GV$ 뷰 필수 사용**
   - 인스턴스 간 비교 분석
   - 글로벌 핫 블록/서비스 식별

4. **SQL Monitor와의 시너지 활용**
   - 실시간 실행 분석 + 과거 패턴 분석 조합

5. **장기 트렌드 모니터링**
   - `DBA_HIST_ACTIVE_SESS_HISTORY`를 활용한 성능 회귀 탐지

6. **자동화 및 경고 시스템 구축**
   - 이상 탐지 쿼리를 기반으로 한 프로액티브 모니터링

ASH는 단순한 모니터링 도구를 넘어, **데이터베이스의 심장박동을 듣는 청진기**와 같습니다. 정기적으로 들어보고, 패턴을 이해하고, 변화에 민감하게 반응할 때, 비로소 진정한 성능 예측과 최적화가 가능해집니다. 성공적인 성능 관리는 한 번의 대응이 아니라, ASH 데이터를 통한 지속적인 대화와 학습의 과정입니다.