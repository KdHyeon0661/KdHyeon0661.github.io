---
layout: post
title: 영상처리 - 동영상 처리와 움직임 추정 (C#)
date: 2025-12-11 19:30:23 +0900
category: 영상처리
---
# 동영상 처리와 움직임 추정

## 동영상 처리의 개요

동영상은 **시간 축을 포함한 영상의 집합**으로 정의되며, 연속적인 프레임 시퀀스로 구성된다. 동영상 처리는 정지 영상 처리에 시간적 차원이 추가되어 다음과 같은 3차원 함수로 표현된다:

$$
f(x, y, t)
$$

여기서 $t$는 프레임 인덱스(시간)이며, 움직임 추정은 **연속 프레임 간 변화**를 분석하는 과정이다.

### 동영상 처리의 특성과 도전 과제

| 특성 | 설명 | 도전 과제 |
|------|------|-----------|
| **시간적 연속성** | 프레임 간 높은 상관관계 | 움직임 연속성 모델링 |
| **큰 데이터량** | 초당 24-60 프레임 | 실시간 처리 및 저장 |
| **다중 해상도** | 공간적 + 시간적 해상도 | 다중 스케일 분석 |
| **움직임 다양성** | 병진, 회전, 확대/축소 | 복잡한 움직임 모델링 |
| **실시간 요구** | 많은 응용에서 실시간 필요 | 알고리즘 효율성 |

### 동영상 처리 파이프라인

```
동영상 입력 → 프레임 추출 → 전처리 → 움직임 분석 → 후처리 → 결과
     ↓           ↓          ↓          ↓          ↓       ↓
 파일/스트림   프레임별   노이즈 제거  모션 벡터  객체 추적  비디오
              이미지로    색상 보정     계산      이벤트 감지  출력
```

---

## 비디오 파일 포맷과 코덱

### 비디오 파일 구조 비교표

| 포맷 | 컨테이너 | 영상 코덱 | 오디오 코덱 | 특징 |
|------|----------|-----------|-------------|------|
| **AVI** | RIFF | 다양한 코덱 | PCM/MP3 | 비압축/압축 모두 지원 |
| **MP4** | MPEG-4 | H.264/HEVC | AAC | 높은 압축률, 넓은 호환성 |
| **MKV** | Matroska | 다양한 코덱 | 다양한 코덱 | 오픈 포맷, 자막 내장 |
| **MOV** | QuickTime | 다양한 코덱 | 다양한 코덱 | 애플 생태계 최적화 |
| **WebM** | WebM | VP8/VP9 | Opus/Vorbis | 웹 최적화, 로열티 프리 |

### AVI 파일 포맷 상세 구조 (RIFF 기반)

AVI(Audio Video Interleave) 파일은 RIFF(Resource Interchange File Format)를 기반으로 한다.

```
AVI 파일 구조 계층:
┌─────────────────────────────────────────────────────────┐
│                    RIFF AVI Chunk                        │
├─────────────────┬─────────────────┬─────────────────────┤
│ "RIFF" 헤더     │ 파일 크기        │ "AVI " 포맷         │
├─────────────────┴───────────────────────────────────────┤
│                   LIST 'hdrl' 청크                       │
│ ├────────────────┬────────────────┬────────────────────┤
│ │ avih (메인 헤더)│ strl (스트림 리스트)│ ...             │
│ │ - 프레임 속도  │ - 비디오 스트림 │ - 오디오 스트림    │
│ │ - 프레임 수    │ - 코덱 정보     │ - 포맷 정보        │
│ │ - 화면 크기    │ - 샘플링 레이트 │                    │
├─────────────────────────────────────────────────────────┤
│                   LIST 'movi' 청크                       │
│ ├────────────────┬────────────────┬────────────────────┤
│ │ 00dc (비압축)  │ 01wb (오디오)   │ idx1 (인덱스)      │
│ │ 00db (압축)    │                │                    │
└─────────────────────────────────────────────────────────┘
```

### AVI 헤더 파싱 및 처리 구현

```csharp
public class VideoFileProcessor
{
    public enum VideoFormat
    {
        AVI,
        MP4,
        MKV,
        MOV,
        Unknown
    }
    
    public class VideoMetadata
    {
        public VideoFormat Format { get; set; }
        public int Width { get; set; }
        public int Height { get; set; }
        public int TotalFrames { get; set; }
        public double FrameRate { get; set; }
        public TimeSpan Duration { get; set; }
        public string Codec { get; set; }
        public bool HasAudio { get; set; }
    }
    
    public VideoMetadata ReadVideoMetadata(string filePath)
    {
        using (FileStream fs = new FileStream(filePath, FileMode.Open, FileAccess.Read))
        using (BinaryReader br = new BinaryReader(fs))
        {
            // 파일 시그니처 확인
            byte[] signature = br.ReadBytes(12);
            VideoFormat format = DetectFormat(signature);
            
            VideoMetadata metadata = new VideoMetadata { Format = format };
            
            switch (format)
            {
                case VideoFormat.AVI:
                    metadata = ParseAviMetadata(fs, br);
                    break;
                case VideoFormat.MP4:
                    metadata = ParseMp4Metadata(fs, br);
                    break;
                default:
                    throw new NotSupportedException("지원하지 않는 비디오 포맷입니다.");
            }
            
            return metadata;
        }
    }
    
    private VideoFormat DetectFormat(byte[] signature)
    {
        string sigStr = Encoding.ASCII.GetString(signature, 0, Math.Min(12, signature.Length));
        
        if (sigStr.StartsWith("RIFF") && sigStr.Contains("AVI"))
            return VideoFormat.AVI;
        else if (sigStr.StartsWith("ftyp"))
            return VideoFormat.MP4;
        else if (sigStr.StartsWith("\x1A\x45\xDF\xA3")) // Matroska EBML 헤더
            return VideoFormat.MKV;
        else
            return VideoFormat.Unknown;
    }
    
    private VideoMetadata ParseAviMetadata(FileStream fs, BinaryReader br)
    {
        // RIFF 헤더 건너뛰기
        fs.Seek(12, SeekOrigin.Begin);
        
        // 청크 찾기
        while (fs.Position < fs.Length - 8)
        {
            string chunkId = new string(br.ReadChars(4));
            uint chunkSize = br.ReadUInt32();
            
            if (chunkId == "avih") // AVI 메인 헤더 청크
            {
                uint microSecPerFrame = br.ReadUInt32(); // 프레임당 마이크로초
                uint totalFrames = br.ReadUInt32();      // 총 프레임 수
                uint width = br.ReadUInt32();            // 프레임 너비
                uint height = br.ReadUInt32();           // 프레임 높이
                
                double frameRate = 1000000.0 / microSecPerFrame;
                TimeSpan duration = TimeSpan.FromSeconds(totalFrames / frameRate);
                
                return new VideoMetadata
                {
                    Format = VideoFormat.AVI,
                    Width = (int)width,
                    Height = (int)height,
                    TotalFrames = (int)totalFrames,
                    FrameRate = frameRate,
                    Duration = duration,
                    Codec = "Unknown (추가 파싱 필요)"
                };
            }
            
            // 다음 청크로 이동
            fs.Seek(chunkSize, SeekOrigin.Current);
        }
        
        throw new Exception("AVI 헤더를 찾을 수 없습니다.");
    }
    
    private VideoMetadata ParseMp4Metadata(FileStream fs, BinaryReader br)
    {
        // MP4 박스 구조 파싱 (간소화된 구현)
        // 실제 구현은 MP4 박스 구조를 완전히 파싱해야 함
        return new VideoMetadata
        {
            Format = VideoFormat.MP4,
            Width = 0,  // 실제 구현에서 추출
            Height = 0, // 실제 구현에서 추출
            FrameRate = 30.0, // 기본값
            Codec = "H.264/MPEG-4 AVC"
        };
    }
    
    // 프레임 단위 읽기 (AVI용)
    public IEnumerable<Bitmap> ReadVideoFrames(string filePath, int skipFrames = 0)
    {
        using (FileStream fs = new FileStream(filePath, FileMode.Open, FileAccess.Read))
        using (BinaryReader br = new BinaryReader(fs))
        {
            // movi 청크 찾기
            FindMoviChunk(fs, br);
            
            int frameCount = 0;
            
            while (fs.Position < fs.Length - 8)
            {
                string chunkId = new string(br.ReadChars(4));
                uint chunkSize = br.ReadUInt32();
                
                if (chunkId.StartsWith("00") || chunkId.StartsWith("01"))
                {
                    // 비디오 프레임 청크
                    if (frameCount >= skipFrames)
                    {
                        byte[] frameData = br.ReadBytes((int)chunkSize);
                        Bitmap frame = DecodeFrame(frameData, chunkId);
                        yield return frame;
                    }
                    
                    frameCount++;
                }
                else
                {
                    // 다른 청크는 건너뛰기
                    fs.Seek(chunkSize, SeekOrigin.Current);
                }
            }
        }
    }
    
    private void FindMoviChunk(FileStream fs, BinaryReader br)
    {
        // movi 청크 위치 찾기
        // 실제 구현에서는 청크 계층 구조를 탐색해야 함
        fs.Seek(0, SeekOrigin.Begin);
        
        while (fs.Position < fs.Length - 8)
        {
            string chunkId = new string(br.ReadChars(4));
            uint chunkSize = br.ReadUInt32();
            
            if (chunkId == "LIST")
            {
                string listType = new string(br.ReadChars(4));
                if (listType == "movi")
                {
                    // movi 청크 발견
                    return;
                }
                else
                {
                    fs.Seek(chunkSize - 4, SeekOrigin.Current);
                }
            }
            else
            {
                fs.Seek(chunkSize, SeekOrigin.Current);
            }
        }
        
        throw new Exception("movi 청크를 찾을 수 없습니다.");
    }
    
    private Bitmap DecodeFrame(byte[] frameData, string chunkId)
    {
        // 간단한 비압축 RGB 디코딩 (실제로는 코덱에 따라 다름)
        if (chunkId == "00db" || chunkId == "00dc")
        {
            // DIB(Device Independent Bitmap) 디코딩
            return DecodeDibToBitmap(frameData);
        }
        
        throw new NotSupportedException($"지원하지 않는 청크 형식: {chunkId}");
    }
    
    private Bitmap DecodeDibToBitmap(byte[] dibData)
    {
        // 간단한 DIB 디코딩 구현
        // 실제 구현에서는 BITMAPINFOHEADER 파싱 필요
        using (MemoryStream ms = new MemoryStream(dibData))
        using (BinaryReader br = new BinaryReader(ms))
        {
            // BITMAPINFOHEADER 구조체 읽기 (40바이트)
            ms.Seek(14, SeekOrigin.Begin); // BITMAPFILEHEADER 건너뛰기
            int width = br.ReadInt32();
            int height = br.ReadInt32();
            br.ReadInt16(); // planes
            short bitCount = br.ReadInt16();
            
            // 픽셀 데이터 위치 계산
            int pixelDataOffset = 54; // 일반적인 오프셋
            
            // 비트맵 생성 (단순화된 구현)
            Bitmap bitmap = new Bitmap(width, height);
            
            // 픽셀 데이터 읽기 및 설정 (실제 구현에서는 더 복잡함)
            ms.Seek(pixelDataOffset, SeekOrigin.Begin);
            
            for (int y = height - 1; y >= 0; y--) // DIB는 bottom-up
            {
                for (int x = 0; x < width; x++)
                {
                    if (bitCount == 24)
                    {
                        byte blue = br.ReadByte();
                        byte green = br.ReadByte();
                        byte red = br.ReadByte();
                        bitmap.SetPixel(x, y, Color.FromArgb(red, green, blue));
                    }
                    // 다른 비트 심도 처리...
                }
                
                // 행 정렬 (4바이트 배수)
                int rowSize = ((width * bitCount + 31) / 32) * 4;
                int bytesRead = width * (bitCount / 8);
                int padding = rowSize - bytesRead;
                ms.Seek(padding, SeekOrigin.Current);
            }
            
            return bitmap;
        }
    }
}
```

---

## 차영상 기법 (Difference Image)과 배경 모델링

### 기본 차영상 이론

연속된 두 프레임 $I_t$, $I_{t+1}$의 차이를 이용해 움직임을 검출:

**단순 차영상:**
$$
D(x,y) = |I_{t+1}(x,y) - I_t(x,y)|
$$

**이진화 차영상:**
$$
B(x,y) = 
\begin{cases}
1 & \text{if } D(x,y) > T \\
0 & \text{otherwise}
\end{cases}
$$

### 개선된 차영상 알고리즘

```csharp
public class FrameDifferencing
{
    public enum DifferenceMethod
    {
        Absolute,       // 단순 절대값 차이
        Squared,        // 제곱 차이
        Adaptive,       // 적응형 임계값
        RunningAverage  // 누적 평균 기반
    }
    
    // 다중 프레임 차영상
    public Bitmap ComputeMultiFrameDifference(
        Bitmap[] frames, 
        DifferenceMethod method = DifferenceMethod.Absolute,
        int threshold = 30)
    {
        if (frames.Length < 2)
            throw new ArgumentException("최소 2개 프레임 필요");
        
        int width = frames[0].Width;
        int height = frames[0].Height;
        Bitmap result = new Bitmap(width, height);
        
        // 첫 프레임과 나머지 프레임들의 차이 누적
        int[,] cumulativeDiff = new int[height, width];
        
        for (int f = 1; f < frames.Length; f++)
        {
            for (int y = 0; y < height; y++)
            {
                for (int x = 0; x < width; x++)
                {
                    Color c1 = frames[0].GetPixel(x, y);
                    Color c2 = frames[f].GetPixel(x, y);
                    
                    int diff = 0;
                    switch (method)
                    {
                        case DifferenceMethod.Absolute:
                            diff = Math.Abs(c1.R - c2.R) + 
                                   Math.Abs(c1.G - c2.G) + 
                                   Math.Abs(c1.B - c2.B);
                            diff /= 3;
                            break;
                            
                        case DifferenceMethod.Squared:
                            diff = (int)Math.Sqrt(
                                Math.Pow(c1.R - c2.R, 2) +
                                Math.Pow(c1.G - c2.G, 2) +
                                Math.Pow(c1.B - c2.B, 2));
                            diff /= 3;
                            break;
                    }
                    
                    cumulativeDiff[y, x] += diff;
                }
            }
        }
        
        // 평균 차이 계산 및 이진화
        double scale = 1.0 / (frames.Length - 1);
        
        for (int y = 0; y < height; y++)
        {
            for (int x = 0; x < width; x++)
            {
                int avgDiff = (int)(cumulativeDiff[y, x] * scale);
                int value = (avgDiff > threshold) ? 255 : 0;
                result.SetPixel(x, y, Color.FromArgb(value, value, value));
            }
        }
        
        return result;
    }
    
    // 적응형 배경 모델링 (Running Gaussian Average)
    public class AdaptiveBackgroundModel
    {
        private double[,] mean;
        private double[,] variance;
        private double learningRate;
        private int frameCount;
        
        public AdaptiveBackgroundModel(int width, int height, double learningRate = 0.05)
        {
            mean = new double[height, width];
            variance = new double[height, width];
            this.learningRate = learningRate;
            frameCount = 0;
        }
        
        public Bitmap UpdateAndGetForeground(Bitmap frame, double threshold = 2.5)
        {
            int width = frame.Width;
            int height = frame.Height;
            Bitmap foreground = new Bitmap(width, height);
            
            for (int y = 0; y < height; y++)
            {
                for (int x = 0; x < width; x++)
                {
                    Color c = frame.GetPixel(x, y);
                    double intensity = (c.R + c.G + c.B) / 3.0;
                    
                    if (frameCount == 0)
                    {
                        // 초기화
                        mean[y, x] = intensity;
                        variance[y, x] = 100.0; // 초기 분산
                    }
                    else
                    {
                        // 배경 모델 업데이트
                        double diff = intensity - mean[y, x];
                        
                        // 평균 업데이트
                        mean[y, x] = (1 - learningRate) * mean[y, x] + 
                                     learningRate * intensity;
                        
                        // 분산 업데이트
                        variance[y, x] = (1 - learningRate) * variance[y, x] + 
                                         learningRate * diff * diff;
                        
                        // 전경 검출
                        double std = Math.Sqrt(variance[y, x]);
                        bool isForeground = Math.Abs(diff) > threshold * std;
                        
                        int value = isForeground ? 255 : 0;
                        foreground.SetPixel(x, y, Color.FromArgb(value, value, value));
                    }
                }
            }
            
            frameCount++;
            return foreground;
        }
    }
    
    // 모션 히스토그램 (움직임 방향 분석)
    public class MotionHistogram
    {
        public Dictionary<Point, int> ComputeMotionVectorsHistogram(
            Point[,] motionVectors, int numBins = 8)
        {
            Dictionary<Point, int> histogram = new Dictionary<Point, int>();
            
            int height = motionVectors.GetLength(0);
            int width = motionVectors.GetLength(1);
            
            // 방향 양자화 (8방향)
            double angleStep = 2 * Math.PI / numBins;
            
            for (int y = 0; y < height; y++)
            {
                for (int x = 0; x < width; x++)
                {
                    Point mv = motionVectors[y, x];
                    double magnitude = Math.Sqrt(mv.X * mv.X + mv.Y * mv.Y);
                    
                    if (magnitude > 0)
                    {
                        double angle = Math.Atan2(mv.Y, mv.X);
                        if (angle < 0) angle += 2 * Math.PI;
                        
                        int bin = (int)(angle / angleStep) % numBins;
                        
                        // 양자화된 방향 벡터
                        Point quantized = QuantizeDirection(bin, numBins);
                        
                        if (!histogram.ContainsKey(quantized))
                            histogram[quantized] = 0;
                        
                        histogram[quantized]++;
                    }
                }
            }
            
            return histogram;
        }
        
        private Point QuantizeDirection(int bin, int numBins)
        {
            double angle = 2 * Math.PI * bin / numBins;
            int x = (int)Math.Round(Math.Cos(angle));
            int y = (int)Math.Round(Math.Sin(angle));
            return new Point(x, y);
        }
    }
}
```

### 차영상 기반 기법 비교표

| 기법 | 공식 | 장점 | 단점 | 적용 분야 |
|------|------|------|------|-----------|
| **단순 차영상** | $D = \|I_t - I_{t-1}\|$ | 구현 간단, 빠름 | 노이즈 민감, 조명 변화에 취약 | 빠른 움직임 감지 |
| **누적 차영상** | $D = \sum\|I_t - I_{t-i}\|$ | 강건성 향상 | 계산량 증가, 메모리 사용 | 보안 시스템 |
| **배경 뺄셈** | $D = \|I_t - B\|$ | 정적 배경 효과적 | 동적 배경 문제 | 교통 모니터링 |
| **적응형 배경** | 업데이트: $B_t = αI_t + (1-α)B_{t-1}$ | 조명 변화 적응 | 초기 학습 필요 | 실내 감시 |
| **GMM 배경** | 가우시안 혼합 모델 | 복잡한 배경 처리 | 계산 비용 높음 | 도로 교통 |

---

## 움직임 추정 (Motion Estimation)

### 블록 매칭 알고리즘 (Block Matching Algorithm)

블록 매칭 알고리즘은 현재 프레임을 고정 크기 블록으로 나누고, 이전/다음 프레임에서 가장 유사한 블록을 탐색하여 움직임 벡터를 추정하는 방법이다.

#### 블록 매칭 파이프라인

```
현재 프레임              참조 프레임
┌─────────────┐        ┌─────────────┐
│    블록 분할   │ →     │  탐색 영역 내   │
│   (16×16)    │        │  유사 블록 탐색 │
└─────────────┘        └─────────────┘
       ↓                        ↓
 움직임 벡터             비용 함수 최소화
    계산                    (MAD/MSE)
```

### 다양한 탐색 알고리즘

| 알고리즘 | 탐색 패턴 | 최대 탐색 점 수 | 장점 | 단점 |
|----------|-----------|----------------|------|------|
| **전역 탐색 (FS)** | 모든 점 탐색 | $(2p+1)^2$ | 최적 해 보장 | 계산량 매우 큼 |
| **삼단계 탐색 (TSS)** | 3단계 로그 탐색 | $1+8\log_2 p$ | 효율적 | 국소 최적 문제 |
| **다이아몬드 탐색 (DS)** | 다이아몬드 패턴 | 약 13-17점 | 빠른 수렴 | 초기 위치 민감 |
| **헥사곤 탐색 (HS)** | 육각형 패턴 | 약 7-13점 | 효율적 | 대각선 이동 제한 |
| **예측 벡터 탐색** | 예측 벡터 주변 | 가변적 | 매우 빠름 | 예측 실패시 성능 저하 |

### 탐색 패턴 시각화

```
전역 탐색:        삼단계 탐색:      다이아몬드 탐색:
□□□□□□□□□        □ □ □            □
□□□□□□□□□         □□□           □ □ □
□□□□■□□□□        □□■□□          □□□□□
□□□□□□□□□         □□□           □ □ □
□□□□□□□□□        □ □ □            □

(■: 현재 위치, □: 탐색 위치)
```

### 블록 매칭 구현

```csharp
public class BlockMatchingMotionEstimator
{
    public enum SearchAlgorithm
    {
        FullSearch,      // 전역 탐색
        ThreeStepSearch, // 삼단계 탐색
        DiamondSearch,   // 다이아몬드 탐색
        HexagonSearch,   // 헥사곤 탐색
        Predictive       // 예측 기반 탐색
    }
    
    public enum CostFunction
    {
        MAD,  // Mean Absolute Difference
        MSE,  // Mean Squared Error
        SAD,  // Sum of Absolute Differences
        SATD  // Sum of Absolute Transformed Differences
    }
    
    public class MotionVectorField
    {
        public Point[,] Vectors { get; set; }
        public int BlockSize { get; set; }
        public int Width { get; set; }
        public int Height { get; set; }
        public double AverageMagnitude { get; set; }
        public double AverageAngle { get; set; }
    }
    
    // 메인 움직임 추정 함수
    public MotionVectorField EstimateMotion(
        Bitmap currentFrame,
        Bitmap referenceFrame,
        int blockSize = 16,
        int searchRange = 16,
        SearchAlgorithm algorithm = SearchAlgorithm.DiamondSearch,
        CostFunction costFunc = CostFunction.SAD)
    {
        int width = currentFrame.Width;
        int height = currentFrame.Height;
        
        int blocksX = width / blockSize;
        int blocksY = height / blockSize;
        
        Point[,] motionVectors = new Point[blocksY, blocksX];
        double totalMagnitude = 0;
        double totalAngle = 0;
        int vectorCount = 0;
        
        // 블록 단위 처리
        for (int by = 0; by < blocksY; by++)
        {
            for (int bx = 0; bx < blocksX; bx++)
            {
                int blockX = bx * blockSize;
                int blockY = by * blockSize;
                
                Point bestMatch;
                
                switch (algorithm)
                {
                    case SearchAlgorithm.FullSearch:
                        bestMatch = FullSearch(
                            currentFrame, referenceFrame,
                            blockX, blockY, blockSize,
                            searchRange, costFunc);
                        break;
                        
                    case SearchAlgorithm.ThreeStepSearch:
                        bestMatch = ThreeStepSearch(
                            currentFrame, referenceFrame,
                            blockX, blockY, blockSize,
                            searchRange, costFunc);
                        break;
                        
                    case SearchAlgorithm.DiamondSearch:
                        bestMatch = DiamondSearch(
                            currentFrame, referenceFrame,
                            blockX, blockY, blockSize,
                            searchRange, costFunc);
                        break;
                        
                    default:
                        bestMatch = FullSearch(
                            currentFrame, referenceFrame,
                            blockX, blockY, blockSize,
                            searchRange, costFunc);
                        break;
                }
                
                motionVectors[by, bx] = bestMatch;
                
                // 통계 계산
                double magnitude = Math.Sqrt(bestMatch.X * bestMatch.X + 
                                            bestMatch.Y * bestMatch.Y);
                double angle = Math.Atan2(bestMatch.Y, bestMatch.X);
                
                totalMagnitude += magnitude;
                totalAngle += angle;
                vectorCount++;
            }
        }
        
        return new MotionVectorField
        {
            Vectors = motionVectors,
            BlockSize = blockSize,
            Width = blocksX,
            Height = blocksY,
            AverageMagnitude = totalMagnitude / vectorCount,
            AverageAngle = totalAngle / vectorCount
        };
    }
    
    // 전역 탐색 (Full Search)
    private Point FullSearch(
        Bitmap current, Bitmap reference,
        int blockX, int blockY, int blockSize,
        int searchRange, CostFunction costFunc)
    {
        double minCost = double.MaxValue;
        Point bestVector = new Point(0, 0);
        
        for (int dy = -searchRange; dy <= searchRange; dy++)
        {
            for (int dx = -searchRange; dx <= searchRange; dx++)
            {
                double cost = ComputeBlockCost(
                    current, reference,
                    blockX, blockY, blockSize,
                    dx, dy, costFunc);
                
                if (cost < minCost)
                {
                    minCost = cost;
                    bestVector = new Point(dx, dy);
                }
            }
        }
        
        return bestVector;
    }
    
    // 삼단계 탐색 (Three-Step Search)
    private Point ThreeStepSearch(
        Bitmap current, Bitmap reference,
        int blockX, int blockY, int blockSize,
        int searchRange, CostFunction costFunc)
    {
        int stepSize = searchRange / 2;
        Point bestVector = new Point(0, 0);
        
        // 3단계 탐색
        for (int step = 0; step < 3; step++)
        {
            double minCost = double.MaxValue;
            Point localBest = bestVector;
            
            // 현재 최적점 주변 8개 점 탐색
            for (int dy = -stepSize; dy <= stepSize; dy += stepSize)
            {
                for (int dx = -stepSize; dx <= stepSize; dx += stepSize)
                {
                    // 현재 최적점 기준으로 상대적 위치 계산
                    int testDx = bestVector.X + dx;
                    int testDy = bestVector.Y + dy;
                    
                    double cost = ComputeBlockCost(
                        current, reference,
                        blockX, blockY, blockSize,
                        testDx, testDy, costFunc);
                    
                    if (cost < minCost)
                    {
                        minCost = cost;
                        localBest = new Point(testDx, testDy);
                    }
                }
            }
            
            bestVector = localBest;
            stepSize /= 2; // 단계마다 탐색 범위 반으로 축소
        }
        
        return bestVector;
    }
    
    // 다이어몬드 탐색 (Diamond Search)
    private Point DiamondSearch(
        Bitmap current, Bitmap reference,
        int blockX, int blockY, int blockSize,
        int searchRange, CostFunction costFunc)
    {
        // 대형 다이아몬드 패턴 (LDSP)
        Point[,] largeDiamond = new Point[,]
        {
            { new Point(0, -2), new Point(1, -1), new Point(2, 0), new Point(1, 1), new Point(0, 2), new Point(-1, 1), new Point(-2, 0), new Point(-1, -1) }
        };
        
        // 소형 다이아몬드 패턴 (SDSP)
        Point[,] smallDiamond = new Point[,]
        {
            { new Point(0, -1), new Point(1, 0), new Point(0, 1), new Point(-1, 0) }
        };
        
        Point bestVector = new Point(0, 0);
        bool usingLargePattern = true;
        
        while (true)
        {
            Point[,] pattern = usingLargePattern ? largeDiamond : smallDiamond;
            double minCost = double.MaxValue;
            Point localBest = bestVector;
            bool foundBetter = false;
            
            // 패턴 내 점들 탐색
            for (int i = 0; i < pattern.GetLength(1); i++)
            {
                Point offset = pattern[0, i];
                int testDx = bestVector.X + offset.X;
                int testDy = bestVector.Y + offset.Y;
                
                // 탐색 범위 제한
                if (Math.Abs(testDx) > searchRange || Math.Abs(testDy) > searchRange)
                    continue;
                
                double cost = ComputeBlockCost(
                    current, reference,
                    blockX, blockY, blockSize,
                    testDx, testDy, costFunc);
                
                if (cost < minCost)
                {
                    minCost = cost;
                    localBest = new Point(testDx, testDy);
                    foundBetter = true;
                }
            }
            
            if (foundBetter)
            {
                bestVector = localBest;
                // 더 나은 점을 찾으면 계속 대형 패턴 사용
                usingLargePattern = true;
            }
            else
            {
                // 대형 패턴에서 더 나은 점이 없으면 소형 패턴으로 전환
                if (usingLargePattern)
                {
                    usingLargePattern = false;
                }
                else
                {
                    // 소형 패턴에서도 더 나은 점이 없으면 종료
                    break;
                }
            }
        }
        
        return bestVector;
    }
    
    // 비용 함수 계산
    private double ComputeBlockCost(
        Bitmap current, Bitmap reference,
        int blockX, int blockY, int blockSize,
        int dx, int dy, CostFunction costFunc)
    {
        double cost = 0;
        
        for (int y = 0; y < blockSize; y++)
        {
            int refY = blockY + y + dy;
            if (refY < 0 || refY >= current.Height)
                return double.MaxValue; // 경계 벗어나면 큰 비용 반환
            
            for (int x = 0; x < blockSize; x++)
            {
                int refX = blockX + x + dx;
                if (refX < 0 || refX >= current.Width)
                    return double.MaxValue;
                
                Color curColor = current.GetPixel(blockX + x, blockY + y);
                Color refColor = reference.GetPixel(refX, refY);
                
                int diffR = curColor.R - refColor.R;
                int diffG = curColor.G - refColor.G;
                int diffB = curColor.B - refColor.B;
                
                switch (costFunc)
                {
                    case CostFunction.SAD:
                        cost += Math.Abs(diffR) + Math.Abs(diffG) + Math.Abs(diffB);
                        break;
                        
                    case CostFunction.MAD:
                        cost += (Math.Abs(diffR) + Math.Abs(diffG) + Math.Abs(diffB)) / 3.0;
                        break;
                        
                    case CostFunction.MSE:
                        cost += (diffR * diffR + diffG * diffG + diffB * diffB) / 3.0;
                        break;
                }
            }
        }
        
        // 정규화
        switch (costFunc)
        {
            case CostFunction.SAD:
                return cost;
            case CostFunction.MAD:
                return cost / (blockSize * blockSize);
            case CostFunction.MSE:
                return cost / (blockSize * blockSize);
            default:
                return cost;
        }
    }
    
    // 움직임 벡터 필드 시각화
    public Bitmap VisualizeMotionVectors(
        MotionVectorField motionField,
        Bitmap backgroundFrame,
        int vectorScale = 4,
        Color vectorColor = default)
    {
        if (vectorColor == default) vectorColor = Color.Red;
        
        Bitmap visualization = new Bitmap(backgroundFrame);
        using (Graphics g = Graphics.FromImage(visualization))
        {
            Pen vectorPen = new Pen(vectorColor, 1);
            int blockSize = motionField.BlockSize;
            
            for (int by = 0; by < motionField.Height; by++)
            {
                for (int bx = 0; bx < motionField.Width; bx++)
                {
                    Point mv = motionField.Vectors[by, bx];
                    
                    // 벡터 시작점 (블록 중심)
                    int startX = bx * blockSize + blockSize / 2;
                    int startY = by * blockSize + blockSize / 2;
                    
                    // 스케일링된 벡터 끝점
                    int endX = startX + mv.X * vectorScale;
                    int endY = startY + mv.Y * vectorScale;
                    
                    // 벡터 그리기
                    g.DrawLine(vectorPen, startX, startY, endX, endY);
                    
                    // 시작점 표시
                    g.FillEllipse(Brushes.Blue, startX - 2, startY - 2, 4, 4);
                }
            }
        }
        
        return visualization;
    }
    
    // 움직임 보상 (Motion Compensation)
    public Bitmap ApplyMotionCompensation(
        Bitmap referenceFrame,
        MotionVectorField motionField)
    {
        Bitmap compensated = new Bitmap(referenceFrame.Width, referenceFrame.Height);
        int blockSize = motionField.BlockSize;
        
        using (Graphics g = Graphics.FromImage(compensated))
        {
            // 배경 복사
            g.DrawImage(referenceFrame, 0, 0);
            
            // 각 블록에 대해 움직임 보상 적용
            for (int by = 0; by < motionField.Height; by++)
            {
                for (int bx = 0; bx < motionField.Width; bx++)
                {
                    Point mv = motionField.Vectors[by, bx];
                    
                    int srcX = bx * blockSize + mv.X;
                    int srcY = by * blockSize + mv.Y;
                    int dstX = bx * blockSize;
                    int dstY = by * blockSize;
                    
                    // 참조 프레임에서 블록 복사 (경계 처리 포함)
                    CopyBlockWithBounds(referenceFrame, compensated,
                        srcX, srcY, dstX, dstY, blockSize);
                }
            }
        }
        
        return compensated;
    }
    
    private void CopyBlockWithBounds(
        Bitmap src, Bitmap dst,
        int srcX, int srcY, int dstX, int dstY, int blockSize)
    {
        for (int y = 0; y < blockSize; y++)
        {
            int srcYPos = srcY + y;
            int dstYPos = dstY + y;
            
            // 세로 경계 검사
            if (srcYPos < 0 || srcYPos >= src.Height || 
                dstYPos < 0 || dstYPos >= dst.Height)
                continue;
            
            for (int x = 0; x < blockSize; x++)
            {
                int srcXPos = srcX + x;
                int dstXPos = dstX + x;
                
                // 가로 경계 검사
                if (srcXPos < 0 || srcXPos >= src.Width || 
                    dstXPos < 0 || dstXPos >= dst.Width)
                    continue;
                
                Color pixel = src.GetPixel(srcXPos, srcYPos);
                dst.SetPixel(dstXPos, dstYPos, pixel);
            }
        }
    }
}
```

### 비용 함수 비교표

| 비용 함수 | 공식 | 장점 | 단점 | 적합한 상황 |
|-----------|------|------|------|------------|
| **SAD** | $\sum\|I_t - I_{t-1}\|$ | 계산 간단, 빠름 | 명암도 차이 민감 | 고속 처리 |
| **MAD** | $\frac{1}{N}\sum\|I_t - I_{t-1}\|$ | 블록 크기 정규화 | SAD와 유사 | 일반적 용도 |
| **MSE** | $\frac{1}{N}\sum(I_t - I_{t-1})^2$ | 제곱으로 큰 오차 강조 | 계산 비용 높음 | 정밀 매칭 |
| **SATD** | $\sum\|H(I_t) - H(I_{t-1})\|$ | 주파수 영역 특성 반영 | 변환 계산 필요 | 압축 효율 |

---

## 고급 움직임 추정: 광학 흐름 (Optical Flow)

### 광학 흐름 이론

광학 흐름은 영상에서의 움직임 패턴을 설명하는 벡터 필드로, 다음 두 가지 주요 제약 조건으로 정의된다:

1. **밝기 항등성 제약 (Brightness Constancy):**
   $$
   I(x,y,t) = I(x+dx, y+dy, t+dt)
   $$

2. **작은 움직임 제약 (Small Motion):**
   테일러 급수 전개를 통해 유도:
   $$
   I_x u + I_y v + I_t = 0
   $$
   여기서 $u = dx/dt$, $v = dy/dt$는 속도 벡터, $I_x$, $I_y$, $I_t$는 편미분.

### 광학 흐름 알고리즘 구현

```csharp
public class OpticalFlowEstimator
{
    public enum OpticalFlowMethod
    {
        LucasKanade,    // 지역적 방법
        HornSchunck,    // 전역적 방법
        Farneback,      // 다중 스케일 방법
        DeepFlow        // 딥러닝 기반
    }
    
    public class OpticalFlowField
    {
        public double[,] U { get; set; } // x 방향 속도
        public double[,] V { get; set; } // y 방향 속도
        public double[,] Magnitude { get; set; } // 속도 크기
        public double[,] Angle { get; set; } // 속도 방향
    }
    
    // Lucas-Kanade 광학 흐름 (지역적 방법)
    public OpticalFlowField ComputeLucasKanade(
        Bitmap frame1, Bitmap frame2,
        int windowSize = 15)
    {
        int width = frame1.Width;
        int height = frame1.Height;
        
        double[,] u = new double[height, width];
        double[,] v = new double[height, width];
        
        // 그레이스케일 변환
        double[,] I1 = ConvertToGrayscale(frame1);
        double[,] I2 = ConvertToGrayscale(frame2);
        
        // 시공간 그래디언트 계산
        double[,] Ix = ComputeGradientX(I1);
        double[,] Iy = ComputeGradientY(I1);
        double[,] It = ComputeTemporalGradient(I1, I2);
        
        int halfWindow = windowSize / 2;
        
        // 각 픽셀에 대해 Lucas-Kanade 적용
        for (int y = halfWindow; y < height - halfWindow; y++)
        {
            for (int x = halfWindow; x < width - halfWindow; x++)
            {
                // 지역 윈도우 내 행렬 구성
                double A11 = 0, A12 = 0, A22 = 0;
                double b1 = 0, b2 = 0;
                
                for (int j = -halfWindow; j <= halfWindow; j++)
                {
                    for (int i = -halfWindow; i <= halfWindow; i++)
                    {
                        int xi = x + i;
                        int yj = y + j;
                        
                        double ix = Ix[yj, xi];
                        double iy = Iy[yj, xi];
                        double it = It[yj, xi];
                        
                        A11 += ix * ix;
                        A12 += ix * iy;
                        A22 += iy * iy;
                        b1 += ix * it;
                        b2 += iy * it;
                    }
                }
                
                // 행렬 역행렬 계산 (2×2)
                double det = A11 * A22 - A12 * A12;
                
                if (Math.Abs(det) > 1e-6) // 역행렬 존재 확인
                {
                    u[y, x] = (A22 * b1 - A12 * b2) / det;
                    v[y, x] = (-A12 * b1 + A11 * b2) / det;
                }
            }
        }
        
        return CreateFlowField(u, v);
    }
    
    // Horn-Schunck 광학 흐름 (전역적 방법)
    public OpticalFlowField ComputeHornSchunck(
        Bitmap frame1, Bitmap frame2,
        double lambda = 0.001, int iterations = 100)
    {
        int width = frame1.Width;
        int height = frame1.Height;
        
        double[,] u = new double[height, width];
        double[,] v = new double[height, width];
        double[,] uAvg = new double[height, width];
        double[,] vAvg = new double[height, width];
        
        // 그레이스케일 변환
        double[,] I1 = ConvertToGrayscale(frame1);
        double[,] I2 = ConvertToGrayscale(frame2);
        
        // 그래디언트 계산
        double[,] Ix = ComputeGradientX(I1);
        double[,] Iy = ComputeGradientY(I1);
        double[,] It = ComputeTemporalGradient(I1, I2);
        
        // 반복적 최적화
        for (int iter = 0; iter < iterations; iter++)
        {
            // 이웃 평균 계산
            ComputeNeighborhoodAverage(u, ref uAvg);
            ComputeNeighborhoodAverage(v, ref vAvg);
            
            // 업데이트
            for (int y = 1; y < height - 1; y++)
            {
                for (int x = 1; x < width - 1; x++)
                {
                    double ix = Ix[y, x];
                    double iy = Iy[y, x];
                    double it = It[y, x];
                    
                    double numerator = ix * uAvg[y, x] + iy * vAvg[y, x] + it;
                    double denominator = lambda * lambda + ix * ix + iy * iy;
                    
                    if (Math.Abs(denominator) > 1e-6)
                    {
                        double factor = numerator / denominator;
                        u[y, x] = uAvg[y, x] - ix * factor;
                        v[y, x] = vAvg[y, x] - iy * factor;
                    }
                }
            }
        }
        
        return CreateFlowField(u, v);
    }
    
    // Farneback 다중 스케일 광학 흐름
    public OpticalFlowField ComputeFarneback(
        Bitmap frame1, Bitmap frame2,
        double pyrScale = 0.5, int levels = 3, int windowSize = 15)
    {
        // 다중 스케일 피라미드 생성
        List<Bitmap> pyramid1 = BuildGaussianPyramid(frame1, levels, pyrScale);
        List<Bitmap> pyramid2 = BuildGaussianPyramid(frame2, levels, pyrScale);
        
        OpticalFlowField coarseFlow = null;
        
        // 거친 해상도에서 미세 해상도로 순차적 계산
        for (int level = levels - 1; level >= 0; level--)
        {
            Bitmap img1 = pyramid1[level];
            Bitmap img2 = pyramid2[level];
            
            if (coarseFlow == null)
            {
                // 가장 거친 레벨에서 초기화
                coarseFlow = ComputeLucasKanade(img1, img2, windowSize);
            }
            else
            {
                // 현재 레벨로 업샘플링
                coarseFlow = UpscaleFlow(coarseFlow, 2);
                
                // 미세 조정
                OpticalFlowField refined = RefineFlow(
                    img1, img2, coarseFlow, windowSize);
                coarseFlow = refined;
            }
        }
        
        return coarseFlow;
    }
    
    private double[,] ConvertToGrayscale(Bitmap image)
    {
        int width = image.Width;
        int height = image.Height;
        double[,] gray = new double[height, width];
        
        for (int y = 0; y < height; y++)
        {
            for (int x = 0; x < width; x++)
            {
                Color c = image.GetPixel(x, y);
                gray[y, x] = 0.299 * c.R + 0.587 * c.G + 0.114 * c.B;
            }
        }
        
        return gray;
    }
    
    private double[,] ComputeGradientX(double[,] image)
    {
        int height = image.GetLength(0);
        int width = image.GetLength(1);
        double[,] gradient = new double[height, width];
        
        // Sobel 필터 적용
        for (int y = 1; y < height - 1; y++)
        {
            for (int x = 1; x < width - 1; x++)
            {
                gradient[y, x] = (
                    -1 * image[y-1, x-1] + 0 * image[y-1, x] + 1 * image[y-1, x+1] +
                    -2 * image[y,   x-1] + 0 * image[y,   x] + 2 * image[y,   x+1] +
                    -1 * image[y+1, x-1] + 0 * image[y+1, x] + 1 * image[y+1, x+1]
                ) / 4.0;
            }
        }
        
        return gradient;
    }
    
    private double[,] ComputeGradientY(double[,] image)
    {
        int height = image.GetLength(0);
        int width = image.GetLength(1);
        double[,] gradient = new double[height, width];
        
        // Sobel 필터 적용
        for (int y = 1; y < height - 1; y++)
        {
            for (int x = 1; x < width - 1; x++)
            {
                gradient[y, x] = (
                    -1 * image[y-1, x-1] - 2 * image[y-1, x] - 1 * image[y-1, x+1] +
                     0 * image[y,   x-1] + 0 * image[y,   x] + 0 * image[y,   x+1] +
                     1 * image[y+1, x-1] + 2 * image[y+1, x] + 1 * image[y+1, x+1]
                ) / 4.0;
            }
        }
        
        return gradient;
    }
    
    private double[,] ComputeTemporalGradient(double[,] I1, double[,] I2)
    {
        int height = I1.GetLength(0);
        int width = I1.GetLength(1);
        double[,] gradient = new double[height, width];
        
        for (int y = 0; y < height; y++)
        {
            for (int x = 0; x < width; x++)
            {
                gradient[y, x] = I2[y, x] - I1[y, x];
            }
        }
        
        return gradient;
    }
    
    private void ComputeNeighborhoodAverage(double[,] field, ref double[,] avg)
    {
        int height = field.GetLength(0);
        int width = field.GetLength(1);
        
        for (int y = 1; y < height - 1; y++)
        {
            for (int x = 1; x < width - 1; x++)
            {
                avg[y, x] = (
                    field[y-1, x] + field[y+1, x] +
                    field[y, x-1] + field[y, x+1]
                ) / 4.0;
            }
        }
    }
    
    private OpticalFlowField CreateFlowField(double[,] u, double[,] v)
    {
        int height = u.GetLength(0);
        int width = u.GetLength(1);
        
        double[,] magnitude = new double[height, width];
        double[,] angle = new double[height, width];
        
        for (int y = 0; y < height; y++)
        {
            for (int x = 0; x < width; x++)
            {
                magnitude[y, x] = Math.Sqrt(
                    u[y, x] * u[y, x] + v[y, x] * v[y, x]);
                angle[y, x] = Math.Atan2(v[y, x], u[y, x]);
            }
        }
        
        return new OpticalFlowField
        {
            U = u,
            V = v,
            Magnitude = magnitude,
            Angle = angle
        };
    }
    
    // 광학 흐름 시각화 (HSV 색상 맵)
    public Bitmap VisualizeOpticalFlow(OpticalFlowField flow)
    {
        int height = flow.Magnitude.GetLength(0);
        int width = flow.Magnitude.GetLength(1);
        
        Bitmap visualization = new Bitmap(width, height);
        
        // 최대 크기 계산 (정규화용)
        double maxMagnitude = 0;
        for (int y = 0; y < height; y++)
        {
            for (int x = 0; x < width; x++)
            {
                maxMagnitude = Math.Max(maxMagnitude, flow.Magnitude[y, x]);
            }
        }
        
        // HSV → RGB 변환으로 시각화
        for (int y = 0; y < height; y++)
        {
            for (int x = 0; x < width; x++)
            {
                // H: 각도 (0~360°)
                // S: 채도 (고정 또는 크기에 비례)
                // V: 값 (크기에 비례)
                
                double hue = (flow.Angle[y, x] + Math.PI) * 180 / Math.PI;
                double saturation = 1.0;
                double value = Math.Min(flow.Magnitude[y, x] / maxMagnitude, 1.0);
                
                Color color = HsvToRgb(hue, saturation, value);
                visualization.SetPixel(x, y, color);
            }
        }
        
        return visualization;
    }
    
    private Color HsvToRgb(double h, double s, double v)
    {
        h = h % 360;
        if (h < 0) h += 360;
        
        double c = v * s;
        double x = c * (1 - Math.Abs((h / 60) % 2 - 1));
        double m = v - c;
        
        double r1 = 0, g1 = 0, b1 = 0;
        
        if (h >= 0 && h < 60) { r1 = c; g1 = x; b1 = 0; }
        else if (h >= 60 && h < 120) { r1 = x; g1 = c; b1 = 0; }
        else if (h >= 120 && h < 180) { r1 = 0; g1 = c; b1 = x; }
        else if (h >= 180 && h < 240) { r1 = 0; g1 = x; b1 = c; }
        else if (h >= 240 && h < 300) { r1 = x; g1 = 0; b1 = c; }
        else { r1 = c; g1 = 0; b1 = x; }
        
        byte r = (byte)((r1 + m) * 255);
        byte g = (byte)((g1 + m) * 255);
        byte b = (byte)((b1 + m) * 255);
        
        return Color.FromArgb(r, g, b);
    }
}
```

### 광학 흐름 알고리즘 비교표

| 알고리즘 | 원리 | 장점 | 단점 | 계산복잡도 |
|----------|------|------|------|------------|
| **Lucas-Kanade** | 지역 최소자승법 | 지역적 정확도 높음 | 큰 움직임 취약 | 중간 |
| **Horn-Schunck** | 전역 에너지 최소화 | 부드러운 흐름 생성 | 경계 블러링 | 높음 |
| **Farneback** | 다중 스케일 다항식 근사 | 큰 움직임 처리 가능 | 매개변수 설정 민감 | 중간-높음 |
| **DeepFlow** | CNN 기반 특징 매칭 | 복잡한 움직임 처리 | 학습 데이터 필요 | 매우 높음 |

---

## 움직임 추정 응용 분야

### 비디오 압축 (MPEG, H.264/HEVC)

```csharp
public class VideoCompressor
{
    public class CompressedFrame
    {
        public enum FrameType { I, P, B }
        
        public FrameType Type { get; set; }
        public byte[] Data { get; set; }
        public MotionVectorField MotionVectors { get; set; }
        public int Quality { get; set; }
    }
    
    public CompressedFrame CompressFrame(
        Bitmap currentFrame,
        Bitmap referenceFrame,
        FrameType frameType,
        int blockSize = 16,
        int quality = 75)
    {
        BlockMatchingMotionEstimator estimator = new BlockMatchingMotionEstimator();
        
        if (frameType == FrameType.I)
        {
            // I-프레임: 인트라 코딩 (움직임 추정 없음)
            return new CompressedFrame
            {
                Type = FrameType.I,
                Data = CompressIntraFrame(currentFrame, quality),
                MotionVectors = null,
                Quality = quality
            };
        }
        else
        {
            // P/B-프레임: 움직임 추정 기반 인터 코딩
            MotionVectorField motionVectors = estimator.EstimateMotion(
                currentFrame, referenceFrame, blockSize);
            
            Bitmap compensated = estimator.ApplyMotionCompensation(
                referenceFrame, motionVectors);
            
            // 잔차(차이) 계산 및 압축
            Bitmap residual = ComputeResidual(currentFrame, compensated);
            byte[] residualData = CompressResidual(residual, quality);
            
            return new CompressedFrame
            {
                Type = frameType,
                Data = residualData,
                MotionVectors = motionVectors,
                Quality = quality
            };
        }
    }
    
    private Bitmap ComputeResidual(Bitmap original, Bitmap predicted)
    {
        // 원본과 예측 프레임의 차이 계산
        int width = original.Width;
        int height = original.Height;
        Bitmap residual = new Bitmap(width, height);
        
        for (int y = 0; y < height; y++)
        {
            for (int x = 0; x < width; x++)
            {
                Color orig = original.GetPixel(x, y);
                Color pred = predicted.GetPixel(x, y);
                
                int diffR = Math.Abs(orig.R - pred.R);
                int diffG = Math.Abs(orig.G - pred.G);
                int diffB = Math.Abs(orig.B - pred.B);
                
                // 0-255 범위로 클리핑
                diffR = Math.Min(255, diffR * 2); // 시각화를 위해 확대
                diffG = Math.Min(255, diffG * 2);
                diffB = Math.Min(255, diffB * 2);
                
                residual.SetPixel(x, y, 
                    Color.FromArgb(diffR, diffG, diffB));
            }
        }
        
        return residual;
    }
}
```

### 객체 추적 (Object Tracking)

```csharp
public class ObjectTracker
{
    public class TrackedObject
    {
        public Rectangle BoundingBox { get; set; }
        public Point Velocity { get; set; }
        public double Confidence { get; set; }
        public int Id { get; set; }
        public List<Point> Path { get; set; }
    }
    
    private Dictionary<int, TrackedObject> trackedObjects = new Dictionary<int, TrackedObject>();
    private int nextId = 0;
    
    public List<TrackedObject> UpdateTracking(
        Bitmap currentFrame,
        Bitmap previousFrame,
        List<Rectangle> detectedObjects)
    {
        List<TrackedObject> updatedObjects = new List<TrackedObject>();
        
        if (trackedObjects.Count == 0)
        {
            // 초기 추적 객체 생성
            foreach (var rect in detectedObjects)
            {
                var obj = new TrackedObject
                {
                    Id = nextId++,
                    BoundingBox = rect,
                    Velocity = new Point(0, 0),
                    Confidence = 1.0,
                    Path = new List<Point> { 
                        new Point(rect.X + rect.Width/2, rect.Y + rect.Height/2) 
                    }
                };
                trackedObjects[obj.Id] = obj;
                updatedObjects.Add(obj);
            }
        }
        else
        {
            // 움직임 추정 기반 매칭
            BlockMatchingMotionEstimator estimator = new BlockMatchingMotionEstimator();
            MotionVectorField motionField = estimator.EstimateMotion(
                previousFrame, currentFrame, 16, 32);
            
            // 각 추적 객체에 대해 움직임 보상
            foreach (var obj in trackedObjects.Values)
            {
                // 객체 중심에서의 평균 움직임 벡터 계산
                Point avgMotion = ComputeAverageMotionInRegion(
                    motionField, obj.BoundingBox);
                
                // 바운딩 박스 업데이트
                Rectangle newBox = new Rectangle(
                    obj.BoundingBox.X + avgMotion.X,
                    obj.BoundingBox.Y + avgMotion.Y,
                    obj.BoundingBox.Width,
                    obj.BoundingBox.Height);
                
                // 속도 업데이트 (저속 필터 적용)
                obj.Velocity = new Point(
                    (int)(0.7 * obj.Velocity.X + 0.3 * avgMotion.X),
                    (int)(0.7 * obj.Velocity.Y + 0.3 * avgMotion.Y));
                
                // 경로 기록
                Point center = new Point(
                    newBox.X + newBox.Width/2,
                    newBox.Y + newBox.Height/2);
                obj.Path.Add(center);
                
                obj.BoundingBox = newBox;
                updatedObjects.Add(obj);
            }
            
            // 새로운 객체 검출 및 매칭
            foreach (var rect in detectedObjects)
            {
                bool isNew = true;
                Point center = new Point(
                    rect.X + rect.Width/2,
                    rect.Y + rect.Height/2);
                
                // 기존 객체와 거리 계산
                foreach (var obj in updatedObjects)
                {
                    Point objCenter = new Point(
                        obj.BoundingBox.X + obj.BoundingBox.Width/2,
                        obj.BoundingBox.Y + obj.BoundingBox.Height/2);
                    
                    double distance = Math.Sqrt(
                        Math.Pow(center.X - objCenter.X, 2) +
                        Math.Pow(center.Y - objCenter.Y, 2));
                    
                    if (distance < 50) // 임계값 내이면 동일 객체
                    {
                        isNew = false;
                        break;
                    }
                }
                
                if (isNew)
                {
                    var newObj = new TrackedObject
                    {
                        Id = nextId++,
                        BoundingBox = rect,
                        Velocity = new Point(0, 0),
                        Confidence = 1.0,
                        Path = new List<Point> { center }
                    };
                    trackedObjects[newObj.Id] = newObj;
                    updatedObjects.Add(newObj);
                }
            }
        }
        
        return updatedObjects;
    }
    
    private Point ComputeAverageMotionInRegion(
        MotionVectorField motionField, Rectangle region)
    {
        int sumX = 0, sumY = 0;
        int count = 0;
        
        int blockSize = motionField.BlockSize;
        int startX = region.X / blockSize;
        int startY = region.Y / blockSize;
        int endX = (region.X + region.Width) / blockSize;
        int endY = (region.Y + region.Height) / blockSize;
        
        // 영역 내 블록들에 대한 평균 움직임 계산
        for (int by = startY; by < endY && by < motionField.Height; by++)
        {
            for (int bx = startX; bx < endX && bx < motionField.Width; bx++)
            {
                Point mv = motionField.Vectors[by, bx];
                sumX += mv.X;
                sumY += mv.Y;
                count++;
            }
        }
        
        if (count > 0)
        {
            return new Point(sumX / count, sumY / count);
        }
        
        return new Point(0, 0);
    }
}
```

### 행동 인식 (Activity Recognition)

```csharp
public class ActivityRecognizer
{
    public enum ActivityType
    {
        Walking,
        Running,
        Jumping,
        Falling,
        Sitting,
        Standing,
        Unknown
    }
    
    public class ActivityFeatures
    {
        public double AverageSpeed { get; set; }
        public double SpeedVariance { get; set; }
        public double DirectionConsistency { get; set; }
        public double MotionEnergy { get; set; }
        public double MotionPeriodicity { get; set; }
    }
    
    public ActivityType RecognizeActivity(
        List<MotionVectorField> motionSequence,
        int frameRate = 30)
    {
        // 모션 시퀀스에서 특징 추출
        ActivityFeatures features = ExtractFeatures(motionSequence, frameRate);
        
        // 특징 기반 분류
        return ClassifyActivity(features);
    }
    
    private ActivityFeatures ExtractFeatures(
        List<MotionVectorField> sequence, int frameRate)
    {
        if (sequence.Count < 2)
            return new ActivityFeatures();
        
        List<double> speeds = new List<double>();
        List<double> directions = new List<double>();
        double totalEnergy = 0;
        
        // 각 프레임별 속도 및 방향 계산
        for (int i = 0; i < sequence.Count; i++)
        {
            double frameSpeed = sequence[i].AverageMagnitude * frameRate;
            speeds.Add(frameSpeed);
            directions.Add(sequence[i].AverageAngle);
            
            // 모션 에너지 계산
            totalEnergy += frameSpeed * frameSpeed;
        }
        
        // 통계적 특징 계산
        double avgSpeed = speeds.Average();
        double speedVar = speeds.Select(s => Math.Pow(s - avgSpeed, 2)).Sum() / speeds.Count;
        
        // 방향 일관성 계산
        double dirConsistency = ComputeDirectionConsistency(directions);
        
        // 주기성 분석 (자동상관)
        double periodicity = ComputePeriodicity(speeds);
        
        return new ActivityFeatures
        {
            AverageSpeed = avgSpeed,
            SpeedVariance = speedVar,
            DirectionConsistency = dirConsistency,
            MotionEnergy = totalEnergy / sequence.Count,
            MotionPeriodicity = periodicity
        };
    }
    
    private ActivityType ClassifyActivity(ActivityFeatures features)
    {
        // 규칙 기반 분류 (실제로는 머신러닝 사용 권장)
        if (features.AverageSpeed < 0.5)
        {
            if (features.MotionEnergy < 10)
                return features.DirectionConsistency < 0.3 ? 
                    ActivityType.Sitting : ActivityType.Standing;
        }
        else if (features.AverageSpeed < 2.0)
        {
            return features.MotionPeriodicity > 0.7 ? 
                ActivityType.Walking : ActivityType.Unknown;
        }
        else if (features.AverageSpeed < 5.0)
        {
            return features.MotionPeriodicity > 0.8 ? 
                ActivityType.Running : ActivityType.Unknown;
        }
        else if (features.AverageSpeed > 5.0 && features.SpeedVariance > 10)
        {
            return ActivityType.Jumping;
        }
        
        return ActivityType.Unknown;
    }
}
```

---

## 성능 최적화 기법

### 다중 스레드 처리

```csharp
public class ParallelMotionEstimator
{
    public MotionVectorField EstimateMotionParallel(
        Bitmap currentFrame,
        Bitmap referenceFrame,
        int blockSize = 16,
        int searchRange = 16,
        int numThreads = 4)
    {
        int width = currentFrame.Width;
        int height = currentFrame.Height;
        
        int blocksX = width / blockSize;
        int blocksY = height / blockSize;
        
        Point[,] motionVectors = new Point[blocksY, blocksX];
        
        // 블록을 스레드별로 분할
        int blocksPerThread = blocksY / numThreads;
        
        Parallel.For(0, numThreads, threadId =>
        {
            int startBlockY = threadId * blocksPerThread;
            int endBlockY = (threadId == numThreads - 1) ? 
                blocksY : (threadId + 1) * blocksPerThread;
            
            BlockMatchingMotionEstimator estimator = 
                new BlockMatchingMotionEstimator();
            
            for (int by = startBlockY; by < endBlockY; by++)
            {
                for (int bx = 0; bx < blocksX; bx++)
                {
                    Point vector = estimator.FullSearch(
                        currentFrame, referenceFrame,
                        bx * blockSize, by * blockSize,
                        blockSize, searchRange,
                        BlockMatchingMotionEstimator.CostFunction.SAD);
                    
                    motionVectors[by, bx] = vector;
                }
            }
        });
        
        return new MotionVectorField
        {
            Vectors = motionVectors,
            BlockSize = blockSize,
            Width = blocksX,
            Height = blocksY
        };
    }
}
```

### GPU 가속 (CUDA/OpenCL)

```csharp
// 의사 코드 - 실제 구현은 CUDA나 OpenCL 라이브러리 필요
public class GpuMotionEstimator
{
    /*
    [CudaKernel]
    public static void BlockMatchingKernel(
        byte[] currFrame, byte[] refFrame,
        int[] motionVectors, int width, int height,
        int blockSize, int searchRange)
    {
        int blockIdx = blockIdx.x * blockDim.x + threadIdx.x;
        int totalBlocks = (width / blockSize) * (height / blockSize);
        
        if (blockIdx >= totalBlocks) return;
        
        int bx = blockIdx % (width / blockSize);
        int by = blockIdx / (width / blockSize);
        
        int bestDx = 0, bestDy = 0;
        int minCost = int.MaxValue;
        
        for (int dy = -searchRange; dy <= searchRange; dy++)
        {
            for (int dx = -searchRange; dx <= searchRange; dx++)
            {
                int cost = 0;
                
                for (int y = 0; y < blockSize; y++)
                {
                    for (int x = 0; x < blockSize; x++)
                    {
                        int currIdx = ((by * blockSize + y) * width + 
                                       (bx * blockSize + x)) * 3;
                        int refIdx = ((by * blockSize + y + dy) * width + 
                                      (bx * blockSize + x + dx)) * 3;
                        
                        // SAD 계산
                        cost += Math.Abs(currFrame[currIdx] - refFrame[refIdx]);
                        cost += Math.Abs(currFrame[currIdx+1] - refFrame[refIdx+1]);
                        cost += Math.Abs(currFrame[currIdx+2] - refFrame[refIdx+2]);
                    }
                }
                
                if (cost < minCost)
                {
                    minCost = cost;
                    bestDx = dx;
                    bestDy = dy;
                }
            }
        }
        
        motionVectors[blockIdx * 2] = bestDx;
        motionVectors[blockIdx * 2 + 1] = bestDy;
    }
    */
}
```

### 메모리 최적화

```csharp
public class MemoryOptimizedMotionEstimation
{
    public unsafe MotionVectorField EstimateMotionOptimized(
        Bitmap currentFrame,
        Bitmap referenceFrame,
        int blockSize = 16)
    {
        int width = currentFrame.Width;
        int height = currentFrame.Height;
        
        Rectangle rect = new Rectangle(0, 0, width, height);
        BitmapData currData = currentFrame.LockBits(rect,
            ImageLockMode.ReadOnly, PixelFormat.Format24bppRgb);
        BitmapData refData = referenceFrame.LockBits(rect,
            ImageLockMode.ReadOnly, PixelFormat.Format24bppRgb);
        
        int blocksX = width / blockSize;
        int blocksY = height / blockSize;
        Point[,] motionVectors = new Point[blocksY, blocksX];
        
        int stride = currData.Stride;
        int bytesPerPixel = 3; // 24bpp
        
        byte* currPtr = (byte*)currData.Scan0;
        byte* refPtr = (byte*)refData.Scan0;
        
        // 캐시 친화적인 블록 처리
        for (int by = 0; by < blocksY; by++)
        {
            for (int bx = 0; bx < blocksX; bx++)
            {
                int bestDx = 0, bestDy = 0;
                int minCost = int.MaxValue;
                
                for (int dy = -16; dy <= 16; dy++)
                {
                    for (int dx = -16; dx <= 16; dx++)
                    {
                        int cost = 0;
                        
                        for (int y = 0; y < blockSize; y++)
                        {
                            byte* currRow = currPtr + 
                                ((by * blockSize + y) * stride) + 
                                (bx * blockSize * bytesPerPixel);
                            
                            byte* refRow = refPtr + 
                                ((by * blockSize + y + dy) * stride) + 
                                ((bx * blockSize + dx) * bytesPerPixel);
                            
                            for (int x = 0; x < blockSize; x++)
                            {
                                // SAD 계산 (인라인 최적화)
                                cost += Math.Abs(currRow[0] - refRow[0]);
                                cost += Math.Abs(currRow[1] - refRow[1]);
                                cost += Math.Abs(currRow[2] - refRow[2]);
                                
                                currRow += bytesPerPixel;
                                refRow += bytesPerPixel;
                            }
                        }
                        
                        if (cost < minCost)
                        {
                            minCost = cost;
                            bestDx = dx;
                            bestDy = dy;
                        }
                    }
                }
                
                motionVectors[by, bx] = new Point(bestDx, bestDy);
            }
        }
        
        currentFrame.UnlockBits(currData);
        referenceFrame.UnlockBits(refData);
        
        return new MotionVectorField
        {
            Vectors = motionVectors,
            BlockSize = blockSize,
            Width = blocksX,
            Height = blocksY
        };
    }
}
```

---

## 정리

### 움직임 추정 기법 선택 가이드

| 응용 분야 | 추천 알고리즘 | 이유 | 최적 파라미터 |
|-----------|--------------|------|---------------|
| **비디오 압축** | 블록 매칭 + 다이아몬드 탐색 | 속도/정확도 균형 | 블록 크기: 16×16, 탐색 범위: ±16 |
| **객체 추적** | 광학 흐름 (Lucas-Kanade) | 부드러운 움직임 추적 | 윈도우 크기: 15×15 |
| **행동 인식** | 다중 스케일 광학 흐름 | 다양한 움직임 캡처 | 피라미드 레벨: 3 |
| **실시간 처리** | 삼단계 탐색 블록 매칭 | 빠른 계산 | 탐색 단계: 3 |
| **정밀 분석** | 전역 탐색 블록 매칭 | 최적 해 보장 | 비용 함수: MSE |

### 핵심 개념 요약

1. **차영상**: 가장 간단한 움직임 검출 방법으로 빠르지만 노이즈에 취약
2. **블록 매칭**: 고전적이지만 효과적인 움직임 추정, 비디오 압축의 핵심
3. **광학 흐름**: 픽셀 단위 움직임 분석, 객체 추적에 유용
4. **움직임 보상**: 추정된 움직임을 활용한 프레임 예측
5. **다중 스케일 처리**: 다양한 크기의 움직임을 효과적으로 처리

### 발전 방향

| 분야 | 발전 내용 | 기대 효과 |
|------|----------|-----------|
| **딥러닝 기반** | CNN/LSTM을 이용한 움직임 추정 | 복잡한 움직임 처리 향상 |
| **실시간 처리** | 하드웨어 가속 (GPU, TPU) | 4K/8K 실시간 처리 |
| **3D 움직임** | 다중 카메라 기반 3D 모션 추정 | 증강현실/가상현실 |
| **시맨틱 모션** | 의미 기반 움직임 이해 | 고수준 행동 인식 |
| **에너지 효율** | 모바일 최적화 알고리즘 | 모바일/임베디드 적용 |

### 실무 권장사항

1. **알고리즘 선택**: 응용 요구사항(속도 vs 정확도)에 맞춰 선택
2. **파라미터 튜닝**: 블록 크기, 탐색 범위, 비용 함수 실험적 최적화
3. **전처리 중요성**: 노이즈 제거, 조명 정규화가 성능에 큰 영향
4. **다중 기법 결합**: 블록 매칭 + 광학 흐름 등 하이브리드 접근
5. **하드웨어 활용**: GPU 병렬화, SIMD 명령어 활용

동영상 처리와 움직임 추정은 컴퓨터 비전의 핵심 분야로, 비디오 압축부터 자율주행까지 다양한 응용 분야에서 활용된다. 전통적인 블록 매칭 기법은 여전히 실용적 가치가 높으며, 최신 딥러닝 기법은 더 복잡한 움직임 패턴을 이해하는 데 기여하고 있다.