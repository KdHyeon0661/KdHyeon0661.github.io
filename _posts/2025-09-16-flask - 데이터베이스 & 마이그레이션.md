---
layout: post
title: flask - 데이터베이스 & 마이그레이션
date: 2025-09-16 19:25:23 +0900
category: flask
---
# 데이터베이스 & 마이그레이션

## SQLAlchemy Core vs ORM — 언제 무엇을 쓰나

### 요약 비교

| 항목 | SQLAlchemy Core | SQLAlchemy ORM |
|---|---|---|
| 모델 | 테이블·컬럼 중심(스키마 First) | 도메인 객체 중심(엔티티/관계) |
| 쿼리 | 명시적 SQL(표현식 빌더) | 세션이 엔티티를 로딩/추적 |
| 장점 | 예측 가능한 성능, 복잡 SQL/CTE/윈도우 함수에 강함 | 생산성, 관계 탐색/캐시, 단위 테스트 쉬움 |
| 단점 | 매핑/도메인 계층 별도 구현 필요 | N+1 위험, lazy 로딩 주의, 세션 관리 필요 |
| 쓰임새 | 리포트/배치/ETL/집계, 고성능 read | CRUD/업무 로직, 풍부한 관계 모델 |

실전에서는 **ORM + 선택적 Core**를 기본 전략으로 삼는 것이 좋습니다. 대부분의 업무 로직(약 80%)은 ORM으로 처리하고, 복잡한 집계나 대량 처리가 필요한 부분은 Core나 텍스트 SQL로 보완하는 접근법이 효과적입니다.

---

## 프로젝트 구조 설계

```
app/
├─ __init__.py
├─ extensions.py        # db = SQLAlchemy(), migrate = Migrate()
├─ models/              # ORM 모델
│  ├─ user.py
│  └─ order.py
├─ repositories/        # 리포지토리 추상화
│  ├─ user_repo.py
│  └─ order_repo.py
├─ services/            # 도메인 서비스/유스케이스
│  └─ orders.py
└─ db/                  # Core 스키마/테이블, raw SQL(옵션)
   ├─ tables.py
   └─ queries.py
```

```python
# app/extensions.py

from flask_sqlalchemy import SQLAlchemy
from flask_migrate import Migrate

db = SQLAlchemy(session_options={"autoflush": False})  # flush 타이밍 통제
migrate = Migrate()

def init_extensions(app):
    db.init_app(app)
    migrate.init_app(app, db)
```

```python
# app/__init__.py

from flask import Flask
from .extensions import init_extensions

def create_app(config_name=None):
    app = Flask(__name__)
    app.config.update(
        SQLALCHEMY_DATABASE_URI="sqlite:///dev.db",
        SQLALCHEMY_TRACK_MODIFICATIONS=False,
    )
    init_extensions(app)
    return app
```

---

## ORM 모델 정의 (SQLAlchemy 2.x 스타일)

```python
# app/models/user.py

from datetime import datetime, timezone
from sqlalchemy.orm import Mapped, mapped_column, relationship
from sqlalchemy import String, Integer, DateTime
from app.extensions import db

class User(db.Model):
    __tablename__ = "users"
    id: Mapped[int] = mapped_column(Integer, primary_key=True)
    email: Mapped[str] = mapped_column(String(120), unique=True, nullable=False, index=True)
    name: Mapped[str] = mapped_column(String(60), nullable=False)
    created_at: Mapped[datetime] = mapped_column(DateTime(timezone=True), default=lambda: datetime.now(timezone.utc))

    orders: Mapped[list["Order"]] = relationship(back_populates="user", lazy="raise")  # lazy=raise로 N+1 잡기
```

```python
# app/models/order.py

from datetime import datetime, timezone
from sqlalchemy.orm import Mapped, mapped_column, relationship
from sqlalchemy import Integer, ForeignKey, Numeric, DateTime
from app.extensions import db

class Order(db.Model):
    __tablename__ = "orders"
    id: Mapped[int] = mapped_column(Integer, primary_key=True)
    user_id: Mapped[int] = mapped_column(ForeignKey("users.id", ondelete="CASCADE"), nullable=False, index=True)
    total: Mapped[float] = mapped_column(Numeric(12, 2), nullable=False)
    placed_at: Mapped[datetime] = mapped_column(DateTime(timezone=True), default=lambda: datetime.now(timezone.utc))

    user: Mapped["User"] = relationship(back_populates="orders", lazy="joined")  # 자주 쓰면 joined
```

관계의 lazy 기본값을 `raise` 또는 `selectin`으로 설정하고, 필요한 곳에서만 `joined/selectinload`로 명시적 로딩을 사용하면 N+1 문제를 예방할 수 있습니다.

---

## Core 테이블 & 쿼리 (혼합 전략)

```python
# app/db/tables.py

from sqlalchemy import Table, Column, MetaData, Integer, String, DateTime, ForeignKey, Numeric
metadata = MetaData()

users = Table(
    "users", metadata,
    Column("id", Integer, primary_key=True),
    Column("email", String(120), nullable=False, unique=True, index=True),
    Column("name", String(60), nullable=False),
    Column("created_at", DateTime(timezone=True))
)

orders = Table(
    "orders", metadata,
    Column("id", Integer, primary_key=True),
    Column("user_id", Integer, ForeignKey("users.id", ondelete="CASCADE"), index=True),
    Column("total", Numeric(12,2), nullable=False),
    Column("placed_at", DateTime(timezone=True))
)
```

```python
# app/db/queries.py

from sqlalchemy import select, func, desc
from app.db.tables import orders, users
from app.extensions import db

def top_buyers(limit=10):
    stmt = (
        select(users.c.id, users.c.email, func.sum(orders.c.total).label("spent"))
        .select_from(users.join(orders, users.c.id == orders.c.user_id))
        .group_by(users.c.id, users.c.email)
        .order_by(desc("spent"))
        .limit(limit)
    )
    with db.engine.connect() as conn:
        return [dict(r) for r in conn.execute(stmt)]
```

ORM과 Core를 동일한 세션으로 섞기보다는, 읽기 전용 Core 작업은 **엔진 커넥션**을 사용해 명확히 분리하는 것이 유지보수에 좋습니다.

---

## 세션/트랜잭션 범위 — 실전 적용법

### 세션 기본 개념

- **세션(Session)**: ORM 단위의 "유닛 오브 워크"로 객체 상태 변경을 추적하고 flush/commit을 관리합니다.
- **autoflush=False**를 권장하며, 이는 쿼리 직전의 의도치 않은 flush를 방지합니다.
- **commit/rollback**은 **요청 단위** 혹은 **유스케이스 단위**로 수행합니다.

### 요청 단위 트랜잭션(웹)

대부분의 Flask 애플리케이션에서는 Flask-SQLAlchemy가 자동으로 세션 수명주기를 관리합니다. 직접 훅을 추가하는 경우는 "원자적 유즈케이스"를 강제하고 싶을 때입니다.

### 단위 트랜잭션 패턴

```python
# app/services/orders.py

from contextlib import contextmanager
from app.extensions import db

@contextmanager
def transactional():
    try:
        yield
        db.session.commit()
    except Exception:
        db.session.rollback()
        raise

def place_order(user_id: int, items: list[tuple[int, int]]):
    with transactional():
        # 1) 재고 확인
        # 2) Order 생성
        # 3) 라인아이템 생성
        # 4) 이벤트 기록
        ...
```

**원칙**: "여러 테이블을 수반하는 변경은 하나의 트랜잭션으로 처리"해야 합니다. 실패 시 **전부 롤백**되어야 데이터 무결성을 유지할 수 있습니다.

---

## N+1 방지 — 로딩 전략과 진단

### 현상

목록을 조회한 후 각 항목의 관계를 **루프 안에서 lazy 로딩**하면 **쿼리 수가 N+1**로 폭증하는 문제가 발생합니다.

### 해결책

- `joinedload`: 조인으로 즉시 로딩(1 쿼리, 중복행 발생 가능 → DISTINCT/페이징 주의)
- `selectinload`: IN 서브쿼리로 2번 접근(페이징 친화적, 추천 기본값)
- `lazy="raise"`: 우발적인 lazy 접근 시 예외 발생 → 테스트에서 **N+1 조기 탐지**

```python
from sqlalchemy.orm import selectinload
from app.models.user import User
from app.extensions import db

def list_users_with_orders():
    q = db.session.query(User).options(selectinload(User.orders))
    return q.limit(50).all()
```

테스트에서 방지:

```python
import pytest
from sqlalchemy.exc import InvalidRequestError

def test_lazy_raise(client, db_session):
    from app.models.user import User
    u = db_session.query(User).first()
    with pytest.raises(InvalidRequestError):
        _ = u.orders  # lazy="raise"면 여기서 예외 발생
```

---

## 리포지토리 패턴 — 인프라 의존성 격리

### 사용 이유

- 뷰/서비스가 **DB 세부사항(SQLAlchemy)**에 강결합되는 것을 방지합니다.
- 단위 테스트에서 **Fake/In-Memory** 구현으로 대체해 빠른 테스트가 가능합니다.

### 인터페이스 & 구현

```python
# app/repositories/user_repo.py

from typing import Protocol, Iterable
from app.models.user import User
from app.extensions import db

class IUserRepo(Protocol):
    def get(self, user_id: int) -> User | None: ...
    def by_email(self, email: str) -> User | None: ...
    def add(self, user: User) -> User: ...
    def list(self, limit: int = 100) -> Iterable[User]: ...

class SAUserRepo(IUserRepo):
    def get(self, user_id: int) -> User | None:
        return db.session.get(User, user_id)

    def by_email(self, email: str) -> User | None:
        return db.session.query(User).filter_by(email=email).one_or_none()

    def add(self, user: User) -> User:
        db.session.add(user)
        return user

    def list(self, limit: int = 100):
        return db.session.query(User).limit(limit).all()
```

서비스에서는 인터페이스에만 의존:

```python
# app/services/users.py

from app.models.user import User

def register_user(repo, email: str, name: str) -> User:
    if repo.by_email(email):
        raise ValueError("duplicate email")
    u = User(email=email, name=name)
    repo.add(u)
    return u
```

테스트 시 대체:

```python
class FakeUserRepo:
    def __init__(self): self.store = {}
    def get(self, id): return self.store.get(id)
    def by_email(self, email):
        return next((u for u in self.store.values() if u.email==email), None)
    def add(self, u): self.store[u.id or len(self.store)+1] = u; return u
    def list(self, limit=100): return list(self.store.values())[:limit]
```

---

## 성능 최적화 — 인덱스/배치/락

### 인덱스 설계

- 자주 조회하는 컬럼에 **BTREE 인덱스**를 추가합니다.
- **선행 컬럼 순서**가 중요하며, where/order by 조건과 일치해야 합니다.
- **카디널리티**가 낮은 컬럼만 인덱싱하는 것은 남발하지 않아야 합니다(쓰기 비용 증가).

```python
from sqlalchemy import Index
Index("ix_orders_user_created", Order.user_id, Order.placed_at)
```

### 배치 삽입/갱신

- ORM 대량 삽입 → `session.bulk_save_objects` 또는 Core의 `insert().values(list_of_dicts)`
- 대량 업데이트 → Core `update()`/CTE 활용

```python
# Core bulk insert

from app.db.tables import orders
from app.extensions import db

def bulk_insert_orders(rows: list[dict]):
    with db.engine.begin() as conn:
        conn.execute(orders.insert(), rows)
```

---

## Alembic/Flask-Migrate — 스키마 버전 관리

### 초기화

```bash
pip install flask-migrate alembic
flask db init
```

프로젝트에 `migrations/` 디렉터리가 생성됩니다.

### 자동 마이그레이션 스크립트 생성

```bash
# 모델 변경 후

flask db migrate -m "add users & orders"
```

```bash
flask db upgrade            # 적용
flask db downgrade -1       # 되돌리기
```

**자동 탐지 한계**: 뷰/함수/트리거/체크 제약조건/인덱스 이름 변경 등은 수동 편집이 필요합니다.

### 마이그레이션 스크립트 패턴

```python
# migrations/versions/2025_10_01_add_orders.py

from alembic import op
import sqlalchemy as sa

revision = "2025_10_01_add_orders"
down_revision = None

def upgrade():
    op.create_table(
        "users",
        sa.Column("id", sa.Integer, primary_key=True),
        sa.Column("email", sa.String(120), nullable=False, unique=True, index=True),
        sa.Column("name", sa.String(60), nullable=False),
        sa.Column("created_at", sa.DateTime(timezone=True))
    )
    op.create_table(
        "orders",
        sa.Column("id", sa.Integer, primary_key=True),
        sa.Column("user_id", sa.Integer, sa.ForeignKey("users.id", ondelete="CASCADE")),
        sa.Column("total", sa.Numeric(12,2), nullable=False),
        sa.Column("placed_at", sa.DateTime(timezone=True))
    )
    op.create_index("ix_orders_user_created", "orders", ["user_id", "placed_at"])

def downgrade():
    op.drop_index("ix_orders_user_created", table_name="orders")
    op.drop_table("orders")
    op.drop_table("users")
```

인덱스/제약조건 **명명 규칙**을 문서화하는 것이 중요합니다. 나중에 정확히 drop/rename 하려면 이름이 필요합니다.

---

## 마이그레이션 운영 팁

- **잠금/다운타임 최소화**: 큰 테이블 alter는 **두 단계 롤링**(새 컬럼 추가→백필→스위치→구컬럼 제거) 방식으로 진행합니다.
- **백필(backfill)** 은 **일괄 UPDATE**를 금지하고, **배치/큐**로 천천히 처리합니다.
- **필드 타입 변경**은 새 컬럼으로 복사 후 스위치하는 방식이 안전합니다.
- 프로덕션에서 `downgrade`는 매우 조심해야 하며(데이터 손실 가능성), 대신 **forward-only** 전략과 복구는 백업/스냅샷으로 처리하는 것이 안전합니다.

---

## SQLite → PostgreSQL 전환 시 고려사항

SQLite는 개발/단일 노드 환경에 적합하지만, 운영 환경에서의 동시성/트랜잭션/타입/인덱스 측면에서 제약이 있습니다. 전환 시 확인해야 할 항목들입니다.

### 타입/스키마 차이

- **정밀도**: `Numeric(12,2)` → PG는 정확한 타입, SQLite는 느슨한 타입입니다. 가격/금액 컬럼을 PG에서 재검증해야 합니다.
- **Boolean**: SQLite는 int로 처리, PG는 `boolean` 타입을 사용합니다.
- **DateTime(timezone=True)**: 타임존 저장 일관성(UTC)을 재확인해야 합니다.
- **TEXT/VARCHAR 길이 제약**: PG는 길이 검사를 수행하지만, SQLite는 느슨하게 처리합니다.

### 제약조건/기능

- **Foreign Key**: SQLite는 pragma로 활성화가 필요하며(종종 꺼져있음), PG로 옮길 때 **FK 무결성**을 재확인해야 합니다.
- **Unique/Partial Index**: PG의 부분 인덱스/함수 인덱스 활용을 계획해야 합니다.
- **ON CONFLICT** 문법: `INSERT ... ON CONFLICT DO UPDATE` (PG) → ORM upsert 구현에 적응해야 합니다.

```python
# SQLAlchemy 2.x ORM upsert 예시 (PG)

from sqlalchemy.dialects.postgresql import insert
from app.models.user import User
from app.extensions import db

def upsert_user(email: str, name: str):
    stmt = insert(User).values(email=email, name=name)
    stmt = stmt.on_conflict_do_update(
        index_elements=[User.email],
        set_={"name": stmt.excluded.name}
    )
    db.session.execute(stmt)
    db.session.commit()
```

### 트랜잭션/동시성

- SQLite는 **database-level lock** 경향이 있습니다. PG는 MVCC로 동시성이 우수합니다.
- 격리수준/락 에러 핸들링(재시도 정책)을 도입해야 합니다.

### 연결/풀 설정

PG 연결 풀 설정:

```python
app.config.update(
    SQLALCHEMY_ENGINE_OPTIONS={
        "pool_pre_ping": True,
        "pool_size": 5,
        "max_overflow": 10,
        "pool_recycle": 1800,
    }
)
```

운영 환경에서는 pgbouncer 등 **중간 풀러**를 고려해야 합니다.

### 마이그레이션 경로

1. 코드가 **양쪽 드라이버**로 동작하도록 정리(타입/쿼리 호환)
2. 빈 PG 스키마에 `flask db upgrade` 실행
3. **데이터 마이그레이션** 수행:
   - 간단한 방법: sqlite에서 덤프 → 변환 → pg_restore
   - 안전한 방법: **어플리케이션 레벨 리플리케이션**(읽기 SQLite/쓰기 PG → 점진적 스위치)
4. **Read/Write 분리** 기간 운영(피크 시간 회피)
5. 전환 후 **모니터링/슬로우쿼리** 튜닝 수행

### 쿼리 차이

- `ILIKE`(PG) vs `LIKE`(SQLite): 대소문자 구분 검색을 재검토해야 합니다.
- JSON 필드: PG `jsonb`가 강력하고, SQLite는 약합니다. 검색/인덱스 전략을 변경해야 합니다.

---

## 트랜잭션 패턴 모음

### 두 단계 쓰기(Outbox 패턴)

- 상태 변경과 **이벤트 outbox 테이블**에 기록을 **같은 트랜잭션**에 저장합니다.
- 별도 워커가 outbox → 메시지 브로커(Kafka/SQS) 퍼블리시합니다.

```python
# pseudo model

class Outbox(db.Model):
    __tablename__ = "outbox"
    id = mapped_column(Integer, primary_key=True)
    topic = mapped_column(String(60), nullable=False)
    payload = mapped_column(JSON, nullable=False)
    created_at = mapped_column(DateTime(timezone=True))

def place_order(...):
    with transactional():
        # ... create order
        db.session.add(Outbox(topic="order_placed", payload={"order_id": order.id}))
```

### 재시도 가능한 실패 처리

- **SerializationFailure** 등 **일시적 오류**에 대해 백오프 재시도 데코레이터를 구현합니다.

```python
import time
from sqlalchemy.exc import OperationalError

def retryable(fn):
    def _(*a, **kw):
        for i in range(3):
            try:
                return fn(*a, **kw)
            except OperationalError as e:
                time.sleep(0.1 * (2 ** i))
        raise
    return _
```

---

## 테스트 전략

### 실제 엔진 대비

- 단위 테스트: `sqlite:///:memory:`로 빠르게 실행
- 통합 테스트: **PostgreSQL 테스트 컨테이너**(testcontainers)로 실제 동작 확인

```python
# tests/conftest.py (요약)

import pytest
from app import create_app
from app.extensions import db

@pytest.fixture()
def app():
    app = create_app()
    app.config.update(SQLALCHEMY_DATABASE_URI="sqlite:///:memory:", TESTING=True)
    with app.app_context():
        db.create_all()
        yield app
        db.drop_all()

@pytest.fixture()
def db_session(app):
    with app.app_context():
        yield db.session
        db.session.rollback()
```

---

## 흔한 안티패턴

- **모든 관계 lazy default**: 무심코 N+1 유발 → `raise/selectin`으로 기본화
- **세션 전역 재사용**: 누수/경합 → 요청/컨텍스트 범위로 제한
- **무계획 인덱싱**: 쓰기 성능 악화/불필요 인덱스 → 정기 정리 필요
- **거대 alter 1스텝 강행**: 잠금/다운타임 → 롤링/백필 전략 필요
- **SQLite 전제 가정**: FK 비활성/느슨한 타입에 의존 → PG 전환 시 문제 발생
- **downgrade로 데이터 되돌리기 기대**: 위험. 복구는 백업으로 수행

---

## 실전 예제: 주문 생성 API(ORM + 마이그레이션 + N+1 방지)

### 모델 (요약)

```python
# models/user.py / order.py (앞선 예시와 동일)
```

### 리포지토리

```python
# repositories/order_repo.py

from app.models.order import Order
from app.extensions import db

class OrderRepo:
    def get(self, order_id: int) -> Order | None:
        return db.session.get(Order, order_id)

    def add(self, order: Order) -> Order:
        db.session.add(order)
        return order

    def list_by_user(self, user_id: int, limit=50):
        from sqlalchemy.orm import selectinload
        q = db.session.query(Order).options(selectinload(Order.user)).filter_by(user_id=user_id)
        return q.order_by(Order.placed_at.desc()).limit(limit).all()
```

### 서비스

```python
# services/orders.py

from app.models.order import Order
from app.extensions import db
from contextlib import contextmanager

@contextmanager
def tx():
    try:
        yield
        db.session.commit()
    except:
        db.session.rollback()
        raise

def create_order(user_id: int, total: float) -> Order:
    with tx():
        o = Order(user_id=user_id, total=total)
        db.session.add(o)
        return o
```

### 블루프린트

```python
# blueprints/api/v1/orders.py

from flask import Blueprint, request
from app.services.orders import create_order
from app.repositories.order_repo import OrderRepo

blp = Blueprint("api_v1_orders", __name__)

@blp.post("/orders")
def post_order():
    data = request.get_json(silent=False)
    o = create_order(data["user_id"], float(data["total"]))
    return {"id": o.id, "user_id": o.user_id, "total": float(o.total)}, 201

@blp.get("/users/<int:user_id>/orders")
def list_orders(user_id: int):
    repo = OrderRepo()
    rows = repo.list_by_user(user_id)
    return [{"id":r.id,"total":float(r.total),"user": {"id": r.user.id, "name": r.user.name}} for r in rows]
```

`list_by_user` 메서드에서 `selectinload(Order.user)`를 사용해 **N+1 문제를 차단**하고 있습니다.

---

## 결론

이번 섹션에서는 Flask 애플리케이션에서 데이터베이스를 효과적으로 다루기 위한 핵심 개념과 실전 패턴을 다루었습니다. SQLAlchemy의 Core와 ORM을 상황에 맞게 선택하는 방법부터 시작하여, 세션과 트랜잭션의 적절한 범위 설정, N+1 문제를 방지하는 로딩 전략, 리포지토리 패턴을 통한 의존성 격리, 그리고 Alembic을 활용한 스키마 버전 관리까지 포괄적으로 살펴보았습니다.

특히 SQLite에서 PostgreSQL로의 전환을 고려할 때는 데이터 타입, 제약 조건, 트랜잭션 동작, 연결 풀링 등 여러 차이점을 신중히 고려해야 합니다. 마이그레이션 과정에서 데이터 무결성을 유지하면서도 서비스 다운타임을 최소화하는 전략이 중요합니다.

실제 프로젝트에서는 이러한 개념들을 조합하여 비즈니스 요구사항에 맞는 데이터베이스 접근 계층을 설계해야 합니다. ORM의 생산성과 Core의 성능을 적절히 조화시키고, 테스트 가능한 코드를 작성하며, 운영 환경에서 안정적으로 동작하는 시스템을 구축하는 것이 최종 목표입니다. 데이터베이스 레이어의 견고한 설계는 애플리케이션의 확장성과 유지보수성을 크게 향상시킵니다.