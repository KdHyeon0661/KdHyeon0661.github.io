---
layout: post
title: 선형대수 - 텐서와 다차원 선형대수
date: 2025-07-01 22:20:23 +0900
category: 선형대수
---
# 🔢 텐서와 다차원 선형대수

벡터는 1차원, 행렬은 2차원 구조입니다.  
하지만 복잡한 데이터, 물리 시스템, 신경망 구조, 기하학적 공간을 다루기 위해선 **3차원 이상의 객체**, 즉 **텐서(Tensor)**가 필요합니다.  
이 글에서는 **텐서란 무엇인지**, 그리고 이를 다루는 **다차원 선형대수(multilinear algebra)**의 기본 개념을 정리합니다.

---

## 📦 1. 텐서란?

### 📘 일반 정의

**텐서(Tensor)**는 **다중 인덱스를 가지는 다차원 배열**이며,  
수학적으로는 다음과 같은 **다중 선형 함수(multilinear map)**로 정의할 수 있습니다:

\[
T: V_1 \times V_2 \times \cdots \times V_k \to \mathbb{F}
\]

- \( T \): 텐서
- \( V_i \): 벡터공간
- \( \mathbb{F} \): 체 (예: \( \mathbb{R}, \mathbb{C} \))

즉, 텐서는 여러 개의 벡터를 받아 하나의 스칼라를 출력하는 **다변수 선형 함수**입니다.

---

### 🧮 순서(order) / 계수(rank)

- **0차 텐서**: 스칼라  
- **1차 텐서**: 벡터  
- **2차 텐서**: 행렬  
- **3차 이상**: 고차 텐서 (예: 이미지 데이터, 시간 시퀀스 등)

예:  
- RGB 이미지 \( \in \mathbb{R}^{H \times W \times 3} \)  
- 영상 데이터 \( \in \mathbb{R}^{T \times H \times W \times 3} \)

---

## 🧠 2. 다차원 선형대수란?

### 📌 기본 개념

**다차원 선형대수(Multilinear Algebra)**는 다음과 같은 선형대수의 확장을 다룹니다:

| 개념 | 일반 선형대수 | 다차원 선형대수 |
|------|----------------|------------------|
| 객체 | 벡터, 행렬 | 텐서 |
| 연산 | 선형결합, 곱 | 텐서곱, 축소, 전치 등 |
| 표현 | \( v_i, A_{ij} \) | \( T_{ijk...} \) |
| 기저 | \( e_i \) | \( e_i \otimes e_j \otimes \cdots \) |

---

## 🔁 3. 텐서곱 (Tensor Product)

### 📌 정의

두 벡터공간 \( V \), \( W \)에 대해 텐서곱은 다음을 정의합니다:

\[
V \otimes W = \text{Span} \{ \vec{v}_i \otimes \vec{w}_j \}
\]

여기서 \( \otimes \)는 **텐서곱 연산자**로, 각 원소쌍의 선형결합을 표현합니다.

### 📘 예제

\[
\vec{v} = [1, 2],\quad \vec{w} = [3, 4]
\Rightarrow \vec{v} \otimes \vec{w} =
\begin{bmatrix}
1 \cdot 3 & 1 \cdot 4 \\
2 \cdot 3 & 2 \cdot 4
\end{bmatrix}
=
\begin{bmatrix}
3 & 4 \\
6 & 8
\end{bmatrix}
\]

→ 결과는 2차 텐서(행렬)

---

## 🔄 4. 텐서 연산들

| 연산 | 설명 |
|------|------|
| **텐서곱** (\( \otimes \)) | 텐서 차원 증가 |
| **내적 (contract)** | 차원 축소 |
| **전치 (transpose)** | 인덱스 순서 변경 |
| **reshape** | 형태만 변경 (값은 보존) |
| **flatten** | 1차 벡터로 펼치기 |
| **모드 전개 (mode-n unfolding)** | 행렬 형태로 변환 |

---

## 🔢 5. 좌표 표현

3차 텐서 \( T \in \mathbb{R}^{I \times J \times K} \)는 다음과 같이 인덱스로 접근합니다:

\[
T = \sum_{i=1}^I \sum_{j=1}^J \sum_{k=1}^K T_{ijk} \cdot e_i \otimes e_j \otimes e_k
\]

- \( e_i \): 각 공간의 기저 벡터
- \( T_{ijk} \): 스칼라 계수 (성분)

---

## 🧪 예제 (NumPy)

```python
import numpy as np

# 3차 텐서
T = np.arange(2*3*4).reshape(2, 3, 4)

# 전치
T_transposed = np.transpose(T, (1, 0, 2))  # 모드 1과 0을 교환

# 축소 (내적)
v = np.array([1, 0])
contracted = np.tensordot(v, T, axes=([0], [0]))

print("contracted shape:", contracted.shape)  # (3, 4)
```

---

## 🔬 6. 응용 분야

| 분야 | 설명 |
|------|------|
| **물리학** | 텐서는 장(場), 응력, 변형률 등 표현 |
| **기하학/미분기하학** | 리만 곡률 텐서, 계량 텐서 등 |
| **머신러닝** | CNN 필터, 트랜스포머 주의 메커니즘 등 |
| **컴퓨터 그래픽스** | 변환 행렬의 다차원 확장 |
| **양자컴퓨팅** | 상태벡터는 고차 텐서, 텐서망 계산 |

---

## ✅ 요약

| 개념 | 설명 |
|------|------|
| 텐서 | 다차원 선형 구조 (0차 = 스칼라, 1차 = 벡터, 2차 = 행렬, ... ) |
| 다차원 선형대수 | 고차 텐서의 구조와 연산 다룸 |
| 텐서곱 | 독립적 선형공간을 결합 |
| 연산 | 전치, 축소, 전개, 재구성 등 |
| 활용 | 물리학, 딥러닝, 영상처리 등 |