---
layout: post
title: 딥러닝 - 신경망 블록
date: 2025-09-27 20:25:23 +0900
category: 딥러닝
---
# 1.9 신경망 블록 베이직
**MLP 구조 · CNN 기본(컨볼루션/패딩/스트라이드·풀링) · RNN 개관(LSTM/GRU 맥락)**

## A. MLP(다층 퍼셉트론)

### A-1. 핵심 개념: Affine + Activation 의 반복
- 한 층: $$\mathbf{h}=\phi(\mathbf{W}\mathbf{x}+\mathbf{b})$$  
- MLP: $$\mathbf{h}_1=\phi_1(\mathbf{W}_1\mathbf{x}+\mathbf{b}_1),\;
\mathbf{h}_2=\phi_2(\mathbf{W}_2\mathbf{h}_1+\mathbf{b}_2),\;\dots$$
- **보편근사정리**: 충분한 너비/깊이가 있으면 연속함수 근사 가능(실제 학습/일반화는 별개).

### A-2. 파라미터 수와 Shape 계산
- 완전연결층(Linear)의 파라미터 수:
  $$
  \#\text{params} = d_{\text{in}}\cdot d_{\text{out}} + d_{\text{out}}.
  $$
- 예) (128→256) Linear: $$128\cdot 256 + 256 = 33{,}024$$

### A-3. 활성함수 선택 (요약)
- **은닉층 기본**: ReLU/LeakyReLU/GELU  
- **출력층**: 과제에 맞게 (회귀=선형, 이진=BCEWithLogits 로짓, 다중=CE 로짓)

### A-4. 간단 분류 MLP — 코드
```python
import torch, torch.nn as nn
from torch.utils.data import DataLoader, TensorDataset

class MLP(nn.Module):
    def __init__(self, d_in, d_hidden, d_out, p_drop=0.1):
        super().__init__()
        self.net = nn.Sequential(
            nn.Linear(d_in, d_hidden), nn.GELU(),
            nn.Dropout(p_drop),
            nn.Linear(d_hidden, d_hidden), nn.GELU(),
            nn.Linear(d_hidden, d_out)  # 로짓(CE와 결합)
        )
    def forward(self, x): return self.net(x)

# 더미 데이터(다중분류)
torch.manual_seed(0)
N, D, K = 2048, 20, 5
X = torch.randn(N, D)
Wtrue = torch.randn(D, K)
y = (X @ Wtrue).argmax(1)

ds = TensorDataset(X, y)
dl = DataLoader(ds, batch_size=128, shuffle=True)

model = MLP(D, 128, K)
opt = torch.optim.AdamW(model.parameters(), lr=3e-3, weight_decay=1e-2)
crit = nn.CrossEntropyLoss()

for ep in range(10):
    for xb, yb in dl:
        opt.zero_grad(set_to_none=True)
        logits = model(xb)
        loss = crit(logits, yb)
        loss.backward()
        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)
        opt.step()
```

### A-5. 실전 팁
- **정규화**: MLP에서도 `LayerNorm`(특히 Transformer 계열)이나 `BatchNorm1d`를 섞어 안정화 가능.  
- **드롭아웃**: 은닉층 중간에 0.1~0.5.  
- **입력 스케일**: 표준화/정규화가 수렴에 도움이 됨.

---

## B. CNN 기본

### B-1. 컨볼루션의 정의(딥러닝 구현 관점)
- DL 프레임워크의 “Conv”는 엄밀한 수학적 컨볼루션이 아닌 **cross-correlation**을 사용:
  $$
  y_{(c_{\text{out}}, i, j)}=\sum_{c=1}^{C_{\text{in}}}\sum_{u=1}^{k_h}\sum_{v=1}^{k_w}
  W_{(c_{\text{out}}, c, u, v)}\cdot x_{(c,\, i+u-\Delta_h,\, j+v-\Delta_w)} + b_{c_{\text{out}}}.
  $$
- **패딩**(P), **스트라이드**(S), **커널 크기**(K), **딜레이션**(D)로 출력 크기:
  $$
  H_{\text{out}}=\Big\lfloor\frac{H+2P - D\cdot (K_h-1)-1}{S}\Big\rfloor+1,\quad
  W_{\text{out}}=\Big\lfloor\frac{W+2P - D\cdot (K_w-1)-1}{S}\Big\rfloor+1.
  $$

### B-2. 패딩 / 스트라이드 / 딜레이션 직관
- **패딩(P)**: 가장자리 정보 보존(“same” 패딩은 출력 H,W 유지).  
- **스트라이드(S)**: 출력 해상도 축소(특징 맵 다운샘플링).  
- **딜레이션(D)**: 커널 간격을 넓혀 **수용영역(Receptive Field)** 확대(해상도 유지).

### B-3. 파라미터 수
- 2D Conv: 
  $$
  \#\text{params} = C_{\text{out}}\cdot \Big(\frac{C_{\text{in}}}{\text{groups}}\Big)\cdot K_h K_w + C_{\text{out}}.
  $$
- **Groups/Depthwise**: `groups=C_in`이면 depthwise conv(채널별 필터), 이후 1×1 pointwise로 결합 → MobileNet류.

### B-4. 풀링(Pooling)
- **MaxPool**: 위치 불변성 증가(가장 강한 응답 유지).  
- **AvgPool / GlobalAvgPool(GAP)**: 평균을 취해 **채널별 대표값**(GAP은 분류 헤드에서 자주 사용).  
- **Strided Conv vs Pooling**: 둘 다 다운샘플링. 최근엔 단순화를 위해 **스트라이드 Conv**만 쓰기도.

### B-5. CNN 블록의 전형 구조
- `Conv → Norm(BN/GN) → Activation(ReLU/GELU)`  
- 다운샘플링 구간에서 `stride=2` 혹은 `MaxPool(2)`.

### B-6. 예제 1: 출력 크기 계산 도우미
```python
def conv2d_out(h, w, k, s=1, p=0, d=1):
    # k, s, p, d는 (kh, kw) 또는 int
    import math
    kh, kw = (k, k) if isinstance(k, int) else k
    sh, sw = (s, s) if isinstance(s, int) else s
    ph, pw = (p, p) if isinstance(p, int) else p
    dh, dw = (d, d) if isinstance(d, int) else d
    hout = math.floor((h + 2*ph - d*(kh-1) - 1)/sh + 1)
    wout = math.floor((w + 2*pw - d*(kw-1) - 1)/sw + 1)
    return hout, wout

print(conv2d_out(224, 224, k=7, s=2, p=3))  # → (112, 112)
```

### B-7. 예제 2: 작은 이미지 분류 CNN
```python
import torch, torch.nn as nn
class SmallCNN(nn.Module):
    def __init__(self, num_classes=10, norm='bn'):
        super().__init__()
        def N(ch):  # 정규화 스위치
            if norm=='bn': return nn.BatchNorm2d(ch)
            if norm=='gn': return nn.GroupNorm(32, ch)
            return nn.Identity()
        self.features = nn.Sequential(
            nn.Conv2d(3, 64, 3, padding=1, bias=False), N(64), nn.ReLU(inplace=True),
            nn.Conv2d(64, 64, 3, padding=1, bias=False), N(64), nn.ReLU(inplace=True),
            nn.MaxPool2d(2),  # 1/2
            nn.Conv2d(64, 128, 3, padding=1, bias=False), N(128), nn.ReLU(inplace=True),
            nn.Conv2d(128,128, 3, padding=1, bias=False), N(128), nn.ReLU(inplace=True),
            nn.MaxPool2d(2),  # 1/2
            nn.Conv2d(128,256, 3, padding=1, bias=False), N(256), nn.ReLU(inplace=True),
            nn.AdaptiveAvgPool2d(1),  # GAP
        )
        self.head = nn.Linear(256, num_classes)

    def forward(self, x):
        x = self.features(x)     # (B,256,1,1)
        x = x.flatten(1)         # (B,256)
        return self.head(x)      # 로짓

# 더미 입력
x = torch.randn(4,3,32,32)
print(SmallCNN()(x).shape)  # torch.Size([4, 10])
```

### B-8. 실전 팁
- **BN을 쓴다면 Conv의 bias=False** (BN의 β가 shift 역할).  
- 다운샘플링은 `stride=2` Conv로도 충분(파라미터/속도 트레이드오프 고려).  
- **수용영역**: 깊이/커널/딜레이션으로 확장. 작은 물체 검출엔 해상도 유지가 중요.  
- **Transposed Conv(Deconv)**: 업샘플링에 사용(세그멘테이션 등). Checkerboard 아티팩트 예방을 위해 `Upsample → Conv` 조합도 자주 사용.

---

## C. RNN 개관: Vanilla → LSTM → GRU

### C-1. 왜 RNN인가?
- 시계열/문장/이벤트 스트림 등 **순서가 중요한 데이터**에 적합.  
- 과거 정보를 **상태(hidden state)** 로 요약해 다음 스텝 예측에 사용.

### C-2. 바닐라 RNN(요약)
- 업데이트:
  $$
  \mathbf{h}_t = \phi(\mathbf{W}_h \mathbf{h}_{t-1} + \mathbf{W}_x \mathbf{x}_t + \mathbf{b})
  $$
- **문제**: 긴 시퀀스에서 **기울기 소실/폭주**.

### C-3. LSTM(Long Short-Term Memory)
- **게이트**로 정보 흐름 제어:
  $$
  \begin{aligned}
  \mathbf{i}_t &= \sigma(\mathbf{W}_i[\mathbf{h}_{t-1},\mathbf{x}_t]+\mathbf{b}_i)\\
  \mathbf{f}_t &= \sigma(\mathbf{W}_f[\mathbf{h}_{t-1},\mathbf{x}_t]+\mathbf{b}_f)\\
  \mathbf{o}_t &= \sigma(\mathbf{W}_o[\mathbf{h}_{t-1},\mathbf{x}_t]+\mathbf{b}_o)\\
  \tilde{\mathbf{c}}_t &= \tanh(\mathbf{W}_c[\mathbf{h}_{t-1},\mathbf{x}_t]+\mathbf{b}_c)\\
  \mathbf{c}_t &= \mathbf{f}_t \odot \mathbf{c}_{t-1} + \mathbf{i}_t \odot \tilde{\mathbf{c}}_t\\
  \mathbf{h}_t &= \mathbf{o}_t \odot \tanh(\mathbf{c}_t)
  \end{aligned}
  $$
- 셀 상태 $$\mathbf{c}_t$$ 가 **정보를 오래 보존**.

### C-4. GRU(Gated Recurrent Unit)
- 더 간결한 두 게이트 구조:
  $$
  \begin{aligned}
  \mathbf{z}_t &= \sigma(\mathbf{W}_z[\mathbf{h}_{t-1},\mathbf{x}_t]) \\
  \mathbf{r}_t &= \sigma(\mathbf{W}_r[\mathbf{h}_{t-1},\mathbf{x}_t]) \\
  \tilde{\mathbf{h}}_t &= \tanh(\mathbf{W}[\mathbf{r}_t\odot \mathbf{h}_{t-1},\mathbf{x}_t]) \\
  \mathbf{h}_t &= (1-\mathbf{z}_t)\odot \tilde{\mathbf{h}}_t + \mathbf{z}_t \odot \mathbf{h}_{t-1}
  \end{aligned}
  $$
- 파라미터 적고 빠른 경향.

### C-5. 시퀀스 태스크 유형
- **Many-to-One**: 감성분석(문장→긍/부정). 마지막 hidden만 FC로 분류.  
- **Many-to-Many**: 태깅/번역(입력 길이와 출력 길이가 다를 수도). Teacher Forcing 고려.

### C-6. PyTorch LSTM 기본 사용
```python
import torch, torch.nn as nn

# 입력: (seq_len, batch, input_size) 또는 batch_first=True → (batch, seq_len, input_size)
lstm = nn.LSTM(input_size=128, hidden_size=256, num_layers=2, dropout=0.1, batch_first=True, bidirectional=True)

x = torch.randn(32, 50, 128)  # (B=32, T=50, D_in=128)
out, (h_n, c_n) = lstm(x)
# out: (B, T, D_out) with D_out=hidden*2 for bidirectional
# h_n/c_n: (num_layers*directions, B, hidden_size)

# 예: Many-to-One 분류(마지막 타임스텝 사용)
logits = nn.Linear(256*2, 3)(out[:, -1, :])  # 3개 클래스
```

### C-7. 가변 길이 시퀀스(패킹/마스킹)
- **패딩 토큰**을 무시하려면 `pack_padded_sequence` 사용:
```python
from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence

# x_padded: (B, T_max, D), lengths: 실제 길이 리스트(내림차순 정렬 필요)
packed = pack_padded_sequence(x_padded, lengths, batch_first=True, enforce_sorted=False)
out_packed, (h_n, c_n) = lstm(packed)
out, _ = pad_packed_sequence(out_packed, batch_first=True)  # (B, T_max, D_out)
```

### C-8. RNN 실전 팁
- **Gradient Clipping**(폭주 방지): `clip_grad_norm_`.  
- **Truncated BPTT**: 아주 긴 시퀀스는 구간으로 잘라 역전파.  
- **Bidirectional**: 앞/뒤 문맥 모두 활용(분류/태깅에 자주 사용).  
- **Dropout**: `nn.LSTM`의 dropout은 **층 사이**에만 적용. 타임스텝 간에는 **variational dropout** 개념을 별도 구현하기도 한다.  
- **초기화**: `h_0, c_0`를 0으로 두거나 학습 파라미터로 둘 수 있다.

---

## D. 미니 프로젝트 1 — MLP vs CNN: 작은 이미지 분류

### D-1. 데이터(가상)
- 32×32 RGB 이미지, 2개 클래스(원형 vs 십자). **MLP**는 Flatten 후 처리, **CNN**은 2D 구조를 활용.

### D-2. 코드 스니펫
```python
import torch, torch.nn as nn, torch.nn.functional as F

class MLP_Img(nn.Module):
    def __init__(self, num_classes=2):
        super().__init__()
        self.net = nn.Sequential(
            nn.Flatten(),            # (B, 3*32*32)
            nn.Linear(3*32*32, 512), nn.GELU(),
            nn.Linear(512, 256),     nn.GELU(),
            nn.Linear(256, num_classes)
        )
    def forward(self, x): return self.net(x)

class CNN_Img(nn.Module):
    def __init__(self, num_classes=2):
        super().__init__()
        self.feat = nn.Sequential(
            nn.Conv2d(3, 32, 3, padding=1, bias=False), nn.BatchNorm2d(32), nn.ReLU(),
            nn.Conv2d(32,64, 3, padding=1, bias=False), nn.BatchNorm2d(64), nn.ReLU(),
            nn.MaxPool2d(2), # 16×16
            nn.Conv2d(64,128,3, padding=1, bias=False), nn.BatchNorm2d(128), nn.ReLU(),
            nn.AdaptiveAvgPool2d(1),
        )
        self.head = nn.Linear(128, num_classes)
    def forward(self, x):
        x = self.feat(x).flatten(1)
        return self.head(x)
```

> **관찰**: MLP도 충분히 학습되지만 **공간 구조**를 직접 활용하는 CNN이 **파라미터 효율/성능**에서 유리.

---

## E. 미니 프로젝트 2 — LSTM으로 시퀀스 분류

### E-1. 태스크
- 길이 다양한 숫자 시퀀스에서 “**합이 임곗값 이상이면 1, 아니면 0**”을 예측(가상의 many-to-one).

### E-2. 코드 (패킹 포함)
```python
import torch, torch.nn as nn
from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence
torch.manual_seed(0)

class LSTMClassifier(nn.Module):
    def __init__(self, d_in=16, hidden=64, num_layers=2, bidir=True):
        super().__init__()
        self.lstm = nn.LSTM(d_in, hidden, num_layers=num_layers, batch_first=True, dropout=0.1, bidirectional=bidir)
        self.fc = nn.Linear(hidden*(2 if bidir else 1), 2)

    def forward(self, x, lengths):
        # x: (B, T_max, D), lengths: (B,)
        packed = pack_padded_sequence(x, lengths.cpu(), batch_first=True, enforce_sorted=False)
        out_packed, (h_n, c_n) = self.lstm(packed)
        # bidirectional → 마지막 layer의 두 방향 hidden을 concat
        if self.lstm.bidirectional:
            h_last = torch.cat([h_n[-2], h_n[-1]], dim=-1)  # (B, hidden*2)
        else:
            h_last = h_n[-1]                                # (B, hidden)
        logits = self.fc(h_last)
        return logits

# 더미 배치 만들기
B, D = 8, 16
lengths = torch.randint(low=5, high=30, size=(B,))
T_max = lengths.max().item()
x = torch.randn(B, T_max, D)
y = (x.sum(dim=(1,2)) > 0).long()

model = LSTMClassifier(d_in=D)
opt = torch.optim.AdamW(model.parameters(), lr=2e-3, weight_decay=1e-2)
ce = nn.CrossEntropyLoss()

for _ in range(50):
    opt.zero_grad(set_to_none=True)
    logits = model(x, lengths)
    loss = ce(logits, y)
    loss.backward()
    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)
    opt.step()
```

> **핵심**: `pack_padded_sequence` 로 **패딩 무시**, `clip_grad_norm_` 로 **폭주 방지**.

---

## F. 1D/2D/3D Conv — 어느 때 쓰나?

- **1D Conv**: 오디오 파형, 센서 시계열, 토큰 임베딩 위에 얹는 Temporal CNN.  
- **2D Conv**: 이미지/비전.  
- **3D Conv**: 비디오(시간축 포함), 의학 영상(3D 볼륨).  
- 1D Conv 출력 길이:
  $$
  L_{\text{out}}=\Big\lfloor\frac{L+2P - D\cdot (K-1)-1}{S}\Big\rfloor+1.
  $$

**간단 1D Conv 예시(시계열 분류)**
```python
import torch, torch.nn as nn
class TCN(nn.Module):
    def __init__(self, d_in=4, ch=64, num_classes=3):
        super().__init__()
        self.net = nn.Sequential(
            nn.Conv1d(d_in, ch, 5, padding=2), nn.ReLU(),
            nn.Conv1d(ch, ch, 5, padding=2), nn.ReLU(),
            nn.AdaptiveAvgPool1d(1)
        )
        self.head = nn.Linear(ch, num_classes)
    def forward(self, x):      # x: (B, C_in, L)
        h = self.net(x).squeeze(-1)
        return self.head(h)

x = torch.randn(16, 4, 200)
print(TCN()(x).shape)  # torch.Size([16, 3])
```

---

## G. 블록 조합과 설계 체크리스트

1) **MLP**
   - 입력 전처리(스케일링)  
   - 은닉층: Linear → (Norm) → GELU/ReLU → Dropout  
   - 출력층: 과제별 로짓, 손실은 **안정형(BCEWithLogits/CE)**  
   - 과적합 시 Dropout↑, WD↑, 데이터 증강(표(tabular)면 MixUp/노이즈)

2) **CNN**
   - Conv(bias=False) → Norm(BN/GN) → Act → (Pooling or stride conv)  
   - 다운샘플링 단계는 3~5번(입력 크기/문제 난이도에 따라)  
   - 마지막은 **GAP** 후 FC (채널 수 = 특성 차원)  
   - 작은 배치면 **GN/LN** 또는 **SyncBN**  
   - 업샘플링은 `Upsample(scale) → Conv`(아티팩트 완화)

3) **RNN(LSTM/GRU)**
   - `batch_first=True` 습관화(루프 가독성↑)  
   - 가변 길이는 **pack/pad** 사용  
   - 긴 시퀀스는 **Truncated BPTT**  
   - **Clip grad** 필수(1.0 근처)  
   - Many-to-One vs Many-to-Many에 맞게 head 구성

4) **공통**
   - **초기화**: ReLU/GELU→He, tanh/선형→Xavier  
   - **정규화**: BN(큰 배치)/LN·GN(작은 배치)  
   - **스케줄**: Cosine/OneCycle + Warmup  
   - **정규화형 규제**: Weight Decay(AdamW no_decay 그룹), Dropout  
   - **재현성**: 시드 고정, DataLoader의 `worker_init_fn`/`generator` 관리

---

## H. 자주 하는 실수와 방지책

- **CE에 softmax 중복**: 로짓을 그대로 `CrossEntropyLoss`에 넣기.  
- **BCEWithLogits에 sigmoid 중복**: 로짓을 그대로 넣기.  
- **Conv bias=True + BN**: 중복 → `bias=False`.  
- **BN 작은 배치 불안정**: GN/LN/SyncBN 전환.  
- **RNN 길이 미스매치**: pack/pad에서 `enforce_sorted=False` 또는 lengths 정렬.  
- **Gradient 폭주**: 클리핑/스케줄/LR 조정.  
- **형태(Shape) 오류**: `print(t.shape)` · `einops`(개념적으로)로 확실히 점검.

---

## I. 빠른 수식 모음(암기 카드)

- Conv2D 출력 크기:
  $$
  H_{\text{out}}=\Big\lfloor\frac{H+2P - D\cdot (K_h-1)-1}{S}\Big\rfloor+1,\quad
  W_{\text{out}}=\Big\lfloor\frac{W+2P - D\cdot (K_w-1)-1}{S}\Big\rfloor+1
  $$
- Conv2D 파라미터 수:
  $$
  C_{\text{out}}\cdot \Big(\frac{C_{\text{in}}}{\text{groups}}\Big)\cdot K_h K_w + C_{\text{out}}
  $$
- MLP Linear 파라미터 수:
  $$
  d_{\text{in}} d_{\text{out}} + d_{\text{out}}
  $$
- LSTM 게이트:
  $$
  \mathbf{i},\mathbf{f},\mathbf{o}=\sigma(\cdot),\quad \tilde{\mathbf{c}}=\tanh(\cdot),\quad
  \mathbf{c}_t = \mathbf{f}\odot\mathbf{c}_{t-1} + \mathbf{i}\odot\tilde{\mathbf{c}},\;
  \mathbf{h}_t=\mathbf{o}\odot\tanh(\mathbf{c}_t)
  $$
- GRU 게이트:
  $$
  \mathbf{z},\mathbf{r}=\sigma(\cdot),\quad
  \mathbf{h}_t=(1-\mathbf{z})\odot \tilde{\mathbf{h}} + \mathbf{z}\odot \mathbf{h}_{t-1}
  $$

---

## J. 마무리
- **MLP**는 가장 보편적인 근사기,  
- **CNN**은 **공간적 패턴**을 파라미터 효율적으로 포착,  
- **RNN(LSTM/GRU)** 은 **순서/문맥**을 상태로 전달.  
현대 딥러닝의 대부분은 이 블록들을 섞어 문제를 풀며, 이후 장(Attention & Transformer)에서 **순서 정보를 더 잘 다루는 대안**을 본격적으로 다루게 됩니다.  
실습 코드는 바로 붙여 넣어 실행해 보면서, **입력/출력의 Shape**과 **학습 안정 장치**(정규화·스케줄·클리핑)를 항상 점검하세요.