---
layout: post
title: 컴퓨터시스템 - 물리 및 가상 주소 방식
date: 2025-08-16 19:20:23 +0900
category: 컴퓨터시스템
---
# 물리(Physical) 및 가상(Virtual) 주소 방식

## 0. 한눈 개요 — “가상 주소 → 물리 주소”의 파이프라인

```
프로세스(가상 주소, VA)
   ├─ 코드/데이터/힙/스택/맵핑(권한: R/W/X)
   └─ (접근) ─► CPU
                 └─ TLB 조회(히트? 변환 완료)
                     └─ 미스 → 페이지 워크(페이지 테이블 따라가기)
                             └─ PTE 검사(R/W/X, U/S, NX, A/D, Present)
                                   ├─ 합법 → PFN‖Offset = 물리 주소(PA)
                                   └─ 불법 → #PF(Page Fault) → 커널 처리
DRAM/캐시 서브시스템 (PA)
```

**이점(왜 두 주소?)**
1) **격리/보호**: 프로세스·커널 간 접근 차단  
2) **유연성**: 산개한 물리 프레임을 연속 VA로 제공(큰 힙, 파일 매핑)  
3) **기능/성능**: COW, ASLR, 공유 라이브러리, huge page, NUMA 최적화

---

## 1. 주소의 수학 — VPN‖Offset → PFN‖Offset

가상 주소는 **페이지 번호 + 오프셋**으로 쪼개진다(4KB 페이지 가정).

$$
\begin{aligned}
\text{VA} &= \underbrace{\text{VPN}}_{\text{상위 비트}} \,\|\, \underbrace{\text{Offset}}_{12\text{ bits}} \\
\text{PA} &= \underbrace{\text{PFN}}_{\text{프레임 번호}} \,\|\, \text{Offset}
\end{aligned}
$$

여기서 **페이지 테이블**은 \( \text{VPN} \mapsto (\text{PFN}, \text{권한}) \) 매핑을 정의한다.  
MMU는 PTE의 **권한 비트(R/W/X, U/S, NX, A/D, Present)** 를 검사하여 허용/거부를 결정.

---

## 2. 물리 주소 방식(직접 접근)의 세계(역사/임베디드)

- **특징**: VA 없이 CPU가 **직접 물리 주소**를 발생. MMU·페이지 테이블 불필요 → 단순/저오버헤드.
- **한계**: **보호/격리 부재**. 현대 범용 OS에는 부적합.  
- **현대 사용처**: 아주 작은 MCU/RTOS, 특수 펌웨어 일부.

---

## 3. 가상 주소 방식(현대 OS의 표준) — 페이징과 보호

### 3.1 페이징(Paging)의 핵심
- VA 공간을 **고정 크기 페이지**로 나눠 **물리 프레임**에 매핑.
- 불연속 PA를 연속 VA로 보이게 함 → **큰 힙/연속 배열** 가능.

### 3.2 보호/격리
- **PTE 권한**(R/W/X, U/S, NX)으로 접근 제어.
- 사용자/커널 분리: 사용자 모드는 **커널 페이지 접근 불가**.
- 위반 시 **#PF → SIGSEGV** 로 격리 종료.

### 3.3 수요 페이징(Demand Paging)
- 실제 접근이 있을 때만 페이지만 올림 → 메모리 절약.
- 디스크 I/O와 결합(페이지 캐시): 파일 매핑이 빠른 이유.

### 3.4 COW(Copy-On-Write)
- `fork()` 직후 부모/자식은 **읽기전용** 공유.  
- **쓰기 시점**에만 사본을 할당 → 빠른 포크·낮은 메모리.

---

## 4. x86-64 주소 변환 — 4/5 레벨 페이징, NX/SMEP/SMAP

### 4.1 4-레벨(전통 48-bit canonical) 주소구조(4KB 페이지)

```
VA[47:39] PML4 index  ┐
VA[38:30] PDPT index  ├─ 각 9비트
VA[29:21] PD   index  ┤
VA[20:12] PT   index  ┘
VA[11:0]  Offset
```

- **huge page**: PD(2MB), PDPT(1GB)에서 큰 페이지 비트로 종결.
- **LA57(5-레벨)**: 선택적으로 57-bit VA(상위 9비트 레벨 추가) 지원 시스템도 있음.

### 4.2 PTE 주요 비트
- **P**(Present), **R/W**, **U/S**, **NX**(Execute Disable), **A/D**(Access/Dirty)
- **W^X** 정책: 한 페이지에 **동시 RWX 금지**(보안↑). JIT은 **RW→RX 전환** 패턴 사용.

### 4.3 커널 보호 가속
- **SMEP**: 커널 모드에서 **사용자 공간 코드 실행 금지**  
- **SMAP**: 커널의 사용자 페이지 **읽기/쓰기 금지**(명시적 케어 필요)  
- **KPTI**: 사용자/커널 **페이지 테이블 분리**(측채널 완화)

---

## 5. ARMv8(AArch64) 개요 — TTBR, PXN/UXN, 가변 페이지 크기

- **TTBR0/TTBR1**: 사용자/커널 루트 테이블 분리.  
- **페이지 크기**: 4KB / 16KB / 64KB 선택 가능(SoC·OS 정책).  
- **PXN/UXN**: 권한별 **Execute-Never**. **PAN**(Privileged Access Never) 등 세밀 보호.

---

## 6. TLB(Translation Lookaside Buffer) — 주소 변환의 캐시

- **I-TLB / D-TLB / L2-TLB** 등 다단 구조. 대부분 접근은 **TLB 히트**로 해결.
- **TLB 미스**: 페이지 워크(4~5회의 메모리 접근) → 비싸다.  
- **huge page(2MB/1GB)**: TLB 엔트리 효율↑, 페이지 워크↓ → **대용량 워킹셋** 유리.

---

## 7. 커널·사용자 VA 배치(리눅스 예, 단순화)

```
[ 높은 주소 ]
Kernel text/data (R-X / RW-)
vmalloc/ioremap
Direct physical map
-----------------------------------
User stack        (ASLR, RW-)
Shared libraries  (ASLR, R-X/RO)
Heap              (ASLR, RW-)
Code (PIE)        (ASLR, R-X)
NULL page         (unmapped)
[ 낮은 주소 ]
```

- **ASLR**: 스택/힙/맵핑/PIE 베이스 랜덤화 → 익스플로잇 난이도↑.

---

## 8. 파일/공유 메모리 매핑 — 메모리처럼 쓰는 I/O

### 8.1 파일 매핑
```c
#include <sys/mman.h>
#include <fcntl.h>
#include <unistd.h>
int fd = open("data.bin", O_RDWR);
void* p = mmap(NULL, 1<<20, PROT_READ|PROT_WRITE, MAP_SHARED, fd, 0);
// p에 쓰면 OS가 dirty 페이지를 백그라운드로 writeback
```

### 8.2 공유 메모리
- `MAP_SHARED` / POSIX `shm_open` / SysV `shmget`  
- **같은 물리 페이지**를 **여러 프로세스 VA**에 매핑 → **고속 IPC**

---

## 9. 페이지 폴트(Page Fault) — 합법과 불법

- **합법 폴트**: 수요페이징(아직 안 올림), COW 트랩, 스왑 인 → 커널이 PTE 채움 후 재시도.
- **불법 폴트**: 권한 위반/미매핑 → **SIGSEGV**. 사용자 핸들러로 로깅 가능.

---

## 10. I/O와 주소 — DMA, IOMMU, 고정(pinning)

- 장치 DMA는 **물리 주소**가 필요.  
- **IOMMU**: 장치에도 **장치-가상 주소(IOVA) → 물리** 변환 제공.  
  - 장치 격리(버스 마스터 악용 방지), **산개 버퍼를 연속 IOVA**로 제공.  
- 고성능 DMA는 페이지를 **핀(pin)** 하여 스왑/이동을 금지.

---

## 11. 가상화 — EPT/NPT의 2차 변환

- 게스트: **VA → GPA(게스트 물리)** (게스트 페이지 테이블)  
- 하드웨어: **GPA → HPA(호스트 물리)** (**EPT/NPT**, 2차 테이블)
- 비용↑(이중 TLB). → **Nested/Combined TLB**, **EPT huge page**로 완화.  
- **EPT 권한 비트(R/W/X)**, 위반 시 **VM-Exit** 발생.

---

## 12. 캐시와 인덱싱 — VIPT, aliasing 주의

- L1D가 **VIPT(virtually indexed, physically tagged)** 가 일반적.  
- **에일리어스**(같은 PA가 서로 다른 VA로 매핑) 시 캐시 동기화 이슈 → 커널이 **페이지 컬러링/플러시**로 관리.  
- 사용자 입장에서는 **동일 물리 페이지를 여러 VA로 중복 매핑**하지 않도록 설계.

---

## 13. 성능 튜닝 — TLB·huge page·NUMA·madvise

### 13.1 Transparent Huge Pages(THP) vs hugetlbfs
- **THP**: 커널이 자동으로 2MB 페이지로 승격(워크로드에 따라 성패 갈림).  
- **hugetlbfs**: 명시적 2MB/1GB huge page 예약/사용 → 예측 가능, 관리 필요.

### 13.2 `madvise`/`posix_fadvise`
- 순차 접근: `madvise(p,len,MADV_SEQUENTIAL)`  
- 랜덤 접근: `MADV_RANDOM`  
- 필요 없음: `MADV_DONTNEED`  
- 파일 I/O 힌트: `posix_fadvise(fd, 0, 0, POSIX_FADV_SEQUENTIAL)`

### 13.3 NUMA
- **first-touch** 정책: 최초 접근 CPU의 노드에 프레임 할당.  
- 바인딩: `numactl --cpunodebind=0 --membind=0 ./app`

---

## 14. 보안/격리 — W^X, NX, SMEP/SMAP, ASLR, KASLR

- **W^X**: 쓰기와 실행을 분리(동시에 부여 금지).  
- **NX/XD/UXN**: 데이터 실행 방지.  
- **SMEP/SMAP**: 커널의 사용자 코드 실행/접근 차단.  
- **ASLR/KASLR**: 사용자/커널 주소 랜덤화.

---

## 15. 실전 코드 — 관측/실험/튜닝

### 15.1 VA/보호/폴트 관찰(간단)
```c
// vm_maps.c
#include <stdio.h>
#include <sys/mman.h>
#include <string.h>
#include <unistd.h>

int main(){
    long ps = sysconf(_SC_PAGESIZE);
    void* p = mmap(NULL, ps, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0);
    printf("VA=%p (page=%ld)\n", p, ps);
    strcpy((char*)p, "hello");
    mprotect(p, ps, PROT_READ);
    // ((char*)p)[0]='H'; // 주석을 풀면 SIGSEGV
    pause(); // /proc/$$/maps 관찰 시간
    return 0;
}
```

### 15.2 TLB 민감도 측정(스트라이드 접근 + perf)
```c
// tlb_stride.c
#define _GNU_SOURCE
#include <stdio.h>
#include <stdlib.h>
#include <stdint.h>
#include <time.h>
#include <unistd.h>

int main(int argc, char** argv){
    size_t n = (argc>1? atol(argv[1]): 256*1024*1024); // 바이트
    size_t stride = (argc>2? atol(argv[2]): 4096);     // 바이트
    uint8_t *a = aligned_alloc(4096, n);
    for(size_t i=0;i<n;i+=4096) a[i]=1; // pre-touch
    struct timespec t0,t1; clock_gettime(CLOCK_MONOTONIC,&t0);
    volatile uint64_t s=0;
    for(size_t i=0;i<n;i+=stride) s += a[i];
    clock_gettime(CLOCK_MONOTONIC,&t1);
    double dt = (t1.tv_sec-t0.tv_sec)+(t1.tv_nsec-t0.tv_nsec)/1e9;
    printf("sum=%lu time=%.6f stride=%zu\n", s, dt, stride);
    free(a);
}
```
실행/측정:
```bash
gcc -O2 tlb_stride.c -o tlb_stride
perf stat -e page-faults,minor-faults,major-faults,dtlb_load_misses.walk_duration ./tlb_stride $((512*1024*1024)) 4096
perf stat -e dTLB-load-misses,dTLB-loads ./tlb_stride $((512*1024*1024)) 4096
# stride를 4K→2M→1G로 바꿔 TLB/huge page 효과 비교
```

### 15.3 Transparent Huge Pages(THP) ON/OFF 비교(히ント)
```bash
cat /sys/kernel/mm/transparent_hugepage/enabled
# [always] madvise never
echo madvise | sudo tee /sys/kernel/mm/transparent_hugepage/enabled
# 코드에서는 madvise(ptr,len,MADV_HUGEPAGE) 사용
```

### 15.4 명시적 huge page(hugetlbfs) 사용
```bash
# 준비
sudo mkdir -p /mnt/huge
echo 128 | sudo tee /proc/sys/vm/nr_hugepages   # 2MB x 128 예약
sudo mount -t hugetlbfs nodev /mnt/huge

# 코드: MAP_HUGETLB 사용 예
```
```c
// huge_alloc.c
#define _GNU_SOURCE
#include <sys/mman.h>
#include <fcntl.h>
#include <unistd.h>
#include <stdio.h>
#include <string.h>
int main(){
    int fd = open("/mnt/huge/blk", O_CREAT|O_RDWR, 0666);
    ftruncate(fd, 2*1024*1024);
    void* p = mmap(NULL, 2*1024*1024, PROT_READ|PROT_WRITE,
                   MAP_SHARED, fd, 0); // hugetlbfs 파일 매핑
    memset(p, 0xAB, 2*1024*1024);
    printf("huge page mapped at %p\n", p);
    return 0;
}
```

### 15.5 COW 관찰 — 부모/자식 쓰기 시점 복사
```c
// cow_demo.c
#include <sys/mman.h>
#include <sys/wait.h>
#include <unistd.h>
#include <stdio.h>
#include <string.h>
int main(){
    size_t len = 4096;
    char* p = mmap(NULL,len,PROT_READ|PROT_WRITE,MAP_PRIVATE|MAP_ANONYMOUS,-1,0);
    strcpy(p,"parent");
    pid_t pid=fork();
    if(pid==0){ // child
        p[0]='C'; // 여기서 COW 발생(자식에 사본 할당)
        printf("child: %s\n", p);
        _exit(0);
    } else {
        int st; wait(&st);
        printf("parent: %s\n", p); // 원본 유지
    }
}
```

### 15.6 물리 주소 관찰 힌트(`/proc/self/pagemap`)
- 최신 배포판은 **보안상 제한**으로 비특권 읽기 제한 가능.  
- 커널/보안 정책을 이해하지 않으면 **접근이 거부**될 수 있음(정보 유출 방지).

---

## 16. 운영 관측·디버깅 도구

| 목적 | 명령 |
|---|---|
| VA 맵/권한 | `cat /proc/$pid/maps`, `pmap -x $pid` |
| 메모리 통계 | `cat /proc/$pid/smaps`, `vmstat 1`, `free -h` |
| 폴트/성능 | `perf stat -e page-faults,...`, `perf top`, `perf record` |
| 상주 여부 | `mincore(addr,len,vec)` |
| 페이지 어드바이스 | `madvise`, `posix_fadvise` |
| 보호 전환 | `mprotect`, (x86) `pkey_mprotect` |

---

## 17. 튜닝 체크리스트(성능·안정성·보안)

- [ ] **TLB 히트율**: 데이터 구조 **군집화**, **연속 접근**, 필요 시 **huge page**  
- [ ] **W^X/NX**: JIT는 **RW→RX 전환**, RWX 금지  
- [ ] **ASLR/PIE** 활성, 라이브러리도 기본 PIE 시스템 권장  
- [ ] **NUMA**: first-touch, 바인딩으로 원격 접근 최소화  
- [ ] **IOMMU**: DMA 격리·연속 IOVA 제공, 핀/스왑 정책 이해  
- [ ] **COW/파일 매핑** 적극 활용(복사·I/O 감소)  
- [ ] **폴트 로깅**: SIGSEGV 핸들러(ALTSTACK)로 주소/코드 기록  
- [ ] **캐시 에일리어스** 회피: 동일 PA의 다중 VA 중복 매핑 지양

---

## 18. 자주 하는 질문(FAQ) — 간결 해설

**Q1. 사용자 포인터 값은 VA인가요?**  
A. 네, **항상 VA**입니다. PA는 커널/드라이버가 관리합니다.

**Q2. 같은 `.so`를 여러 프로세스가 써도 메모리 낭비가 없나요?**  
A. 코드/RO 데이터는 **같은 물리 페이지**를 각 프로세스 VA에 **공유 매핑**합니다.

**Q3. 64비트면 2⁶⁴ 전부 쓰나요?**  
A. 아키텍처/실장에 따라 **유효 비트**만 사용(x86-64는 오래 48-bit canonical, 일부는 57-bit LA57).

**Q4. huge page는 항상 빠른가요?**  
A. 대부분의 **대용량 워킹셋**에서 유리하지만, **내부 단편화**·승격 실패·NUMA 상호작용을 고려해야 합니다.

**Q5. 왜 가끔 `mprotect`가 느리죠?**  
A. 보호 전환은 **TLB flush(슈트다운)** 를 유발, 코어 수가 많을수록 비용↑.

---

## 19. 보너스: 간단 수식으로 보는 TLB 이점

페이지 크기를 \(P\), TLB 엔트리 수를 \(N\)라 하면, **한 번에 커버하는 주소량**은
$$
\text{TLB coverage} = N \times P
$$
**huge page**(예: 2MB)로 \(P\)를 키우면 **coverage↑** → **TLB 미스율↓**,  
단, **내부 단편화**와 승격 실패 리스크를 함께 고려해야 한다.

---

## 20. 결론 — 두 세계를 가르는 얇고 빠른 막

가상 주소는 개발자에게 **넓고 안전한 착시 공간**을 제공하고, MMU·페이지 테이블·TLB는 그 착시를 **물리 주소**로 **보호를 지키며** 빠르게 매핑한다.  
이 구조 위에서 OS는 **COW/매핑/ASLR/huge page/NUMA** 를 결합해 **안정성·보안·성능**을 동시에 달성한다.  
실무자는 **관측(perf, maps/smaps)** 과 **정책(W^X/ASLR/NUMA/IOMMU)** 을 습관화하여 워크로드 맞춤의 **주소 변환 비용을 최소화**하라.