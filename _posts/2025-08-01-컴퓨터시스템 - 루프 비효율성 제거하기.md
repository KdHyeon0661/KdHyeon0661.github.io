---
layout: post
title: 컴퓨터시스템 - 루프 비효율성 제거하기
date: 2025-08-01 17:20:23 +0900
category: 컴퓨터시스템
---
# 루프 비효율성 제거하기 — 자세한 가이드

루프는 프로그램 실행 시간의 많은 부분을 차지한다. 루프를 잘 최적화하면 성능이 크게 올라가고, 못하면 아무리 빠른 CPU라도 낭비가 발생한다. 아래는 **측정 → 원인분석 → 기법 적용 → 검증**의 순서로 루프 비효율성을 제거하는 실용적이고 상세한 방법론과 구체적 기법들(코드 예제 포함)이다.

---

## 1) 시작 전에 — 측정이 우선이다
1. **핫스팟을 찾아라**: 전체 프로그램에서 어느 루프가 시간을 먹는지 `perf`, `gprof`, `callgrind`, 샘플링 프로파일러로 확인.  
2. **마이크로벤치마크**: 최적화 전후 비교를 위해 안정적인 측정 스크립트/함수를 둔다.  
   간단한 시간 측정 예 (C, `clock_gettime`):

```c
#include <time.h>
#include <stdio.h>

double now_sec(void) {
    struct timespec t;
    clock_gettime(CLOCK_MONOTONIC, &t);
    return t.tv_sec + t.tv_nsec*1e-9;
}

/* 사용법:
   t0 = now_sec();
   work();
   t1 = now_sec();
   printf("Elapsed: %.6f s\n", t1 - t0);
*/
```

> 측정 팁: 워밍업 반복(캐시/브랜치예측 안정화), 여러 번 실행하여 중앙값/표준편차 보고.

---

## 2) 성능 관점의 기본 원칙 (언제나 기억)
- **최소한의 작업**만 반복문 내부에서 하라 (loop body work ↓).  
- **데이터 지역성**(time & space locality)을 높여 캐시 미스 줄이기.  
- **분기(brach)**를 줄여 분기 미스 비용을 낮추기.  
- **연산의 병렬성(ILP/SIMD/Threading)**을 노출시켜 하드웨어를 활용.  
- **메모리 트래픽 최소화** — 메모리 바운드인지 확인 (Roofline 모델).

---

## 3) 구체적 기법들 (설명 + 전/후 코드 + 주의점)

### 3.1 루프 불변 코드 호이스팅 (Loop-invariant code motion)
루프 안에서 매 반복마다 같은 값을 계산하면 루프 밖으로 빼라.

**before**
```c
for (int i = 0; i < n; ++i) {
    double t = expensive() * 2.0; // expensive()는 루프 전체에서 불변
    a[i] = b[i] + t;
}
```

**after**
```c
double t = expensive() * 2.0;
for (int i = 0; i < n; ++i) {
    a[i] = b[i] + t;
}
```

- **적용조건**: `expensive()`가 반복마다 부수효과를 내지 않아야 함.  
- **주의**: 부동소수점 연산의 순서 변경이 정밀도에 영향 줄 수 있음.

---

### 3.2 강도 감소 (Strength reduction)
곱셈/제곱처럼 비용 높은 연산을 덧셈/시프트 등 저비용 연산으로 바꿈.

**before**
```c
for (int i = 0; i < n; ++i)
    a[i] = base + i * 8;
```

**after**
```c
int val = base;
for (int i = 0; i < n; ++i) {
    a[i] = val;
    val += 8; // 곱셈 제거
}
```

- 컴파일러가 많은 경우 자동으로 적용하지만, 복잡한 인덕션 변수는 수동으로 정리 필요.

---

### 3.3 인덕션 변수 최적화 (Induction variable elimination)
루프 내 여러 관련 변수를 단순화: 중복 인덕션 변수 제거.

**before**
```c
for (int i=0;i<n;i++){
    int x = 3*i + 5;
    use(x);
    int y = 3*i + 7;
    use2(y);
}
```

**after**
```c
int x = 5, y = 7;
for (int i=0;i<n;i++){
    use(x);
    use2(y);
    x += 3;
    y += 3;
}
```

---

### 3.4 루프 언롤링 (Loop unrolling)
반복문 본문을 여러 번 복사하여 분기·루프 오버헤드 감소, ILP 증가.

**before**
```c
for (int i=0;i<n;i++) sum += a[i];
```

**after (4x unroll)**
```c
int i = 0;
for (; i+3 < n; i += 4) {
    sum += a[i] + a[i+1] + a[i+2] + a[i+3];
}
for (; i < n; ++i) sum += a[i];
```

- **장점**: 분기 감소, 레지스터 활용 증가.  
- **단점**: 코드 크기 증가, 컴파일러가 이미 `-funroll-loops`로 처리할 수도 있음.  
- **방법**: 수동, 컴파일러 옵션, 또는 `#pragma unroll`/`#pragma GCC optimize("unroll-loops")`.

특이기법: **Duff's device** (C의 switch 기반 언롤링) — 간단하지만 가독성↓.

---

### 3.5 루프 상호교환 (Loop interchange)
중첩 루프(order)를 바꿔 데이터 접근 패턴을 캐시 친화적으로.

**bad (column-major access on row-major array)**
```c
for (int j = 0; j < N; ++j)
  for (int i = 0; i < N; ++i)
    sum += A[i][j];
```

**good**
```c
for (int i = 0; i < N; ++i)
  for (int j = 0; j < N; ++j)
    sum += A[i][j];
```

- **조건**: loop interchange 시 의존성(데이터 의존성)이 없어야 한다.

---

### 3.6 루프 합치기/분할 (Fusion / Fission)
관련 루프들을 합치거나(캐시 효율) 큰 루프를 나누어(병렬화/레지스터 압력 감소) 최적화.

**fusion**
```c
for (i) a[i] = b[i] * 2;
for (i) c[i] = d[i] + 3;
// → fuse:
for (i) { a[i] = b[i]*2; c[i] = d[i] + 3; }
```

- **주의**: 합치면 레지스터 압력이나 코드 로컬리티가 악화될 수 있으니 프로파일 기반 판단 필요.

---

### 3.7 타일링 / 블로킹 (Loop tiling / blocking)
대형 작업(예: 행렬 곱)을 캐시 블록 크기에 맞춰 나눠 메모리 재사용을 최대화.

**단순 행렬 곱 (비효율)**
```c
for (i) for (j) for (k) C[i][j] += A[i][k] * B[k][j];
```

**블록된 버전 (pseudo)**
```c
for (ii = 0; ii < N; ii += B)
  for (jj = 0; jj < N; jj += B)
    for (kk = 0; kk < N; kk += B)
      for (i = ii; i < min(ii+B,N); ++i)
        for (j = jj; j < min(jj+B,N); ++j)
          for (k = kk; k < min(kk+B,N); ++k)
            C[i][j] += A[i][k] * B[k][j];
```

- **효과**: 블록 내에서는 데이터가 캐시에 머물러 메모리 대역폭 요구 ↓.  
- **B 선택**: L1/L2 캐시 크기와 데이터 타입에 의해 결정 — 실험 필요.

---

### 3.8 벡터화 (SIMD) — 자동/수동
컴파일러의 자동 벡터화가 적용되려면 데이터 의존성·정렬·별칭 없는 것이 좋다.

**예: 벡터화 친화 코드**
```c
void saxpy(int n, float *restrict x, float *restrict y, float a) {
    for (int i=0;i<n;i++) y[i] += a * x[i];
}
```

- `restrict`가 별칭을 없애주므로 컴파일러가 안전하게 벡터화 가능.  
- 정렬: `posix_memalign`/`aligned_alloc`로 16/32/64바이트 정렬하면 추가 이득.  
- pragma: `#pragma omp simd` 또는 `#pragma GCC ivdep`로 힌트 제공 가능.  
- **주의**: `-ffast-math` 같은 옵션은 FP 규칙을 완화해 더 공격적 벡터화를 허용하지만 정확도/표준 위반 가능.

---

### 3.9 경계 검사 제거 / 인덱스 체크 회피
언어(예: Java, C#)에서의 범위 체크는 비용. 컴파일러가 체크 제거(범위가 보장될 때)할 수 있도록 패턴을 작성하라. C에서는 직접 체크를 피하는 것이 일반.

---

### 3.10 분기 제거(Branch elimination) — 분기 예측 비용 최소화
루프 내 조건이 자주 분기 미스 유발하면 **branchless** 코드로 바꿔라.

**before**
```c
for (i) {
  if (a[i] > 0) b[i] = a[i]; else b[i] = 0;
}
```

**after (branchless)**
```c
for (i) {
  int mask = (a[i] > 0); // 0 or 1  (주의: branch may still be generated)
  b[i] = a[i] * mask;
}
```

또는 비트 연산을 이용한 절댓값 등 `cmov`-style 변환:

```c
int abs(int x) {
    int m = x >> 31;
    return (x ^ m) - m;
}
```

- **주의**: 컴파일러/아키텍처에 따라 더 빠르거나 느릴 수 있음 — 측정 필요.

---

### 3.11 루프 분할(Loop peeling)
루프 시작에 몇 반복을 따로 처리해 정렬(예: SIMD 정렬, 메모리 주소 정렬)을 맞춘다. 그 후 핵심 루프는 정렬된 길이로 빠르게 실행.

---

### 3.12 소프트웨어 프리페치 (Software prefetch)
메모리 접근이 예상 가능하면 `__builtin_prefetch` 등으로 미리 캐시 로드.

```c
for (i=0;i<n;i++) {
    __builtin_prefetch(&a[i+16], 0, 1);
    work(a[i]);
}
```

- **주의**: 부적절한 prefetch는 오히려 캐시 오염을 일으킴.

---

### 3.13 함수 호출 제거 / 인라인
루프 내부의 짧은 함수는 인라인시키면 호출 오버헤드 제거 및 추가 최적화 가능. 컴파일러의 인라인 정책 또는 `inline`/`static inline` 사용.

---

### 3.14 병렬화 (Thread-level parallelism)
루프가 반복 독립이면 OpenMP 등으로 병렬화:

```c
#pragma omp parallel for
for (int i=0;i<n;i++) {
    a[i] = b[i] + c[i];
}
```

- **주의**: 데이터 레이스, false sharing, 스레드 오버헤드 고려.

---

## 4) 메모리·성능 모델 (간단한 수식)
- CPU 시간 (근사):
\[
\text{CPU time} \approx \text{Instruction Count} \times \text{CPI} \times \text{Clock time}
\]
- 메모리 바운드 판단 (Roofline 요약):
\[
\text{Attainable Perf} = \min(\text{Peak FLOPS},\; \text{AI} \times \text{Peak BW})
\]
여기서 \(\text{AI} = \dfrac{\text{FLOPs}}{\text{Bytes moved}}\). 루프 최적화는 보통 AI ↑ (데이터 재사용 ↑)를 목표로 함.

---

## 5) 적용 순서(현실적 워크플로)
1. 프로파일로 **문제 루프** 식별.  
2. 루프를 단위로 **핫스팟 분석** (cycles, cache-misses, branch-misses).  
3. 간단한 소스 변경: 루프 불변 호이스팅, 강도 감소. 측정.  
4. 데이터 레이아웃/접근 변경(루프 interchange, blocking). 측정.  
5. 언롤링/벡터화 시도(+ `restrict`, align, pragmas). 측정.  
6. 병렬화(스레드) 적용. 측정(스케일링 확인).  
7. 필요 시 profile-guided optimization (PGO) 또는 hand-tune.

---

## 6) 검증·측정 체크리스트
- 변경 전/후 **wall-clock**, **cycles**, **instructions**, **cache-misses**, **branch-misses** 비교.  
- 여러 입력 크기와 데이터를 테스트 (캐시 경계, 메모리 대역폭 포인트 확인).  
- 안정성 확인: 수치 정확도(부동소수점), 논리/레이스 부작용 없음.  
- 코드 크기 / 유지보수성 고려: gain 대비 복잡성/버그 가능성 판단.

---

## 7) 실전 팁 & 주의사항
- **컴파일러 먼저 믿어보라**: `-O3 -march=native`로 컴파일하면 많은 최적화를 자동 적용. 컴파일러가 미처 못한 부분만 손대자.  
- **피상적 최적화 금지**: 루프 내 불필요한 마이크로-트릭은 가독성·유지보수 악화.  
- **부동소수점 주의**: 수식 재배열/언롤링/벡터화는 정밀도/결과를 바꿀 수 있음. `-ffast-math`는 주의해서 사용.  
- **별칭(alias) 문제 해결**: `restrict` 또는 더 정교한 설계로 컴파일러 쉽게 최적화하게 하라.  
- **정확한 도구 사용**: `perf stat`, `perf record`,`vtune`, `cachegrind` 등으로 원인 파악.  
- **기계종속성**: 특정 최적화(예: SIMD 너비) 는 아키텍처에 따라 효과 달라짐 — `-march=native` 권장(단 재현성 고려).

---

## 8) 요약 체크리스트 (Quick actionable)
- [ ] 프로파일로 어느 루프가 문제인지 확인했나?  
- [ ] 루프 내부에 루프 불변 코드가 없는가? 빼낼 수 있나?  
- [ ] 곱셈/제곱 등 고비용 연산을 덧셈/시프트로 바꿀 수 있나?  
- [ ] 메모리 접근 패턴이 캐시 친화적인가? interchange / blocking 할 수 있나?  
- [ ] 벡터화/언롤링으로 ILP/SIMD를 활용할 여지가 있나? (`restrict`/align 적용)  
- [ ] 분기가 많은가? branchless로 바꿀 수 있나?  
- [ ] 병렬화 가능성은? false-sharing 등을 고려했나?  
- [ ] 변경 후 정확도/안정성/성능을 측정했나?

---

## 마무리
루프 최적화는 **과학적 실험**이다. 단순한 규칙(호이스팅, 강도감소, 블로킹, 벡터화 등)을 적용하고, 항상 측정으로 확인하라. 소프트웨어·하드웨어·데이터 특성에 따라 최적의 해법은 달라진다 — **프로파일 → 변경 → 재프로파일**의 반복이 핵심이다.
