---
layout: post
title: 컴퓨터시스템 - 루프 비효율성 제거하기
date: 2025-08-01 17:20:23 +0900
category: 컴퓨터시스템
---
# 루프 비효율성 제거하기

## 파운데이션 — 시간/성능 모델과 계측의 원칙

### 계산 모델(간단)

CPU 시간은 대략
$$
T \approx \text{(명령 수)} \times \text{(CPI)} \times \text{(클럭 주기)}
$$
메모리 바운드 여부는 **Roofline**으로 판단:
$$
\text{성능} \le \min\{\text{피크 FLOPS},\; \text{연산집약도 }(\text{AI}) \times \text{피크 대역폭}\},\quad
\text{AI}=\frac{\text{FLOPs}}{\text{Bytes moved}}
$$

### 루프 단위 지표

- **CPE(cycles per element)**: 요소 1개 처리당 사이클 수. 루프 개선 효과가 **가장 직관적으로** 보인다.
- **Branch-miss rate**, **LLC miss rate**, **IPC**, **L1D MPKI** 등 마이크로카운터 병행.

---

## 측정이 먼저다 — 프로파일링/마이크로벤치

### 신뢰 가능한 시간 측정 헬퍼(C)

```c
#include <time.h>
#include <stdio.h>

static inline double now_sec(void) {
    struct timespec t;
    clock_gettime(CLOCK_MONOTONIC, &t);
    return (double)t.tv_sec + (double)t.tv_nsec * 1e-9;
}

static inline void clobber(void *p) { asm volatile("" : : "g"(p) : "memory"); } // DCE 방지

int main(void){
    double t0, t1, acc=0.0;
    const int warmup = 3, iters = 10;
    for(int w=0; w<warmup; ++w) {/* 워밍업 */}
    t0 = now_sec();
    for(int i=0;i<iters;++i){
        // work(); // 여기에 테스트 루프 호출
        clobber(&acc);
    }
    t1 = now_sec();
    printf("Elapsed: %.6f s\n", t1-t0);
}
```
- **워밍업**: 캐시/분기예측 안정화.
- **DCE(dead-code elimination) 방지**: 결과를 `volatile` 저장/출력, 혹은 `asm volatile("":::"memory")`.
- 여러 번 실행 → **중앙값**과 **분산** 보고.

### 시스템 프로파일러 빠른 사용법

- Linux: `perf stat -r 5 ./a.out` (IPC/branch-miss/cache-miss), `perf record -g`, `perf report`.
- Valgrind: `callgrind`/`cachegrind`로 함수·라인별 비용과 캐시행동 추적.
- Intel VTune/AMD μProf 등 벤더 툴: 병목 원인(메모리 vs 코어) 분해.

---

## 마이크로아키텍처 관점 핵심 원칙

- **루프 본문 최소화**: 불변식은 밖으로, 고비용 연산은 치환/사전계산.
- **메모리 지역성 극대화**: 선형 접근, 캐시 타일링, SoA 전환.
- **분기 미스 최소화**: 브랜치 제거/CMOV/벡터화.
- **병렬성 노출**: ILP(언롤링/스케줄링), SIMD(자동/수동), TLP(OpenMP).
- **메모리 트래픽 억제**: 불필요한 로드/스토어 제거, non-temporal store, prefetch 적재적소.

---

## 루프 불변 코드 호이스팅 (LICM)

**원리**: 반복마다 변하지 않는 값/주소계산은 루프 밖으로.

**before**
```c
for (int i=0;i<n;++i) {
    double t = expensive(); // 부수효과 없음
    out[i] = in[i] + 2.0 * t;
}
```
**after**
```c
double t = expensive();
double two_t = 2.0 * t;
for (int i=0;i<n;++i) out[i] = in[i] + two_t;
```

**적용조건**: 함수가 **부수효과 없음**, 인자가 루프 내에서 불변.
**주의**: FP 결합법칙 가정이 필요한 변형은 `-ffast-math`류 옵션이 개입—정확도 요구 시 주의.
**검증**: perf에서 **instructions↓**, **CPE↓** 확인.

---

## 강도 감소(Strength Reduction) & 인덕션 변수 정리

### 곱셈 → 덧셈 누적

**before**
```c
for (int i=0;i<n;++i) a[i] = base + i*8;
```
**after**
```c
int v = base;
for (int i=0;i<n;++i){ a[i]=v; v+=8; }
```

### 다중 인덕션 변수 정리

**before**
```c
for (int i=0;i<n;++i){
    int x = 3*i + 5;
    int y = 3*i + 7;
    use(x,y);
}
```
**after**
```c
int x=5, y=7;
for (int i=0;i<n;++i){ use(x,y); x+=3; y+=3; }
```

**효과**: ALU 사용량↓, 주소계산 간소화 → ILP↑.
**주의**: 컴파일러가 이미 수행할 수도 있으나, 복잡한 포인터 산술/조건 결합 시 수동 정리가 이득.

---

## 포인터 인덱싱 단순화 & 별칭 제거

### 포인터 전진(p++ 스타일)으로 주소계산 감소

**before**
```c
for (int i=0;i<n;++i) dst[i] = src[i] + k;
```
**after**
```c
const float* __restrict s = src;
      float* __restrict d = dst;
for (int i=0;i<n;++i) *d++ = *s++ + k;
```
- 컴파일러는 두 형태 모두 최적화 가능하나, **`restrict`** 는 **별칭(aliasing) 부재**를 알려 **벡터화**/로드-스토어 재배치를 용이하게 한다.

### restrict/align 힌트

```c
void saxpy(int n, float a,
           float* __restrict y,
           const float* __restrict x){
    #pragma omp simd
    for (int i=0;i<n;++i) y[i] += a * x[i];
}
```
- **restrict**: x/y 겹치지 않음 → 자동 벡터화 촉진.
- **pragma omp simd**: 의존성 없음 힌트.

---

## 루프 언롤링 (정적/반정적)

**원리**: 루프 제어 오버헤드/분기 빈도↓, 동시 독립 연산↑(ILP).

**before**
```c
double sum=0;
for (int i=0;i<n;++i) sum += a[i];
```
**after(4×)**
```c
double s0=0,s1=0,s2=0,s3=0;
int i=0;
for (; i+3<n; i+=4){
    s0 += a[i]; s1 += a[i+1]; s2 += a[i+2]; s3 += a[i+3];
}
for (; i<n; ++i) s0 += a[i];
double sum = (s0+s1) + (s2+s3);
```

**장점**: 분기↓, 축적 레지스터 다수 사용→ILP↑.
**단점**: 코드 크기↑, 레지스터 압력↑ → 스필 발생 위험.
**지시어/옵션**: `#pragma unroll N`, `-funroll-loops`.
**검증**: IPC↑, branch-misses↓, L1 I-cache 미스 유의.

---

## 루프 상호교환(Interchange) & 타일링/블로킹

### Interchange — 행렬 접근 순서 교정

**before (row-major 배열에 column-first 접근)**
```c
for (int j=0;j<N;++j)
  for (int i=0;i<N;++i)
    sum += A[i][j];
```
**after**
```c
for (int i=0;i<N;++i)
  for (int j=0;j<N;++j)
    sum += A[i][j];
```
- **조건**: 데이터 의존성 없음.
- **효과**: 선형 스트라이드 → 캐시라인 히트↑.

### 타일링(블로킹) — 캐시에 맞춰 쪼개기

**기본 GEMM**
```c
for (int i=0;i<N;++i)
  for (int j=0;j<N;++j)
    for (int k=0;k<N;++k)
      C[i][j]+=A[i][k]*B[k][j];
```
**타일링**
```c
for (int ii=0; ii<N; ii+=B)
  for (int kk=0; kk<N; kk+=B)
    for (int jj=0; jj<N; jj+=B)
      for (int i=ii; i<ii+B && i<N; ++i)
        for (int k=kk; k<kk+B && k<N; ++k){
          double aik = A[i][k];
          for (int j=jj; j<jj+B && j<N; ++j)
            C[i][j] += aik * B[k][j];
        }
```
**블록 크기 B 선택**: 대략 “타일 3개(A 블록, B 블록, C 행 패널)가 L1/L2에 **동시에** 상주하도록” 경험적으로 탐색.

---

## 데이터 레이아웃 변환 — AoS→SoA

**문제**: 구조체 배열(AoS)은 필드 간 **스트라이드**가 커 벡터화/캐시 비효율.
**개선**: 필드별 배열(SoA)로 전환.

**AoS**
```c
typedef struct { float x,y,z,w; } Pt;
Pt* pts; // N개
for (int i=0;i<N;++i) pts[i].x += s * pts[i].y;
```
**SoA**
```c
typedef struct { float *x,*y,*z,*w; } PtSoA;
PtSoA p;
for (int i=0;i<N;++i) p.x[i] += s * p.y[i]; // 연속 메모리 접근 → 벡터화↑
```
- **효과**: **연속 로드**, 불필요한 필드 로드 제거, gather 회피.

---

## 분기 제거(Branch elimination) & 조건 이동

### 조건 없는 형태로

**before**
```c
for (int i=0;i<n;++i)
    out[i] = (in[i] > 0) ? in[i] : 0;
```
**after (가능한 branchless)**
```c
for (int i=0;i<n;++i) {
    int m = in[i] > 0;         // 0/1
    out[i] = in[i] * m;
}
```
또는 **조건 이동/CMOV**를 기대할 패턴:
```c
int clamp_pos(int x){ return (x>0)?x:0; } // 컴파일러가 cmov로 바꿀 수 있음
```

### 통계적 분기 패턴

- **난수/균등 분기**는 예측 실패↑ → 꼭 branchless 고려.
- **편향 분기**(예: 95% false)라면 분기 유지가 더 빠를 수 있음 → **측정**.

---

## 경계 핸들링 — 루프 필링(peeling) & 잔여 처리

**원리**: SIMD/정렬에 맞춰 **앞부분 몇 개**를 별도 처리 후 **핵심 루프는 깔끔한 배수 길이**로.

```c
int i=0;
// 정렬/정수배 도달 전까지 peeling
for (; i<align_prefix; ++i) body_scalar(i);
// 메인 SIMD/언롤 루프
for (; i+7<n; i+=8) body_8way(i);
// 꼬리 처리
for (; i<n; ++i) body_scalar(i);
```

---

## 소프트웨어 프리페치 & Non-temporal Store

### 프리페치

```c
for (int i=0;i<n;++i){
    __builtin_prefetch(&a[i+32], 0, 1); // 읽기, 지역성 중간
    consume(a[i]);
}
```
- **효과**: 대기시간 은닉. **거리**(i+Δ)는 **메모리/코어/캐시** 지연에 맞게 조율.
- **주의**: 남발 시 캐시 오염.

### Non-temporal Stores(스트리밍)

- 큰 배열에 **한번만 쓰고** 다시 안 읽을 때, **NT store**로 쓰기→캐시 오염 방지.
- 인트린식 예: `_mm_stream_ps`/`_mm256_stream_ps` (플랫폼별 상이).
- **주의**: 정렬/버퍼 크기 조건, 메모리 장벽 필요성 확인.

---

## 함수 호출 제거/인라인 & 컨테이너 경량화

- 루프 내 자잘한 함수 호출 → **`static inline`** 으로 인라인 유도.
- 가상호출/간접호출은 **분기 예측/BTB 부담** → 핫루프 회피.
- STL/고수준 컨테이너 사용 시 **이터레이터 범위 체크/디버그 모드** 해제(-DNDEBUG), **reserve** 선할당으로 재할당 방지.

---

## 병렬화(TLP) — OpenMP로 빠르게

### 독립 반복 OpenMP

```c
#pragma omp parallel for schedule(static)

for (int i=0;i<n;++i) out[i]=f(in[i]);
```
- **감소연산(reduction)**:
```c
double sum=0;
#pragma omp parallel for reduction(+:sum)

for (int i=0;i<n;++i) sum += a[i];
```
- **주의**: False sharing 방지 → 스레드 로컬 패딩/배열 분할.
- **스케줄링**: `static`(균일 비용), `dynamic/guided`(비균일).

### 작업 크기와 오버헤드

- 너무 작은 루프는 **스레드 생성/동기화 비용**이 이득을 잠식 — **chunk** 조정.

---

## 자동 벡터화 성공 조건 정리

- **별칭 없음**: `restrict`, 불변 참조.
- **메모리 정렬**: 16/32/64B 정렬(플랫폼에 맞게).
- **의존성 제거**: 쓰기-이후-읽기(anti), 읽기-이후-쓰기(output) 의존 제거.
- **깔끔한 루프 형태**: 상수 스트라이드, 함수 콜 없음(혹은 `declare simd`).
- **컴파일 플래그**: `-O3 -ffast-math -march=native` (정확도 요구 시 fast-math는 보류).
- **프라그마**: `#pragma omp simd`, `#pragma ivdep`, `#pragma clang loop vectorize(enable)`.

---

## 사례 연구 (미니)

### SAXPY (y += a*x)

**baseline**
```c
void saxpy(int n, float a, float* y, const float* x){
    for(int i=0;i<n;++i) y[i]+=a*x[i];
}
```
**optimized**
```c
void saxpy(int n, float a,
           float* __restrict y,
           const float* __restrict x){
    int i=0;
    // (선택) 정렬 전처리/peeling
    #pragma omp simd
    for (; i<n; ++i) y[i] += a * x[i];
}
```
- **검증**: `perf stat`로 **instructions↓, IPC↑**, `-Rpass=loop-vectorize`(Clang)로 벡터화 확인.

### Histogram — 분기/경쟁 완화

**before**
```c
for (int i=0;i<n;++i){
    int b = bucket(a[i]);
    hist[b]++; // 다중 스레드 경쟁/false sharing
}
```
**after(스레드 로컬)**
```c
#pragma omp parallel

{
  int local[BINS]={0};
  #pragma omp for nowait
  for (int i=0;i<n;++i) local[bucket(a[i])]++;
  #pragma omp critical
  for (int b=0;b<BINS;++b) hist[b]+=local[b];
}
```
- **효과**: 원자적 증가/false sharing 제거 → 스케일링↑.

### GEMM 타일링 효과(정성)

- L1/L2 miss 급감, 메모리 트래픽↓ → AI↑ → roofline 상한 근접.

---

## 경계 검사/안전성 vs 성능(언어별)

- C/C++: 수동 범위검사는 비용이지만 필수 지점에서만 수행.
- Java/C#: JIT가 **경계 검사 제거**를 시도할 패턴(선행 체크)로 코드를 작성.
- Python: **NumPy/Numba/Cython** 등 **벡터화/네이티브 경로**로 옮겨 루프를 해체.

---

## IO/메모리 바운드 루프 특화 팁

- **읽기 합치기(read coalescing)**, **큰 버퍼**로 syscalls 수 최소화.
- **메모리 복사**는 `memcpy`(플랫폼 최적화) 신뢰.
- **NUMA**: 초기 바인딩/메모리 배치 정책으로 원격 접근 최소화.

---

## 정확도·재현성·안정성 체크

- FP 최적화는 결과 변동 유발 가능 → **상대/절대 오차 허용 범위**로 검증.
- 멀티스레딩은 **데이터 레이스**/재현성 이슈 → **불변성 테스트**/TSAN.
- **PGO**(Profile-Guided Optimization): 실제 워크로드로 학습 → 브랜치/레이아웃 최적.

---

## 퀵 체크리스트 (실행 순서)

1. [ ] **프로파일**로 진짜 핫루프 식별(Top N).
2. [ ] **불변 호이스팅/강도 감소/인덕션 정리** 적용.
3. [ ] **데이터 접근 교정**(interchange/SoA/타일링).
4. [ ] **언롤링/벡터화**(restrict/pragma/align).
5. [ ] **브랜치 제거/CMOV** 검토(분기 패턴 분석).
6. [ ] **프리페치/NT store**(패턴 확실할 때만).
7. [ ] **병렬화**(작업 크기/스케줄/false sharing 대응).
8. [ ] **검증**: 다양한 입력 크기, **CPE/IPC/미스율** 비교.
9. [ ] **가독성/유지보수** 대비 **이득** 평가(Pareto).

---

## 부록 — 벤치마크 스캐폴딩, 두 가지 루프 최적화 데모

### CPE 측정 스캐폴딩

```c
#include <time.h>
#include <stdio.h>
#include <stdlib.h>
#include <x86intrin.h>

static inline double now(void){ struct timespec t; clock_gettime(CLOCK_MONOTONIC,&t); return t.tv_sec+t.tv_nsec*1e-9; }

double kernel_baseline(const float* a, float* b, int n){
    double t0=now();
    float acc=0;
    for(int i=0;i<n;++i){ acc+=a[i]; b[i]=acc; }
    double t1=now();
    // DCE 방지
    volatile float sink=b[n-1];
    (void)sink;
    return (t1-t0);
}

double kernel_optimized(const float* __restrict a, float* __restrict b, int n){
    double t0=now();
    // 언롤+두 개 축적기 → ILP
    float s0=0, s1=0;
    int i=0;
    for (; i+1<n; i+=2){
        s0 += a[i];
        b[i] = s0;
        s1 += a[i+1];
        b[i+1] = s0 + s1;
    }
    for (; i<n; ++i){ s0 += a[i]; b[i]=s0; }
    double t1=now();
    volatile float sink=b[n-1];
    (void)sink;
    return (t1-t0);
}

int main(){
    const int n=1<<24;
    float* a=(float*)aligned_alloc(64, n*sizeof(float));
    float* b=(float*)aligned_alloc(64, n*sizeof(float));
    for(int i=0;i<n;++i) a[i]=(float)(i&7);

    double tb=kernel_baseline(a,b,n);
    double to=kernel_optimized(a,b,n);

    printf("baseline: %.3f s  | optimized: %.3f s  | speedup: %.2fx\n", tb,to,tb/to);
    free(a); free(b);
}
```
- 단순 누산 예지만, **언롤+복수 축적기**로 **ILP**를 드러내고, **정렬 할당**으로 메모리 경계 최적화.

### 행렬 곱 미니 타일링 비교(스칼라 → 타일링)

**스칼라**
```c
void gemm_naive(int N, double* C, const double* A, const double* B){
    for(int i=0;i<N;++i)
      for(int j=0;j<N;++j){
        double s=0;
        for(int k=0;k<N;++k) s += A[i*N+k] * B[k*N+j];
        C[i*N+j]=s;
      }
}
```
**타일링**
```c
void gemm_block(int N, double* C, const double* A, const double* B, int BS){
    for(int ii=0; ii<N; ii+=BS)
      for(int kk=0; kk<N; kk+=BS)
        for(int jj=0; jj<N; jj+=BS){
          int iimax = (ii+BS<N)? ii+BS:N;
          int kkmax = (kk+BS<N)? kk+BS:N;
          int jjmax = (jj+BS<N)? jj+BS:N;
          for(int i=ii;i<iimax;++i){
            for(int k=kk;k<kkmax;++k){
              double aik=A[i*N+k];
              for(int j=jj;j<jjmax;++j)
                C[i*N+j]+=aik*B[k*N+j];
            }
          }
        }
}
```
- **검증**: L1/L2 miss 대폭 감소, 성능 급상승. BS는 **플랫폼별 튜닝**.

---

## 수학으로 보는 개선 효과(간단 추정)

### 언롤링/분기감소로 CPI 개선

분기 오버헤드가 반복마다 \(b\) 사이클, 언롤링 팩터 \(u\)일 때
$$
\Delta \text{CPE} \approx b\left(1-\frac{1}{u}\right)
$$

### 타일링으로 AI 상승

원래 AI가 \(AI_0\), 타일링으로 각 타일 내 재사용이 \(r\)배 증가하면
$$
AI \approx r \cdot AI_0 \quad\Rightarrow\quad \text{성능} \le \min(\text{Peak},\, r\cdot AI_0\cdot BW)
$$

---

## 마무리 — 과학적 루틴

- **프로파일 → 가설 → 수술적 변경 → 재측정**을 **루프 단위로 반복**한다.
- 항상 **데이터·하드웨어 특성**을 기준으로 판단: “무엇이 병목인가?”
- 가독성과 유지보수를 **마지막까지** 저울질하라 — **작은 코드**가 **큰 성능**을 주는 지점이 반드시 있다.
