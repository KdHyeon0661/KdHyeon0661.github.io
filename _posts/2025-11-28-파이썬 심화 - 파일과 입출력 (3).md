---
layout: post
title: íŒŒì´ì¬ ì‹¬í™” - íŒŒì¼ê³¼ ì…ì¶œë ¥ (3)
date: 2025-11-28 19:25:23 +0900
category: íŒŒì´ì¬ ì‹¬í™”
---
# íŒŒì¼ê³¼ ì…ì¶œë ¥ (3)

íŒŒì¼ ì‹œìŠ¤í…œ ì‘ì—…ê³¼ ì¸ì½”ë”© ì²˜ë¦¬ëŠ” íŒŒì´ì¬ ê°œë°œì—ì„œ ìì£¼ ë§ˆì£¼ì¹˜ëŠ” ì‹¤ì „ ë¬¸ì œì…ë‹ˆë‹¤. ë‹¤ì–‘í•œ ìš´ì˜ì²´ì œ, íŒŒì¼ ì‹œìŠ¤í…œ, ì–¸ì–´ í™˜ê²½ì—ì„œ ì•ˆì •ì ìœ¼ë¡œ ì‘ë™í•˜ëŠ” ì½”ë“œë¥¼ ì‘ì„±í•˜ê¸° ìœ„í•œ ì‹¬ì¸µì ì¸ ê¸°ë²•ë“¤ì„ ì•Œì•„ë³´ê² ìŠµë‹ˆë‹¤.

## ë””ë ‰í„°ë¦¬ ë¦¬ìŠ¤íŒ… êµ¬í•˜ê¸°: os ëª¨ë“ˆì˜ ì™„ì „ì •ë³µ

ë””ë ‰í„°ë¦¬ ë‚´ íŒŒì¼ ëª©ë¡ì„ ì–»ëŠ” ì‘ì—…ì€ ë‹¨ìˆœí•´ ë³´ì´ì§€ë§Œ, ì„±ëŠ¥, ì¬ê·€ì  íƒìƒ‰, í•„í„°ë§, ì •ë ¬ ë“± ë‹¤ì–‘í•œ ìš”êµ¬ì‚¬í•­ì„ ê³ ë ¤í•´ì•¼ í•©ë‹ˆë‹¤.

### ê¸°ë³¸ì ì¸ ë””ë ‰í„°ë¦¬ ë¦¬ìŠ¤íŒ… ë°©ë²•

```python
import os
import glob
import pathlib
import time
from fnmatch import fnmatch

# 1. os.listdir() - ê°€ì¥ ê¸°ë³¸ì ì¸ ë°©ë²•
def list_directory_basic(directory_path):
    """ë””ë ‰í„°ë¦¬ ë‚´ ëª¨ë“  í•­ëª© ë¦¬ìŠ¤íŠ¸"""
    try:
        items = os.listdir(directory_path)
        return items
    except FileNotFoundError:
        print(f"ë””ë ‰í„°ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {directory_path}")
        return []
    except PermissionError:
        print(f"ë””ë ‰í„°ë¦¬ ì ‘ê·¼ ê¶Œí•œì´ ì—†ìŠµë‹ˆë‹¤: {directory_path}")
        return []

# 2. os.scandir() - ë” íš¨ìœ¨ì ì¸ ë°©ë²• (Python 3.5+)
def list_directory_efficient(directory_path):
    """scandirë¥¼ ì´ìš©í•œ íš¨ìœ¨ì ì¸ ë””ë ‰í„°ë¦¬ ë¦¬ìŠ¤íŒ…"""
    entries = []
    try:
        with os.scandir(directory_path) as it:
            for entry in it:
                entries.append({
                    'name': entry.name,
                    'path': entry.path,
                    'is_file': entry.is_file(),
                    'is_dir': entry.is_dir(),
                    'stat': entry.stat() if entry.is_file() else None
                })
    except (FileNotFoundError, PermissionError) as e:
        print(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
    return entries

# 3. glob ëª¨ë“ˆì„ ì´ìš©í•œ íŒ¨í„´ ë§¤ì¹­
def find_files_by_pattern(directory_path, pattern="*"):
    """ì™€ì¼ë“œì¹´ë“œ íŒ¨í„´ìœ¼ë¡œ íŒŒì¼ ê²€ìƒ‰"""
    search_path = os.path.join(directory_path, pattern)
    return glob.glob(search_path)

# 4. pathlib ëª¨ë“ˆ (Python 3.4+ í˜„ëŒ€ì  ì ‘ê·¼)
def list_directory_modern(directory_path):
    """pathlibë¥¼ ì´ìš©í•œ ê°ì²´ì§€í–¥ì  ì ‘ê·¼"""
    from pathlib import Path
    
    path = Path(directory_path)
    if not path.exists():
        print(f"ê²½ë¡œê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {directory_path}")
        return []
    
    items = {
        'files': [],
        'directories': [],
        'other': []
    }
    
    for item in path.iterdir():
        if item.is_file():
            items['files'].append({
                'name': item.name,
                'size': item.stat().st_size,
                'modified': time.ctime(item.stat().st_mtime)
            })
        elif item.is_dir():
            items['directories'].append(item.name)
        else:
            items['other'].append(item.name)
    
    return items
```

### ê³ ê¸‰ ë””ë ‰í„°ë¦¬ íƒìƒ‰ ê¸°ë²•

```python
import os
import fnmatch
from collections import defaultdict
from datetime import datetime, timedelta

class AdvancedDirectoryScanner:
    """ê³ ê¸‰ ë””ë ‰í„°ë¦¬ ìŠ¤ìºë„ˆ í´ë˜ìŠ¤"""
    
    def __init__(self, root_path):
        self.root_path = os.path.abspath(root_path)
        self.file_index = defaultdict(list)
        self.stats = {
            'total_files': 0,
            'total_dirs': 0,
            'total_size': 0,
            'by_extension': defaultdict(int),
            'by_date': defaultdict(int)
        }
    
    def scan_recursive(self, pattern="*", max_depth=None):
        """ì¬ê·€ì  ë””ë ‰í„°ë¦¬ ìŠ¤ìº”"""
        results = []
        
        def _scan(current_path, depth):
            if max_depth is not None and depth > max_depth:
                return
            
            try:
                with os.scandir(current_path) as entries:
                    for entry in entries:
                        # íŒ¨í„´ ë§¤ì¹­ í™•ì¸
                        if not fnmatch.fnmatch(entry.name, pattern):
                            continue
                        
                        full_path = entry.path
                        relative_path = os.path.relpath(full_path, self.root_path)
                        
                        entry_info = {
                            'name': entry.name,
                            'path': full_path,
                            'relative_path': relative_path,
                            'is_file': entry.is_file(),
                            'is_dir': entry.is_dir(),
                            'depth': depth
                        }
                        
                        if entry.is_file():
                            try:
                                stat = entry.stat()
                                entry_info.update({
                                    'size': stat.st_size,
                                    'modified': datetime.fromtimestamp(stat.st_mtime),
                                    'created': datetime.fromtimestamp(stat.st_ctime),
                                    'accessed': datetime.fromtimestamp(stat.st_atime)
                                })
                                
                                # í†µê³„ ì—…ë°ì´íŠ¸
                                self.stats['total_files'] += 1
                                self.stats['total_size'] += stat.st_size
                                
                                # í™•ì¥ìë³„ ë¶„ë¥˜
                                _, ext = os.path.splitext(entry.name)
                                if ext:
                                    self.stats['by_extension'][ext.lower()] += 1
                                
                                # ë‚ ì§œë³„ ë¶„ë¥˜ (ì›” ê¸°ì¤€)
                                month_key = entry_info['modified'].strftime('%Y-%m')
                                self.stats['by_date'][month_key] += 1
                                
                            except (OSError, PermissionError):
                                pass
                        
                        results.append(entry_info)
                        
                        # ë””ë ‰í„°ë¦¬ì¸ ê²½ìš° ì¬ê·€ì  íƒìƒ‰
                        if entry.is_dir():
                            self.stats['total_dirs'] += 1
                            _scan(full_path, depth + 1)
                            
            except (PermissionError, FileNotFoundError):
                pass
        
        _scan(self.root_path, 0)
        return results
    
    def find_duplicate_files(self):
        """ì¤‘ë³µ íŒŒì¼ ì°¾ê¸° (í¬ê¸°ì™€ í•´ì‹œ ê¸°ë°˜)"""
        import hashlib
        
        size_map = defaultdict(list)
        hash_map = defaultdict(list)
        
        # 1ë‹¨ê³„: íŒŒì¼ í¬ê¸°ë¡œ ê·¸ë£¹í™”
        all_files = self.scan_recursive()
        for file_info in all_files:
            if file_info['is_file'] and 'size' in file_info:
                size_map[file_info['size']].append(file_info)
        
        # 2ë‹¨ê³„: ë™ì¼ í¬ê¸°ì˜ íŒŒì¼ë“¤ì— ëŒ€í•´ í•´ì‹œ ê³„ì‚°
        for size, files in size_map.items():
            if len(files) > 1:  # ë™ì¼ í¬ê¸°ê°€ 2ê°œ ì´ìƒì¸ ê²½ìš°ë§Œ
                for file_info in files:
                    try:
                        with open(file_info['path'], 'rb') as f:
                            file_hash = hashlib.md5(f.read()).hexdigest()
                            hash_map[file_hash].append(file_info)
                    except (IOError, PermissionError):
                        continue
        
        # ì§„ì§œ ì¤‘ë³µ íŒŒì¼ë§Œ ë°˜í™˜ (ë™ì¼ í•´ì‹œ)
        duplicates = {hash_val: files for hash_val, files in hash_map.items() 
                     if len(files) > 1}
        
        return duplicates
    
    def find_recent_files(self, days=7):
        """ìµœê·¼ Nì¼ ë‚´ ìˆ˜ì •ëœ íŒŒì¼ ì°¾ê¸°"""
        cutoff_date = datetime.now() - timedelta(days=days)
        recent_files = []
        
        all_files = self.scan_recursive()
        for file_info in all_files:
            if file_info['is_file'] and 'modified' in file_info:
                if file_info['modified'] > cutoff_date:
                    recent_files.append(file_info)
        
        return recent_files
    
    def get_directory_tree(self, max_depth=3):
        """ë””ë ‰í„°ë¦¬ íŠ¸ë¦¬ êµ¬ì¡° ìƒì„±"""
        tree = {}
        
        def _build_tree(current_path, current_depth):
            if current_depth > max_depth:
                return None
            
            node = {
                'name': os.path.basename(current_path),
                'path': current_path,
                'files': [],
                'subdirs': {}
            }
            
            try:
                with os.scandir(current_path) as entries:
                    for entry in entries:
                        if entry.is_file():
                            node['files'].append(entry.name)
                        elif entry.is_dir():
                            subdir_tree = _build_tree(entry.path, current_depth + 1)
                            if subdir_tree:
                                node['subdirs'][entry.name] = subdir_tree
            except (PermissionError, FileNotFoundError):
                pass
            
            return node
        
        return _build_tree(self.root_path, 0)

# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    scanner = AdvancedDirectoryScanner(".")
    
    # ì „ì²´ ìŠ¤ìº”
    print("ë””ë ‰í„°ë¦¬ ìŠ¤ìº” ì‹œì‘...")
    all_items = scanner.scan_recursive()
    
    print(f"\ní†µê³„:")
    print(f"  ì´ íŒŒì¼: {scanner.stats['total_files']:,}ê°œ")
    print(f"  ì´ ë””ë ‰í† ë¦¬: {scanner.stats['total_dirs']:,}ê°œ")
    print(f"  ì´ í¬ê¸°: {scanner.stats['total_size']:,} bytes")
    
    print(f"\ní™•ì¥ìë³„ ë¶„í¬:")
    for ext, count in sorted(scanner.stats['by_extension'].items(), 
                            key=lambda x: x[1], reverse=True)[:10]:
        print(f"  {ext}: {count}ê°œ")
    
    # ì¤‘ë³µ íŒŒì¼ ê²€ìƒ‰
    duplicates = scanner.find_duplicate_files()
    if duplicates:
        print(f"\nì¤‘ë³µ íŒŒì¼ ë°œê²¬ ({len(duplicates)}ê·¸ë£¹):")
        for hash_val, files in list(duplicates.items())[:3]:  # ì²˜ìŒ 3ê°œë§Œ ì¶œë ¥
            print(f"  í•´ì‹œ {hash_val[:8]}...:")
            for f in files:
                print(f"    - {f['relative_path']}")
    else:
        print("\nì¤‘ë³µ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
    
    # ìµœê·¼ íŒŒì¼ ê²€ìƒ‰
    recent_files = scanner.find_recent_files(days=30)
    print(f"\nìµœê·¼ 30ì¼ ë‚´ ìˆ˜ì •ëœ íŒŒì¼ ({len(recent_files)}ê°œ):")
    for file_info in sorted(recent_files, 
                           key=lambda x: x['modified'], 
                           reverse=True)[:5]:
        print(f"  {file_info['modified'].strftime('%Y-%m-%d')}: {file_info['relative_path']}")
```

### ëŒ€ìš©ëŸ‰ ë””ë ‰í„°ë¦¬ ì²˜ë¦¬ ìµœì í™”

```python
import os
import threading
import queue
import time
from concurrent.futures import ThreadPoolExecutor

class ParallelDirectoryScanner:
    """ë³‘ë ¬ ë””ë ‰í„°ë¦¬ ìŠ¤ìºë„ˆ"""
    
    def __init__(self, root_path, max_workers=4):
        self.root_path = os.path.abspath(root_path)
        self.max_workers = max_workers
        self.file_queue = queue.Queue()
        self.results = []
        self.lock = threading.Lock()
    
    def _scan_directory(self, dir_path):
        """ë‹¨ì¼ ë””ë ‰í„°ë¦¬ ìŠ¤ìº” (ì‘ì—…ì í•¨ìˆ˜)"""
        try:
            with os.scandir(dir_path) as entries:
                for entry in entries:
                    entry_info = {
                        'path': entry.path,
                        'name': entry.name,
                        'is_file': entry.is_file(),
                        'is_dir': entry.is_dir()
                    }
                    
                    if entry.is_file():
                        try:
                            stat = entry.stat()
                            entry_info.update({
                                'size': stat.st_size,
                                'modified': stat.st_mtime
                            })
                        except OSError:
                            pass
                    
                    self.file_queue.put(entry_info)
                    
                    # ë””ë ‰í„°ë¦¬ì¸ ê²½ìš° ì¬ê·€ì ìœ¼ë¡œ íì— ì¶”ê°€
                    if entry.is_dir():
                        self._scan_directory(entry.path)
                        
        except (PermissionError, FileNotFoundError):
            pass
    
    def scan_parallel(self):
        """ë³‘ë ¬ ë””ë ‰í„°ë¦¬ ìŠ¤ìº”"""
        start_time = time.time()
        
        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            # ì´ˆê¸° ë””ë ‰í„°ë¦¬ ìŠ¤ìº” ì‘ì—… ì œì¶œ
            executor.submit(self._scan_directory, self.root_path)
            
            # ê²°ê³¼ ìˆ˜ì§‘ ìŠ¤ë ˆë“œ
            def result_collector():
                while True:
                    try:
                        item = self.file_queue.get(timeout=1)
                        with self.lock:
                            self.results.append(item)
                        self.file_queue.task_done()
                    except queue.Empty:
                        # ëª¨ë“  ì‘ì—…ì ìŠ¤ë ˆë“œê°€ ì¢…ë£Œë˜ì—ˆëŠ”ì§€ í™•ì¸
                        if executor._shutdown:
                            break
            
            # ê²°ê³¼ ìˆ˜ì§‘ê¸° ì‹¤í–‰
            collector_thread = threading.Thread(target=result_collector)
            collector_thread.start()
            
            # ì‘ì—… ì™„ë£Œ ëŒ€ê¸°
            self.file_queue.join()
            collector_thread.join()
        
        elapsed = time.time() - start_time
        print(f"ë³‘ë ¬ ìŠ¤ìº” ì™„ë£Œ: {len(self.results)}ê°œ í•­ëª©, {elapsed:.2f}ì´ˆ ì†Œìš”")
        
        return self.results

# ì„±ëŠ¥ ë¹„êµ
def benchmark_scanners():
    """ë‹¤ì–‘í•œ ìŠ¤ìºë„ˆ ì„±ëŠ¥ ë¹„êµ"""
    import tempfile
    import random
    import string
    
    # í…ŒìŠ¤íŠ¸ ë””ë ‰í„°ë¦¬ ìƒì„±
    def create_test_directory(root, depth=3, files_per_dir=10):
        """í…ŒìŠ¤íŠ¸ìš© ë””ë ‰í„°ë¦¬ êµ¬ì¡° ìƒì„±"""
        if depth == 0:
            return
        
        # íŒŒì¼ ìƒì„±
        for i in range(files_per_dir):
            filename = ''.join(random.choices(string.ascii_letters, k=10))
            filepath = os.path.join(root, f"{filename}.txt")
            with open(filepath, 'w') as f:
                f.write("í…ŒìŠ¤íŠ¸ íŒŒì¼ ë‚´ìš©")
        
        # í•˜ìœ„ ë””ë ‰í„°ë¦¬ ìƒì„±
        for i in range(2):  # ê° ë””ë ‰í„°ë¦¬ì— 2ê°œì˜ í•˜ìœ„ ë””ë ‰í„°ë¦¬
            dirname = ''.join(random.choices(string.ascii_letters, k=8))
            dirpath = os.path.join(root, dirname)
            os.makedirs(dirpath, exist_ok=True)
            create_test_directory(dirpath, depth-1, files_per_dir//2)
    
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    with tempfile.TemporaryDirectory() as tmpdir:
        print(f"í…ŒìŠ¤íŠ¸ ë””ë ‰í„°ë¦¬ ìƒì„± ì¤‘: {tmpdir}")
        create_test_directory(tmpdir, depth=3, files_per_dir=5)
        
        print("\nì„±ëŠ¥ ë¹„êµ:")
        
        # ë‹¨ì¼ ìŠ¤ë ˆë“œ ìŠ¤ìº”
        scanner1 = AdvancedDirectoryScanner(tmpdir)
        start = time.time()
        scanner1.scan_recursive()
        single_time = time.time() - start
        print(f"ë‹¨ì¼ ìŠ¤ë ˆë“œ: {single_time:.2f}ì´ˆ")
        
        # ë³‘ë ¬ ìŠ¤ìº”
        scanner2 = ParallelDirectoryScanner(tmpdir, max_workers=4)
        start = time.time()
        scanner2.scan_parallel()
        parallel_time = time.time() - start
        print(f"ë³‘ë ¬ ìŠ¤ìº” (4 workers): {parallel_time:.2f}ì´ˆ")
        
        print(f"\nì„±ëŠ¥ í–¥ìƒ: {single_time/parallel_time:.1f}ë°° ë¹ ë¦„")

# benchmark_scanners()  # ì‹¤í–‰ ì‹œ ì£¼ì„ í•´ì œ
```

## íŒŒì¼ ì´ë¦„ ì¸ì½”ë”© ìš°íšŒ: ìš´ì˜ì²´ì œ ê°„ í˜¸í™˜ì„± ë³´ì¥

ë‹¤ì–‘í•œ ìš´ì˜ì²´ì œì™€ íŒŒì¼ ì‹œìŠ¤í…œì—ì„œ ë°œìƒí•˜ëŠ” ì¸ì½”ë”© ë¬¸ì œë¥¼ í•´ê²°í•˜ëŠ” ë°©ë²•ì„ ì•Œì•„ë´…ë‹ˆë‹¤.

### ê¸°ë³¸ì ì¸ ì¸ì½”ë”© ë¬¸ì œ ì´í•´

```python
import os
import sys
import locale

def examine_system_encoding():
    """ì‹œìŠ¤í…œ ì¸ì½”ë”© ì •ë³´ ë¶„ì„"""
    print("ì‹œìŠ¤í…œ ì¸ì½”ë”© ì •ë³´:")
    print(f"  íŒŒì¼ ì‹œìŠ¤í…œ ì¸ì½”ë”©: {sys.getfilesystemencoding()}")
    print(f"  ê¸°ë³¸ ë¡œì¼€ì¼ ì¸ì½”ë”©: {locale.getpreferredencoding()}")
    print(f"  íŒŒì´ì¬ ê¸°ë³¸ ì¸ì½”ë”©: {sys.getdefaultencoding()}")
    print(f"  í”Œë«í¼: {sys.platform}")
    
    # í˜„ì¬ ë¡œì¼€ì¼ ì„¤ì •
    try:
        current_locale = locale.getlocale()
        print(f"  í˜„ì¬ ë¡œì¼€ì¼: {current_locale}")
    except:
        print("  ë¡œì¼€ì¼ ì •ë³´ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

examine_system_encoding()
```

### ì•ˆì „í•œ íŒŒì¼ ì´ë¦„ ì²˜ë¦¬ í´ë˜ìŠ¤

```python
import os
import unicodedata
import re
from pathlib import Path

class SafeFilenameHandler:
    """ì•ˆì „í•œ íŒŒì¼ ì´ë¦„ ì²˜ë¦¬ê¸°"""
    
    # ìœ„í—˜í•œ ë¬¸ì íŒ¨í„´
    DANGEROUS_CHARS = {
        'windows': r'[<>:"/\\|?*]',
        'unix': r'[/\0]',
        'reserved': r'^(CON|PRN|AUX|NUL|COM[1-9]|LPT[1-9])$',
        'trailing': r'[ .]+$'
    }
    
    # ìš´ì˜ì²´ì œë³„ ì œí•œ ì‚¬í•­
    OS_LIMITS = {
        'windows': {
            'max_length': 260,  # ê²½ë¡œ í¬í•¨
            'reserved_names': ['CON', 'PRN', 'AUX', 'NUL', 
                              'COM1', 'COM2', 'COM3', 'COM4', 'COM5', 'COM6', 'COM7', 'COM8', 'COM9',
                              'LPT1', 'LPT2', 'LPT3', 'LPT4', 'LPT5', 'LPT6', 'LPT7', 'LPT8', 'LPT9']
        },
        'linux': {
            'max_length': 255,  # íŒŒì¼ëª…ë§Œ
            'reserved_names': []
        },
        'darwin': {  # macOS
            'max_length': 255,
            'reserved_names': []
        }
    }
    
    @staticmethod
    def normalize_filename(filename, target_os=None):
        """
        íŒŒì¼ëª…ì„ ì•ˆì „í•œ í˜•íƒœë¡œ ì •ê·œí™”
        
        Args:
            filename: ì›ë³¸ íŒŒì¼ëª…
            target_os: ëŒ€ìƒ ìš´ì˜ì²´ì œ (None=í˜„ì¬ ì‹œìŠ¤í…œ)
        
        Returns:
            ì •ê·œí™”ëœ ì•ˆì „í•œ íŒŒì¼ëª…
        """
        if target_os is None:
            target_os = 'windows' if os.name == 'nt' else 'unix'
        
        # 1. ìœ ë‹ˆì½”ë“œ ì •ê·œí™” (NFC í˜•ì‹)
        normalized = unicodedata.normalize('NFC', filename)
        
        # 2. ìš´ì˜ì²´ì œë³„ ìœ„í—˜ ë¬¸ì ì œê±° ë˜ëŠ” ì¹˜í™˜
        if target_os == 'windows':
            pattern = SafeFilenameHandler.DANGEROUS_CHARS['windows']
            replacement = '_'
        else:  # Unix/Linux/macOS
            pattern = SafeFilenameHandler.DANGEROUS_CHARS['unix']
            replacement = '_'
        
        safe_name = re.sub(pattern, replacement, normalized)
        
        # 3. ì˜ˆì•½ëœ ì´ë¦„ ê²€ì‚¬ (Windows)
        if target_os == 'windows':
            name_root, ext = os.path.splitext(safe_name)
            if name_root.upper() in SafeFilenameHandler.OS_LIMITS['windows']['reserved_names']:
                safe_name = f'_{name_root}{ext}'
        
        # 4. ì„ í–‰/í›„í–‰ ê³µë°± ë° ì  ì œê±°
        safe_name = safe_name.strip(' .')
        
        # 5. ì—°ì†ëœ ê³µë°±/ë°‘ì¤„ ë‹¨ì¼í™”
        safe_name = re.sub(r'[ _]+', '_', safe_name)
        
        # 6. ê¸¸ì´ ì œí•œ ì ìš©
        max_len = SafeFilenameHandler.OS_LIMITS.get(target_os, {}).get('max_length', 255)
        if len(safe_name.encode('utf-8')) > max_len:
            # UTF-8 ë°”ì´íŠ¸ ê¸¸ì´ ê³ ë ¤í•˜ì—¬ ìë¥´ê¸°
            encoded = safe_name.encode('utf-8')[:max_len]
            safe_name = encoded.decode('utf-8', 'ignore').rstrip('\x00')
        
        # 7. ë¹ˆ ë¬¸ìì—´ ê²€ì‚¬
        if not safe_name:
            safe_name = 'unnamed_file'
        
        return safe_name
    
    @staticmethod
    def safe_path_join(*args, target_os=None):
        """
        ì•ˆì „í•œ ê²½ë¡œ ê²°í•©
        
        Args:
            *args: ê²°í•©í•  ê²½ë¡œ êµ¬ì„± ìš”ì†Œ
            target_os: ëŒ€ìƒ ìš´ì˜ì²´ì œ
        
        Returns:
            ì •ê·œí™”ëœ ì•ˆì „í•œ ì „ì²´ ê²½ë¡œ
        """
        normalized_parts = []
        
        for part in args:
            if not part:
                continue
            
            # ê° ë¶€ë¶„ ì •ê·œí™”
            if os.path.isabs(part) and not normalized_parts:
                # ì ˆëŒ€ ê²½ë¡œì¸ ê²½ìš°
                norm_part = part
            else:
                # ìƒëŒ€ ê²½ë¡œ ë¶€ë¶„ ì •ê·œí™”
                norm_part = SafeFilenameHandler.normalize_filename(
                    os.path.basename(part), 
                    target_os
                )
            
            normalized_parts.append(norm_part)
        
        # ìš´ì˜ì²´ì œì— ë§ëŠ” ê²½ë¡œ êµ¬ë¶„ì ì‚¬ìš©
        if target_os == 'windows':
            sep = '\\'
        else:
            sep = '/'
        
        full_path = sep.join(normalized_parts)
        
        # Windows ê²½ë¡œ ê¸¸ì´ ì œí•œ í™•ì¸
        if target_os == 'windows' and len(full_path) > 260:
            print(f"ê²½ê³ : Windows ê²½ë¡œ ì œí•œ ì´ˆê³¼ ({len(full_path)} > 260)")
            # ê²½ë¡œ ë‹¨ì¶• í•„ìš”ì‹œ ì—¬ê¸°ì— ë¡œì§ ì¶”ê°€
        
        return full_path
    
    @staticmethod
    def create_unique_filename(directory, base_name, target_os=None):
        """
        ì¤‘ë³µë˜ì§€ ì•ŠëŠ” ê³ ìœ í•œ íŒŒì¼ëª… ìƒì„±
        
        Args:
            directory: ëŒ€ìƒ ë””ë ‰í„°ë¦¬
            base_name: ê¸°ë³¸ íŒŒì¼ëª…
            target_os: ëŒ€ìƒ ìš´ì˜ì²´ì œ
        
        Returns:
            ê³ ìœ í•œ íŒŒì¼ëª…
        """
        safe_base = SafeFilenameHandler.normalize_filename(base_name, target_os)
        name_root, ext = os.path.splitext(safe_base)
        
        counter = 1
        test_name = safe_base
        
        while os.path.exists(os.path.join(directory, test_name)):
            test_name = f"{name_root}_{counter}{ext}"
            counter += 1
        
        return test_name

# ì‚¬ìš© ì˜ˆì‹œ
def demonstrate_safe_filenames():
    """ì•ˆì „í•œ íŒŒì¼ëª… ì²˜ë¦¬ ë°ëª¨"""
    
    test_names = [
        "ì •ìƒ íŒŒì¼.txt",
        "file with spaces.doc",
        "íŠ¹ìˆ˜ë¬¸ì:ì´ìˆëŠ”*íŒŒì¼?.pdf",
        "CON (ì˜ˆì•½ì–´).txt",  # Windows ì˜ˆì•½ì–´
        "very_long_filename_" + "x" * 100 + ".txt",
        "  ì„ í–‰ê³µë°±.txt ",
        "trailing dots...",
        "..ìƒìœ„ë””ë ‰í„°ë¦¬ì°¸ì¡°..",
        "mixedí•œê¸€English123.pdf",
        "<script>alert('xss')</script>.html"
    ]
    
    print("íŒŒì¼ëª… ì•ˆì „ì„± ì²˜ë¦¬ ë°ëª¨:")
    print("=" * 60)
    
    for original in test_names:
        safe_windows = SafeFilenameHandler.normalize_filename(original, 'windows')
        safe_unix = SafeFilenameHandler.normalize_filename(original, 'linux')
        
        print(f"\nì›ë³¸: '{original}'")
        print(f"  Windows ì•ˆì „: '{safe_windows}'")
        print(f"  Unix ì•ˆì „:    '{safe_unix}'")
        
        # ê²½ë¡œ ê²°í•© í…ŒìŠ¤íŠ¸
        test_path = SafeFilenameHandler.safe_path_join(
            "/home/user/documents", 
            original, 
            target_os='linux'
        )
        print(f"  ì•ˆì „í•œ ê²½ë¡œ:  '{test_path}'")

demonstrate_safe_filenames()
```

### ë‹¤êµ­ì–´ íŒŒì¼ ì´ë¦„ ì²˜ë¦¬

```python
import os
import sys
import codecs

class MultilingualFilenameHandler:
    """ë‹¤êµ­ì–´ íŒŒì¼ ì´ë¦„ ì²˜ë¦¬"""
    
    @staticmethod
    def detect_filename_encoding(filename_bytes):
        """
        íŒŒì¼ëª… ë°”ì´íŠ¸ì˜ ì¸ì½”ë”© ê°ì§€
        
        Args:
            filename_bytes: íŒŒì¼ëª…ì˜ ë°”ì´íŠ¸ í‘œí˜„
        
        Returns:
            ê°ì§€ëœ ì¸ì½”ë”©ê³¼ ë””ì½”ë”©ëœ ë¬¸ìì—´
        """
        encodings_to_try = [
            'utf-8',
            'cp949',      # í•œêµ­ì–´ Windows
            'euc-kr',     # í•œêµ­ì–´
            'shift_jis',  # ì¼ë³¸ì–´
            'gbk',        # ì¤‘êµ­ì–´ ê°„ì²´
            'big5',       # ì¤‘êµ­ì–´ ë²ˆì²´
            'latin-1',
            'cp1252',     # ì„œìœ ëŸ½ Windows
        ]
        
        for encoding in encodings_to_try:
            try:
                decoded = filename_bytes.decode(encoding)
                return encoding, decoded
            except UnicodeDecodeError:
                continue
        
        # ëª¨ë“  ì¸ì½”ë”© ì‹¤íŒ¨ ì‹œ Latin-1ë¡œ í´ë°±
        return 'latin-1', filename_bytes.decode('latin-1', 'replace')
    
    @staticmethod
    def read_directory_with_encoding(directory_path):
        """
        ì¸ì½”ë”© ë¬¸ì œë¥¼ ì²˜ë¦¬í•˜ë©° ë””ë ‰í„°ë¦¬ ì½ê¸°
        
        Args:
            directory_path: ëŒ€ìƒ ë””ë ‰í„°ë¦¬ ê²½ë¡œ
        
        Returns:
            ì¸ì½”ë”©ì´ ìˆ˜ì •ëœ íŒŒì¼ëª… ëª©ë¡
        """
        corrected_files = []
        
        try:
            # ìš´ì˜ì²´ì œ ìˆ˜ì¤€ì—ì„œ ë””ë ‰í„°ë¦¬ ì½ê¸° (ë°”ì´íŠ¸ ëª¨ë“œ)
            with os.scandir(directory_path) as entries:
                for entry in entries:
                    original_name = entry.name
                    
                    # ë¬¸ì œê°€ ìˆì„ ìˆ˜ ìˆëŠ” íŒŒì¼ëª… ê°ì§€
                    try:
                        # ì •ìƒì ì¸ ë””ì½”ë”© ì‹œë„
                        encoded_name = original_name.encode('utf-8')
                        corrected_files.append(original_name)
                    except UnicodeEncodeError:
                        # ì¸ì½”ë”© ë¬¸ì œ ë°œê²¬
                        print(f"ì¸ì½”ë”© ë¬¸ì œ ë°œê²¬: {original_name}")
                        
                        # ìˆ˜ë™ ì¸ì½”ë”© ê°ì§€ ë° ìˆ˜ì •
                        if isinstance(original_name, bytes):
                            encoding, decoded = MultilingualFilenameHandler.detect_filename_encoding(
                                original_name
                            )
                            corrected_name = decoded
                            print(f"  â†’ ê°ì§€ëœ ì¸ì½”ë”©: {encoding}")
                            print(f"  â†’ ìˆ˜ì •ëœ ì´ë¦„: {corrected_name}")
                            corrected_files.append(corrected_name)
                        else:
                            # ì´ë¯¸ ë¬¸ìì—´ì´ì§€ë§Œ ë¬¸ì œ ìˆëŠ” ê²½ìš°
                            corrected_files.append(original_name)
        
        except (FileNotFoundError, PermissionError) as e:
            print(f"ë””ë ‰í„°ë¦¬ ì ‘ê·¼ ì˜¤ë¥˜: {e}")
        
        return corrected_files
    
    @staticmethod
    def create_surrogate_filename_handler():
        """
        ì„œë¡œê²Œì´íŠ¸ í˜ì–´ ì²˜ë¦¬ë¥¼ ìœ„í•œ ì‚¬ìš©ì ì •ì˜ ì¸ì½”ë”© í•¸ë“¤ëŸ¬
        
        Returns:
            codecs.CodecInfo ê°ì²´
        """
        def surrogate_decode(input, errors='strict'):
            """
            ì„œë¡œê²Œì´íŠ¸ í˜ì–´ë¥¼ ì‚¬ìš©í•œ ë³µì›ì„± ìˆëŠ” ë””ì½”ë”©
            """
            result = []
            i = 0
            
            while i < len(input):
                try:
                    # UTF-8 ë””ì½”ë”© ì‹œë„
                    char = input[i:i+1].decode('utf-8')
                    result.append(char)
                    i += 1
                except UnicodeDecodeError:
                    try:
                        # ë‹¤ìŒ ë°”ì´íŠ¸ì™€ í•¨ê»˜ ì‹œë„
                        char = input[i:i+2].decode('utf-8')
                        result.append(char)
                        i += 2
                    except UnicodeDecodeError:
                        try:
                            # 3ë°”ì´íŠ¸ ì‹œë„
                            char = input[i:i+3].decode('utf-8')
                            result.append(char)
                            i += 3
                        except UnicodeDecodeError:
                            # 4ë°”ì´íŠ¸ ì‹œë„
                            try:
                                char = input[i:i+4].decode('utf-8')
                                result.append(char)
                                i += 4
                            except UnicodeDecodeError:
                                # ë³µêµ¬ ë¶ˆê°€ - ëŒ€ì²´ ë¬¸ì ì‚¬ìš©
                                if errors == 'replace':
                                    result.append('ï¿½')
                                    i += 1
                                elif errors == 'ignore':
                                    i += 1
                                else:
                                    raise
            return (''.join(result), i)
        
        # codec ë“±ë¡
        class SurrogateCodec:
            def encode(self, input, errors='strict'):
                return input.encode('utf-8', errors), len(input)
            
            def decode(self, input, errors='strict'):
                return surrogate_decode(input, errors)
        
        return codecs.CodecInfo(
            name='surrogate',
            encode=SurrogateCodec().encode,
            decode=SurrogateCodec().decode
        )

# ì‚¬ìš© ì˜ˆì‹œ
def handle_problematic_directory():
    """ë¬¸ì œ ìˆëŠ” ë””ë ‰í„°ë¦¬ ì²˜ë¦¬ ì˜ˆì‹œ"""
    
    # í…ŒìŠ¤íŠ¸: ë‹¤ì–‘í•œ ì¸ì½”ë”©ì˜ íŒŒì¼ëª… ìƒì„±
    test_filenames = [
        "ì •ìƒíŒŒì¼.txt",  # UTF-8
        # ê°€ìƒì˜ ê¹¨ì§„ íŒŒì¼ëª… (ì‹œë®¬ë ˆì´ì…˜)
        b'\xc0\xaf\xc0\xfa\xb9\xe8\xb0\xa1.txt',  # CP949ë¡œ ì¸ì½”ë”©ëœ í•œêµ­ì–´
        b'\x83\x65\x83\x58\x83\x67.txt',  # Shift-JIS ì¼ë³¸ì–´
        "mixed_í•œê¸€_english_123.pdf",
        b'broken_\xff\xfe\xfd.txt',  # ì†ìƒëœ ë°”ì´íŠ¸
    ]
    
    print("ë‹¤êµ­ì–´ íŒŒì¼ëª… ì²˜ë¦¬ í…ŒìŠ¤íŠ¸:")
    print("=" * 60)
    
    for filename in test_filenames:
        if isinstance(filename, bytes):
            print(f"\në°”ì´íŠ¸ ì…ë ¥: {filename}")
            encoding, decoded = MultilingualFilenameHandler.detect_filename_encoding(filename)
            print(f"  ê°ì§€ëœ ì¸ì½”ë”©: {encoding}")
            print(f"  ë””ì½”ë”© ê²°ê³¼: {decoded}")
        else:
            print(f"\në¬¸ìì—´ ì…ë ¥: {filename}")
            # ì •ìƒì ì¸ UTF-8 ë¬¸ìì—´
            print(f"  UTF-8 ì¸ì½”ë”© ê°€ëŠ¥: {all(ord(c) < 128 for c in filename)}")

# handle_problematic_directory()  # ì‹¤í–‰ ì‹œ ì£¼ì„ í•´ì œ
```

## ë§ê°€ì§„ íŒŒì¼ ì´ë¦„ ì¶œë ¥: ì½ì„ ìˆ˜ ì—†ëŠ” íŒŒì¼ëª… ì²˜ë¦¬

ì‹œìŠ¤í…œì—ì„œ ì½ì„ ìˆ˜ ì—†ëŠ” íŒŒì¼ëª…ì„ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬í•˜ê³  ì¶œë ¥í•˜ëŠ” ë°©ë²•ì„ ì•Œì•„ë´…ë‹ˆë‹¤.

### ì•ˆì „í•œ íŒŒì¼ëª… ì¶œë ¥ ì‹œìŠ¤í…œ

```python
import os
import sys
import traceback
from pathlib import Path, PurePath

class SafeFilenamePrinter:
    """ì•ˆì „í•œ íŒŒì¼ëª… ì¶œë ¥ê¸°"""
    
    def __init__(self, 
                 replacement_char='ï¿½',
                 max_display_length=50,
                 show_hex_for_invalid=True):
        """
        Args:
            replacement_char: ëŒ€ì²´ ë¬¸ì
            max_display_length: ìµœëŒ€ í‘œì‹œ ê¸¸ì´
            show_hex_for_invalid: ìœ íš¨í•˜ì§€ ì•Šì€ ë¬¸ìë¥¼ 16ì§„ìˆ˜ë¡œ í‘œì‹œ
        """
        self.replacement_char = replacement_char
        self.max_display_length = max_display_length
        self.show_hex_for_invalid = show_hex_for_invalid
        
    def safe_repr(self, filename):
        """
        íŒŒì¼ëª…ì˜ ì•ˆì „í•œ ë¬¸ìì—´ í‘œí˜„ ìƒì„±
        
        Args:
            filename: íŒŒì¼ëª… (str ë˜ëŠ” bytes)
        
        Returns:
            ì•ˆì „í•œ í‘œí˜„ ë¬¸ìì—´
        """
        if filename is None:
            return '<None>'
        
        result_parts = []
        
        if isinstance(filename, bytes):
            # ë°”ì´íŠ¸ ë¬¸ìì—´ ì²˜ë¦¬
            try:
                # UTF-8 ë””ì½”ë”© ì‹œë„
                decoded = filename.decode('utf-8')
                result_parts.append(self._process_string(decoded))
                result_parts.append(f" [bytes: {filename.hex()}]")
            except UnicodeDecodeError:
                # UTF-8 ì‹¤íŒ¨ ì‹œ Latin-1ìœ¼ë¡œ í´ë°±
                try:
                    decoded = filename.decode('latin-1')
                    result_parts.append(self._process_string(decoded))
                    result_parts.append(f" [latin-1 bytes: {filename.hex()}]")
                except:
                    # ì™„ì „ ì‹¤íŒ¨ ì‹œ 16ì§„ìˆ˜ í‘œí˜„
                    hex_repr = filename.hex()
                    if len(hex_repr) > self.max_display_length * 2:
                        hex_repr = hex_repr[:self.max_display_length * 2] + '...'
                    result_parts.append(f"<ë°”ì´íŠ¸: {hex_repr}>")
        else:
            # ë¬¸ìì—´ ì²˜ë¦¬
            result_parts.append(self._process_string(filename))
        
        return ''.join(result_parts)
    
    def _process_string(self, text):
        """ë¬¸ìì—´ ì•ˆì „ ì²˜ë¦¬"""
        if not text:
            return '<ë¹ˆ ë¬¸ìì—´>'
        
        # ê¸¸ì´ ì œí•œ
        if len(text) > self.max_display_length:
            display_text = text[:self.max_display_length] + '...'
        else:
            display_text = text
        
        # ì•ˆì „í•œ ë¬¸ìë§Œ í‘œì‹œ
        safe_chars = []
        for char in display_text:
            if self._is_safe_char(char):
                safe_chars.append(char)
            elif self.show_hex_for_invalid:
                safe_chars.append(f'\\x{ord(char):02x}')
            else:
                safe_chars.append(self.replacement_char)
        
        return ''.join(safe_chars)
    
    def _is_safe_char(self, char):
        """ì•ˆì „í•œ ë¬¸ì ì—¬ë¶€ í™•ì¸"""
        code = ord(char)
        
        # ê¸°ë³¸ ì•ˆì „ ë²”ìœ„
        if 32 <= code <= 126:  # ì¶œë ¥ ê°€ëŠ¥í•œ ASCII
            return True
        
        # í•œê¸€ ë²”ìœ„ (ê°€-í£)
        if 0xAC00 <= code <= 0xD7A3:
            return True
        
        # í•œê¸€ ìëª¨ ë²”ìœ„
        if 0x1100 <= code <= 0x11FF or 0x3130 <= code <= 0x318F:
            return True
        
        # ì¶”ê°€ ì•ˆì „ ë¬¸ì
        safe_ranges = [
            (0x3040, 0x309F),  # íˆë¼ê°€ë‚˜
            (0x30A0, 0x30FF),  # ê°€íƒ€ì¹´ë‚˜
            (0x4E00, 0x9FFF),  # CJK í†µí•© í•œì
        ]
        
        for start, end in safe_ranges:
            if start <= code <= end:
                return True
        
        return False
    
    def print_directory_safely(self, directory_path, recursive=False, indent=0):
        """
        ë””ë ‰í„°ë¦¬ ë‚´ìš© ì•ˆì „í•˜ê²Œ ì¶œë ¥
        
        Args:
            directory_path: ë””ë ‰í„°ë¦¬ ê²½ë¡œ
            recursive: ì¬ê·€ì  íƒìƒ‰ ì—¬ë¶€
            indent: ë“¤ì—¬ì“°ê¸° ë ˆë²¨
        """
        try:
            with os.scandir(directory_path) as entries:
                for entry in entries:
                    try:
                        # ì•ˆì „í•œ íŒŒì¼ëª… í‘œí˜„ ìƒì„±
                        safe_name = self.safe_repr(entry.name)
                        
                        # ì¶”ê°€ ì •ë³´
                        info_parts = []
                        if entry.is_file():
                            try:
                                size = entry.stat().st_size
                                info_parts.append(f"{size:,} bytes")
                            except:
                                info_parts.append("í¬ê¸° ì•Œ ìˆ˜ ì—†ìŒ")
                        
                        # ì¶œë ¥
                        prefix = '  ' * indent
                        file_type = 'ğŸ“' if entry.is_dir() else 'ğŸ“„'
                        info_str = f" ({', '.join(info_parts)})" if info_parts else ""
                        
                        print(f"{prefix}{file_type} {safe_name}{info_str}")
                        
                        # ì¬ê·€ì  íƒìƒ‰
                        if recursive and entry.is_dir():
                            self.print_directory_safely(
                                entry.path, 
                                recursive=True, 
                                indent=indent + 1
                            )
                    
                    except Exception as e:
                        # ê°œë³„ í•­ëª© ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜
                        error_msg = f"<ì²˜ë¦¬ ì˜¤ë¥˜: {type(e).__name__}>"
                        print(f"{'  ' * indent}âŒ {error_msg}")
        
        except PermissionError:
            print(f"{'  ' * indent}âš ï¸ ê¶Œí•œ ì—†ìŒ: {directory_path}")
        except FileNotFoundError:
            print(f"{'  ' * indent}âš ï¸ ì°¾ì„ ìˆ˜ ì—†ìŒ: {directory_path}")
        except Exception as e:
            print(f"{'  ' * indent}âš ï¸ ì˜¤ë¥˜: {type(e).__name__}: {e}")

# ì‚¬ìš© ì˜ˆì‹œ
def demonstrate_broken_filename_handling():
    """ë§ê°€ì§„ íŒŒì¼ëª… ì²˜ë¦¬ ë°ëª¨"""
    
    # ë‹¤ì–‘í•œ í…ŒìŠ¤íŠ¸ íŒŒì¼ëª… ìƒì„±
    test_cases = [
        # (ì„¤ëª…, íŒŒì¼ëª…_ë˜ëŠ”_ë°”ì´íŠ¸)
        ("ì •ìƒ í•œêµ­ì–´", "í•œê¸€íŒŒì¼.txt"),
        ("ì •ìƒ ì˜ì–´", "normal_file.pdf"),
        ("í˜¼í•©", "mixed_í•œê¸€_english_123.doc"),
        ("íŠ¹ìˆ˜ë¬¸ì í¬í•¨", "file:with*weird?chars.txt"),
        ("UTF-8 ë°”ì´íŠ¸", "í…ŒìŠ¤íŠ¸".encode('utf-8')),
        ("CP949 ë°”ì´íŠ¸", "í•œê¸€".encode('cp949')),
        ("ì†ìƒëœ UTF-8", b'\xff\xfe\xfdbroken'),
        ("ë„ ë°”ì´íŠ¸ í¬í•¨", b'file\x00name.txt'),
        ("ì œì–´ ë¬¸ì í¬í•¨", "file\x01\x02\x03name"),
        ("ë§¤ìš° ê¸´ ì´ë¦„", "A" * 100),
    ]
    
    printer = SafeFilenamePrinter(
        replacement_char='ï¿½',
        max_display_length=30,
        show_hex_for_invalid=True
    )
    
    print("ë§ê°€ì§„ íŒŒì¼ëª… ì²˜ë¦¬ ë°ëª¨:")
    print("=" * 60)
    
    for description, filename in test_cases:
        safe_repr = printer.safe_repr(filename)
        print(f"\n{description}:")
        print(f"  ì›ë³¸: {repr(filename)}")
        print(f"  ì•ˆì „: {safe_repr}")
    
    # ë””ë ‰í„°ë¦¬ ìŠ¤ìº” ë°ëª¨
    print("\n\në””ë ‰í„°ë¦¬ ì•ˆì „ ìŠ¤ìº” ë°ëª¨:")
    print("=" * 60)
    
    # í˜„ì¬ ë””ë ‰í„°ë¦¬ ìŠ¤ìº”
    printer.print_directory_safely(
        ".",
        recursive=False,
        indent=0
    )

# demonstrate_broken_filename_handling()  # ì‹¤í–‰ ì‹œ ì£¼ì„ í•´ì œ
```

### íŒŒì¼ëª… ë³µêµ¬ ë° ë¶„ì„ ë„êµ¬

```python
import os
import hashlib
import json
from datetime import datetime

class FilenameRecoveryTool:
    """íŒŒì¼ëª… ë³µêµ¬ ë° ë¶„ì„ ë„êµ¬"""
    
    def __init__(self, work_dir="recovery_output"):
        self.work_dir = work_dir
        os.makedirs(work_dir, exist_ok=True)
        
        # ë³µêµ¬ ë¡œê·¸ íŒŒì¼
        self.log_file = os.path.join(work_dir, "recovery_log.json")
        self.recovery_log = self._load_log()
    
    def _load_log(self):
        """ë³µêµ¬ ë¡œê·¸ ë¶ˆëŸ¬ì˜¤ê¸°"""
        if os.path.exists(self.log_file):
            try:
                with open(self.log_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except:
                return {}
        return {}
    
    def _save_log(self):
        """ë³µêµ¬ ë¡œê·¸ ì €ì¥"""
        with open(self.log_file, 'w', encoding='utf-8') as f:
            json.dump(self.recovery_log, f, ensure_ascii=False, indent=2)
    
    def analyze_problematic_files(self, target_directory):
        """
        ë¬¸ì œ ìˆëŠ” íŒŒì¼ ë¶„ì„
        
        Args:
            target_directory: ë¶„ì„ ëŒ€ìƒ ë””ë ‰í„°ë¦¬
        
        Returns:
            ë¶„ì„ ê²°ê³¼ ë¦¬í¬íŠ¸
        """
        report = {
            'scan_date': datetime.now().isoformat(),
            'directory': os.path.abspath(target_directory),
            'total_files': 0,
            'problematic_files': [],
            'encoding_issues': [],
            'statistics': {
                'by_issue_type': {},
                'by_file_extension': {}
            }
        }
        
        try:
            with os.scandir(target_directory) as entries:
                for entry in entries:
                    if not entry.is_file():
                        continue
                    
                    report['total_files'] += 1
                    filename = entry.name
                    
                    # íŒŒì¼ ë¶„ì„
                    analysis = self._analyze_filename(filename)
                    
                    if analysis['has_issues']:
                        file_info = {
                            'filename': self._safe_representation(filename),
                            'hex_representation': filename.encode('latin-1', 'replace').hex() 
                                if isinstance(filename, str) else filename.hex(),
                            'issues': analysis['issues'],
                            'suggested_fix': analysis['suggested_name'],
                            'file_stats': self._get_file_stats(entry.path)
                        }
                        
                        report['problematic_files'].append(file_info)
                        
                        # í†µê³„ ì—…ë°ì´íŠ¸
                        for issue in analysis['issues']:
                            report['statistics']['by_issue_type'][issue] = \
                                report['statistics']['by_issue_type'].get(issue, 0) + 1
                        
                        # í™•ì¥ì í†µê³„
                        _, ext = os.path.splitext(filename)
                        if ext:
                            report['statistics']['by_file_extension'][ext] = \
                                report['statistics']['by_file_extension'].get(ext, 0) + 1
                    
                    # ì¸ì½”ë”© ë¬¸ì œ íŠ¹ë³„ ë¶„ì„
                    encoding_analysis = self._analyze_encoding(filename)
                    if encoding_analysis['has_encoding_issues']:
                        report['encoding_issues'].append({
                            'filename': self._safe_representation(filename),
                            'detected_encodings': encoding_analysis['possible_encodings'],
                            'confidence': encoding_analysis['confidence']
                        })
        
        except (PermissionError, FileNotFoundError) as e:
            report['error'] = str(e)
        
        # ë¦¬í¬íŠ¸ íŒŒì¼ ì €ì¥
        report_file = os.path.join(
            self.work_dir, 
            f"analysis_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        )
        
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        
        return report
    
    def _analyze_filename(self, filename):
        """íŒŒì¼ëª… ë¶„ì„"""
        issues = []
        suggested_name = filename
        
        if isinstance(filename, bytes):
            issues.append('bytes_object')
            try:
                suggested_name = filename.decode('utf-8')
            except UnicodeDecodeError:
                try:
                    suggested_name = filename.decode('latin-1')
                except:
                    suggested_name = filename.hex()[:20] + '...'
        
        # ë„ ë¬¸ì ê²€ì‚¬
        if isinstance(filename, str) and '\x00' in filename:
            issues.append('null_character')
            suggested_name = suggested_name.replace('\x00', '')
        
        # ì œì–´ ë¬¸ì ê²€ì‚¬
        if isinstance(filename, str):
            control_chars = [c for c in filename if ord(c) < 32]
            if control_chars:
                issues.append('control_characters')
                for c in control_chars:
                    suggested_name = suggested_name.replace(c, '')
        
        # ì˜ˆì•½ëœ ì´ë¦„ ê²€ì‚¬ (Windows)
        name_root, ext = os.path.splitext(suggested_name)
        reserved_names = ['CON', 'PRN', 'AUX', 'NUL'] + \
                        [f'COM{i}' for i in range(1, 10)] + \
                        [f'LPT{i}' for i in range(1, 10)]
        
        if name_root.upper() in reserved_names:
            issues.append('reserved_name')
            suggested_name = f'_{suggested_name}'
        
        # ê¸¸ì´ ê²€ì‚¬
        if len(suggested_name) > 255:
            issues.append('too_long')
            suggested_name = suggested_name[:250] + '...' + ext
        
        # ê³µë°± ë¬¸ì œ
        if suggested_name.strip() != suggested_name:
            issues.append('leading_trailing_spaces')
            suggested_name = suggested_name.strip()
        
        if '  ' in suggested_name:
            issues.append('multiple_spaces')
            suggested_name = ' '.join(suggested_name.split())
        
        return {
            'has_issues': len(issues) > 0,
            'issues': issues,
            'suggested_name': suggested_name
        }
    
    def _analyze_encoding(self, filename):
        """ì¸ì½”ë”© ë¶„ì„"""
        if isinstance(filename, str):
            # ì´ë¯¸ ë¬¸ìì—´ì¸ ê²½ìš°
            try:
                filename.encode('utf-8')
                return {
                    'has_encoding_issues': False,
                    'possible_encodings': ['utf-8'],
                    'confidence': 1.0
                }
            except UnicodeEncodeError:
                # ë¬¸ìì—´ì´ì§€ë§Œ UTF-8 ì¸ì½”ë”© ë¶ˆê°€
                return {
                    'has_encoding_issues': True,
                    'possible_encodings': ['unknown'],
                    'confidence': 0.0
                }
        
        # ë°”ì´íŠ¸ì¸ ê²½ìš°
        test_encodings = ['utf-8', 'cp949', 'euc-kr', 'shift_jis', 'gbk', 'big5', 'latin-1']
        possible = []
        
        for encoding in test_encodings:
            try:
                decoded = filename.decode(encoding)
                # ë””ì½”ë”© ì„±ê³µ - ìœ íš¨ì„± ì¶”ê°€ ê²€ì‚¬
                if self._looks_valid(decoded):
                    possible.append(encoding)
            except UnicodeDecodeError:
                continue
        
        return {
            'has_encoding_issues': len(possible) == 0,
            'possible_encodings': possible,
            'confidence': len(possible) / len(test_encodings) if possible else 0.0
        }
    
    def _looks_valid(self, text):
        """í…ìŠ¤íŠ¸ê°€ ìœ íš¨í•´ ë³´ì´ëŠ”ì§€ ê²€ì‚¬"""
        if not text:
            return False
        
        # ê¸°ë³¸ì ì¸ ìœ íš¨ì„± ê²€ì‚¬
        # ë„ˆë¬´ ë§ì€ ì œì–´ ë¬¸ì ì²´í¬
        control_count = sum(1 for c in text if ord(c) < 32 and c not in '\n\r\t')
        if control_count > len(text) * 0.1:  # 10% ì´ìƒ ì œì–´ ë¬¸ì
            return False
        
        return True
    
    def _safe_representation(self, filename):
        """ì•ˆì „í•œ í‘œí˜„ ìƒì„±"""
        if isinstance(filename, bytes):
            try:
                return filename.decode('utf-8', 'replace')
            except:
                return filename.hex()[:30] + '...'
        return filename
    
    def _get_file_stats(self, filepath):
        """íŒŒì¼ í†µê³„ ì •ë³´"""
        try:
            stat = os.stat(filepath)
            return {
                'size': stat.st_size,
                'modified': datetime.fromtimestamp(stat.st_mtime).isoformat(),
                'created': datetime.fromtimestamp(stat.st_ctime).isoformat()
            }
        except:
            return {'size': 0, 'modified': None, 'created': None}
    
    def generate_html_report(self, analysis_report):
        """HTML ë¦¬í¬íŠ¸ ìƒì„±"""
        html_template = """
        <!DOCTYPE html>
        <html>
        <head>
            <meta charset="UTF-8">
            <title>íŒŒì¼ëª… ë¶„ì„ ë¦¬í¬íŠ¸</title>
            <style>
                body {{ font-family: Arial, sans-serif; margin: 20px; }}
                h1 {{ color: #333; }}
                .summary {{ background: #f5f5f5; padding: 15px; border-radius: 5px; }}
                .issue {{ background: #fff3cd; padding: 10px; margin: 10px 0; border-left: 4px solid #ffc107; }}
                .file-list {{ border-collapse: collapse; width: 100%; }}
                .file-list th, .file-list td {{ border: 1px solid #ddd; padding: 8px; }}
                .file-list tr:nth-child(even) {{ background: #f9f9f9; }}
            </style>
        </head>
        <body>
            <h1>ğŸ“Š íŒŒì¼ëª… ë¶„ì„ ë¦¬í¬íŠ¸</h1>
            <div class="summary">
                <p><strong>ìŠ¤ìº” ë‚ ì§œ:</strong> {scan_date}</p>
                <p><strong>ë””ë ‰í„°ë¦¬:</strong> {directory}</p>
                <p><strong>ì´ íŒŒì¼:</strong> {total_files}ê°œ</p>
                <p><strong>ë¬¸ì œ íŒŒì¼:</strong> {problem_count}ê°œ</p>
            </div>
            
            <h2>ğŸ“ˆ ë¬¸ì œ ìœ í˜•ë³„ í†µê³„</h2>
            <table class="file-list">
                <tr><th>ë¬¸ì œ ìœ í˜•</th><th>ê°œìˆ˜</th></tr>
                {issue_stats}
            </table>
            
            <h2>ğŸ”§ ë¬¸ì œ íŒŒì¼ ëª©ë¡</h2>
            <table class="file-list">
                <tr>
                    <th>íŒŒì¼ëª…</th>
                    <th>ë¬¸ì œì </th>
                    <th>ì œì•ˆ ì´ë¦„</th>
                    <th>í¬ê¸°</th>
                </tr>
                {file_rows}
            </table>
        </body>
        </html>
        """
        
        # í†µê³„ í–‰ ìƒì„±
        issue_stats_rows = ''
        for issue_type, count in analysis_report.get('statistics', {}).get('by_issue_type', {}).items():
            issue_stats_rows += f'<tr><td>{issue_type}</td><td>{count}</td></tr>\n'
        
        # íŒŒì¼ í–‰ ìƒì„±
        file_rows = ''
        for file_info in analysis_report.get('problematic_files', []):
            issues_str = ', '.join(file_info.get('issues', []))
            file_rows += f"""
            <tr>
                <td><code>{file_info.get('filename', '')}</code></td>
                <td>{issues_str}</td>
                <td><code>{file_info.get('suggested_fix', '')}</code></td>
                <td>{file_info.get('file_stats', {}).get('size', 0):,} bytes</td>
            </tr>
            """
        
        # ë¦¬í¬íŠ¸ ì±„ìš°ê¸°
        html_content = html_template.format(
            scan_date=analysis_report.get('scan_date', ''),
            directory=analysis_report.get('directory', ''),
            total_files=analysis_report.get('total_files', 0),
            problem_count=len(analysis_report.get('problematic_files', [])),
            issue_stats=issue_stats_rows,
            file_rows=file_rows
        )
        
        # HTML íŒŒì¼ ì €ì¥
        html_file = os.path.join(
            self.work_dir,
            f"report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.html"
        )
        
        with open(html_file, 'w', encoding='utf-8') as f:
            f.write(html_content)
        
        print(f"HTML ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ: {html_file}")
        return html_file

# ì‚¬ìš© ì˜ˆì‹œ
def run_filename_recovery_demo():
    """íŒŒì¼ëª… ë³µêµ¬ ë„êµ¬ ë°ëª¨"""
    
    # ë³µêµ¬ ë„êµ¬ ìƒì„±
    recovery_tool = FilenameRecoveryTool("recovery_demo")
    
    # í˜„ì¬ ë””ë ‰í„°ë¦¬ ë¶„ì„
    print("íŒŒì¼ëª… ë¶„ì„ ì‹œì‘...")
    report = recovery_tool.analyze_problematic_files(".")
    
    # ê²°ê³¼ ì¶œë ¥
    print(f"\në¶„ì„ ì™„ë£Œ!")
    print(f"ì´ íŒŒì¼: {report['total_files']}ê°œ")
    print(f"ë¬¸ì œ íŒŒì¼: {len(report['problematic_files'])}ê°œ")
    
    if report['problematic_files']:
        print("\në¬¸ì œ íŒŒì¼ ëª©ë¡:")
        for i, file_info in enumerate(report['problematic_files'][:5], 1):
            print(f"\n{i}. {file_info['filename']}")
            print(f"   ë¬¸ì œ: {', '.join(file_info['issues'])}")
            print(f"   ì œì•ˆ: {file_info['suggested_fix']}")
        
        if len(report['problematic_files']) > 5:
            print(f"\n... ì™¸ {len(report['problematic_files']) - 5}ê°œ íŒŒì¼ ìƒëµ")
    
    # HTML ë¦¬í¬íŠ¸ ìƒì„±
    html_file = recovery_tool.generate_html_report(report)
    print(f"\nHTML ë¦¬í¬íŠ¸: {html_file}")
    
    # í†µê³„ ì¶œë ¥
    print("\në¬¸ì œ ìœ í˜•ë³„ í†µê³„:")
    for issue_type, count in report['statistics']['by_issue_type'].items():
        print(f"  {issue_type}: {count}ê°œ")

# run_filename_recovery_demo()  # ì‹¤í–‰ ì‹œ ì£¼ì„ í•´ì œ
```

## ì´ë¯¸ ì—´ë ¤ ìˆëŠ” íŒŒì¼ì˜ ì¸ì½”ë”©ì„ ìˆ˜ì •í•˜ê±°ë‚˜ ì¶”ê°€í•˜ê¸°

íŒŒì¼ì„ ì—´ì–´ì„œ ì‘ì—…í•˜ëŠ” ì¤‘ì— ì¸ì½”ë”© ë¬¸ì œë¥¼ ë°œê²¬í•˜ê³  ìˆ˜ì •í•˜ëŠ” ë°©ë²•ì„ ì•Œì•„ë´…ë‹ˆë‹¤.

### íŒŒì¼ ì¸ì½”ë”© ê°ì§€ ë° ë³€í™˜

```python
import os
import chardet
import codecs
from io import StringIO, BytesIO

class FileEncodingHandler:
    """íŒŒì¼ ì¸ì½”ë”© ì²˜ë¦¬ê¸°"""
    
    # ì¼ë°˜ì ì¸ ì¸ì½”ë”© ëª©ë¡ (í™•ë¥ ìˆœ)
    COMMON_ENCODINGS = [
        'utf-8',
        'utf-8-sig',  # UTF-8 with BOM
        'ascii',
        'cp949',      # í•œêµ­ì–´ Windows
        'euc-kr',     # í•œêµ­ì–´
        'iso-8859-1', # Latin-1
        'utf-16',
        'utf-16-le',
        'utf-16-be',
        'shift_jis',  # ì¼ë³¸ì–´
        'gbk',        # ì¤‘êµ­ì–´ ê°„ì²´
        'big5',       # ì¤‘êµ­ì–´ ë²ˆì²´
    ]
    
    @staticmethod
    def detect_encoding(filepath, sample_size=1024):
        """
        íŒŒì¼ì˜ ì¸ì½”ë”© ê°ì§€
        
        Args:
            filepath: íŒŒì¼ ê²½ë¡œ
            sample_size: ìƒ˜í”Œë§ í¬ê¸° (ë°”ì´íŠ¸)
        
        Returns:
            (ê°ì§€ëœ ì¸ì½”ë”©, ì‹ ë¢°ë„)
        """
        try:
            with open(filepath, 'rb') as f:
                raw_data = f.read(sample_size)
            
            if not raw_data:
                return 'utf-8', 0.0
            
            # chardetë¥¼ ì´ìš©í•œ ê°ì§€
            result = chardet.detect(raw_data)
            
            if result['encoding']:
                confidence = result['confidence']
                encoding = result['encoding'].lower()
                
                # ì¸ì½”ë”© ì´ë¦„ ì •ê·œí™”
                encoding = FileEncodingHandler._normalize_encoding_name(encoding)
                
                return encoding, confidence
            else:
                # ê°ì§€ ì‹¤íŒ¨ ì‹œ UTF-8ë¡œ ê°€ì •
                return 'utf-8', 0.0
                
        except Exception as e:
            print(f"ì¸ì½”ë”© ê°ì§€ ì˜¤ë¥˜: {e}")
            return 'utf-8', 0.0
    
    @staticmethod
    def _normalize_encoding_name(encoding):
        """ì¸ì½”ë”© ì´ë¦„ ì •ê·œí™”"""
        encoding = encoding.lower()
        
        # ë™ì˜ì–´ ì •ê·œí™”
        encoding_map = {
            'ks_c_5601-1987': 'cp949',
            'windows-949': 'cp949',
            'ms949': 'cp949',
            'iso-8859-1': 'latin-1',
            'utf8': 'utf-8',
            'utf_8': 'utf-8',
            'utf_16_le': 'utf-16-le',
            'utf_16_be': 'utf-16-be',
        }
        
        return encoding_map.get(encoding, encoding)
    
    @staticmethod
    def convert_file_encoding(source_path, target_path, 
                            target_encoding='utf-8', 
                            source_encoding=None):
        """
        íŒŒì¼ ì¸ì½”ë”© ë³€í™˜
        
        Args:
            source_path: ì›ë³¸ íŒŒì¼ ê²½ë¡œ
            target_path: ëŒ€ìƒ íŒŒì¼ ê²½ë¡œ
            target_encoding: ëŒ€ìƒ ì¸ì½”ë”©
            source_encoding: ì›ë³¸ ì¸ì½”ë”© (Noneì´ë©´ ìë™ ê°ì§€)
        
        Returns:
            ë³€í™˜ ì„±ê³µ ì—¬ë¶€
        """
        try:
            # ì›ë³¸ ì¸ì½”ë”© ê°ì§€
            if source_encoding is None:
                source_encoding, confidence = FileEncodingHandler.detect_encoding(source_path)
                print(f"ê°ì§€ëœ ì¸ì½”ë”©: {source_encoding} (ì‹ ë¢°ë„: {confidence:.2f})")
            
            # íŒŒì¼ ì½ê¸°
            with open(source_path, 'r', encoding=source_encoding, errors='replace') as f:
                content = f.read()
            
            # íŒŒì¼ ì“°ê¸°
            with open(target_path, 'w', encoding=target_encoding, errors='strict') as f:
                f.write(content)
            
            print(f"ì¸ì½”ë”© ë³€í™˜ ì™„ë£Œ: {source_path} â†’ {target_path}")
            print(f"  {source_encoding} â†’ {target_encoding}")
            
            return True
            
        except UnicodeDecodeError as e:
            print(f"ë””ì½”ë”© ì˜¤ë¥˜: {e}")
            # ë‹¤ë¥¸ ì¸ì½”ë”©ìœ¼ë¡œ ì¬ì‹œë„
            if source_encoding != 'utf-8':
                print("UTF-8ë¡œ ì¬ì‹œë„ ì¤‘...")
                return FileEncodingHandler.convert_file_encoding(
                    source_path, target_path, target_encoding, 'utf-8'
                )
            return False
            
        except UnicodeEncodeError as e:
            print(f"ì¸ì½”ë”© ì˜¤ë¥˜: {e}")
            return False
            
        except Exception as e:
            print(f"ë³€í™˜ ì˜¤ë¥˜: {e}")
            return False
    
    @staticmethod
    def fix_encoding_in_memory(file_obj, suspected_encodings=None):
        """
        ë©”ëª¨ë¦¬ì—ì„œ íŒŒì¼ ì¸ì½”ë”© ìˆ˜ì •
        
        Args:
            file_obj: íŒŒì¼ ê°ì²´ (í…ìŠ¤íŠ¸ ëª¨ë“œ)
            suspected_encodings: ì˜ì‹¬ë˜ëŠ” ì¸ì½”ë”© ëª©ë¡
        
        Returns:
            ìˆ˜ì •ëœ í…ìŠ¤íŠ¸
        """
        if suspected_encodings is None:
            suspected_encodings = FileEncodingHandler.COMMON_ENCODINGS
        
        # í˜„ì¬ íŒŒì¼ ìœ„ì¹˜ ì €ì¥
        original_position = file_obj.tell()
        file_obj.seek(0)
        
        # ë°”ì´íŠ¸ ë°ì´í„° ì½ê¸°
        raw_bytes = file_obj.buffer.read() if hasattr(file_obj, 'buffer') else b''
        
        # ì›ë˜ ìœ„ì¹˜ë¡œ ë³µì›
        file_obj.seek(original_position)
        
        # ë‹¤ì–‘í•œ ì¸ì½”ë”© ì‹œë„
        for encoding in suspected_encodings:
            try:
                decoded = raw_bytes.decode(encoding, errors='strict')
                
                # ìœ íš¨ì„± ê²€ì‚¬ (ê¸°ë³¸ì ì¸ ê²€ì‚¬)
                if FileEncodingHandler._is_likely_valid(decoded):
                    print(f"ì„±ê³µ: {encoding} ì¸ì½”ë”©ìœ¼ë¡œ ë””ì½”ë”©ë¨")
                    return decoded, encoding
                    
            except (UnicodeDecodeError, LookupError):
                continue
        
        # ëª¨ë“  ì¸ì½”ë”© ì‹¤íŒ¨ ì‹œ ëŒ€ì²´ ë°©ì‹
        print("ëª¨ë“  ì¸ì½”ë”© ì‹¤íŒ¨, ëŒ€ì²´ ë°©ì‹ ì‚¬ìš©")
        decoded = raw_bytes.decode('utf-8', errors='replace')
        return decoded, 'utf-8'
    
    @staticmethod
    def _is_likely_valid(text, threshold=0.95):
        """
        í…ìŠ¤íŠ¸ê°€ ìœ íš¨í•´ ë³´ì´ëŠ”ì§€ ê²€ì‚¬
        
        Args:
            text: ê²€ì‚¬í•  í…ìŠ¤íŠ¸
            threshold: ìœ íš¨ì„± ì„ê³„ê°’ (0-1)
        
        Returns:
            ìœ íš¨ì„± ì—¬ë¶€
        """
        if not text:
            return False
        
        # ì œì–´ ë¬¸ì ë¹„ìœ¨ ê³„ì‚°
        total_chars = len(text)
        control_chars = sum(1 for c in text if ord(c) < 32 and c not in '\n\r\t')
        
        control_ratio = control_chars / total_chars if total_chars > 0 else 0
        
        # ë„ ë¬¸ì í™•ì¸
        has_null = '\x00' in text
        
        return control_ratio < (1 - threshold) and not has_null
    
    @staticmethod
    def add_bom_to_file(filepath, encoding='utf-8-sig'):
        """
        íŒŒì¼ì— BOM(Byte Order Mark) ì¶”ê°€
        
        Args:
            filepath: íŒŒì¼ ê²½ë¡œ
            encoding: ëŒ€ìƒ ì¸ì½”ë”©
        
        Returns:
            ì„±ê³µ ì—¬ë¶€
        """
        try:
            # íŒŒì¼ ì½ê¸°
            with open(filepath, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # BOM ì¶”ê°€í•˜ì—¬ ë‹¤ì‹œ ì“°ê¸°
            with open(filepath, 'w', encoding=encoding) as f:
                f.write(content)
            
            print(f"BOM ì¶”ê°€ ì™„ë£Œ: {filepath} ({encoding})")
            return True
            
        except Exception as e:
            print(f"BOM ì¶”ê°€ ì˜¤ë¥˜: {e}")
            return False
    
    @staticmethod
    def remove_bom_from_file(filepath):
        """
        íŒŒì¼ì—ì„œ BOM ì œê±°
        
        Args:
            filepath: íŒŒì¼ ê²½ë¡œ
        
        Returns:
            ì„±ê³µ ì—¬ë¶€
        """
        try:
            with open(filepath, 'rb') as f:
                raw_data = f.read()
            
            # BOM íŒ¨í„´ë“¤
            boms = [
                codecs.BOM_UTF8,
                codecs.BOM_UTF16_LE,
                codecs.BOM_UTF16_BE,
                codecs.BOM_UTF32_LE,
                codecs.BOM_UTF32_BE,
            ]
            
            # BOM ì œê±°
            for bom in boms:
                if raw_data.startswith(bom):
                    raw_data = raw_data[len(bom):]
                    print(f"BOM ì œê±°ë¨: {bom.hex()}")
                    break
            
            # ë‹¤ì‹œ ì“°ê¸°
            with open(filepath, 'wb') as f:
                f.write(raw_data)
            
            print(f"BOM ì œê±° ì™„ë£Œ: {filepath}")
            return True
            
        except Exception as e:
            print(f"BOM ì œê±° ì˜¤ë¥˜: {e}")
            return False

# ì‚¬ìš© ì˜ˆì‹œ
def demonstrate_encoding_fixes():
    """ì¸ì½”ë”© ìˆ˜ì • ë°ëª¨"""
    
    import tempfile
    import shutil
    
    # í…ŒìŠ¤íŠ¸ ë””ë ‰í„°ë¦¬ ìƒì„±
    test_dir = tempfile.mkdtemp(prefix="encoding_test_")
    print(f"í…ŒìŠ¤íŠ¸ ë””ë ‰í„°ë¦¬: {test_dir}")
    
    # ë‹¤ì–‘í•œ ì¸ì½”ë”©ì˜ í…ŒìŠ¤íŠ¸ íŒŒì¼ ìƒì„±
    test_cases = [
        ("utf8_file.txt", "UTF-8 ì¸ì½”ë”© í…ŒìŠ¤íŠ¸ íŒŒì¼\ní•œê¸€ í…ŒìŠ¤íŠ¸", 'utf-8'),
        ("cp949_file.txt", "CP949 ì¸ì½”ë”© í…ŒìŠ¤íŠ¸\ní•œê¸€ í…ŒìŠ¤íŠ¸", 'cp949'),
        ("euckr_file.txt", "EUC-KR ì¸ì½”ë”© í…ŒìŠ¤íŠ¸\ní•œê¸€ í…ŒìŠ¤íŠ¸", 'euc-kr'),
        ("with_bom.txt", "BOMì´ ìˆëŠ” UTF-8 íŒŒì¼\ní…ŒìŠ¤íŠ¸", 'utf-8-sig'),
    ]
    
    # í…ŒìŠ¤íŠ¸ íŒŒì¼ ìƒì„±
    created_files = []
    for filename, content, encoding in test_cases:
        filepath = os.path.join(test_dir, filename)
        with open(filepath, 'w', encoding=encoding) as f:
            f.write(content)
        created_files.append(filepath)
        print(f"ìƒì„±ë¨: {filename} ({encoding})")
    
    print("\n" + "="*60)
    print("ì¸ì½”ë”© ê°ì§€ í…ŒìŠ¤íŠ¸:")
    print("="*60)
    
    # ê° íŒŒì¼ì˜ ì¸ì½”ë”© ê°ì§€
    for filepath in created_files:
        encoding, confidence = FileEncodingHandler.detect_encoding(filepath)
        filename = os.path.basename(filepath)
        print(f"{filename}: {encoding} (ì‹ ë¢°ë„: {confidence:.2f})")
    
    print("\n" + "="*60)
    print("ì¸ì½”ë”© ë³€í™˜ í…ŒìŠ¤íŠ¸:")
    print("="*60)
    
    # UTF-8ë¡œ ë³€í™˜ í…ŒìŠ¤íŠ¸
    source_file = os.path.join(test_dir, "cp949_file.txt")
    target_file = os.path.join(test_dir, "converted_utf8.txt")
    
    success = FileEncodingHandler.convert_file_encoding(
        source_file, target_file, 'utf-8'
    )
    
    if success:
        print("ë³€í™˜ ì„±ê³µ!")
        
        # ë³€í™˜ëœ íŒŒì¼ì˜ ì¸ì½”ë”© í™•ì¸
        encoding, confidence = FileEncodingHandler.detect_encoding(target_file)
        print(f"ë³€í™˜ëœ íŒŒì¼ ì¸ì½”ë”©: {encoding} (ì‹ ë¢°ë„: {confidence:.2f})")
        
        # ë‚´ìš© í™•ì¸
        with open(target_file, 'r', encoding='utf-8') as f:
            content = f.read()
        print(f"ë³€í™˜ëœ ë‚´ìš© (ì²˜ìŒ 50ì): {content[:50]}...")
    
    print("\n" + "="*60)
    print("BOM ì²˜ë¦¬ í…ŒìŠ¤íŠ¸:")
    print("="*60)
    
    # BOM ì¶”ê°€ í…ŒìŠ¤íŠ¸
    bom_file = os.path.join(test_dir, "no_bom.txt")
    with open(bom_file, 'w', encoding='utf-8') as f:
        f.write("BOMì´ ì—†ëŠ” íŒŒì¼")
    
    print(f"BOM ì¶”ê°€ ì „ íŒŒì¼ í¬ê¸°: {os.path.getsize(bom_file)} bytes")
    
    # BOM ì¶”ê°€
    FileEncodingHandler.add_bom_to_file(bom_file, 'utf-8-sig')
    print(f"BOM ì¶”ê°€ í›„ íŒŒì¼ í¬ê¸°: {os.path.getsize(bom_file)} bytes")
    
    # BOM ì œê±°
    FileEncodingHandler.remove_bom_from_file(bom_file)
    print(f"BOM ì œê±° í›„ íŒŒì¼ í¬ê¸°: {os.path.getsize(bom_file)} bytes")
    
    print("\n" + "="*60)
    print("ë©”ëª¨ë¦¬ì—ì„œ ì¸ì½”ë”© ìˆ˜ì • í…ŒìŠ¤íŠ¸:")
    print("="*60)
    
    # ê¹¨ì§„ ì¸ì½”ë”© íŒŒì¼ ìƒì„± (ì‹œë®¬ë ˆì´ì…˜)
    broken_file = os.path.join(test_dir, "broken_encoding.txt")
    broken_text = "ê¹¨ì§„ í…ìŠ¤íŠ¸".encode('cp949')
    
    with open(broken_file, 'wb') as f:
        f.write(broken_text)
    
    # ë©”ëª¨ë¦¬ì—ì„œ ìˆ˜ì •
    with open(broken_file, 'r', encoding='utf-8', errors='replace') as f:
        try:
            # ì¼ë¶€ëŸ¬ ê¹¨ì§„ ì¸ì½”ë”©ìœ¼ë¡œ ì½ê¸°
            broken_content = f.read()
            print(f"ê¹¨ì§„ ë‚´ìš©: {broken_content}")
        except:
            pass
    
    # ë©”ëª¨ë¦¬ì—ì„œ ì¸ì½”ë”© ìˆ˜ì •
    with open(broken_file, 'r', encoding='utf-8', errors='replace') as f:
        fixed_content, detected_encoding = FileEncodingHandler.fix_encoding_in_memory(f)
        print(f"ìˆ˜ì •ëœ ë‚´ìš©: {fixed_content}")
        print(f"ê°ì§€ëœ ì¸ì½”ë”©: {detected_encoding}")
    
    # ì •ë¦¬
    print(f"\ní…ŒìŠ¤íŠ¸ ì™„ë£Œ. ë””ë ‰í„°ë¦¬ ìœ ì§€: {test_dir}")
    # shutil.rmtree(test_dir)  # ì •ë¦¬í•˜ë ¤ë©´ ì£¼ì„ í•´ì œ

# demonstrate_encoding_fixes()  # ì‹¤í–‰ ì‹œ ì£¼ì„ í•´ì œ
```

### ëŒ€ìš©ëŸ‰ íŒŒì¼ ìŠ¤íŠ¸ë¦¬ë° ë³€í™˜

```python
import os
import sys
from io import TextIOWrapper

class StreamingEncodingConverter:
    """ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹ì˜ ëŒ€ìš©ëŸ‰ íŒŒì¼ ì¸ì½”ë”© ë³€í™˜ê¸°"""
    
    def __init__(self, buffer_size=8192):
        """
        Args:
            buffer_size: ë²„í¼ í¬ê¸° (ë°”ì´íŠ¸)
        """
        self.buffer_size = buffer_size
    
    def convert_large_file(self, source_path, target_path, 
                          target_encoding='utf-8',
                          source_encoding=None):
        """
        ëŒ€ìš©ëŸ‰ íŒŒì¼ ìŠ¤íŠ¸ë¦¬ë° ë³€í™˜
        
        Args:
            source_path: ì›ë³¸ íŒŒì¼ ê²½ë¡œ
            target_path: ëŒ€ìƒ íŒŒì¼ ê²½ë¡œ
            target_encoding: ëŒ€ìƒ ì¸ì½”ë”©
            source_encoding: ì›ë³¸ ì¸ì½”ë”©
        
        Returns:
            ë³€í™˜ í†µê³„
        """
        stats = {
            'bytes_read': 0,
            'bytes_written': 0,
            'lines_processed': 0,
            'errors': 0
        }
        
        try:
            # ì›ë³¸ ì¸ì½”ë”© ê°ì§€ (ì²« ë¶€ë¶„ë§Œ)
            if source_encoding is None:
                sample_size = min(4096, os.path.getsize(source_path))
                source_encoding, _ = FileEncodingHandler.detect_encoding(
                    source_path, sample_size
                )
                print(f"ê°ì§€ëœ ì¸ì½”ë”©: {source_encoding}")
            
            # ìŠ¤íŠ¸ë¦¬ë° ë³€í™˜
            with open(source_path, 'r', 
                     encoding=source_encoding,
                     errors='replace') as source_file:
                
                with open(target_path, 'w',
                         encoding=target_encoding,
                         errors='strict') as target_file:
                    
                    # ì²­í¬ ë‹¨ìœ„ ì²˜ë¦¬
                    while True:
                        chunk = source_file.read(self.buffer_size)
                        if not chunk:
                            break
                        
                        stats['bytes_read'] += len(chunk.encode(source_encoding))
                        stats['lines_processed'] += chunk.count('\n')
                        
                        # ëŒ€ìƒ íŒŒì¼ì— ì“°ê¸°
                        try:
                            target_file.write(chunk)
                            stats['bytes_written'] += len(chunk.encode(target_encoding))
                        except UnicodeEncodeError as e:
                            stats['errors'] += 1
                            print(f"ì¸ì½”ë”© ì˜¤ë¥˜ (ì¤„ {stats['lines_processed']}): {e}")
                            # ì˜¤ë¥˜ ë°œìƒ ì‹œ ëŒ€ì²´ ë¬¸ìë¡œ ì‘ì„±
                            target_file.write(chunk.encode(target_encoding, 
                                                         errors='replace').decode(target_encoding))
            
            print(f"ë³€í™˜ ì™„ë£Œ: {stats['bytes_read']:,} bytes â†’ {stats['bytes_written']:,} bytes")
            print(f"ì²˜ë¦¬ëœ ì¤„: {stats['lines_processed']:,}")
            
            if stats['errors'] > 0:
                print(f"ê²½ê³ : {stats['errors']}ê°œì˜ ì¸ì½”ë”© ì˜¤ë¥˜ ë°œìƒ")
            
            return stats
            
        except Exception as e:
            print(f"ë³€í™˜ ì¤‘ ì˜¤ë¥˜: {e}")
            stats['errors'] += 1
            return stats
    
    def convert_with_progress(self, source_path, target_path,
                            target_encoding='utf-8',
                            source_encoding=None,
                            progress_callback=None):
        """
        ì§„í–‰ ìƒí™© í‘œì‹œê°€ ìˆëŠ” ë³€í™˜
        
        Args:
            source_path: ì›ë³¸ íŒŒì¼ ê²½ë¡œ
            target_path: ëŒ€ìƒ íŒŒì¼ ê²½ë¡œ
            target_encoding: ëŒ€ìƒ ì¸ì½”ë”©
            source_encoding: ì›ë³¸ ì¸ì½”ë”©
            progress_callback: ì§„í–‰ ìƒí™© ì½œë°± í•¨ìˆ˜
        
        Returns:
            ë³€í™˜ í†µê³„
        """
        import tqdm
        
        total_size = os.path.getsize(source_path)
        
        if source_encoding is None:
            source_encoding, _ = FileEncodingHandler.detect_encoding(source_path)
        
        stats = {
            'bytes_read': 0,
            'bytes_written': 0,
            'lines_processed': 0,
            'errors': 0
        }
        
        # ì§„í–‰ í‘œì‹œê¸° ìƒì„±
        with tqdm.tqdm(total=total_size, 
                      unit='B', 
                      unit_scale=True,
                      desc="ì¸ì½”ë”© ë³€í™˜") as pbar:
            
            with open(source_path, 'r', 
                     encoding=source_encoding,
                     errors='replace') as source_file:
                
                with open(target_path, 'w',
                         encoding=target_encoding,
                         errors='strict') as target_file:
                    
                    while True:
                        chunk = source_file.read(self.buffer_size)
                        if not chunk:
                            break
                        
                        chunk_size = len(chunk.encode(source_encoding))
                        stats['bytes_read'] += chunk_size
                        stats['lines_processed'] += chunk.count('\n')
                        
                        # ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸
                        pbar.update(chunk_size)
                        
                        if progress_callback:
                            progress = stats['bytes_read'] / total_size
                            progress_callback(progress, stats)
                        
                        # ì“°ê¸°
                        try:
                            target_file.write(chunk)
                            stats['bytes_written'] += len(chunk.encode(target_encoding))
                        except UnicodeEncodeError:
                            stats['errors'] += 1
                            # ì˜¤ë¥˜ ì²˜ë¦¬
                            target_file.write(chunk.encode(target_encoding,
                                                         errors='replace').decode(target_encoding))
        
        return stats

# ì‚¬ìš© ì˜ˆì‹œ
def demonstrate_streaming_conversion():
    """ìŠ¤íŠ¸ë¦¬ë° ë³€í™˜ ë°ëª¨"""
    
    import tempfile
    import time
    
    # ëŒ€ìš©ëŸ‰ í…ŒìŠ¤íŠ¸ íŒŒì¼ ìƒì„±
    test_dir = tempfile.mkdtemp(prefix="streaming_test_")
    large_file = os.path.join(test_dir, "large_file.txt")
    
    print(f"ëŒ€ìš©ëŸ‰ í…ŒìŠ¤íŠ¸ íŒŒì¼ ìƒì„± ì¤‘... ({large_file})")
    
    # 10MB í¬ê¸°ì˜ í…ŒìŠ¤íŠ¸ íŒŒì¼ ìƒì„±
    target_size = 10 * 1024 * 1024  # 10MB
    chunk = "í•œê¸€ê³¼ English mixed content. " * 100 + "\n"
    chunk_size = len(chunk.encode('utf-8'))
    
    with open(large_file, 'w', encoding='utf-8') as f:
        written = 0
        while written < target_size:
            f.write(chunk)
            written += chunk_size
    
    actual_size = os.path.getsize(large_file)
    print(f"ìƒì„± ì™„ë£Œ: {actual_size:,} bytes")
    
    # ìŠ¤íŠ¸ë¦¬ë° ë³€í™˜ í…ŒìŠ¤íŠ¸
    converter = StreamingEncodingConverter(buffer_size=65536)  # 64KB ë²„í¼
    
    output_file = os.path.join(test_dir, "converted_file.txt")
    
    print("\nìŠ¤íŠ¸ë¦¬ë° ë³€í™˜ ì‹œì‘...")
    start_time = time.time()
    
    stats = converter.convert_large_file(
        large_file,
        output_file,
        target_encoding='utf-8',
        source_encoding='utf-8'  # ì‹¤ì œë¡œëŠ” ë‹¤ë¥¸ ì¸ì½”ë”©ìœ¼ë¡œ í…ŒìŠ¤íŠ¸
    )
    
    elapsed = time.time() - start_time
    speed = stats['bytes_read'] / elapsed / 1024 / 1024  # MB/s
    
    print(f"\në³€í™˜ ì™„ë£Œ!")
    print(f"ì†Œìš” ì‹œê°„: {elapsed:.2f}ì´ˆ")
    print(f"ì²˜ë¦¬ ì†ë„: {speed:.2f} MB/s")
    print(f"ì½ì€ ë°”ì´íŠ¸: {stats['bytes_read']:,}")
    print(f"ì“´ ë°”ì´íŠ¸: {stats['bytes_written']:,}")
    print(f"ì²˜ë¦¬ëœ ì¤„: {stats['lines_processed']:,}")
    print(f"ì˜¤ë¥˜: {stats['errors']}")
    
    # íŒŒì¼ ë¹„êµ
    original_size = os.path.getsize(large_file)
    converted_size = os.path.getsize(output_file)
    
    print(f"\níŒŒì¼ í¬ê¸° ë¹„êµ:")
    print(f"ì›ë³¸: {original_size:,} bytes")
    print(f"ë³€í™˜: {converted_size:,} bytes")
    print(f"ì°¨ì´: {abs(original_size - converted_size):,} bytes")
    
    # ì •ë¦¬
    import shutil
    shutil.rmtree(test_dir)
    print(f"\ní…ŒìŠ¤íŠ¸ ì™„ë£Œ. ë””ë ‰í„°ë¦¬ ì •ë¦¬ë¨.")

# demonstrate_streaming_conversion()  # ì‹¤í–‰ ì‹œ ì£¼ì„ í•´ì œ
```

## ê²°ë¡ : íŒŒì¼ ì‹œìŠ¤í…œê³¼ ì¸ì½”ë”© ì²˜ë¦¬ì˜ ëª¨ë²” ì‚¬ë¡€

íŒŒì´ì¬ì—ì„œ íŒŒì¼ ì‹œìŠ¤í…œ ì‘ì—…ê³¼ ì¸ì½”ë”© ì²˜ë¦¬ë¥¼ ì•ˆì •ì ìœ¼ë¡œ ìˆ˜í–‰í•˜ê¸° ìœ„í•œ í•µì‹¬ ì›ì¹™ì„ ì •ë¦¬í•©ë‹ˆë‹¤:

### 1. **ë°©ì–´ì  í”„ë¡œê·¸ë˜ë° ì² í•™**
- í•­ìƒ ì˜ˆì™¸ ì²˜ë¦¬ë¥¼ êµ¬í˜„í•˜ê³ , íŠ¹íˆ `PermissionError`, `FileNotFoundError`, `UnicodeError`ë¥¼ ê³ ë ¤
- ì‚¬ìš©ì ì…ë ¥ì´ë‚˜ ì™¸ë¶€ ë°ì´í„°ëŠ” í•­ìƒ ê²€ì¦ í›„ ì²˜ë¦¬
- íŒŒì¼ ì‘ì—… ì „ì— ì¡´ì¬ ì—¬ë¶€ì™€ ê¶Œí•œ í™•ì¸

### 2. **ì¸ì½”ë”© ì²˜ë¦¬ì˜ ê¸°ë³¸ ì›ì¹™**
- **ëª…ì‹œì  ì¸ì½”ë”© ì§€ì •**: íŒŒì¼ì„ ì—´ ë•Œ í•­ìƒ `encoding` ë§¤ê°œë³€ìˆ˜ ëª…ì‹œ
- **ì¼ê´€ëœ ì¸ì½”ë”© ì •ì±…**: í”„ë¡œì íŠ¸ ë‚´ë¶€ì—ì„œëŠ” UTF-8ì„ ê¸°ë³¸ìœ¼ë¡œ í†µì¼
- **ì¸ì½”ë”© ê°ì§€ í™œìš©**: `chardet` ë¼ì´ë¸ŒëŸ¬ë¦¬ë¡œ ë¶ˆí™•ì‹¤í•œ íŒŒì¼ì˜ ì¸ì½”ë”© ê°ì§€
- **BOM ì²˜ë¦¬ ì´í•´**: í•„ìš”ì‹œ `utf-8-sig` ì‚¬ìš©, ë¶ˆí•„ìš”ì‹œ ì œê±°

### 3. **íŒŒì¼ ì‹œìŠ¤í…œ ì‘ì—… ìµœì í™”**
- **ì ì ˆí•œ ë„êµ¬ ì„ íƒ**: 
  - ê°„ë‹¨í•œ ì‘ì—…: `os.listdir()`
  - ë©”íƒ€ë°ì´í„° í•„ìš”: `os.scandir()`
  - ê°ì²´ì§€í–¥ ì ‘ê·¼: `pathlib.Path`
  - íŒ¨í„´ ë§¤ì¹­: `glob` ëª¨ë“ˆ
- **ëŒ€ìš©ëŸ‰ íŒŒì¼ ì²˜ë¦¬**: ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹ê³¼ ì ì ˆí•œ ë²„í¼ í¬ê¸° ì‚¬ìš©
- **ë³‘ë ¬ ì²˜ë¦¬ ê³ ë ¤**: `concurrent.futures`ë¡œ I/O ë³‘ëª© í•´ì†Œ

### 4. **í”Œë«í¼ ê°„ í˜¸í™˜ì„± ë³´ì¥**
- **ê²½ë¡œ ë¶„ë¦¬ì**: `os.path.join()` ì‚¬ìš©ìœ¼ë¡œ ìš´ì˜ì²´ì œì— ë§ëŠ” êµ¬ë¶„ì ì ìš©
- **íŒŒì¼ëª… ì œí•œ**: ìš´ì˜ì²´ì œë³„ íŒŒì¼ëª… ê¸¸ì´ì™€ ì˜ˆì•½ì–´ ì œí•œ ê³ ë ¤
- **ì¸ì½”ë”© ì°¨ì´**: Windowsì˜ CP949ì™€ Unixì˜ UTF-8 ê¸°ë³¸ê°’ ì´í•´

### 5. **ì•ˆì „í•œ íŒŒì¼ëª… ì²˜ë¦¬ ì „ëµ**
- **ì •ê·œí™”**: `unicodedata.normalize()`ë¡œ ìœ ë‹ˆì½”ë“œ ì •ê·œí™”
- **ìœ„í—˜ ë¬¸ì ì œê±°**: ì •ê·œí‘œí˜„ì‹ìœ¼ë¡œ ìš´ì˜ì²´ì œë³„ ìœ„í—˜ ë¬¸ì í•„í„°ë§
- **ê¸¸ì´ ì œí•œ**: íŒŒì¼ì‹œìŠ¤í…œ ì œí•œ ê³ ë ¤í•œ ì ì ˆí•œ ê¸¸ì´ ê´€ë¦¬
- **ì¤‘ë³µ ë°©ì§€**: íƒ€ì„ìŠ¤íƒ¬í”„ë‚˜ í•´ì‹œë¥¼ ì´ìš©í•œ ê³ ìœ  íŒŒì¼ëª… ìƒì„±

### 6. **ë””ë²„ê¹…ê³¼ ëª¨ë‹ˆí„°ë§**
- **ë¡œê·¸ ê¸°ë¡**: ëª¨ë“  íŒŒì¼ ì‘ì—…ì„ ì ì ˆí•œ ë¡œê·¸ ë ˆë²¨ë¡œ ê¸°ë¡
- **ì—ëŸ¬ ë³µêµ¬**: ì‹¤íŒ¨í•œ ì‘ì—…ì„ ì¬ì‹œë„í•˜ê±°ë‚˜ ëŒ€ì²´í•  ìˆ˜ ìˆëŠ” ë©”ì»¤ë‹ˆì¦˜ êµ¬í˜„
- **ì§„í–‰ ìƒí™© í‘œì‹œ**: ëŒ€ìš©ëŸ‰ ì‘ì—… ì‹œ ì§„í–‰ë¥  í‘œì‹œë¡œ ì‚¬ìš©ì ê²½í—˜ í–¥ìƒ

### 7. **ë³´ì•ˆ ê³ ë ¤ì‚¬í•­**
- **ê²½ë¡œ ì¡°ì‘ ë°©ì§€**: ì‚¬ìš©ì ì…ë ¥ ê²½ë¡œì˜ `..` íŒ¨í„´ ê²€ì‚¬
- **ì‹¬ë³¼ë¦­ ë§í¬ ì²˜ë¦¬**: `os.path.islink()`ë¡œ ì‹¬ë³¼ë¦­ ë§í¬ ê²€ì‚¬
- **ê¶Œí•œ ìµœì†Œí™”**: í•„ìš”í•œ ìµœì†Œ ê¶Œí•œë§Œ ë¶€ì—¬

### 8. **í…ŒìŠ¤íŠ¸ì™€ ê²€ì¦**
- **ìœ ë‹› í…ŒìŠ¤íŠ¸**: ë‹¤ì–‘í•œ ì¸ì½”ë”©ê³¼ íŒŒì¼ëª…ìœ¼ë¡œ ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì‘ì„±
- **í†µí•© í…ŒìŠ¤íŠ¸**: ì‹¤ì œ íŒŒì¼ ì‹œìŠ¤í…œ í™˜ê²½ì—ì„œì˜ ë™ì‘ ê²€ì¦
- **ì„±ëŠ¥ í…ŒìŠ¤íŠ¸**: ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§

íŒŒì´ì¬ì˜ íŒŒì¼ ì‹œìŠ¤í…œê³¼ ì¸ì½”ë”© ì²˜ë¦¬ ê¸°ëŠ¥ì€ ê°•ë ¥í•˜ì§€ë§Œ, ë‹¤ì–‘í•œ í™˜ê²½ì—ì„œ ì•ˆì •ì ìœ¼ë¡œ ì‘ë™í•˜ë ¤ë©´ ì´ëŸ¬í•œ ëª¨ë²” ì‚¬ë¡€ë¥¼ ë”°ë¥´ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤. íŠ¹íˆ êµ­ì œí™”(i18n)ê°€ í•„ìš”í•œ ì• í”Œë¦¬ì¼€ì´ì…˜ì´ë‚˜ ë‹¤ì–‘í•œ ìš´ì˜ì²´ì œì—ì„œ ì‹¤í–‰ë˜ëŠ” ì†Œí”„íŠ¸ì›¨ì–´ë¥¼ ê°œë°œí•  ë•ŒëŠ” ì¸ì½”ë”© ì²˜ë¦¬ì— ê°ë³„í•œ ì£¼ì˜ê°€ í•„ìš”í•©ë‹ˆë‹¤. ì´ëŸ¬í•œ ê¸°ë²•ë“¤ì„ ìˆ™ì§€í•˜ê³  ì ì ˆíˆ ì ìš©í•˜ë©´ íŒŒì¼ ê´€ë ¨ ë¬¸ì œë¥¼ ìµœì†Œí™”í•˜ë©´ì„œ ì•ˆì •ì ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ê°œë°œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.