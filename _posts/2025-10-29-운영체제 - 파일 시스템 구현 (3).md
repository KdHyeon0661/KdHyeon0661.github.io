---
layout: post
title: 운영체제 - 파일 시스템 구현 (3)
date: 2025-10-29 18:25:23 +0900
category: 운영체제
---
# Chapter 14 — Recovery & WAFL

## 14.7 Recovery

### 14.7.1 장애 모델과 불변식(Invariants)

**장애 모델**
- **크래시/전원장애**: “어떤 쓰기도 부분적으로만 내려갈 수 있음(tear/write-reordering)”
- **장치 오류**: 불량 블록/읽기 실패/미디어 사망
- **펌웨어·캐시 순서 꼬임**: 장치 캐시가 전원과 함께 유실, **배리어(FUA/flush)** 누락 시 순서 보장 안 됨

**파일시스템 불변식(예)**
1) **한 블록은 0개 또는 1개의 “소유자”에게만 할당** (이중 할당 금지)  
2) **디렉터리 트리는 루트에서 도달 가능** (Orphan 없음)  
3) **링크 수 == 실제 참조 수**  
4) **메타데이터는 자기 자신을 모순 없이 가리킴** (포인터 일관성)  

복구는 장애 이후에 **이 불변식**을 빠르게 회복하는 절차다.

---

### 14.7.2 복구 전략 분류

1) **fsck(오프라인 스캐닝)**  
   - 온디스크 구조를 **전수 검사**하고 모순을 수정  
   - 장점: 구현 단순, 어떤 FS에도 가능  
   - 단점: **대용량에서 시간↑**(TB~PB면 사실상 불가), 수정은 **보수적**(예: `lost+found`로 고아 파일 이동)

2) **저널링(Journaling)**  
   - **WAL(write-ahead logging)**: “홈 위치”에 쓰기 전에 **저널에 트랜잭션** 기록  
   - 크래시 후 **redo**(필요 시 undo)로 일관성 회복  
   - **메타데이터 전용**, **데이터+메타**(data=journal), **ordered**(데이터→저널메타 순) 모드

3) **Soft Updates(의존성 기반)**  
   - 메타데이터 간 **쓰기 의존 그래프**를 지키며 **지연·순서화**  
   - 저널 없이도 **크래시 일관성** 달성(FreeBSD UFS 등)

4) **COW/Log-Structured**  
   - **항상 새 블록**에 쓰고 **루트 포인터 스윙**으로 원자 커밋  
   - 크래시 후 **최근 체크포인트**로 복귀, 로그/세그먼트 요약으로 재생

5) **스냅샷·체크섬**  
   - **스냅샷**은 즉시 복구 지점 제공, **체크섬**은 손상 탐지/스크럽에 필수

---

### 14.7.3 WAL(저널링)의 핵심

**트랜잭션 구조(개요)**  
- `BEGIN(T)` → `UPDATE(meta#123 ← new)`… → `COMMIT(T)` → (옵션) `CHECKPOINT`

**주요 모드 비교**
- **metadata-only**: 빠름, 데이터 내용은 순서 보장 없음  
- **ordered**: **데이터 블록이 먼저** 디스크에 내려간 뒤 메타데이터 커밋 → “쓰레기 노출” 방지  
- **data=journal**: 데이터까지 저널에 기록 후 홈 반영(쓰기 증폭↑, 안정성 최고)

**재생 알고리즘(redo 중심)**
```c
// pseudo: journal_replay()
scan_log();
for each T in committed_not_applied():
    for each UPDATE u in T:
        apply(u); // 홈 위치에 반영
flush_barrier();
```
- **idempotent** 해야 함(중복 적용 안전)
- **그룹 커밋**: 여러 T를 묶어 디스크 flush amortization

**원자적 rename 예**  
1) 저널에 “디렉터리 엔트리 삭제/추가”를 같은 T로 기록  
2) `COMMIT` 후 순서대로 홈 위치 갱신 → 크래시에서도 “둘 중 하나만 반영” 상태가 나오지 않음

---

### 14.7.4 Soft Updates (의존성 그래프)

핵심 아이디어: “**절대 깨져선 안 되는 의존 순서**”를 보장하도록 쓰기를 재배열·지연한다. 예:
- 새 파일 생성: **데이터 블록 초기화** → **아이노드 사이즈/포인터 갱신** → **디렉터리 엔트리 추가** 순서
- 제거: **디렉터리 엔트리 제거** → **링크수 감소** → **블록 해제**

장점: 저널 부하 없음, 크래시 후 fsck 시간이 짧음(그래도 필요할 수 있음)

---

### 14.7.5 Log-Structured/COW 복구

**LFS**:  
- 디스크는 **세그먼트**들의 로그  
- 각 세그먼트에 **세그먼트 요약**이 있어 재생 시 “살아있는 최신 버전”을 재구성  
- **체크포인트 영역**에서 최근 루트 찾기 → 필요한 범위만 재생

**COW(ZFS/Btrfs/WAFL 계열)**:  
- 수정된 노드는 **새 블록**에 기록, 부모 포인터 업데이트를 **아래→위**로 전파  
- 마지막에 **슈퍼블록/루트 포인터** 교체(원자 스윙)  
- 복구: **가장 최근 일관 루트**로 마운트, 로그(NVRAM 등)가 있으면 **리플레이**

---

### 14.7.6 체크섬·무결성·스크럽

- 데이터/메타 **체크섬**: $$\Pr[\text{침묵 손상 미검출}] \approx 2^{-b}$$ (체크섬 비트수 \(b\))  
- **엔드-투-엔드**(상위→디스크까지) 체크섬이면 **사일런트 코럽션** 감지  
- **Scrub**: 백그라운드 순회 검증/복구(미러/RAID/스냅샷과 결합)

---

### 14.7.7 fsck가 실제로 하는 일(요약)

1) **패스 1**: 아이노드/블록 맵 스캔, **이중/유령 할당** 탐지  
2) **패스 2**: 디렉터리 트리 순회, **부모-자식** 일관성 확인  
3) **패스 3**: 링크 수 재계산 → **링크 불일치 수정**  
4) **패스 4**: 고아 파일 `lost+found` 이동  
5) **패스 5**: 프리 스페이스 재구성

아래는 “고아 탐지” 장난감 코드:

```python
# fsck_orphan.py — 루트에서 도달하지 못한 inode 수집(개념)
from collections import defaultdict, deque
graph=defaultdict(list)  # parent -> [child...]
inodes=set(range(1,1000))
reachable=set([1])  # 1: root
q=deque([1])
while q:
    u=q.popleft()
    for v in graph[u]:
        if v not in reachable:
            reachable.add(v); q.append(v)
orphans = inodes - reachable
print("orphans:", sorted(orphans)[:10])
```

---

### 14.7.8 복구 시간/데이터 손실 기대값(근사)

**체크포인트(또는 저널 커밋) 주기** \( \Delta \) 에서 **최대 손실 시간**은 \( \le \Delta \).  
균일 도착 가정 시 **기대 손실 시간**은
$$
E[L] \approx \frac{\Delta}{2}
$$
복구 시간 \(R\) 은 **재생해야 할 로그 길이** \(L_{\text{log}}\) 과 IOPS/BW에 비례:
$$
R \approx \frac{L_{\text{log}}}{\text{BW}} + c\cdot \text{IOPS\_miss}
$$

---

### 14.7.9 저널 재생 미니 실습(Python)

```python
# journal_replay_demo.py — metadata-only redo 로그 리플레이(장난감)
log = [
  ("BEGIN",1), ("UPD",1,("inode#5.size", 4096)), ("UPD",1,("dir:/a->#5", True)), ("COMMIT",1),
  ("BEGIN",2), ("UPD",2,("inode#5.size", 8192)), ("CRASH",)
]

applied=set(); meta={}
for rec in log:
    if rec[0]=="BEGIN": pass
    elif rec[0]=="UPD":
        _,tid,(k,v)=rec
        # 실제 반영은 COMMIT 이후
    elif rec[0]=="COMMIT":
        _,tid=rec
        # 커밋된 트랜잭션을 다시 스캔하며 반영(간단화를 위해 즉시 처리)
        for r in log:
            if r[0]=="UPD" and r[1]==tid:
                meta[r[2][0]]=r[2][1]
        applied.add(tid)
    elif rec[0]=="CRASH":
        break

print("replayed:", meta)
```

---

## 14.8 Example: The WAFL File System (Write Anywhere File Layout)

> **WAFL(웨이플)** 은 “**어디에나 쓰기(COW)** + **일관성 포인트(CP)** + **스냅샷**”을 핵심으로 하는 상용 파일시스템(넷앱 계열)이다. 아래 내용은 널리 알려진 **개념 수준** 요약이다.

### 14.8.1 목표와 철학
- NFS/SMB 등 **온라인 서비스 중**에도 **일관성·스냅샷**을 값싸게 제공  
- **COW 트리**로 업데이트하고, **주기적으로 CP** 하여 항상 **일관 루트** 보유  
- **NVRAM 로그**로 CP 사이의 변경을 흡수 → 크래시 시 **빠른 재생**

### 14.8.2 온디스크 개요(개념)
- **Inode File**: 모든 파일의 아이노드를 담는 **특수 파일**  
- **블록 매핑**: **extent/인덱스** 스타일 포인터 트리(간접 계층)  
- **프리 블록 맵(FBM)** 과 **스냅샷 맵**: 참조 카운트/사용 여부  
- **슈퍼블록(루트 포인터)**: **현재 일관 트리** 와 **스냅샷 루트들**로 향함

```
Superblock -> { Active Root, Snapshot Roots[] }
Active Root/InodeFile -> Inodes -> Indirects -> Data Blocks
Free Block Map, Snapshot Refcounts
```

### 14.8.3 쓰기 경로: “Write Anywhere + Consistency Point(CP)”

1) 애플리케이션 쓰기 → **메모리 캐시** + **NVRAM 로그(NVLOG)** 에 기록  
2) 일정 트리거(버튼/시간/로그량)에서 **CP 시작**  
3) CP 동안 **변경된 데이터 블록**들을 **새 위치**에 기록  
4) 그 부모 메타(간접, 아이노드, InodeFile, …)를 **아래→위** 순서로 **새 위치**에 기록  
5) **슈퍼블록의 루트 포인터**를 새 트리로 **원자 교체**  
6) 성공 시 해당 변경에 대응하는 **NVLOG 항목 삭제**

**의사코드**
```c
// pseudo: do_consistency_point()
for each dirty_data in writeback_order:
    new_blk = alloc_block();
    write(new_blk, dirty_data);
    mark_parent_pointer_update(dirty_data.owner, new_blk);

for level from leaves up to root:
    for each dirty_meta at level:
        new_blk = alloc_block();
        patch_pointers(new_blk);
        write(new_blk, dirty_meta);
        mark_parent_pointer_update(dirty_meta.owner, new_blk);

atomic_swap_superblock(new_root);
```

**핵심**: 어느 시점이든 **슈퍼블록이 가리키는 트리**는 **완전 일관**. 크래시가 나도 **이전 CP** 루트로 안전히 마운트 가능.

---

### 14.8.4 스냅샷

- **스냅샷 루트 포인터**를 **배열**에 저장 → **즉시 생성(O(1))**  
- 스냅샷/라이브는 **블록을 공유**, 이후 변경 시 COW로 새 블록 할당  
- 참조 카운트로 **공유 블록 해제** 시점 관리

```python
# toy_wafl_snapshot.py — COW 트리 + 스냅샷(개념)
import itertools, copy
_id = itertools.count(1)
class Node:
    def __init__(self, kids=None, data=None):
        self.id=next(_id); self.kids=kids or []; self.data=data
def cow_write(node, path, newdata):
    if not path:                      # leaf
        return Node(data=newdata)
    i=path[0]
    newkids=list(node.kids)
    newkids[i]=cow_write(node.kids[i], path[1:], newdata)
    return Node(kids=newkids)

# 초기 트리
leafs=[Node(data=b'A'), Node(data=b'B')]
root=Node(kids=leafs)
snap0=root                        # 스냅샷 0: 루트 포인터만 보관
root=cow_write(root, [1], b'B2')  # 라이브에서 B->B2 (COW)
snap1=root
print("snap0,B=", snap0.kids[1].data, "snap1,B=", snap1.kids[1].data)
```

---

### 14.8.5 NVLOG(비휘발 로그) 재생

- CP 사이 구간을 **NVRAM** 에 순차 기록  
- 크래시 후 **마지막 CP 루트** 로 마운트한 뒤 NVLOG를 **리플레이**  
- 리플레이가 끝나면 상태는 “**CP + NVLOG 누적 적용**” 지점

```python
# toy_nvlog_replay.py — CP 루트 + 로그 재생(개념)
cp_state={"inode5.size":4096}
nvlog=[("inode5.size",8192), ("dir:/a->#5",True)]
for k,v in nvlog:
    cp_state[k]=v
print(cp_state)
```

---

### 14.8.6 WAFL의 성능·일관성 트레이드오프

- **CP 주기(Δ)** vs **쓰기 지연/폭주**:  
  - CP가 잦으면 **로그 짧아** 복구 빠름, write amp↑  
  - CP가 길면 **대량 묶음 쓰기** 가능, **복구 로그 길이↑**
- RAID와의 결합: **정렬된 큰 청크**를 선호(스트라이프 정렬)  
- 스냅샷 많을수록 **공유 블록** 증가 → COW 빈도↑ → **공간 재활용 지연** 가능

**간단 근사**: 평균 CP에서 쓰는 블록 수 \(N_b\), 장치 BW \(R\) 일 때 CP 시간
$$
T_{\text{CP}} \approx \frac{N_b \cdot B}{R}
$$
로그(초당 \(\lambda\))와 CP 간격 \(\Delta\)에서 평균 로그 길이
$$
E[L] \approx \lambda \cdot \frac{\Delta}{2}
$$

---

### 14.8.7 운영 시나리오(예)

**Use-case: 다중 클라이언트 NFS + 초 단위 스냅샷**
- **NVRAM 로그**에 빠르게 흡수 → **낮은 쓰기 대기시간**  
- 5초마다 CP → 스냅샷 포인터 추가(설정에 따라)  
- 크래시: **가장 최근 CP 루트**로 즉시 마운트 → **NVLOG 재생** 수 초 내 완료  
- 롤백: 스냅샷 루트로 **즉시 활성 전환**(O(1) 포인터 스윙)

---

### 14.8.8 WAFL 스타일 COW-트리 체크포인트 미니 시뮬레이터(Python)

```python
# toy_wafl_cp.py — 파일(leaf) 수정→CP→크래시 복구 흐름
from dataclasses import dataclass, field
import itertools
_id=itertools.count(1)

@dataclass
class Node:
    kids:list=field(default_factory=list)
    data:bytes|None=None
    id:int=field(default_factory=lambda: next(_id))

def write_leaf(n, data): return Node(data=data)  # 새 블록(COW)

def cow_update(root, path, data):
    if not path: return write_leaf(root, data)   # leaf
    i=path[0]; newkids=list(root.kids)
    newkids[i]=cow_update(root.kids[i], path[1:], data)
    return Node(kids=newkids)

def do_cp(old_root, dirty_ops):
    # dirty_ops: [(path, data), ...]
    root=old_root
    for p,d in dirty_ops:
        root=cow_update(root,p,d)                # 아래->위 COW
    return root                                   # 새 루트(슈퍼블록 스윙)

# 초기
root=Node(kids=[Node(data=b'A'), Node(data=b'B')])
cp0=root
# NVLOG에 기록되었으나 아직 CP 미반영된 변경
nvlog=[([1],b'B2'), ([0],b'A2')]
# 크래시 바로 전 CP 실행
root = do_cp(root, nvlog)  # 새 루트
cp1=root
print("cp0:", cp0.kids[0].data, cp0.kids[1].data)
print("cp1:", cp1.kids[0].data, cp1.kids[1].data)
```

---

### 14.8.9 실무 체크리스트

1) **CP 튜닝**: 워크로드에 맞춰 간격/임계 설정, **그룹 커밋**으로 flush 줄이기  
2) **로그 보존/사이징**: NVLOG 가득차면 **즉시 CP**(백프레셔)  
3) **스냅샷 정책**: 보존 개수/주기/만료, **공간 압력**과 COW 빈도 균형  
4) **스크럽/복구 훈련**: 주기적 무결성 검사, 장애 주입 테스트  
5) **정렬 쓰기**: RAID/SSD 특성에 맞춘 I/O 크기와 정렬

---

## 핵심 요약

- **14.7 Recovery**: fsck/저널링/Soft Updates/COW/체크섬·스냅샷을 조합해 **크래시 이후에도 불변식을 빠르게 회복**한다. **저널은 WAL**, **COW는 루트 스윙**이 일관성의 핵심.  
- **14.8 WAFL**: **Write-Anywhere + Consistency Point + Snapshot + NVLOG** 조합으로 온라인 워크로드에서 **짧은 복구 시간과 강력한 스냅샷**을 제공한다. COW 트리를 **아래→위로 플러시**하고 **슈퍼블록 포인터를 원자 교체**하는 패턴이 본질이다.
