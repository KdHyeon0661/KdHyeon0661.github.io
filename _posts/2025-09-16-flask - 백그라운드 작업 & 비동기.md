---
layout: post
title: flask - 백그라운드 작업 & 비동기
date: 2025-09-16 21:25:23 +0900
category: flask
---
# 9. 백그라운드 작업 & 비동기

> 이 장은 **작업 큐(Celery/RQ)로 비동기·스케줄링·리트라이·체크포인트/진행률**을 만드는 법, **Flask-SocketIO로 실시간 푸시(채팅/알림/진행률 스트리밍)**, **asyncio와 Flask의 가능한 것/한계(Quart 비교)** 를 **운영 기준**으로 정리한다.  
> 모든 코드는 ``` 로 감싸고, 수식이 필요하면 반드시 $$...$$ 로 감싼다(이 장은 수식이 거의 없음).

---

## 9.1 왜 백그라운드 작업인가?

- **응답 시간을 짧게**: 오래 걸리는 연산(영상 처리, 대용량 I/O, 외부 API)을 요청-응답 경로에서 분리  
- **내결함성**: 실패 시 **리트라이/백오프**로 복구  
- **스케줄링**: 주기 작업(리포트, 정리, 캐시 빌드)  
- **확장성**: **워커 수평 확장**으로 처리량 늘리기

---

## 9.2 선택지 개관

| 범주 | 라이브러리 | 장점 | 주의 |
|---|---|---|---|
| 풀스택 작업 큐 | **Celery** | 리트라이/체이닝/스케줄링(Beat)/강력한 라우팅 | 설정 복잡, RabbitMQ/Redis 필수 |
| 경량 큐 | **RQ** | 간단함, Redis만으로 충분 | 고급 워크플로(체인/코드스케줄)는 제한 |
| 실시간 푸시 | **Flask-SocketIO** | 실시간 이벤트(알림/채팅/진행률) | eventlet/gevent/async 기반 선택 필요 |
| ASGI 프레임워크 | **Quart** | 네이티브 asyncio, WebSocket 자연스러움 | Flask와 일부 호환 차이 |

> **전략**: Flask(WSGI) + Celery/RQ + Flask-SocketIO 조합이 보편. **진짜 asyncio가 필요한 경우** Quart를 검토.

---

## 9.3 Celery로 작업 큐 구성 (Redis/RabbitMQ)

### 9.3.1 설치 & 기본 구성

```bash
pip install "celery[redis]"  # Redis 브로커/백엔드
# 또는: pip install celery && apt/yum/brew install rabbitmq
```

프로젝트 구조:

```
app/
├─ __init__.py
├─ extensions.py
├─ tasks/
│  ├─ __init__.py
│  ├─ celery_app.py
│  ├─ demo.py
│  └─ reports.py
└─ blueprints/
   └─ api/
      └─ jobs.py
```

Flask와 Celery 연결(앱 컨텍스트 주입):

```python
# app/tasks/celery_app.py
import os
from celery import Celery
from flask import Flask

def make_flask() -> Flask:
    from app import create_app  # 앱 팩토리
    return create_app(os.getenv("APP_ENV"))

def make_celery(flask_app: Flask) -> Celery:
    broker = os.getenv("CELERY_BROKER_URL", "redis://localhost:6379/0")
    backend = os.getenv("CELERY_RESULT_BACKEND", "redis://localhost:6379/1")
    celery = Celery(
        flask_app.import_name,
        broker=broker,
        backend=backend,
        include=["app.tasks.demo", "app.tasks.reports"]
    )
    celery.conf.update(
        task_serializer="json",
        accept_content=["json"],
        result_serializer="json",
        timezone="Asia/Seoul",
        enable_utc=True,
        task_acks_late=True,        # 워커 크래시시 재배달
        worker_prefetch_multiplier=1, # 공정한 작업 분배
        broker_transport_options={"visibility_timeout": 3600},  # Redis 비지빌리티
        task_time_limit=600,        # 하드 타임리밋
        task_soft_time_limit=540,   # 소프트 타임리밋(정리 기회)
    )

    # Flask 컨텍스트에서 Task 실행
    class ContextTask(celery.Task):
        def __call__(self, *args, **kwargs):
            with flask_app.app_context():
                return self.run(*args, **kwargs)

    celery.Task = ContextTask
    return celery

flask_app = make_flask()
celery = make_celery(flask_app)
```

샘플 태스크:

```python
# app/tasks/demo.py
import time
from celery import shared_task

@shared_task(bind=True, autoretry_for=(Exception,), retry_backoff=2, retry_jitter=True, max_retries=5)
def long_sum(self, n: int) -> int:
    """데모: 점진 합계, 체크포인트(메타)에 진행률 기록"""
    total = 0
    for i in range(1, n + 1):
        total += i
        if i % 1000 == 0:
            self.update_state(state="PROGRESS", meta={"done": i, "total": n})
            time.sleep(0.01)  # 데모용 지연
    return total
```

> `bind=True` 로 `self.update_state` 사용(진행률/중간결과 저장), `autoretry_for`+`retry_backoff` 로 지수 백오프.

### 9.3.2 워커/스케줄러 실행

```bash
# 워커
celery -A app.tasks.celery_app.celery worker -l info --concurrency 4

# 스케줄러(Beat)
celery -A app.tasks.celery_app.celery beat -l info
```

**주기 작업 등록**:

```python
# app/tasks/celery_app.py (conf.update 아래)
celery.conf.beat_schedule = {
    "nightly-report": {
        "task": "app.tasks.reports.generate_daily",
        "schedule": 60.0 * 60 * 24,  # 매 24시간
        "options": {"queue": "reports"}
    }
}
```

리포트 태스크:

```python
# app/tasks/reports.py
from celery import shared_task

@shared_task
def generate_daily():
    # DB 집계/파일 생성/메일 발송 등
    return {"ok": True}
```

### 9.3.3 체인/그룹/코드(워크플로)

```python
from celery import chain, group, chord
from app.tasks.demo import long_sum

# 순차
workflow = chain(long_sum.s(10_000), long_sum.s(20_000))()
# 병렬
g = group(long_sum.s(50_000) for _ in range(8))()
# 병렬 후 집계
final = chord((long_sum.s(10_000), long_sum.s(20_000)), long_sum.s(5_000))()
```

### 9.3.4 API에서 작업 제출/상태 조회

```python
# app/blueprints/api/jobs.py
from flask import Blueprint, jsonify, request
from celery.result import AsyncResult
from app.tasks.celery_app import celery
from app.tasks.demo import long_sum

jobs_bp = Blueprint("jobs", __name__, url_prefix="/api/jobs")

@jobs_bp.post("/sum")
def submit_sum():
    n = int(request.json["n"])
    job = long_sum.apply_async(args=[n], queue="default", countdown=0)  # ETA/Countdown 스케줄 가능
    return {"task_id": job.id}, 202

@jobs_bp.get("/<task_id>")
def job_status(task_id):
    r = AsyncResult(task_id, app=celery)
    return jsonify(
        id=task_id, state=r.state, result=r.result if r.successful() else None, meta=r.info
    )
```

### 9.3.5 운영 포인트

- **Idempotency**: 태스크 재시도/중복 실행 대비 **업무 키**로 중복 방지(예: 외부 결제 capture).  
- **ACK 시점**: `task_acks_late=True` + 안정적인 **Result Backend** → **적어도 한 번(at-least-once)** 처리.  
- **정확히 한 번(Exactly-once)** 은 일반적으로 **업무 논리로 보장**(멱등 처리/unique key).  
- **타임리밋**: `soft_time_limit`(리소스 정리), `time_limit`(강제 종료)  
- **큐 라우팅**: CPU 바운드와 I/O 바운드를 분리 큐로  
- **모니터링**: Flower(`pip install flower` → `celery -A ... flower`) / Prometheus exporter

---

## 9.4 RQ(간단하고 직관적인 Redis 큐)

### 9.4.1 설치 & 최소 예제

```bash
pip install rq redis
```

큐/잡 제출:

```python
# app/tasks/rq.py
from redis import Redis
from rq import Queue, Retry

redis = Redis.from_url("redis://localhost:6379/0")
q = Queue("default", connection=redis, default_timeout=600)

def long_sum(n: int) -> int:
    s = 0
    for i in range(1, n + 1):
        s += i
        if i % 1_000_000 == 0:
            pass  # RQ는 기본적으로 job.meta에 진행률 저장 가능(아래)
    return s

def enqueue_sum(n: int):
    job = q.enqueue(long_sum, n, retry=Retry(max=5, interval=[1,2,4,8,16]))
    return job.id
```

워크플로:

```bash
rq worker default --with-scheduler
```

진행률 저장/조회:

```python
# 작업 함수 내에서
from rq import get_current_job
job = get_current_job()
job.meta["progress"] = {"done": i, "total": n}
job.save_meta()

# API에서 조회
from rq.job import Job
job = Job.fetch(job_id, connection=redis)
progress = job.meta.get("progress")
```

> RQ는 단순하고 직관적이지만 **복합 워크플로/체이닝은 약함**. 필요시 상위 레벨에서 조립.

---

## 9.5 진행률 & 체크포인트 — UI/재개 전략

### 9.5.1 Celery의 `update_state` / RQ의 `job.meta`

- 주기적으로 진행률(%) 혹은 단계(step) 업데이트  
- **체크포인트**: 외부 스토리지(DB/S3)에 **중간 산출물** 저장 → **재시도/재개**에 활용

```python
# Celery 예: 단계 체크포인트
@shared_task(bind=True)
def export_csv(self, query_id: int):
    stage = 1
    self.update_state(state="STAGE1", meta={"stage": stage})
    path = _run_query_to_temp(query_id)  # 체크포인트1: temp path

    stage = 2
    self.update_state(state="STAGE2", meta={"stage": stage, "temp": path})
    final = _upload_to_s3(path)         # 체크포인트2: S3 key

    return {"s3": final}
```

> 재시도 시 `meta` 를 복원해 **이미 끝난 단계는 건너뛰기**(중복 작업 줄이기).

### 9.5.2 취소/중단

- Celery: `AsyncResult.revoke(terminate=True, signal='SIGTERM')`  
- RQ: `job.cancel()`  
- **주의**: 안전한 중단을 위해 작업 함수는 **소프트 타임리밋/플래그**를 존중해 **정리 후 종료**.

---

## 9.6 Flask-SocketIO로 실시간 업데이트

### 9.6.1 언제 쓰나

- **진행률/알림 푸시**, **채팅/Presence**, **대시보드 실시간 반영**  
- HTTP Polling/Long-polling보다 **낮은 지연** & **양방향**

### 9.6.2 설치 & 선택지

```bash
pip install flask-socketio
# 전송 계층 선택:
pip install eventlet      # 간단/일체형
# 또는
pip install gevent gevent-websocket
# 또는 asyncio 고급:
pip install "flask-socketio[asyncio]"
```

**서버 선택 가이드**  
- **eventlet**: 설정 단순, 많은 튜토리얼.  
- **gevent**: 성능/안정성 우수.  
- **asyncio**: 최신 파이썬 네이티브; 단, **Flask는 WSGI**(아래 asyncio/ASGI 절 참고).

### 9.6.3 기본 세팅

```python
# app/realtime.py
from flask_socketio import SocketIO

socketio = SocketIO(
    async_mode="eventlet",          # "gevent" / "asgi" 가능
    cors_allowed_origins=["https://app.example.com"],  # 최소 허용
    message_queue="redis://localhost:6379/2"  # 여러 인스턴스 간 브로드캐스트(필수!)
)
```

앱에 장착:

```python
# app/__init__.py
from .realtime import socketio

def create_app(...):
    app = Flask(__name__)
    ...
    socketio.init_app(app)
    return app

# run.py (개발)
from app import create_app
from app.realtime import socketio
app = create_app()
socketio.run(app, host="0.0.0.0", port=5000)
```

### 9.6.4 이벤트/네임스페이스/룸

```python
# app/blueprints/realtime/events.py
from flask_socketio import emit, join_room, leave_room
from app.realtime import socketio

@socketio.on("connect")
def on_connect():
    emit("server:welcome", {"msg": "connected"})

@socketio.on("join")
def on_join(data):
    room = data["room"]
    join_room(room)
    emit("server:joined", {"room": room}, to=room)

@socketio.on("chat:send")
def chat_send(data):
    emit("chat:message", {"user": data["user"], "text": data["text"]}, to=data["room"])
```

**네임스페이스**로 기능 분리:

```python
from flask_socketio import Namespace

class JobsNamespace(Namespace):
    def on_connect(self):
        emit("jobs:welcome", {"ok": True})

socketio.on_namespace(JobsNamespace("/jobs"))
```

### 9.6.5 백엔드 작업 ↔ 실시간 진행률 연동

Celery 태스크에서 **Redis Pub/Sub** 또는 `socketio.emit`(메시지 큐 설정 시 가능)으로 푸시:

```python
# app/tasks/progress.py
from app.tasks.celery_app import celery
from app.realtime import socketio

@celery.task(bind=True)
def heavy_task(self, room: str):
    for i in range(100):
        self.update_state(state="PROGRESS", meta={"pct": i})
        socketio.emit("jobs:progress", {"pct": i}, to=room, namespace="/jobs")
    socketio.emit("jobs:done", {"ok": True}, to=room, namespace="/jobs")
```

클라이언트(브라우저):

```html
<script src="/socket.io/socket.io.js"></script>
<script>
  const socket = io({path: "/socket.io", transports:["websocket"]});
  socket.on("connect", () => {
    socket.emit("join", {room: "job_{{ task_id }}"});
  });
  socket.on("jobs:progress", (data) => {
    document.querySelector("#pct").innerText = data.pct + "%";
  });
  socket.on("jobs:done", () => alert("완료!"));
</script>
```

### 9.6.6 인증/토큰

- **연결 시** 쿼리/헤더에 토큰을 보내고 서버에서 검증 → `disconnect()`  
- 룸 join 시 **인가** 확인(자신의 작업만 구독 가능)

```python
@socketio.on("connect")
def sock_auth():
    token = request.args.get("token")
    if not verify(token):
        return False  # 거부
```

### 9.6.7 배포/스케일

- **Gunicorn + eventlet**:
  ```bash
  gunicorn -k eventlet -w 1 "wsgi:app" --bind :5000
  ```
  여러 인스턴스/프로세스에서 **message_queue=Redis** 설정으로 **브로드캐스트 보장**.
- **프록시**: Nginx에서 **WebSocket 업그레이드** 헤더 전달  
- **CORS/Origin 제한**: 실수로 `*` + credential 허용하지 않기

---

## 9.7 asyncio와 Flask: 가능한 것과 한계

### 9.7.1 Flask의 async 지원 요약

- Flask 2.x/3.x 는 **`async def` 뷰**를 **지원**하지만, Flask 자체는 **WSGI 프레임워크**  
- WSGI 서버에서 `async` 뷰는 요청마다 **이벤트 루프를 돌려 실행**(동시성 이점 제한)  
- 진짜 **비동기 네트워킹 병렬성**(await 기반 다중 I/O)은 **ASGI 서버**(Uvicorn/Hypercorn)와 **ASGI 프레임워크**가 적합

> 결론: Flask의 `async`는 **코드 스타일/호환성** 수준. **대규모 동시 I/O**에는 Quart/FastAPI 같은 **ASGI**가 낫다.

### 9.7.2 Quart 비교

| 항목 | Flask | Quart |
|---|---|---|
| 서버 인터페이스 | WSGI | **ASGI** |
| `async def` | 지원(제한) | **네이티브** |
| WebSocket | 확장(Flask-SocketIO 등) | **내장** |
| 미들웨어 | WSGI 미들웨어 | ASGI 미들웨어(Starlette 호환 일부) |
| 생태계 | 매우 넓음 | Flask와 유사 API, 규모는 작음 |

**마이그레이션 난이도**: Flask와 API가 유사하여 비교적 쉬운 편.  
**선택 기준**:  
- **이미 WSGI 중심 스택 + Celery + SocketIO**: Flask 유지  
- **고동시성 async I/O + 네이티브 WS**: Quart 고려

### 9.7.3 Flask에서 asyncio 안전하게 사용하기

- 백그라운드에서 **threadpool** 로 블로킹 I/O 넘기기:
  ```python
  import asyncio
  from concurrent.futures import ThreadPoolExecutor

  executor = ThreadPoolExecutor(max_workers=8)

  async def fetch_blocking():
      loop = asyncio.get_running_loop()
      return await loop.run_in_executor(executor, _blocking_call)
  ```
- Flask-SocketIO의 **async_mode="asgi"** + **ASGI 서버**로 운영할 수 있으나, 스택 복잡도↑  
- **권장**: I/O 병목은 **작업 큐(Celery/RQ)** 로 넘기고, 웹은 **빠른 핸드오프**에 집중

---

## 9.8 실전 보안/운영 체크리스트

- [ ] **작업 멱등성**: 중복 실행 대비(외부 API 호출 키/DB unique)  
- [ ] **리트라이 백오프**: 네트워크 장애/레이트 리밋 대응  
- [ ] **타임리밋/킬**: 루프 방지 및 리소스 회수  
- [ ] **리소스 격리**: CPU 바운드/ML은 별 큐/노드(우선순위/자원한도)  
- [ ] **진행률/취소**: UX 필수, `update_state`/`job.meta`, revoke/cancel 존중  
- [ ] **모니터링**: Flower/RQ-Dashboard, 실패율/대기시간/재시도 추적  
- [ ] **메시지 안정성**: Redis persistence/RabbitMQ durable queue, visibility timeout  
- [ ] **실시간 계층**: message_queue(Redis) 필수, Origin 제한, 토큰 인증  
- [ ] **WS 프록시**: 업그레이드 헤더, 아이들 타임아웃  
- [ ] **로그 상관 ID**: 작업과 요청을 **request_id/job_id** 로 연결  
- [ ] **테스트**: 큐를 **동기 모드**로 돌려 단위 테스트, 통합은 실제 브로커로

---

## 9.9 빠른 스타터(붙여넣기 용)

### 9.9.1 Celery + Flask

```python
# run_worker.sh
celery -A app.tasks.celery_app.celery worker -l info -Q default,reports -c 4
```

```python
# API: 제출/조회
@jobs_bp.post("/resize")
def submit_resize():
    task = image_resize.apply_async(args=[request.json["path"]], queue="media")
    return {"task_id": task.id}, 202

@jobs_bp.get("/resize/<tid>")
def get_resize(tid):
    r = AsyncResult(tid, app=celery)
    return {"state": r.state, "meta": r.info}
```

### 9.9.2 RQ 스니펫

```python
job = q.enqueue(process_video, vid, retry=Retry(max=3))
# 상태
from rq.job import Job
Job.fetch(job.id, connection=redis).get_status()
```

### 9.9.3 SocketIO 스니펫

```python
@socketio.on("subscribe_job", namespace="/jobs")
def sub(d):
    join_room(f"job_{d['id']}")
```

태스크에서:

```python
socketio.emit("jobs:progress", {"pct": pct}, to=f"job_{job_id}", namespace="/jobs")
```

---

## 9.10 예제: “엑셀 대량 업로드 → 비동기 처리 → 진행률 푸시 → 다운로드 링크”

### 9.10.1 흐름

1) 사용자가 **엑셀 업로드** → 서버는 **작업 큐에 등록**하고 **task_id** 반환  
2) 워커가 엑셀을 **청크로 처리**, 각 청크 완료 시 **`update_state` + SocketIO emit**  
3) 완료 시 **S3 업로드** 후 **다운로드 URL** 푸시  
4) 브라우저는 실시간 바를 0→100%로 표시

### 9.10.2 코드 요점

```python
# enqueue
@jobs_bp.post("/bulk")
def bulk():
    fid = save_temp_file(request.files["xlsx"])
    room = f"user_{current_user.id}"
    task = process_xlsx.apply_async(args=[fid, room], queue="io")
    return {"task_id": task.id}, 202
```

```python
# task
@shared_task(bind=True)
def process_xlsx(self, file_id: str, room: str):
    chunks = split_to_chunks(file_id, size=500)
    total = len(chunks)
    for i, chunk in enumerate(chunks, 1):
        handle_chunk(chunk)
        pct = int(i / total * 100)
        self.update_state(state="PROGRESS", meta={"pct": pct})
        socketio.emit("jobs:progress", {"pct": pct}, to=room, namespace="/jobs")
    url = upload_to_s3(file_id)
    socketio.emit("jobs:done", {"url": url}, to=room, namespace="/jobs")
    return {"url": url}
```

---

## 9.11 테스트 전략

- **동기 실행(Celery)**:  
  ```python
  celery.conf.update(task_always_eager=True, task_eager_propagates=True)
  ```
  이렇게 두면 테스트에서 `task()` 호출이 **즉시 실행**되어 단위 테스트가 쉬워진다.  
- **SocketIO 테스트 클라이언트**: Flask-SocketIO가 **테스트 클라이언트**를 제공  
- **통합 테스트**: docker-compose(Redis/RabbitMQ)로 실제 큐 환경 구동 후 시나리오 검증

---

## 9.12 마무리

- **작업 큐**로 **지속성/리트라이/스케줄링/워크플로**를 확보하고, **진행률/취소/체크포인트**로 UX를 완성하라.  
- **Flask-SocketIO** 로 실시간 푸시(채팅/알림/진행률)를 더하면 **반응형 사용자 경험**을 제공할 수 있다.  
- **Flask의 async** 는 제한적이며, **대규모 async I/O** 가 필요하면 **Quart(ASGI)** 를 검토하라.  
- 배포에서는 **큐 라우팅/자원 격리/모니터링** 을 갖추고, **멱등성** 과 **보안(Origin/토큰)** 을 잊지 말 것.
