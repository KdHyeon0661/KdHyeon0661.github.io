---
layout: post
title: Django - 마이그레이션/의존성 장애 대응
date: 2025-10-11 16:25:23 +0900
category: Django
---
# 마이그레이션/의존성 장애 대응 체크리스트 (Django 5.x · PostgreSQL · Redis · Celery · S3 · DRF/Channels 기준)

> 이 문서는 **프로덕션 환경에서 마이그레이션**(스키마/데이터)과 **외부 의존성 장애**(DB/Redis/S3/메일/PG/서드파티 API)의 **사전 예방/무중단 배포/장애 대응/롤백**까지 한 번에 다루는 **운영 실전 가이드**입니다.
> 모든 예시는 Django 5.x, PostgreSQL, Redis, Celery를 기본으로 하고, 코드/명령은 ``` 로 감쌉니다. 수학 표기는 없습니다.

---

## 0. 한눈에 보는 골든 룰

- **스키마 변경은 “추가→이중쓰기→전환→제거” 4단계**로 쪼갠다(Backward Compatible, 점진적 제거).
- **마이그레이션은 짧고 안전하게**: 락/테이블 풀스캔 피하기, 배치/오프피크, 인덱스 CONCURRENTLY.
- **데이터 마이그레이션은 앱 코드 외부로 새지 않게**: `RunPython` + 재시도 + idempotent.
- **장애는 가정이 아니라 전제**: 타임아웃, 재시도, 서킷브레이커, 폴백(큐잉/버퍼링/드레인) 기본.
- **배포는 실험**: 카나리/블루-그린/피쳐 플래그/빠른 롤백 경로 확보.
- **가시성**: 마이그레이션/잡/외부호출에 **트레이싱·구조화로그·대시보드** 필수.

---

## 1. 배포 전 공통 체크리스트

### 1.1 변경 영향도 식별
- [ ] 스키마 변경 유형: **추가/수정/삭제/인덱스/제약/파티셔닝/리네임** 분류
- [ ] 데이터량/카디널리티/핫테이블/핫컬럼 파악 (최근 7~30일 쿼리 로그)
- [ ] 다운타임 위험 구간(테이블 락/리라이트)을 식별하고 우회 전략 수립
- [ ] 관련 코드 경로/크론잡/ETL/리포트/어드민/웹훅도 종단까지 추적

### 1.2 배포/롤백 전략 결정
- [ ] **Draft → Additive → Dual-Write → Read-Switch → Cleanup** 플랜
- [ ] **카나리**(1~5%) 또는 **블루-그린** 전환 계획
- [ ] 실패 시 롤백: **DB 스키마는 되돌리기 어려움** → “코드 롤백 + 호환 스키마 유지” 원칙
- [ ] 피쳐 플래그로 **읽기 전환/새 컬럼 참조**를 on/off 가능하게

### 1.3 수행 타이밍/리소스
- [ ] 오프피크 윈도우/락 영향 적은 시간대
- [ ] 세션/커넥션 한도, autovacuum, maintenance_work_mem, work_mem 확인
- [ ] 롱런 마이그레이션은 **배치/분할/스냅라인**으로 나눔

### 1.4 사전 리허설
- [ ] **스테이징**에 데이터 샘플(≥ 생산 5~10%) 복제 후 시간 측정
- [ ] `--plan`, `sqlmigrate`, `EXPLAIN (ANALYZE, BUFFERS)`로 실제 비용 확인
- [ ] 리허설 결과로 배치 크기/동시성/인덱스 전략 조정

---

## 2. Django 마이그레이션 실전 패턴

### 2.1 필드 추가(안전)
1) **새 컬럼 추가** (nullable 또는 default 제공)
2) **앱 코드에서 이중 쓰기**(old + new)
3) **백필**(데이터 마이그레이션)
4) **읽기 전환**(피쳐 플래그)
5) **구 컬럼 제거**(후행 릴리스에서)

```python
# 1. 새 필드 추가 (nullable)
class Migration(migrations.Migration):
    operations = [
        migrations.AddField(
            model_name='order',
            name='total_amount_v2',
            field=models.BigIntegerField(null=True, blank=True),
        ),
    ]
```

```python
# 2. 이중 쓰기 (서비스 계층 혹은 모델 save())
def compute_total(order):
    v = sum(i.qty * i.unit_price for i in order.items.all())
    order.total_amount_v2 = v
    # order.total_amount (old)도 가능하다면 유지, 신규부터 v2 사용
    order.save(update_fields=["total_amount_v2"])
```

```python
# 3. 백필 (배치/재시도/idempotent)
def forwards(apps, schema_editor):
    Order = apps.get_model("shop","Order")
    qs = Order.objects.filter(total_amount_v2__isnull=True).order_by("id")
    BATCH = 1000
    while True:
        ids = list(qs.values_list("id", flat=True)[:BATCH])
        if not ids: break
        for o in Order.objects.filter(id__in=ids).prefetch_related("items"):
            v = sum(i.qty * i.unit_price for i in o.items.all())
            Order.objects.filter(id=o.id).update(total_amount_v2=v)

class Migration(migrations.Migration):
    dependencies = [...]
    operations = [migrations.RunPython(forwards, migrations.RunPython.noop)]
```

> 팁: 백필은 **시간 제한**과 **중단/재개**가 가능해야 한다. 롤백은 `noop`로 정의해 **되돌리지 않음**(되돌림은 후속 코드/플래그로 처리).

### 2.2 인덱스 추가(무중단)
- PostgreSQL: **CONCURRENTLY** 사용 → 테이블 락 최소화
- Django 기본 `AddIndex`는 동시성 옵션 미지원이므로 `RunSQL` 사용

```python
class Migration(migrations.Migration):
    operations = [
        migrations.RunSQL(
            "CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_order_created ON shop_order (created_at DESC);",
            "DROP INDEX IF EXISTS idx_order_created;"
        )
    ]
```

> 주의: `CONCURRENTLY`는 **트랜잭션 밖**에서만 가능 → Django는 자동 트랜잭션을 끔(`atomic=False`).

```python
class Migration(migrations.Migration):
    atomic = False
    operations = [...]
```

### 2.3 컬럼/테이블 리네임
- 리네임은 일부 드라이버/ORM에서 **드롭→생성**으로 보일 수 있으니 주의
- 가능하면 **새 컬럼 추가 + 코드 전환 + 구 컬럼 제거** 패턴으로

### 2.4 제약 추가(Unique/ForeignKey/Not Null)
- Unique: 먼저 **데이터 정합성 정리**(중복 제거), 그 다음 제약 추가
- Not Null: **기본값 채움** → NULL 제거 → 제약 추가
- FK: 참조 방대 시 생성 비용 큼 → 오프피크 + 인덱스 준비

### 2.5 큰 테이블 데이터 마이그레이션(배치)
- 페이징 키는 **PK 증가**를 사용, 범위 스캔으로 청크
- 긴 트랜잭션 금지(메모리/락/리플리케이션 지연)
- 백필은 **여러 배포에 걸쳐 진행 가능**(Feature Flag로 읽기 전환 시점 조절)

```python
def chunked_ids(qs, size=5000):
    start = 0
    while True:
        ids = list(qs.values_list("id", flat=True)[start:start+size])
        if not ids: break
        yield ids
        start += size
```

### 2.6 병합/충돌 해결
- 팀 동시 개발 중 마이그레이션 번호 충돌 → `--empty` + **Merge Migration**
```bash
python manage.py makemigrations --merge
```
- Squash: 변경이 누적되어 실행 시간이 길어지면 **스쿼시**(단, 운영/스테이징 동일 시점 유지)
```bash
python manage.py squashmigrations app 0001 0050
```

### 2.7 멀티 DB/리더-리스/샤딩
- `--database` 옵션으로 대상 지정
```bash
python manage.py migrate --database=replica_a app
```
- 마이그레이션 파일 수준에서 DB 라우터 고려(전사 전략 문서화)

---

## 3. 마이그레이션 실행 전·중·후 체크리스트

### 3.1 사전 점검
- [ ] `python manage.py makemigrations` / `showmigrations` / `--plan` 확인
- [ ] `sqlmigrate` 결과로 DDL/인덱스 생성 방식 검토
- [ ] 트랜잭션/atomic 여부, `CONCURRENTLY` 필요시 `atomic = False`
- [ ] 롱쿼리 타임아웃/락 타임아웃 설정(PG: `lock_timeout`, `statement_timeout`)
- [ ] 백업/스냅샷/Point-in-time Recovery 가능 상태 확인

### 3.2 실행 중
- [ ] **읽기 전환**(플래그)과 **이중쓰기** 코드가 먼저 배포되어 있는지 확인
- [ ] 모니터링: DB 락 대기, replication lag, 에러율, p95 레이턴시
- [ ] 실패 시 중단 기준: 특정 임계치 초과 시 **즉시 중단**(idempotent여야 재개 가능)

### 3.3 실행 후
- [ ] 새 필드/인덱스 **효용 검증**(쿼리 플랜 개선, CPU/IO 감소)
- [ ] 예외/에러 로그 무증상 여부
- [ ] Old Path 사용률(피쳐 플래그) 관찰 후 **구 코드/컬럼 제거 일정 확정**

---

## 4. 다운타임 없는 스키마 전환: 예제 시나리오

**목표**: `orders.total_amount`(int) 를 `orders.total_amount_v2`(bigint)로 전환.

1) v1: `total_amount_v2` **추가**, 앱은 **이중쓰기**
2) v2(백필 배포): `RunPython` 배치 백필, 실패 시 재시도 가능
3) v3: 피쳐 플래그 `READ_FROM_V2` **ON**(읽기 전환)
4) v4: **구 필드 참조 코드 제거**
5) v5: 구 필드 **삭제**(인덱스/제약 정리)

롤백 시나리오:
- v3에서 장애: **플래그 OFF**로 즉시 구 경로 복귀
- 데이터는 이미 v2로 쓰였으나, v1 경로도 유지 → 무손실

---

## 5. Postgres 전용 팁

- 인덱스: `CREATE INDEX CONCURRENTLY`, 드롭도 `CONCURRENTLY`
- 컬럼 타입 변경: 단순 타입 호환 외에는 **새 컬럼 추가** 권장
- 파티셔닝: 오래된 데이터는 파티션 분리로 유지보수/백업 용이
- `lock_timeout`, `statement_timeout` 세팅으로 **최악의 케이스 탈출**
- Autovacuum 모니터링: 대량 업데이트 후 **bloat 증가** → `VACUUM (FULL 아님)` 계획

---

## 6. Celery/비동기 잡와 마이그레이션 상호작용

- 마이그레이션 중 **잡 정지**가 필요한가? (스키마 의존 strong)
  → 배포 전 **작업 큐 Drain** + 새 워커만 가동
- 잡이 새 스키마 전제라면 **피쳐 플래그**로 분기
- 장시간 백필은 Celery Beat + 작은 배치 태스크로 나눔

```python
# 예: 백필 태스크
@shared_task(bind=True, max_retries=5, default_retry_delay=30)
def backfill_total_amount_v2(self, start_id, end_id):
    try:
        ...
    except Exception as e:
        raise self.retry(exc=e)
```

---

## 7. 의존성 장애 대응(일반 원칙)

### 7.1 타임아웃 & 재시도 & 지수 백오프
- **기본 타임아웃** 없으면 장애 때 요청이 쌓인다.
- 재시도는 **idempotent**일 때만, **백오프 + Jitter** 추가.

```python
# requests 예: 외부 API
resp = requests.post(url, json=payload, timeout=(3.05, 5))  # connect/read timeout
```

```python
# 재시도 데코레이터(간단)
import time, random
def retry(f, tries=3, base=0.3, factor=2.0, jitter=0.1):
    def wrap(*a, **kw):
        t, delay = 0, base
        while True:
            try: return f(*a, **kw)
            except Exception:
                t += 1
                if t>=tries: raise
                time.sleep(delay + random.random()*jitter)
                delay *= factor
    return wrap
```

### 7.2 서킷 브레이커(열림/반쯤 열림/닫힘)
- **연속 실패**가 임계치 초과 → 회로 “열림”(바로 실패 반환), 일정 후 “반쯤 열림”으로 프로빙.

```python
# 간단 서킷 구현 뼈대
class Circuit:
    def __init__(self, threshold=5, reset=30):
        self.fail = 0; self.opened_at = None
        self.threshold = threshold; self.reset = reset
    def allow(self):
        if self.opened_at and (time.time() - self.opened_at) < self.reset:
            return False
        return True
    def record(self, ok):
        if ok: self.fail = 0; self.opened_at = None
        else:
            self.fail += 1
            if self.fail >= self.threshold: self.opened_at = time.time()
```

> 실제 서비스에서는 **pybreaker**, **resilience patterns** 라이브러리 사용 권장.

### 7.3 폴백/버퍼링
- DB 쓰기 실패 시 **Outbox**에 기록 후 재전송
- 메일/푸시/웹훅 실패 시 **DLQ**에 저장, 나중에 재시도
- S3 업로드 실패 시 **로컬 임시 보관** + 재전송 잡

---

## 8. 의존성별 체크리스트 & 예제

### 8.1 PostgreSQL 장애
- [ ] 커넥션 풀 한도/대기열 설정 (gunicorn/uvicorn worker × DB connections)
- [ ] 읽기 전용 모드에서의 동작(어드민/쓰기 엔드포인트 차단)
- [ ] **헬스체크**: `/health/db`가 실제 쿼리 수행
- [ ] Failover 시 **DNS/Load Balancer** 전환 — 클라이언트 **connect_timeout** 짧게

```python
# Django DB 옵션 (settings.py)
DATABASES["default"]["CONN_MAX_AGE"] = 60  # keep-alive
DATABASES["default"]["OPTIONS"] = {"connect_timeout": 3}
```

### 8.2 Redis 장애(캐시/채널/세션)
- [ ] 캐시 실패 시 **무시(그레이스풀)** 설정
- [ ] 세션을 Redis에 둘 경우 장애 전파 고려 → **DB 세션 백업 옵션** 준비
- [ ] Channels 레이어 실패 시 WS graceful degrade(폴백: polling)

```python
# 캐시 실패 무시
CACHES["default"]["OPTIONS"]["IGNORE_EXCEPTIONS"] = True
```

### 8.3 S3/스토리지 장애
- [ ] 업로드 경로: **서명 URL** 우선(클라이언트→S3), 서버 Proxy 업로드는 최후
- [ ] 실패 시 **로컬 temp** 저장 + 재전송 태스크
- [ ] 다운로드는 **서명 URL** 재발급으로 리트라이스

```python
# boto3 config timeout/retries
boto3.client("s3", config=Config(connect_timeout=3, read_timeout=5, retries={"max_attempts": 3}))
```

### 8.4 결제/외부 API(PG/Iamport/Stripe 등)
- [ ] **웹훅 멱등성**: `event_id` unique
- [ ] **타임아웃/재시도** + **서킷**
- [ ] API 실패 시 **주문 상태 보류** + 운영자 알림/수동 재처리 툴

### 8.5 이메일(Anymail/SES/SendGrid)
- [ ] 발송 실패 DLQ/재시도
- [ ] 하드바운스 주소 **블록리스트** 자동 반영
- [ ] 템플릿 렌더 실패 분리 로깅(데이터 이슈 빠르게 식별)

---

## 9. 런북(Incident Runbook) — 단계별 액션

### 9.1 “마이그레이션 중 성능 급락/락 폭주”
1) 대시보드 확인: DB 락, 연결 수, 쿼리 대기
2) **즉시 중단**: `migrate` 프로세스 kill (idempotent 전제), 트래픽 핫패스 rate-limit
3) 트러블쿼리 확인: `pg_stat_activity`, `EXPLAIN`
4) 방안:
   - CONCURRENTLY로 변경, 배치 크기 축소
   - 오프피크로 재일정
   - 필요한 경우 **읽기 Only 모드**로 전환 후 실행
5) 사후: 포스트모템 기록(영향범위/복구시간/재발 방지)

### 9.2 “S3 장애로 업로드 대규모 실패”
1) 클라이언트 오류율 폭등 알람 확인
2) **로컬 임시 저장** 활성화 플래그 ON
3) 업로드 API는 **업로드 수신만 승인** → 큐에 적재, 백그라운드 **재전송**
4) 장애 종료 후 드레인 완료 확인, 실패 잔여 로그 조사

### 9.3 “PG/결제 연동 간헐적 타임아웃”
1) 타임아웃/재시도 지표, 서킷 상태 확인
2) 서킷 열린 상태면 **반쯤 열림** 프로브 주기 조정
3) 최대 동시성/스레드 수 조절, 읽기/쓰기 분리 유도
4) SLA 영향 고객 커뮤니케이션 템플릿 발송

---

## 10. 배포 파이프라인 체크리스트(Zero-downtime 지향)

- [ ] **DB 마이그레이션 선적용**(Additive) → 앱 배포(이중쓰기/읽기전환) → **Cleanup 마이그레이션** 후행
- [ ] Gunicorn/Uvicorn **graceful reload** 확인 (prestop hook)
- [ ] Health/Readiness: `/health` + DB/Redis 체크, 200 OK 후 트래픽 라우팅
- [ ] 마이그레이션 전 `migrate --plan` 아티팩트로 남기기
- [ ] 빌드/런타임 분리(Docker 멀티스테이지), DB 계정 최소 권한(DDL 권한 분리 검토)

---

## 11. 모니터링/알림 지표 설계

**DB**
- 마이그레이션 실행 시간/단계별 카운트
- 락 대기/Deadlock/statement timeout
- 테이블/인덱스 bloat, autovacuum 지연

**애플리케이션**
- 마이그레이션 로그 라인(시작/배치 NO./실패/성공 누계)
- 외부 호출타임아웃/재시도/서킷 상태
- 에러율(5xx), p95/p99

**의존성**
- Redis 연결 fail/slowlog
- S3 4xx/5xx, 결제 API 성공률
- 이메일 반송/스팸 비율

---

## 12. 운영 도구/명령 모음

```bash
# 계획 확인
python manage.py showmigrations
python manage.py migrate --plan
python manage.py sqlmigrate app 000X

# 특정 앱/DB만
python manage.py migrate app 000X --database=replica_a

# 초기 마이그레이션 무시(신규 환경 복원 시)
python manage.py migrate app --fake-initial

# 병합 충돌 해결
python manage.py makemigrations --merge

# 스쿼시
python manage.py squashmigrations app 0001 0050
```

```sql
-- PG 현재 락 확인
SELECT * FROM pg_locks l JOIN pg_class t ON l.relation = t.oid;
-- 실행중 쿼리
SELECT pid, state, query, wait_event FROM pg_stat_activity WHERE datname = current_database();
```

---

## 13. 예시: “대규모 텍스트 컬럼 분리” 전체 흐름

**문제**: `post.body`(TEXT)가 너무 커 검색/리스트에 오버헤드 → `post_detail(content)`로 분리.

1) Additive: `PostDetail(post_id PK, content)` 테이블 추가(FK/인덱스)
2) 이중쓰기: 새 글 작성 시 `Post` + `PostDetail` 동시 생성
3) 백필: 기존 `Post.body` → `PostDetail.content` 로 배치 이동
4) 읽기 전환: 상세 API는 `PostDetail`에서 읽기
5) Cleanup: `Post.body` 제거

```python
# migration: create table
migrations.CreateModel(
  name="PostDetail",
  fields=[("post", models.OneToOneField(primary_key=True, serialize=False, to="app.Post", on_delete=models.CASCADE)),
          ("content", models.TextField())],
)
```

백필 코드(배치):

```python
def forwards(apps, schema_editor):
    Post = apps.get_model("app","Post")
    Detail = apps.get_model("app","PostDetail")
    B = 2000
    qs = Post.objects.filter(postdetail__isnull=True).order_by("id")
    while True:
        ids = list(qs.values_list("id", flat=True)[:B])
        if not ids: break
        bulks = []
        for p in Post.objects.filter(id__in=ids):
            bulks.append(Detail(post_id=p.id, content=p.body or ""))
        Detail.objects.bulk_create(bulks, ignore_conflicts=True)
```

---

## 14. 테스트 전략

- **마이그레이션 단위 테스트**: `MigrationExecutor`로 전/후 상태 검증
- **스키마 호환성 테스트**: 구 버전 코드 + 신 스키마, 신 코드 + 구 스키마 CI 매트릭스
- **백필 리허설**: 스테이징에서 실제 시간 측정 + 부분 데이터 무결성 검사
- **의존성 장애 시뮬레이션**: Chaos(네트워크 끊김/고지연), Redis/S3 모킹, 서킷 동작 검증

---

## 15. 보안/컴플라이언스

- 스키마 변경에 **PII 이동/복제**가 있는지 검토(암호화/마스킹)
- 아카이브/삭제 정책(GDPR/CCPA)에 영향 주는지 확인
- 감사 로그: 누가 언제 마이그레이션 실행/중단/재개했는지 기록

---

## 16. 마이그레이션/장애 커뮤니케이션 템플릿

- **사전 공지**: 일시, 영향 범위(성능 저하 가능), 롤백 계획
- **진행 중**: 단계별 진척률/이상 징후 공유(전사 Slack 채널)
- **사후 보고**: 실제 소요/영향/교훈/다음 액션 아이템

---

## 17. 최종 요약 체크리스트

### 스키마/데이터 마이그레이션
- [ ] Additive → Dual-Write → Read Switch → Cleanup 4단계 분리
- [ ] 인덱스 `CONCURRENTLY`, `atomic=False` 고려
- [ ] 백필 배치/재시도/idempotent/중단·재개 가능
- [ ] `--plan`, `sqlmigrate`, EXPLAIN으로 비용 검증
- [ ] 피쳐 플래그/카나리/롤백 경로 준비

### 의존성 장애 대비
- [ ] 타임아웃/재시도/백오프/서킷 브레이커
- [ ] DLQ/Outbox/큐잉으로 폴백
- [ ] 헬스체크/지표/알람/런북
- [ ] Redis 캐시 장애 무시 설정, S3 로컬 버퍼/재전송
- [ ] 결제/웹훅 멱등성(event_id unique)

### 운영/관측
- [ ] 구조화 로그/추적/대시보드
- [ ] 배포 전 리허설 + 오프피크 실행
- [ ] 포스트모템/지식 베이스 업데이트

---

## 18. 부록 — 유틸 코드 스니펫

### 18.1 RunPython 안전 템플릿
```python
def forwards(apps, schema_editor):
    Model = apps.get_model("app","Model")
    qs = Model.objects.order_by("id")
    size = 2000
    while True:
        ids = list(qs.values_list("id", flat=True)[:size])
        if not ids: break
        # do work in small transaction
        with schema_editor.connection.cursor() as cur:
            for obj in Model.objects.filter(id__in=ids):
                # mutate deterministically
                pass

class Migration(migrations.Migration):
    atomic = False  # 긴 작업은 트랜잭션 분리
    operations = [migrations.RunPython(forwards, migrations.RunPython.noop)]
```

### 18.2 요청 서킷 브레이커 미니
```python
import time, random, requests
class MiniCircuit:
    def __init__(self, threshold=5, reset=20):
        self.fail = 0; self.opened = 0; self.threshold = threshold; self.reset = reset
    def allow(self):
        return (time.time() - self.opened) > self.reset
    def call(self, fn, *a, **kw):
        if self.fail >= self.threshold and not self.allow():
            raise RuntimeError("circuit open")
        try:
            r = fn(*a, **kw)
            self.fail = 0; return r
        except Exception:
            self.fail += 1
            if self.fail >= self.threshold: self.opened = time.time()
            raise

circuit = MiniCircuit()
def post_json(url, payload):
    return circuit.call(requests.post, url, json=payload, timeout=(3,5))
```

### 18.3 관리 커맨드: 진행형 백필
```python
# app/management/commands/backfill_v2.py
from django.core.management.base import BaseCommand
from app.models import Order
class Command(BaseCommand):
    help = "Backfill total_amount_v2"
    def add_arguments(self, parser):
        parser.add_argument("--start", type=int, default=0)
        parser.add_argument("--limit", type=int, default=100000)
        parser.add_argument("--batch", type=int, default=1000)
    def handle(self, *args, **opts):
        start, limit, batch = opts["start"], opts["limit"], opts["batch"]
        qs = Order.objects.filter(id__gte=start, id__lt=start+limit, total_amount_v2__isnull=True).order_by("id")
        count=0
        while True:
            ids = list(qs.values_list("id", flat=True)[:batch])
            if not ids: break
            for o in Order.objects.filter(id__in=ids).prefetch_related("items"):
                v = sum(i.qty*i.unit_price for i in o.items.all())
                Order.objects.filter(id=o.id).update(total_amount_v2=v)
                count+=1
            self.stdout.write(f"processed: {count}")
```

---

# 결론

- **마이그레이션**은 기술이 아니라 **절차**입니다. “추가 → 이중쓰기 → 전환 → 제거” 패턴과 **짧고 안전한 변경**이 핵심입니다.
- **의존성 장애**는 상수입니다. **타임아웃·재시도·서킷·폴백·DLQ**를 기본값으로 두고, **가시성/런북**을 준비하세요.
- **배포**는 반복 가능한 실험입니다. **리허설/카나리/빠른 롤백**을 통해 고객 영향 없이 변화를 배송할 수 있습니다.
