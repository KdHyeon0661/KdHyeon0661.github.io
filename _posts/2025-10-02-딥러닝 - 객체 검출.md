---
layout: post
title: 딥러닝 - 객체 검출
date: 2025-10-02 19:25:23 +0900
category: 딥러닝
---
# 객체 검출 개관
**앵커 기반 vs. 앵커 프리 · 라벨 할당(Positive/Negative) · 박스 회귀 파라미터화 · NMS/Soft-NMS/DIoU-NMS · 배포(디플로이) 이슈**

## 0. 문제 정식화(Detection as Set of Boxes)

- 입력 이미지 \(\mathbf{I}\) 에 대해, 모델은 **박스 집합** \(\{(\mathbf{b}_k, c_k, s_k)\}\)를 출력합니다.
  - \(\mathbf{b} = (x_1,y_1,x_2,y_2)\) 또는 \((x,y,w,h)\)
  - \(c\): 클래스(멀티클래스) / \(s\): 신뢰도(score)
- 평가는 보통 **COCO AP**(IoU=.50:.95 평균) 혹은 **VOC AP@0.5**.

**IoU(Intersection over Union)**
$$
\mathrm{IoU}(A,B)=\frac{|A\cap B|}{|A\cup B|}
$$

---

## 1. 큰 지도: 두 계열의 검출기

| 구분 | 앵커 기반(Anchor-based) | 앵커 프리(Anchor-free) |
|---|---|---|
| 대표 | Faster R-CNN, SSD, RetinaNet, YOLOv3/5 | FCOS, CenterNet, YOLOX/YOLOv8(Anchor-free), DETR(쿼리 기반) |
| 아이디어 | **사전 정의된 박스(앵커)**에 대해 “이 앵커가 객체인가? + 보정” | **격자/포인트/쿼리** 위치에서 “여기에 객체가 있는가? + 박스 직접 회귀” |
| 장점 | 오랜 생태계, 성숙한 성능/툴링, 레거시 호환 | 앵커 설계/튜닝 부담↓, 간결한 라벨 할당, 작은/희귀 객체에 유리할 때 많음 |
| 과제 | 앵커 크기/비율/수량 튜닝, 라벨 할당 복잡 | 피쳐-포인트 라벨링 정의, NMS/임계 튜닝, 일부 상황에서 Recall 손실 |

아래에서 각각의 **라벨 할당**, **손실**, **출력/후처리(NMS)** 를 구체화합니다.

---

## 2. 앵커 기반(Anchor-based) 핵심

### 2.1 앵커(Anchor)란?
- 각 피쳐 스케일(예: FPN의 P3~P7)에 대해 **여러 비율/크기**의 사전 박스 집합 \(\{\mathbf{a}_i\}\) 를 둡니다.
- 모델은 각 앵커 \(i\) 에 대해
  1) **분류 로짓** \(\hat{\mathbf{p}}_i\) (K-class 또는 K+1)
  2) **박스 보정(회귀)** \(\hat{\mathbf{t}}_i\) 를 예측합니다.

### 2.2 박스 회귀 파라미터화
- 흔한 파라미터화(앵커 기준 \((x_a,y_a,w_a,h_a)\), GT \((x,y,w,h)\)):
$$
t_x=\frac{x-x_a}{w_a},\quad
t_y=\frac{y-y_a}{h_a},\quad
t_w=\log\frac{w}{w_a},\quad
t_h=\log\frac{h}{h_a}
$$
- 예측 \(\hat t\) 를 디코딩하여 최종 박스 복원.

### 2.3 라벨 할당(Positive/Negative)
- **IoU 임계**로 매칭:
  - **Positive**: IoU \(\ge \tau_{\text{pos}}\) (예: .5)
  - **Negative**: IoU \(\le \tau_{\text{neg}}\) (예: .4)
  - 그 사이 **무시**(ignore)
- **ATSS**(Adaptive Training Sample Selection): 각 GT 주변 앵커 중 **동적 임계**로 양성 선택(클래스/스케일 편향 완화).

### 2.4 손실
- **분류**: RetinaNet류는 **Focal Loss**로 불균형 완화
  $$
  \mathrm{FL}(p_t)=-\alpha(1-p_t)^\gamma\log p_t
  $$
- **회귀**: Smooth L1, 혹은 **IoU/GIoU/DIoU/CIoU** 류(직접 박스 겹침을 최적화).

### 2.5 두-스테이지 vs 원-스테이지
- **Faster R-CNN(2-stage)**: RPN(앵커 기반 제안) → RoIAlign → 박스/클래스 정교화
- **SSD/RetinaNet(1-stage)**: FPN 다중 스케일에서 **직접** 앵커별 cls/reg 예측

---

## 3. 앵커 프리(Anchor-free) 핵심

### 3.1 포인트/격자 기반
- **FCOS**: 각 위치(피셀/특징 포인트)가 객체 중심 근처면 양성.
  - 박스를 **좌/우/상/하 거리 \((l,t,r,b)\)** 로 회귀, **Centerness** 보정.
- **CenterNet/CornerNet**: **중심/코너 heatmap** + 크기 회귀(키포인트 회귀 개념).
- **YOLOX/YOLOv8(AF)**: 앵커 없이 **셀 단위**의 박스/cls 회귀 + **동적 라벨 할당**(SimOTA 등).

### 3.2 쿼리 기반(Transformer; DETR)
- **고정 개수 쿼리**(예: 100개)가 **집합 예측(set prediction)**.
  - **Hungarian 매칭**으로 GT와 1:1 매칭, **NMS 거의 불필요**(중복 억제는 매칭에서 해결).
  - 장점: **라벨 할당 단순화**, 단점: 학습 초기 수렴이 느릴 수 있어 변형들(Deformable DETR 등) 등장.

### 3.3 장단
- **앵커 프리**는 설계/튜닝 복잡도가 낮고 작은 객체 회수에 유리한 사례가 많음.
- 다만 특정 도메인에선 **앵커 사전**이 priors 로 잘 작동할 수 있음(예: 고정 비율/크기 물체).

---

## 4. NMS(Non-Maximum Suppression) & 변형

### 4.1 Greedy NMS
1) 클래스별로 후보를 score 내림차순 정렬
2) 최고 score 박스를 선택하고, **IoU \(\ge \theta\)** 인 나머지를 제거
3) 반복

```python
import torch

def nms(boxes, scores, iou_thresh=0.5, topk=None):
    # boxes: (N,4) [x1,y1,x2,y2], scores: (N,)
    keep = []
    idxs = scores.argsort(descending=True)
    while idxs.numel() > 0:
        i = idxs[0].item()
        keep.append(i)
        if idxs.numel() == 1: break
        cur = boxes[i].unsqueeze(0)
        rest = boxes[idxs[1:]]
        # IoU
        xx1 = torch.maximum(cur[:,0], rest[:,0])
        yy1 = torch.maximum(cur[:,1], rest[:,1])
        xx2 = torch.minimum(cur[:,2], rest[:,2])
        yy2 = torch.minimum(cur[:,3], rest[:,3])
        inter = (xx2-xx1).clamp(min=0) * (yy2-yy1).clamp(min=0)
        area1 = (cur[:,2]-cur[:,0])*(cur[:,3]-cur[:,1])
        area2 = (rest[:,2]-rest[:,0])*(rest[:,3]-rest[:,1])
        iou = inter / (area1 + area2 - inter + 1e-9)
        idxs = idxs[1:][iou <= iou_thresh]
    if topk: keep = keep[:topk]
    return torch.tensor(keep, dtype=torch.long)
```

**클래스별 vs 클래스-불문(class-agnostic)**
- 클래스별 NMS: 같은 클래스끼리만 억제 → 다중 클래스 동시 출현에 유리
- class-agnostic NMS: **속도↑**, 클래스 혼동 시 중복 억제 강함(업무에 따라 선택)

### 4.2 Soft-NMS
- 제거 대신 **점진적으로 score를 낮춤**(선형/가우시안). **밀집 객체**에서 Recall↑.

```python
def soft_nms(boxes, scores, iou_thresh=0.5, sigma=0.5, method='linear', score_thresh=0.001):
    boxes = boxes.clone(); scores = scores.clone()
    N = scores.size(0)
    for i in range(N):
        maxpos = i + scores[i:].argmax()
        # swap
        boxes[i], boxes[maxpos] = boxes[maxpos].clone(), boxes[i].clone()
        scores[i], scores[maxpos] = scores[maxpos].clone(), scores[i].clone()
        # IoU to others
        cur = boxes[i].unsqueeze(0); rest = boxes[i+1:]
        xx1 = torch.maximum(cur[:,0], rest[:,0])
        yy1 = torch.maximum(cur[:,1], rest[:,1])
        xx2 = torch.minimum(cur[:,2], rest[:,2])
        yy2 = torch.minimum(cur[:,3], rest[:,3])
        inter = (xx2-xx1).clamp(min=0) * (yy2-yy1).clamp(min=0)
        area1 = (cur[:,2]-cur[:,0])*(cur[:,3]-cur[:,1])
        area2 = (rest[:,2]-rest[:,0])*(rest[:,3]-rest[:,1])
        iou = inter / (area1 + area2 - inter + 1e-9)
        if method == 'linear':
            decay = torch.ones_like(iou); m = iou > iou_thresh
            decay[m] = 1 - iou[m]
        else:  # gaussian
            decay = torch.exp(- (iou * iou) / sigma)
        scores[i+1:] = scores[i+1:] * decay
    keep = torch.nonzero(scores > score_thresh, as_tuple=False).squeeze(1)
    return keep
```

### 4.3 DIoU-NMS / CIoU-NMS
- IoU 대신 **DIoU/CIoU** 거리 요소를 조건에 포함하여 **가까운 중심 간 중복**을 더 강하게 억제.
- 밀집 배치/긴박스 혼재에서 효과적일 때가 있음.

### 4.4 속도/배포 고려
- 후보 수 \(N\) 이 클수록 NMS 비용↑. 보통 **Top-K pre-filtering**(예: 레벨별 top-1000, 전체 top-300) 후 NMS.
- GPU NMS 커널/플러그인이 중요(TensorRT/ONNX의 NMS op 또는 커스텀).

---

## 5. 라벨 할당과 손실(조금 더 자세히)

### 5.1 앵커 기반의 Positive/Negative 샘플링
- 불균형이 심하므로 **Hard Negative Mining**(SSD) 혹은 **Focal Loss**(RetinaNet).
- ATSS/OTA 류 **동적 할당**은 “가까운 아이들 중 상위 k” 또는 비용 최소화로 양성 셋을 잡아 **안정적 수렴** 유도.

### 5.2 앵커 프리의 양성 정의
- **FCOS**: GT 박스 안의 포인트 중 **중심 근처**만 양성(외곽 노이즈 억제).
  - 회귀 타겟을 **(l,t,r,b)** 거리로 정의, **Centerness**(중심에 가까울수록↑)로 가중.
- **YOLOX/YOLOv8**: 셀 기준 점수 + 동적 비용(분류/회귀/IoU)로 **양성 집합 최적화**(SimOTA 느낌).

### 5.3 회귀 손실 선택
- **GIoU/DIoU/CIoU**: IoU가 0일 때도 유의미한 그라디언트 제공(박스가 멀리 떨어져도 업데이트).
- 학습 초기 안정성과 수렴 속도에 영향 → Focal + (G/DI/CIoU) 조합이 보편.

---

## 6. 박스 좌표 변환(배포에서 매우 자주 틀리는 부분)

### 6.1 형식 변환
- **xywh(center)** ↔ **xyxy(corners)**
  - 전처리/후처리 코드들이 **서로 다른 형식**을 쓰므로, **딱 한 군데**에서 변환하도록 표준화.

```python
import torch

def xywh_to_xyxy(box):  # [...,4] (cx,cy,w,h) → (x1,y1,x2,y2)
    cxy = box[..., :2]; wh = box[..., 2:]
    tl = cxy - wh/2; br = cxy + wh/2
    return torch.cat([tl, br], dim=-1)

def xyxy_to_xywh(box):  # → (cx,cy,w,h)
    tl = box[..., :2]; br = box[..., 2:]
    cxy = (tl + br) / 2; wh = (br - tl)
    return torch.cat([cxy, wh], dim=-1)
```

### 6.2 리스케일(Resize/Letterbox)
- 입력을 **리사이즈**(비율 유지/불유지)하거나 **레터박스**(여백 pad)할 때,
  예측 박스를 **원본 좌표**로 되돌리려면 **스케일/패드**를 정확히 역변환해야 합니다.

```python
def letterbox_inverse(boxes_xyxy, scale, pad_w, pad_h):
    # boxes in network space → original
    boxes = boxes_xyxy.clone()
    boxes[:, [0,2]] -= pad_w
    boxes[:, [1,3]] -= pad_h
    boxes /= scale
    return boxes
```

---

## 7. 앵커 생성/타깃 할당 간단 예제(미니멀)

```python
import torch, itertools

def generate_anchors(feat_h, feat_w, stride, sizes=(32,64,128), ratios=(0.5,1.,2.0)):
    # 한 레벨용 간단 앵커 (중심은 셀 중앙)
    scales = torch.tensor(sizes, dtype=torch.float)
    ratios = torch.tensor(ratios, dtype=torch.float)
    anchors=[]
    for i,j in itertools.product(range(feat_h), range(feat_w)):
        cx = (j + 0.5) * stride
        cy = (i + 0.5) * stride
        for s in scales:
            for r in ratios:
                w = s * torch.sqrt(r); h = s / torch.sqrt(r)
                anchors.append([cx - w/2, cy - h/2, cx + w/2, cy + h/2])
    return torch.tensor(anchors)  # (A,4)

# IoU 계산
def box_iou(a, b):  # a:(N,4), b:(M,4)
    N,M = a.size(0), b.size(0)
    lt = torch.max(a[:,None,:2], b[:,:2])   # (N,M,2)
    rb = torch.min(a[:,None,2:], b[:,2:])
    inter = (rb - lt).clamp(min=0)
    inter = inter[...,0]*inter[...,1]
    area_a = (a[:,2]-a[:,0])*(a[:,3]-a[:,1])
    area_b = (b[:,2]-b[:,0])*(b[:,3]-b[:,1])
    iou = inter / (area_a[:,None] + area_b - inter + 1e-9)
    return iou

# 타깃 할당(아주 단순): 각 GT와 IoU 최대인 앵커를 Positive, 0.5↑ Positive, 0.4↓ Negative
def assign_targets(anchors, gt_boxes, gt_labels, pos_thr=0.5, neg_thr=0.4):
    ious = box_iou(anchors, gt_boxes)      # (A,G)
    max_iou, max_idx = ious.max(dim=1)     # 각 앵커에 가장 가까운 GT
    labels = torch.full((anchors.size(0),), -1, dtype=torch.long)  # -1 ignore
    labels[max_iou < neg_thr] = 0
    pos = max_iou >= pos_thr
    labels[pos] = gt_labels[max_idx[pos]]
    # 회귀 타깃(간단: 앵커 대비 오프셋)
    A = anchors; G = gt_boxes[max_idx]
    # (tx,ty,tw,th) 파라미터화
    wa = (A[:,2]-A[:,0]); ha = (A[:,3]-A[:,1]); xa = (A[:,0]+A[:,2])/2; ya = (A[:,1]+A[:,3])/2
    wg = (G[:,2]-G[:,0]); hg = (G[:,3]-G[:,1]); xg = (G[:,0]+G[:,2])/2; yg = (G[:,1]+G[:,3])/2
    tx = (xg - xa) / wa.clamp_min(1e-6)
    ty = (yg - ya) / ha.clamp_min(1e-6)
    tw = torch.log(wg / wa.clamp_min(1e-6))
    th = torch.log(hg / ha.clamp_min(1e-6))
    reg_targets = torch.stack([tx,ty,tw,th], dim=1)
    return labels, reg_targets, max_idx
```

> 실전은 FPN **다중 레벨**에 대해 앵커/라벨을 합치고, ATSS/OTA 같은 **동적 할당**을 씁니다.

---

## 8. 앵커 프리 스타일(FCOS 풍) 라벨/타깃 스케치

```python
def fcos_assign(feature_stride, gt_boxes, img_h, img_w, center_radius=1.5):
    """
    각 피쳐 포인트 p=(x,y)가 어떤 GT에 속하는지 결정하고 (l,t,r,b) 타깃을 만든다.
    center_radius: 중심 근처만 양성으로 제한하려는 배수(스케일에 비례)
    """
    ys = torch.arange(0, img_h, feature_stride) + 0.5*feature_stride
    xs = torch.arange(0, img_w, feature_stride) + 0.5*feature_stride
    yy, xx = torch.meshgrid(ys, xs, indexing='ij')
    points = torch.stack([xx.reshape(-1), yy.reshape(-1)], dim=1)  # (P,2)

    l = points[:,0][:,None] - gt_boxes[None,:,0]
    t = points[:,1][:,None] - gt_boxes[None,:,1]
    r = gt_boxes[None,:,2] - points[:,0][:,None]
    b = gt_boxes[None,:,3] - points[:,1][:,None]
    reg = torch.stack([l,t,r,b], dim=2)  # (P,G,4)
    in_box = (reg.min(dim=2).values > 0)  # 포인트가 박스 안에 있나?

    # 중심 샘플링: GT 중심에서 radius*stride 범위 안만 양성
    cx = (gt_boxes[:,0]+gt_boxes[:,2])/2; cy=(gt_boxes[:,1]+gt_boxes[:,3])/2
    cx1 = cx - center_radius*feature_stride; cx2 = cx + center_radius*feature_stride
    cy1 = cy - center_radius*feature_stride; cy2 = cy + center_radius*feature_stride
    in_center = (points[:,0][:,None] > cx1) & (points[:,0][:,None] < cx2) & \
                (points[:,1][:,None] > cy1) & (points[:,1][:,None] < cy2)

    mask = in_box & in_center  # (P,G) 후보
    # 후보 중에서 면적이 가장 작은 GT를 선택(작은 물체를 우선)
    areas = (gt_boxes[:,2]-gt_boxes[:,0])*(gt_boxes[:,3]-gt_boxes[:,1])  # (G,)
    areas = areas.unsqueeze(0).repeat(points.size(0),1)
    areas[~mask] = 1e10
    min_area, gt_idx = areas.min(dim=1)  # (P,)
    pos = min_area < 1e9
    # 최종 (l,t,r,b)
    reg_targets = reg[torch.arange(points.size(0)), gt_idx]  # (P,4)
    return pos, gt_idx, reg_targets  # pos=False면 ignore/neg
```

---

## 9. 후처리 파이프라인(스코어 필터 → Top-K → NMS)

```python
def postprocess(cls_logits, box_reg, anchors_or_points, decode_fn, score_thr=0.05, topk=1000, nms_thr=0.5, max_det=300):
    """
    cls_logits: (N,A,K) or (N,P,K)  — 각 앵커/포인트의 클래스 로짓
    box_reg   : (N,A,4)             — 회귀(앵커 기준 또는 ltrb 등)
    anchors_or_points: (A,4) or (P,2/4)
    decode_fn: 회귀 → 최종 xyxy 변환 함수
    """
    N = cls_logits.size(0)
    out_boxes, out_scores, out_labels = [], [], []
    for b in range(N):
        scores = cls_logits[b].sigmoid()   # (A,K)
        score, label = scores.max(dim=1)   # 클래스 점수/라벨
        keep = score > score_thr
        score, label = score[keep], label[keep]
        reg  = box_reg[b][keep]
        anchor = anchors_or_points[keep]
        boxes = decode_fn(anchor, reg)     # xyxy
        # Top-K pre-filter
        if score.numel() > topk:
            v, idx = torch.topk(score, topk)
            boxes, score, label = boxes[idx], v, label[idx]
        # NMS (클래스별)
        final_keep = []
        for c in label.unique():
            m = label==c
            k = nms(boxes[m], score[m], iou_thresh=nms_thr)
            idxs = torch.nonzero(m, as_tuple=False).squeeze(1)[k]
            final_keep.append(idxs)
        final_keep = torch.cat(final_keep, dim=0)
        if final_keep.numel() > max_det:
            v, idx = torch.topk(score[final_keep], max_det)
            final_keep = final_keep[idx]
        out_boxes.append(boxes[final_keep])
        out_scores.append(score[final_keep])
        out_labels.append(label[final_keep])
    return out_boxes, out_scores, out_labels
```

---

## 10. 배포(디플로이) 이슈 핵심 체크

### 10.1 전처리/후처리 정합
- **정규화(mean/std)**, **리사이즈/레터박스**, **좌표계**(xywh/xyxy, 정규/픽셀)
- **stride 정렬**(패딩으로 입력 크기를 stride의 배수로)
- **색상 채널 순서**(RGB/BGR)와 **범위**(0–1/0–255)

### 10.2 NMS 구현 차이
- PyTorch/ONNX/TensorRT **NonMaxSuppression** 동작 차이(클래스별/전체, 입력 정렬, 박스 포맷) →
  **테스트 벡터**로 사전 검증. `topK`/`max_output_boxes_per_class`/`score_threshold` 일치.

### 10.3 동적 크기/성능
- **동적 입력**이면 TRT에서 **프로파일(min/opt/max)** 을 맞추지 않으면 성능/오류.
- **pre-filter Top-K**를 조정하지 않으면 NMS에서 병목.
- **Batch=1 초저지연**이면 별도 엔진/경로 고려.

### 10.4 정밀도/양자화
- FP16/INT8에서 **박스 회귀 수치 민감**.
- PTQ 시 **캘리브레이션**에 다양한 크기/밝기 케이스 포함.
- QAT면 **Q/DQ**를 포함한 ONNX로 엔진 빌드(정확도 보전↑).

### 10.5 멀티스레딩/메모리
- **핀드 메모리**, **고정 버퍼**(최대 후보 수 기반), **CUDA Graphs**(고급)
- **NMS를 GPU**로 올리면 호스트 왕복 감소. (TRT plugin/ORT CUDA EP)

### 10.6 오프라인 수치 회귀 체크
- 새 엔진/정밀도/전처리 변경 시 **AP/AR** 뿐 아니라 **박스/스코어 cos-sim, KL, Top-1 동일률**을 자동 비교(회귀 게이트).

---

## 11. 실전 미니 프로젝트(토치비전 모델로 시작 → 배포 스케치)

### 11.1 학습/추론(토치비전 Faster R-CNN 예시; 사용자 데이터셋은 커스터마이즈)

```python
import torch, torchvision
from torchvision.models.detection import fasterrcnn_resnet50_fpn
from torchvision.transforms import functional as TF

# 1. 모델
model = fasterrcnn_resnet50_fpn(weights="DEFAULT")
model.eval()

# 2. 전처리(Resize+Normalize; torchvision detection은 내부에서 ToTensor+Normalize 처리하는 편)
from PIL import Image
img = Image.open("demo.jpg").convert("RGB")
img_t = TF.to_tensor(img)  # 0~1
with torch.no_grad():
    preds = model([img_t])[0]  # dict: boxes(N,4), labels(N), scores(N)

# 3. 간단 시각화 혹은 파일 저장
print(preds["boxes"][:3], preds["labels"][:3], preds["scores"][:3])
```

> 커스텀 데이터셋은 `__getitem__`에서 **boxes, labels**를 만들어 `Dict[str, Tensor]` 로 반환.
> 학습은 공식 튜토리얼(토치비전 detection finetune) 흐름을 따르되, **증강/불균형/학습률**만 조절.

### 11.2 ONNX 내보내기 & 배포 스케치(원-스테이지 커스텀 헤드 가정)

- **전처리/후처리**를 Python에서 맞춘 뒤, **ONNX**로 내보내 **ONNXRuntime/TensorRT**로 추론.
- NMS는 **런타임 내장**(ONNX NonMaxSuppression) 또는 **애플리케이션 레벨**에서 실행.

---

## 12. 자주 겪는 함정 & 디버깅 루틴

1) **박스가 엉뚱한 위치**
   - 좌표계 혼선(xywh/xyxy), 레터박스 역변환 누락, 정규화/픽셀 단위 혼용
2) **중복 박스 남발**
   - NMS 임계 낮음, class-agnostic ↔ per-class 착오, pre-filter Top-K 없음
3) **작은 물체 Recall 저하**
   - FPN 하위 스케일(anchor sizes/stride) 부족, 라벨 할당(ATSS/center-sampling) 강화
4) **학습 불안정**
   - 양성/음성 불균형, Focal Loss γ/α 튜닝, Warmup 증가, LR 스케줄 보수적으로
5) **배포 수치 차이**
   - 활성/정규화, softmax/sigmoid 위치, NMS 구현 차, 정밀도(half/int8) 차이
6) **엔진 성능 부진**
   - 후보 수 과다 → level-wise top-K, NMS GPU 플러그인, 프로파일 재조정

---

## 13. 퀵 레퍼런스(암기 카드)

- **앵커 회귀 파라미터화**
  $$
  t_x=\frac{x-x_a}{w_a},\ t_y=\frac{y-y_a}{h_a},\ t_w=\log\frac{w}{w_a},\ t_h=\log\frac{h}{h_a}
  $$
- **FCOS 회귀**: \((l,t,r,b)\) + **Centerness**
- **Focal Loss**
  $$
  \mathrm{FL}(p_t)=-\alpha(1-p_t)^\gamma\log p_t
  $$
- **IoU류 손실**: GIoU/DIoU/CIoU
- **NMS**: Greedy / **Soft-NMS**(감쇠) / **DIoU-NMS**(중심 거리 고려)

---

## 14. 마무리

- **앵커 기반**은 “**사전 박스 + 보정**”, **앵커 프리**는 “**지점/쿼리에서 직접 회귀**”라는 **학습 관점의 차이**입니다.
- 두 계열 모두 **라벨 할당·손실·후처리(NMS)** 조합이 성능을 좌우합니다.
- **배포**에서는 전처리/좌표/정밀도/NMS 구현을 **숫자로 검증**(로그잇/박스 일치도, AP 회귀 체크)해야 합니다.
- 본문 스니펫을 바로 붙여 **라벨 할당→후처리→배포 체크리스트**까지 한 번에 구성하면,
  어떤 검출기든 **안전하게 학습·서비스**로 가져갈 수 있습니다.
