---
layout: post
title: íŒŒì´ì¬ ì‹¬í™” - ë¬¸ìì—´ê³¼ í…ìŠ¤íŠ¸ (2)
date: 2025-11-26 18:25:23 +0900
category: íŒŒì´ì¬ ì‹¬í™”
---
# ë¬¸ìì—´ê³¼ í…ìŠ¤íŠ¸ (2)

## ì •ê·œ í‘œí˜„ì‹ì˜ ê³ ê¸‰ í™œìš©

### íƒìš•ì  ë§¤ì¹­ê³¼ ìµœë‹¨ ë§¤ì¹­ ì´í•´í•˜ê¸°

ì •ê·œ í‘œí˜„ì‹ì—ì„œ ìˆ˜ëŸ‰ì(`*`, `+`, `?`, `{n,m}`)ëŠ” ê¸°ë³¸ì ìœ¼ë¡œ **íƒìš•ì (greedy)**ìœ¼ë¡œ ë™ì‘í•©ë‹ˆë‹¤. ì¦‰, ê°€ëŠ¥í•œ í•œ ê°€ì¥ ê¸´ ë¬¸ìì—´ì„ ì°¾ìœ¼ë ¤ í•©ë‹ˆë‹¤. ë°˜ë©´ **ë¹„íƒìš•ì (non-greedy)** ë§¤ì¹­ì€ ê°€ëŠ¥í•œ í•œ ê°€ì¥ ì§§ì€ ë¬¸ìì—´ì„ ì°¾ìŠµë‹ˆë‹¤.

```python
import re

# HTML í˜•ì‹ì˜ í…ìŠ¤íŠ¸ ì˜ˆì‹œ
html_content = """
<div class="header">ë©”ì¸ í—¤ë”</div>
<div class="content">ì£¼ìš” ë‚´ìš© ì˜ì—­</div>
<div class="footer">í‘¸í„° ì •ë³´</div>
"""

print("=== íƒìš•ì  ë§¤ì¹­ vs ìµœë‹¨ ë§¤ì¹­ ===")
print("ì›ë³¸ í…ìŠ¤íŠ¸:")
print(html_content)

# íƒìš•ì  ë§¤ì¹­: ê°€ì¥ ê¸´ ë§¤ì¹­ì„ ì°¾ìŒ
greedy_pattern = r'<div.*>.*</div>'
greedy_match = re.search(greedy_pattern, html_content, re.DOTALL)
print("\n1. íƒìš•ì  ë§¤ì¹­ ê²°ê³¼:")
if greedy_match:
    print(f"ë§¤ì¹­ëœ ë¬¸ìì—´: {greedy_match.group()[:50]}...")
    print(f"ë§¤ì¹­ ê¸¸ì´: {len(greedy_match.group())}ì")

# ë¹„íƒìš•ì  ë§¤ì¹­: ê°€ì¥ ì§§ì€ ë§¤ì¹­ì„ ì°¾ìŒ
non_greedy_pattern = r'<div.*?>.*?</div>'
non_greedy_matches = re.findall(non_greedy_pattern, html_content, re.DOTALL)
print("\n2. ë¹„íƒìš•ì  ë§¤ì¹­ ê²°ê³¼:")
for i, match in enumerate(non_greedy_matches, 1):
    print(f"  {i}. {match[:40]}...")
    print(f"     ê¸¸ì´: {len(match)}ì")

# ì‹¤ì œ í™œìš© ì˜ˆì œ: HTML íƒœê·¸ ë‚´ìš© ì¶”ì¶œ
def extract_div_contents(html_text):
    """ëª¨ë“  div íƒœê·¸ì˜ ë‚´ìš© ì¶”ì¶œ"""
    pattern = r'<div[^>]*>(.*?)</div>'
    contents = re.findall(pattern, html_text, re.DOTALL)
    
    # ë‚´ìš© ì •ì œ (ê³µë°± ì œê±°)
    cleaned_contents = [content.strip() for content in contents]
    return cleaned_contents

print("\n3. div íƒœê·¸ ë‚´ìš© ì¶”ì¶œ:")
contents = extract_div_contents(html_content)
for i, content in enumerate(contents, 1):
    print(f"  div {i}: '{content}'")
```

### ë‹¤ì–‘í•œ ìˆ˜ëŸ‰ìì˜ ë¹„íƒìš•ì  ë²„ì „

```python
# ë‹¤ì–‘í•œ ë¹„íƒìš•ì  ìˆ˜ëŸ‰ì ì˜ˆì œ
text = "aaa bbbb ccccc dddddd eeeeeee"

print("=== ë‹¤ì–‘í•œ ìˆ˜ëŸ‰ì ë¹„êµ ===")

# 1. * (0íšŒ ì´ìƒ) vs *? (0íšŒ ì´ìƒ, ìµœì†Œ)
matches_greedy = re.findall(r'a*', 'aaaa')
matches_non_greedy = re.findall(r'a*?', 'aaaa')
print(f"a* (íƒìš•ì ): {matches_greedy}")
print(f"a*? (ë¹„íƒìš•ì ): {matches_non_greedy}")

# 2. + (1íšŒ ì´ìƒ) vs +? (1íšŒ ì´ìƒ, ìµœì†Œ)
test_text = "<tag>ë‚´ìš©1</tag><tag>ë‚´ìš©2</tag>"
greedy_tags = re.findall(r'<tag>.*</tag>', test_text)
non_greedy_tags = re.findall(r'<tag>.*?</tag>', test_text)
print(f"\n<tag>.*</tag>: {greedy_tags}")
print(f"<tag>.*?</tag>: {non_greedy_tags}")

# 3. ë³µì¡í•œ íŒ¨í„´ì—ì„œì˜ í™œìš©
complex_text = "start{middle1}end start{middle2}{middle3}end"
print(f"\nì›ë³¸ í…ìŠ¤íŠ¸: {complex_text}")

# ì¤‘ê´„í˜¸ ì•ˆì˜ ë‚´ìš© ì¶”ì¶œ
greedy_content = re.findall(r'start\{.*\}end', complex_text)
non_greedy_content = re.findall(r'start\{.*?\}end', complex_text)
print(f"íƒìš•ì  íŒ¨í„´ ê²°ê³¼: {greedy_content}")
print(f"ë¹„íƒìš•ì  íŒ¨í„´ ê²°ê³¼: {non_greedy_content}")
```

## ë‹¤ì¤‘ ë¼ì¸ ëª¨ë“œì™€ DOTALL ëª¨ë“œ

ì •ê·œ í‘œí˜„ì‹ì—ì„œ ì¤„ë°”ê¿ˆ ë¬¸ì(`\n`)ë¥¼ ì²˜ë¦¬í•˜ëŠ” ë‘ ê°€ì§€ ì¤‘ìš”í•œ í”Œë˜ê·¸ê°€ ìˆìŠµë‹ˆë‹¤: `re.MULTILINE`ê³¼ `re.DOTALL`

```python
def demonstrate_multiline_patterns():
    """ë‹¤ì¤‘ ë¼ì¸ í…ìŠ¤íŠ¸ ì²˜ë¦¬ ë°ëª¨"""
    
    # ë©€í‹°ë¼ì¸ í…ìŠ¤íŠ¸ ì˜ˆì‹œ
    log_data = """[INFO] 2024-01-03 10:00:00 - Application started
[ERROR] 2024-01-03 10:05:23 - Database connection failed
    Error details: Connection timeout
    Retrying in 5 seconds...
[WARNING] 2024-01-03 10:05:30 - High memory usage detected
[INFO] 2024-01-03 10:10:00 - Operation completed successfully"""
    
    print("=== ë‹¤ì¤‘ ë¼ì¸ í…ìŠ¤íŠ¸ ì²˜ë¦¬ ===")
    print("ì›ë³¸ ë¡œê·¸:")
    print(log_data)
    
    # 1. ê¸°ë³¸ ëª¨ë“œ (^ì™€ $ëŠ” ë¬¸ìì—´ì˜ ì‹œì‘ê³¼ ëë§Œ ë§¤ì¹­)
    print("\n1. ê¸°ë³¸ ëª¨ë“œ (^ì™€ $ì˜ ë™ì‘):")
    basic_matches = re.findall(r'^\[.*\]', log_data)
    print(f"  '^\\[.*\\]' íŒ¨í„´ ë§¤ì¹­: {basic_matches}")
    print(f"  ê²°ê³¼ ìˆ˜: {len(basic_matches)}ê°œ")
    
    # 2. MULTILINE ëª¨ë“œ (^ì™€ $ê°€ ê° ì¤„ì˜ ì‹œì‘ê³¼ ëì— ë§¤ì¹­)
    print("\n2. MULTILINE ëª¨ë“œ:")
    multiline_matches = re.findall(r'^\[.*\]', log_data, re.MULTILINE)
    print(f"  '^\\[.*\\]' íŒ¨í„´ ë§¤ì¹­: {multiline_matches}")
    print(f"  ê²°ê³¼ ìˆ˜: {len(multiline_matches)}ê°œ")
    
    # 3. DOTALL ëª¨ë“œ (.ì´ ê°œí–‰ë¬¸ìë„ í¬í•¨)
    print("\n3. DOTALL ëª¨ë“œ í™œìš©:")
    # ERROR ë¡œê·¸ ì „ì²´ ì¶”ì¶œ (ì—¬ëŸ¬ ì¤„ì— ê±¸ì¹œ)
    error_pattern = r'\[ERROR\].*?Retrying in \d+ seconds\.\.\.'
    error_match = re.search(error_pattern, log_data, re.DOTALL)
    
    if error_match:
        print("  ERROR ë¡œê·¸ ì „ì²´:")
        print(f"  {error_match.group()}")
    
    # 4. MULTILINEê³¼ DOTALL ì¡°í•©
    print("\n4. MULTILINE + DOTALL ì¡°í•©:")
    combined_pattern = r'^\[(ERROR|WARNING)\].*?(?=^\[|\Z)'
    warnings_and_errors = re.findall(combined_pattern, log_data, 
                                     re.MULTILINE | re.DOTALL)
    
    print("  ëª¨ë“  ê²½ê³ ì™€ ì—ëŸ¬:")
    for i, item in enumerate(warnings_and_errors, 1):
        print(f"  {i}. {item.strip()[:50]}...")
    
    # 5. ì‹¤ì „ ì˜ˆì œ: ë¡œê·¸ ë ˆë²¨ë³„ ë¶„ì„
    print("\n5. ë¡œê·¸ ë ˆë²¨ë³„ í†µê³„:")
    
    def analyze_log_levels(log_text):
        """ë¡œê·¸ ë ˆë²¨ë³„ í†µê³„ ìƒì„±"""
        pattern = r'^\[(\w+)\]'
        levels = re.findall(pattern, log_text, re.MULTILINE)
        
        stats = {}
        for level in levels:
            stats[level] = stats.get(level, 0) + 1
        
        return stats
    
    level_stats = analyze_log_levels(log_data)
    for level, count in level_stats.items():
        print(f"  {level}: {count}ê±´")

demonstrate_multiline_patterns()
```

## ìœ ë‹ˆì½”ë“œì™€ ì •ê·œ í‘œí˜„ì‹

íŒŒì´ì¬ 3ì—ì„œ ë¬¸ìì—´ì€ ê¸°ë³¸ì ìœ¼ë¡œ ìœ ë‹ˆì½”ë“œì´ì§€ë§Œ, ì •ê·œ í‘œí˜„ì‹ì˜ `\w`, `\d`, `\s` ê°™ì€ ë¬¸ì í´ë˜ìŠ¤ëŠ” ê¸°ë³¸ì ìœ¼ë¡œ ASCII ë¬¸ìë§Œ ì¸ì‹í•©ë‹ˆë‹¤.

```python
def unicode_regex_demo():
    """ìœ ë‹ˆì½”ë“œ ì •ê·œ í‘œí˜„ì‹ ë°ëª¨"""
    
    # ë‹¤êµ­ì–´ í…ìŠ¤íŠ¸ ì˜ˆì‹œ
    multilingual_text = """
    ì•ˆë…•í•˜ì„¸ìš”! Hello! ã“ã‚“ã«ã¡ã¯ï¼ Bonjour!
    ìˆ«ì: 123, å››äº”å…­, à¥­à¥®à¥¯
    ì´ëª¨ì§€: ğŸ‘ ğŸ‰ ğŸŒ
    íŠ¹ìˆ˜ë¬¸ì: @#$%^&*
    """
    
    print("=== ìœ ë‹ˆì½”ë“œ ì •ê·œ í‘œí˜„ì‹ ===")
    print("ë‹¤êµ­ì–´ í…ìŠ¤íŠ¸:")
    print(multilingual_text)
    
    # 1. ê¸°ë³¸ ëª¨ë“œ (ASCIIë§Œ ì¸ì‹)
    print("\n1. ê¸°ë³¸ ëª¨ë“œ (ASCII):")
    ascii_words = re.findall(r'\w+', multilingual_text)
    print(f"  ë‹¨ì–´ ì°¾ê¸° (\\w+): {ascii_words}")
    print(f"  ì°¾ì€ ë‹¨ì–´ ìˆ˜: {len(ascii_words)}")
    
    # 2. ìœ ë‹ˆì½”ë“œ ëª¨ë“œ
    print("\n2. ìœ ë‹ˆì½”ë“œ ëª¨ë“œ:")
    unicode_words = re.findall(r'\w+', multilingual_text, re.UNICODE)
    print(f"  ë‹¨ì–´ ì°¾ê¸° (\\w+ with UNICODE): {unicode_words}")
    print(f"  ì°¾ì€ ë‹¨ì–´ ìˆ˜: {len(unicode_words)}")
    
    # 3. ë‹¤ì–‘í•œ ì–¸ì–´ì˜ ë¬¸ì ë§¤ì¹­
    print("\n3. ì–¸ì–´ë³„ ë¬¸ì ë§¤ì¹­:")
    
    # í•œê¸€ë§Œ ì¶”ì¶œ
    korean_pattern = r'[ê°€-í£]+'
    korean_words = re.findall(korean_pattern, multilingual_text)
    print(f"  í•œê¸€ ë‹¨ì–´: {korean_words}")
    
    # íˆë¼ê°€ë‚˜ë§Œ ì¶”ì¶œ
    hiragana_pattern = r'[ã-ã‚”]+'
    hiragana_words = re.findall(hiragana_pattern, multilingual_text)
    print(f"  íˆë¼ê°€ë‚˜: {hiragana_words}")
    
    # í•œì ì¶”ì¶œ
    kanji_pattern = r'[ä¸€-é¾¥]+'
    kanji_words = re.findall(kanji_pattern, multilingual_text)
    print(f"  í•œì: {kanji_words}")
    
    # 4. ìœ ë‹ˆì½”ë“œ ì†ì„± ì‚¬ìš©
    print("\n4. ìœ ë‹ˆì½”ë“œ ì†ì„± ì‚¬ìš©:")
    
    # ëª¨ë“  ë¬¸ì ì°¾ê¸° (ìœ ë‹ˆì½”ë“œ ì¹´í…Œê³ ë¦¬ í¬í•¨)
    def analyze_unicode_chars(text):
        """í…ìŠ¤íŠ¸ì˜ ìœ ë‹ˆì½”ë“œ ë¬¸ì ë¶„ì„"""
        results = {
            'letters': [],
            'numbers': [],
            'punctuation': [],
            'symbols': [],
            'emojis': []
        }
        
        for char in text:
            category = unicodedata.category(char)
            
            if category.startswith('L'):  # Letter
                results['letters'].append(char)
            elif category.startswith('N'):  # Number
                results['numbers'].append(char)
            elif category.startswith('P'):  # Punctuation
                results['punctuation'].append(char)
            elif category.startswith('S'):  # Symbol
                results['symbols'].append(char)
            elif unicodedata.name(char, '').startswith('EMOJI'):
                results['emojis'].append(char)
        
        return results
    
    analysis = analyze_unicode_chars(multilingual_text)
    print(f"  ë¬¸ì ìˆ˜: {len(analysis['letters'])}")
    print(f"  ìˆ«ì ìˆ˜: {len(analysis['numbers'])}")
    print(f"  ì´ëª¨ì§€ ìˆ˜: {len(analysis['emojis'])}")
    print(f"  ì´ëª¨ì§€ ëª©ë¡: {analysis['emojis']}")

unicode_regex_demo()
```

## ìœ ë‹ˆì½”ë“œ ì •ê·œí™” ì‹¬í™”

ìœ ë‹ˆì½”ë“œì—ì„œ ë™ì¼í•œ ë¬¸ìë¼ë„ ë‹¤ë¥¸ ì½”ë“œ í¬ì¸íŠ¸ë¡œ í‘œí˜„ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ë¥¼ í†µì¼í•˜ëŠ” ê³¼ì •ì„ ì •ê·œí™”(normalization)ë¼ê³  í•©ë‹ˆë‹¤.

```python
def unicode_normalization_demo():
    """ìœ ë‹ˆì½”ë“œ ì •ê·œí™” ìƒì„¸ ë°ëª¨"""
    
    print("=== ìœ ë‹ˆì½”ë“œ ì •ê·œí™” ===")
    
    # 1. ë‹¤ì–‘í•œ 'Ã©' í‘œí˜„
    print("\n1. ë‹¤ì–‘í•œ 'Ã©' í‘œí˜„:")
    
    # í‘œí˜„ 1: ë‹¨ì¼ ë¬¸ì (LATIN SMALL LETTER E WITH ACUTE)
    e_single = 'Ã©'  # U+00E9
    print(f"  ë‹¨ì¼ ë¬¸ì 'Ã©':")
    print(f"    ìœ ë‹ˆì½”ë“œ: U+{ord(e_single):04X}")
    print(f"    ê¸¸ì´: {len(e_single)}")
    print(f"    ì´ë¦„: {unicodedata.name(e_single)}")
    
    # í‘œí˜„ 2: ì¡°í•© ë¬¸ì (e + combining acute accent)
    e_combined = 'e\u0301'  # U+0065 + U+0301
    print(f"\n  ì¡°í•© ë¬¸ì 'e\\u0301':")
    print(f"    ìœ ë‹ˆì½”ë“œ: U+{ord(e_combined[0]):04X} + U+{ord(e_combined[1]):04X}")
    print(f"    ê¸¸ì´: {len(e_combined)}")
    print(f"    e ì´ë¦„: {unicodedata.name(e_combined[0])}")
    print(f"    ì•¡ì„¼íŠ¸ ì´ë¦„: {unicodedata.name(e_combined[1])}")
    
    print(f"\n  ë‘ í‘œí˜„ ë¹„êµ:")
    print(f"    ë™ì¼í•œê°€? {e_single == e_combined}")
    print(f"    ì‹œê°ì ìœ¼ë¡œ ë™ì¼í•œê°€? 'Ã©' == 'eÌ'? {'ì˜ˆ' if e_single == e_combined else 'ì•„ë‹ˆì˜¤'}")
    
    # 2. ì •ê·œí™” ë¹„êµ
    print("\n2. ì •ê·œí™” í˜•ì‹ ë¹„êµ:")
    
    # NFC (Normalization Form C): ê²°í•©ëœ í˜•íƒœ
    nfc_single = unicodedata.normalize('NFC', e_single)
    nfc_combined = unicodedata.normalize('NFC', e_combined)
    print(f"  NFC ì •ê·œí™”:")
    print(f"    'Ã©' -> {repr(nfc_single)} (ê¸¸ì´: {len(nfc_single)})")
    print(f"    'e\\u0301' -> {repr(nfc_combined)} (ê¸¸ì´: {len(nfc_combined)})")
    print(f"    ë™ì¼í•œê°€? {nfc_single == nfc_combined}")
    
    # NFD (Normalization Form D): ë¶„í•´ëœ í˜•íƒœ
    nfd_single = unicodedata.normalize('NFD', e_single)
    nfd_combined = unicodedata.normalize('NFD', e_combined)
    print(f"\n  NFD ì •ê·œí™”:")
    print(f"    'Ã©' -> {repr(nfd_single)} (ê¸¸ì´: {len(nfd_single)})")
    print(f"    'e\\u0301' -> {repr(nfd_combined)} (ê¸¸ì´: {len(nfd_combined)})")
    print(f"    ë™ì¼í•œê°€? {nfd_single == nfd_combined}")
    
    # 3. í•œê¸€ ì •ê·œí™” ì˜ˆì œ
    print("\n3. í•œê¸€ ì •ê·œí™” ì˜ˆì œ:")
    
    # í•œê¸€ ìì†Œ ë¶„ë¦¬/ê²°í•©
    hangul_syllable = 'í•œ'  # U+D55C
    hangul_decomposed = unicodedata.normalize('NFD', hangul_syllable)
    
    print(f"  ìŒì ˆ 'í•œ':")
    print(f"    ì›ë³¸: {hangul_syllable} (U+{ord(hangul_syllable):04X})")
    print(f"    NFD: {repr(hangul_decomposed)}")
    print(f"    ê¸¸ì´: {len(hangul_decomposed)}")
    
    # ìì†Œë³„ ë¶„ì„
    for i, char in enumerate(hangul_decomposed):
        print(f"    ìì†Œ {i+1}: {char} (U+{ord(char):04X}, {unicodedata.name(char)})")
    
    # 4. ì‹¤ì „ í™œìš©: í…ìŠ¤íŠ¸ ë¹„êµ
    print("\n4. í…ìŠ¤íŠ¸ ë¹„êµ ì‹¤ì „ ì˜ˆì œ:")
    
    def safe_text_comparison(text1, text2):
        """ì •ê·œí™” í›„ í…ìŠ¤íŠ¸ ë¹„êµ"""
        normalized1 = unicodedata.normalize('NFC', text1)
        normalized2 = unicodedata.normalize('NFC', text2)
        
        return normalized1 == normalized2
    
    test_cases = [
        ("cafÃ©", "cafe\u0301"),  # cafÃ©
        ("naÃ¯ve", "nai\u0308ve"),  # naÃ¯ve with diaeresis
        ("ğŸ‘¨â€ğŸ‘©â€ğŸ‘§â€ğŸ‘¦", "ğŸ‘¨\u200dğŸ‘©\u200dğŸ‘§\u200dğŸ‘¦"),  # ê°€ì¡± ì´ëª¨ì§€
    ]
    
    for text1, text2 in test_cases:
        raw_comparison = text1 == text2
        safe_comparison = safe_text_comparison(text1, text2)
        print(f"  '{text1}' vs '{text2}':")
        print(f"    ì§ì ‘ ë¹„êµ: {'ë™ì¼' if raw_comparison else 'ë‹¤ë¦„'}")
        print(f"    ì •ê·œí™” ë¹„êµ: {'ë™ì¼' if safe_comparison else 'ë‹¤ë¦„'}")

unicode_normalization_demo()
```

## í…ìŠ¤íŠ¸ í´ë¦¬ë‹ ê³ ê¸‰ ê¸°ë²•

```python
def advanced_text_cleaning():
    """ê³ ê¸‰ í…ìŠ¤íŠ¸ í´ë¦¬ë‹ ê¸°ë²•"""
    
    # ë‹¤ì–‘í•œ ë¬¸ì œë¥¼ ê°€ì§„ í…ìŠ¤íŠ¸ ìƒ˜í”Œ
    dirty_text = """
    Hello,   World!  \t\n
    This is a SAMPLE text with   multiple   spaces.  
    
    Special Characters: @#$%^&*()_+
    Mixed ï¼£ï¼¡ï¼³ï¼¥ and  full-width  characters.
    Extra    spaces    and		tabs.
    
    Line breaks\nand\r\nmultiple\rnewlines.
    
    HTML tags: <div>content</div> & <p>paragraph</p>
    URLs: https://example.com/path?query=string
    Emails: user@example.com, admin@test.co.kr
    """
    
    print("=== ê³ ê¸‰ í…ìŠ¤íŠ¸ í´ë¦¬ë‹ ===")
    print("ì›ë³¸ í…ìŠ¤íŠ¸:")
    print(dirty_text)
    
    # 1. ê¸°ë³¸ í´ë¦¬ë‹ íŒŒì´í”„ë¼ì¸
    def basic_clean_pipeline(text):
        """ê¸°ë³¸ì ì¸ í´ë¦¬ë‹ íŒŒì´í”„ë¼ì¸"""
        cleaned = text
        
        # ê³µë°± ì •ê·œí™” (ì—¬ëŸ¬ ê³µë°±ì„ í•˜ë‚˜ë¡œ)
        cleaned = re.sub(r'\s+', ' ', cleaned)
        
        # ì•ë’¤ ê³µë°± ì œê±°
        cleaned = cleaned.strip()
        
        return cleaned
    
    print("\n1. ê¸°ë³¸ í´ë¦¬ë‹ ê²°ê³¼:")
    basic_cleaned = basic_clean_pipeline(dirty_text)
    print(basic_cleaned[:200] + "...")
    
    # 2. ê³ ê¸‰ í´ë¦¬ë‹: íŠ¹ì • íŒ¨í„´ ì œê±°
    def advanced_clean_pipeline(text, remove_patterns=None):
        """ê³ ê¸‰ í´ë¦¬ë‹ íŒŒì´í”„ë¼ì¸"""
        if remove_patterns is None:
            remove_patterns = [
                r'<[^>]+>',  # HTML íƒœê·¸
                r'https?://\S+',  # URLs
                r'\S+@\S+\.\S+',  # ì´ë©”ì¼
                r'[^\w\s.,!?-]',  # íŠ¹ìˆ˜ë¬¸ì (ì¼ë¶€ ì œì™¸)
            ]
        
        cleaned = text
        
        # ê° íŒ¨í„´ ì œê±°
        for pattern in remove_patterns:
            cleaned = re.sub(pattern, '', cleaned)
        
        # ê³µë°± ì •ê·œí™”
        cleaned = re.sub(r'\s+', ' ', cleaned)
        cleaned = cleaned.strip()
        
        return cleaned
    
    print("\n2. ê³ ê¸‰ í´ë¦¬ë‹ (HTML, URL, ì´ë©”ì¼, íŠ¹ìˆ˜ë¬¸ì ì œê±°):")
    advanced_cleaned = advanced_clean_pipeline(dirty_text)
    print(advanced_cleaned)
    
    # 3. translate ë©”ì„œë“œë¥¼ í™œìš©í•œ ê³ ì† ë¬¸ì ì œê±°
    def clean_with_translate(text, chars_to_remove):
        """translate ë©”ì„œë“œë¥¼ ì‚¬ìš©í•œ ê³ ì† í´ë¦¬ë‹"""
        # ë³€í™˜ í…Œì´ë¸” ìƒì„± (ì‚­ì œí•  ë¬¸ì ë§¤í•‘)
        trans_table = str.maketrans('', '', chars_to_remove)
        
        # ë³€í™˜ ì ìš©
        cleaned = text.translate(trans_table)
        
        # ê³µë°± ì •ê·œí™”
        cleaned = re.sub(r'\s+', ' ', cleaned)
        cleaned = cleaned.strip()
        
        return cleaned
    
    print("\n3. translateë¥¼ ì‚¬ìš©í•œ íŠ¹ìˆ˜ë¬¸ì ì œê±°:")
    special_chars = '@#$%^&*()_+<>'
    translated_cleaned = clean_with_translate(dirty_text, special_chars)
    print(translated_cleaned[:200] + "...")
    
    # 4. ìœ ë‹ˆì½”ë“œ ì •ê·œí™” í¬í•¨ í´ë¦¬ë‹
    def unicode_aware_cleaning(text):
        """ìœ ë‹ˆì½”ë“œ ì¸ì‹ í´ë¦¬ë‹"""
        # NFC ì •ê·œí™”
        normalized = unicodedata.normalize('NFC', text)
        
        # ì „ê° ë¬¸ìë¥¼ ë°˜ê°ìœ¼ë¡œ ë³€í™˜
        def full_to_half(char):
            """ì „ê° ë¬¸ìë¥¼ ë°˜ê° ë¬¸ìë¡œ ë³€í™˜"""
            code = ord(char)
            # ì „ê° ì•ŒíŒŒë²³, ìˆ«ì, ê³µë°±ì„ ë°˜ê°ìœ¼ë¡œ
            if 0xFF01 <= code <= 0xFF5E:  # ì „ê° ë¬¸ì ë²”ìœ„
                return chr(code - 0xFEE0)
            elif code == 0x3000:  # ì „ê° ê³µë°±
                return ' '
            return char
        
        # ë¬¸ì ë³€í™˜ ì ìš©
        half_width = ''.join(full_to_half(c) for c in normalized)
        
        # ëŒ€ì†Œë¬¸ì ì •ê·œí™” (ì„ íƒì )
        normalized_case = half_width.lower()  # ë˜ëŠ” .upper()
        
        return normalized_case
    
    print("\n4. ìœ ë‹ˆì½”ë“œ ì¸ì‹ í´ë¦¬ë‹ (ì „ê°â†’ë°˜ê°, NFC ì •ê·œí™”):")
    mixed_case_text = "ï¼­ï½‰ï½˜ï½…ï½„ ï¼£ï¼¡ï¼³ï¼¥ and ï½†ï½•ï½Œï½Œï¼ï½—ï½‰ï½„ï½”ï½ˆ  ï¼¡ï¼¢ï¼£ï¼‘ï¼’ï¼“"
    unicode_cleaned = unicode_aware_cleaning(mixed_case_text)
    print(f"ì›ë³¸: {mixed_case_text}")
    print(f"í´ë¦¬ë‹: {unicode_cleaned}")
    
    # 5. ì‹¤ì „ ì˜ˆì œ: ë°ì´í„° í´ë¦¬ë‹ í´ë˜ìŠ¤
    class TextCleaner:
        """ë‹¤ì–‘í•œ í´ë¦¬ë‹ ì˜µì…˜ì„ ì œê³µí•˜ëŠ” í´ë˜ìŠ¤"""
        
        def __init__(self):
            self.pipelines = {
                'basic': self._basic_pipeline,
                'html': self._html_pipeline,
                'url_email': self._url_email_pipeline,
                'unicode': self._unicode_pipeline,
            }
        
        def clean(self, text, pipeline='basic', **options):
            """ì§€ì •ëœ íŒŒì´í”„ë¼ì¸ìœ¼ë¡œ í…ìŠ¤íŠ¸ í´ë¦¬ë‹"""
            if pipeline not in self.pipelines:
                raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì´í”„ë¼ì¸: {pipeline}")
            
            return self.pipelines[pipeline](text, **options)
        
        def _basic_pipeline(self, text, **kwargs):
            """ê¸°ë³¸ í´ë¦¬ë‹"""
            cleaned = re.sub(r'\s+', ' ', text)
            return cleaned.strip()
        
        def _html_pipeline(self, text, **kwargs):
            """HTML íƒœê·¸ ì œê±°"""
            cleaned = re.sub(r'<[^>]+>', '', text)
            return self._basic_pipeline(cleaned)
        
        def _url_email_pipeline(self, text, **kwargs):
            """URLê³¼ ì´ë©”ì¼ ì œê±°"""
            cleaned = re.sub(r'https?://\S+', '', text)
            cleaned = re.sub(r'\S+@\S+\.\S+', '', cleaned)
            return self._basic_pipeline(cleaned)
        
        def _unicode_pipeline(self, text, **kwargs):
            """ìœ ë‹ˆì½”ë“œ ì •ê·œí™”"""
            normalized = unicodedata.normalize('NFC', text)
            return self._basic_pipeline(normalized)
    
    print("\n5. TextCleaner í´ë˜ìŠ¤ ì‚¬ìš© ì˜ˆì œ:")
    cleaner = TextCleaner()
    
    test_text = "  Hello   <b>World</b>!  Visit https://example.com  "
    
    print(f"ì›ë³¸: '{test_text}'")
    print(f"ê¸°ë³¸ í´ë¦¬ë‹: '{cleaner.clean(test_text, 'basic')}'")
    print(f"HTML ì œê±°: '{cleaner.clean(test_text, 'html')}'")
    print(f"URL ì œê±°: '{cleaner.clean(test_text, 'url_email')}'")

advanced_text_cleaning()
```

## ë¬¸ìì—´ í¬ë§·íŒ…ê³¼ ì •ë ¬ ì‹¬í™”

```python
def advanced_string_formatting():
    """ê³ ê¸‰ ë¬¸ìì—´ í¬ë§·íŒ… ê¸°ë²•"""
    
    print("=== ê³ ê¸‰ ë¬¸ìì—´ í¬ë§·íŒ… ===")
    
    # 1. ë‹¤ì–‘í•œ ì •ë ¬ ì˜µì…˜
    print("\n1. ë¬¸ìì—´ ì •ë ¬:")
    
    sample_text = "Python"
    
    # ê¸°ë³¸ ì •ë ¬ ë©”ì„œë“œ
    print(f"ì›ë³¸: '{sample_text}'")
    print(f"ì¢Œì¸¡ ì •ë ¬ (10ì): '{sample_text.ljust(10, '-')}'")
    print(f"ìš°ì¸¡ ì •ë ¬ (10ì): '{sample_text.rjust(10, '*')}'")
    print(f"ê°€ìš´ë° ì •ë ¬ (10ì): '{sample_text.center(10, '=')}'")
    
    # 2. format() ë©”ì„œë“œ ì‹¬í™”
    print("\n2. format() ë©”ì„œë“œ ì‹¬í™”:")
    
    # ìœ„ì¹˜ ê¸°ë°˜ ì¸ì
    print("ìœ„ì¹˜ ê¸°ë°˜: {}".format("ì²«ë²ˆì§¸"))
    print("ìœ„ì¹˜ ê¸°ë°˜: {} {}".format("ì²«ë²ˆì§¸", "ë‘ë²ˆì§¸"))
    
    # ì´ë¦„ ê¸°ë°˜ ì¸ì
    print("ì´ë¦„ ê¸°ë°˜: {name}ì€ {age}ì‚´".format(name="ì² ìˆ˜", age=30))
    
    # ì¸ë±ìŠ¤ì™€ ì´ë¦„ í˜¼í•©
    print("í˜¼í•©: {0}ì˜ {item}".format("ì² ìˆ˜", item="ì‚¬ê³¼"))
    
    # 3. f-string ê³ ê¸‰ í™œìš©
    print("\n3. f-string ê³ ê¸‰ í™œìš©:")
    
    name = "ê¹€íŒŒì´ì¬"
    score = 95.5678
    count = 1234567
    
    # ë‹¤ì–‘í•œ í¬ë§·íŒ…
    print(f"ì´ë¦„: {name:<15}")  # ì¢Œì¸¡ ì •ë ¬
    print(f"ì´ë¦„: {name:>15}")  # ìš°ì¸¡ ì •ë ¬
    print(f"ì´ë¦„: {name:^15}")  # ê°€ìš´ë° ì •ë ¬
    
    print(f"\nì ìˆ˜: {score:.1f}")      # ì†Œìˆ˜ì  1ìë¦¬
    print(f"ì ìˆ˜: {score:.2f}")      # ì†Œìˆ˜ì  2ìë¦¬
    print(f"ì ìˆ˜: {score:8.2f}")     # ì „ì²´ 8ìë¦¬, ì†Œìˆ˜ì  2ìë¦¬
    
    print(f"\nê°œìˆ˜: {count:,}")       # ì²œë‹¨ìœ„ êµ¬ë¶„
    print(f"ê°œìˆ˜: {count:12,}")     # 12ìë¦¬ + ì²œë‹¨ìœ„ êµ¬ë¶„
    
    # 4. ë‚ ì§œì™€ ì‹œê°„ í¬ë§·íŒ…
    print("\n4. ë‚ ì§œì™€ ì‹œê°„ í¬ë§·íŒ…:")
    
    from datetime import datetime
    now = datetime.now()
    
    print(f"í˜„ì¬ ì‹œê°„: {now:%Y-%m-%d %H:%M:%S}")
    print(f"í˜„ì¬ ì‹œê°„: {now:%Yë…„ %mì›” %dì¼ %A %p %Iì‹œ %Më¶„}")
    print(f"íƒ€ì„ìŠ¤íƒ¬í”„: {now:%s}")
    
    # 5. ì‚¬ìš©ì ì •ì˜ í¬ë§·í„°
    print("\n5. ì‚¬ìš©ì ì •ì˜ í¬ë§·í„°:")
    
    class Product:
        def __init__(self, name, price, stock):
            self.name = name
            self.price = price
            self.stock = stock
        
        def __format__(self, format_spec):
            """ì‚¬ìš©ì ì •ì˜ í¬ë§· ê·œì¹™"""
            if format_spec == 'short':
                return f"{self.name}"
            elif format_spec == 'detail':
                return f"{self.name}: ${self.price:.2f} ({self.stock}ê°œ)"
            elif format_spec.startswith('width='):
                # width=10 ê³¼ ê°™ì€ í˜•ì‹ ì²˜ë¦¬
                width = int(format_spec.split('=')[1])
                return f"{self.name:{width}}"
            else:
                # ê¸°ë³¸ í¬ë§·
                return f"{self.name} - ${self.price}"
    
    product = Product("ë…¸íŠ¸ë¶", 1299.99, 15)
    print(f"ê¸°ë³¸: {product}")
    print(f"ì§§ê²Œ: {product:short}")
    print(f"ìƒì„¸: {product:detail}")
    print(f"ë„ˆë¹„ 10: '{product:width=10}'")
    
    # 6. í‘œ í˜•ì‹ ì¶œë ¥
    print("\n6. í‘œ í˜•ì‹ ë°ì´í„° ì¶œë ¥:")
    
    data = [
        {"name": "Apple MacBook Pro", "price": 2499.99, "stock": 10, "category": "ë…¸íŠ¸ë¶"},
        {"name": "iPhone 15", "price": 1199.99, "stock": 25, "category": "ìŠ¤ë§ˆíŠ¸í°"},
        {"name": "iPad Air", "price": 899.99, "stock": 30, "category": "íƒœë¸”ë¦¿"},
        {"name": "Apple Watch", "price": 499.99, "stock": 50, "category": "ì›Œì¹˜"},
        {"name": "AirPods Pro", "price": 299.99, "stock": 100, "category": "ì´ì–´í°"},
    ]
    
    # í—¤ë” ì¶œë ¥
    header_format = "{:<25} {:>12} {:>8} {:>10}"
    row_format = "{:<25} {:>12,.2f} {:>8} {:>10}"
    
    print(header_format.format("ìƒí’ˆëª…", "ê°€ê²©($)", "ì¬ê³ ", "ì¹´í…Œê³ ë¦¬"))
    print("-" * 65)
    
    for item in data:
        print(row_format.format(
            item["name"][:24],  # 24ìë¡œ ì œí•œ
            item["price"],
            item["stock"],
            item["category"]
        ))
    
    # í†µê³„ ì¶”ê°€
    print("-" * 65)
    total_value = sum(item["price"] * item["stock"] for item in data)
    total_stock = sum(item["stock"] for item in data)
    print(f"{'ì´ê³„':<25} {'':>12} {total_stock:>8} {total_value:>10,.2f}")
    
    # 7. ë™ì  í¬ë§·íŒ…
    print("\n7. ë™ì  í¬ë§·íŒ…:")
    
    def create_formatter(column_specs):
        """ë™ì ìœ¼ë¡œ í¬ë§·í„° ìƒì„±"""
        format_parts = []
        for name, width, align in column_specs:
            if align == 'left':
                format_parts.append(f"{{{name}:<{width}}}")
            elif align == 'right':
                format_parts.append(f"{{{name}:>{width}}}")
            elif align == 'center':
                format_parts.append(f"{{{name}:^{width}}}")
        
        return " ".join(format_parts)
    
    # ë™ì  í¬ë§·í„° ìƒì„±
    columns = [
        ("name", 20, "left"),
        ("price", 10, "right"),
        ("stock", 8, "right"),
    ]
    
    formatter = create_formatter(columns)
    print("ë™ì  ìƒì„±ëœ í¬ë§·í„°:", formatter)
    
    # ì‚¬ìš© ì˜ˆì œ
    sample_items = [
        {"name": "ìƒí’ˆA", "price": 1000, "stock": 50},
        {"name": "ìƒí’ˆB", "price": 2500, "stock": 30},
        {"name": "ìƒí’ˆC", "price": 500, "stock": 100},
    ]
    
    print("\në™ì  í¬ë§·í„°ë¡œ ì¶œë ¥:")
    for item in sample_items:
        print(formatter.format(**item))

advanced_string_formatting()
```

## ê²°ë¡ 

íŒŒì´ì¬ì˜ ë¬¸ìì—´ê³¼ í…ìŠ¤íŠ¸ ì²˜ë¦¬ ê¸°ëŠ¥ì€ ë‹¨ìˆœí•œ ì¡°ì‘ì„ ë„˜ì–´ì„œ ë‹¤ì–‘í•œ ê³ ê¸‰ ê¸°ë²•ì„ ì œê³µí•©ë‹ˆë‹¤. ì •ê·œ í‘œí˜„ì‹ì˜ ë¹„íƒìš•ì  ë§¤ì¹­ì„ í™œìš©í•˜ë©´ HTML íŒŒì‹±ì´ë‚˜ ë³µì¡í•œ íŒ¨í„´ ì¶”ì¶œ ì‹œ ë” ì •í™•í•œ ê²°ê³¼ë¥¼ ì–»ì„ ìˆ˜ ìˆìœ¼ë©°, `re.MULTILINE`ê³¼ `re.DOTALL` í”Œë˜ê·¸ë¥¼ ì¡°í•©í•˜ë©´ ë‹¤ì¤‘ ë¼ì¸ í…ìŠ¤íŠ¸ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ì²˜ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ìœ ë‹ˆì½”ë“œ ì²˜ë¦¬ëŠ” í˜„ëŒ€ì ì¸ í…ìŠ¤íŠ¸ ì²˜ë¦¬ì—ì„œ í•„ìˆ˜ì ì¸ ìš”ì†Œì…ë‹ˆë‹¤. NFC/NFD ì •ê·œí™”ë¥¼ í†µí•´ ë‹¤ì–‘í•œ í‘œí˜„ì˜ ë™ì¼í•œ ë¬¸ìë¥¼ í†µì¼í•˜ê³ , `re.UNICODE` í”Œë˜ê·¸ë¥¼ ì‚¬ìš©í•˜ë©´ ë‹¤êµ­ì–´ í…ìŠ¤íŠ¸ì—ì„œë„ ì •ê·œ í‘œí˜„ì‹ì„ ì˜¬ë°”ë¥´ê²Œ ì ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. íŠ¹íˆ í•œêµ­ì–´, ì¼ë³¸ì–´, ì¤‘êµ­ì–´ì™€ ê°™ì€ ë¹„ë¼í‹´ ë¬¸ìë¥¼ ë‹¤ë£° ë•ŒëŠ” ì´ëŸ¬í•œ ê¸°ëŠ¥ë“¤ì´ ì¤‘ìš”í•©ë‹ˆë‹¤.

í…ìŠ¤íŠ¸ í´ë¦¬ë‹ì€ ë°ì´í„° ì „ì²˜ë¦¬ì˜ í•µì‹¬ ë‹¨ê³„ë¡œ, `re.sub()`ì˜ íŒ¨í„´ ê¸°ë°˜ ì¹˜í™˜, `translate()`ì˜ ê³ ì† ë¬¸ì ì‚­ì œ, ìœ ë‹ˆì½”ë“œ ì •ê·œí™” ë“±ì„ ìƒí™©ì— ë§ê²Œ ì¡°í•©í•´ì•¼ í•©ë‹ˆë‹¤. ë³µì¡í•œ í´ë¦¬ë‹ ë¡œì§ì€ í´ë˜ìŠ¤ë‚˜ íŒŒì´í”„ë¼ì¸ìœ¼ë¡œ êµ¬ì¡°í™”í•˜ë©´ ì¬ì‚¬ìš©ì„±ê³¼ ê°€ë…ì„±ì„ ë†’ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ë¬¸ìì—´ í¬ë§·íŒ…ê³¼ ì •ë ¬ì€ ë°ì´í„° í‘œí˜„ì˜ í•µì‹¬ì…ë‹ˆë‹¤. f-stringì˜ ë“±ì¥ìœ¼ë¡œ íŒŒì´ì¬ 3.6 ì´ìƒì—ì„œëŠ” ë”ìš± ê°„ê²°í•˜ê³  ê°•ë ¥í•œ í¬ë§·íŒ…ì´ ê°€ëŠ¥í•´ì¡Œìœ¼ë©°, ë™ì  í¬ë§·íŒ…ì´ë‚˜ ì‚¬ìš©ì ì •ì˜ `__format__` ë©”ì„œë“œë¥¼ í†µí•´ íŠ¹ì • ìš”êµ¬ì‚¬í•­ì— ë§ì¶˜ ìœ ì—°í•œ ì¶œë ¥ì„ êµ¬í˜„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ì´ëŸ¬í•œ ê³ ê¸‰ ê¸°ë²•ë“¤ì„ ë§ˆìŠ¤í„°í•˜ë©´ ì‹¤ì œ í”„ë¡œì íŠ¸ì—ì„œ ë°œìƒí•˜ëŠ” ë‹¤ì–‘í•œ í…ìŠ¤íŠ¸ ì²˜ë¦¬ ë¬¸ì œë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ í•´ê²°í•  ìˆ˜ ìˆìœ¼ë©°, ë°ì´í„° ë¶„ì„, ì›¹ ìŠ¤í¬ë˜í•‘, ìì—°ì–´ ì²˜ë¦¬, ë¦¬í¬íŠ¸ ìƒì„± ë“± ë‹¤ì–‘í•œ ë¶„ì•¼ì—ì„œ í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê° ìƒí™©ì— ë§ëŠ” ìµœì ì˜ ê¸°ë²•ì„ ì„ íƒí•˜ê³  ì¡°í•©í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤.