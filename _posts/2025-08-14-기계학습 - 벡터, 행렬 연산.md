---
layout: post
title: 기계학습 - 벡터, 행렬 연산
date: 2025-08-14 19:20:23 +0900
category: 기계학습
---
# 선형대수(벡터, 행렬 연산)

머신 러닝에서 **데이터와 모델 파라미터를 수학적으로 표현하고 계산**하는 데 가장 많이 쓰이는 도구가 **선형대수(Linear Algebra)**입니다.  
벡터와 행렬은 모든 머신 러닝 알고리즘의 입력, 출력, 연산 과정에 필수적으로 등장합니다.

이번 글에서는 **벡터(Vector)**와 **행렬(Matrix)**, 그리고 주요 연산을 머신 러닝 관점에서 자세히 다룹니다.

---

## 1. 벡터(Vector)

### (1) 정의
- 여러 개의 숫자를 하나로 묶은 수학적 개체
- 방향과 크기를 가지며, 1차원 배열 형태로 표현
- 머신 러닝에서 하나의 데이터 샘플(feature set)을 나타냄

**예시**:
$$
\mathbf{x} = \begin{bmatrix} x_1 \\ x_2 \\ x_3 \end{bmatrix}
$$
- \(x_1\): 키, \(x_2\): 몸무게, \(x_3\): 나이

---

### (2) 벡터 종류
- **열 벡터(Column Vector)**: \(n \times 1\) 형태
- **행 벡터(Row Vector)**: \(1 \times n\) 형태

---

### (3) 기본 연산
1. **덧셈**:
   $$
   \mathbf{a} + \mathbf{b} =
   \begin{bmatrix} a_1 \\ a_2 \end{bmatrix}
   +
   \begin{bmatrix} b_1 \\ b_2 \end{bmatrix}
   =
   \begin{bmatrix} a_1 + b_1 \\ a_2 + b_2 \end{bmatrix}
   $$
2. **스칼라 곱**:
   $$
   c \cdot \mathbf{a} =
   c \begin{bmatrix} a_1 \\ a_2 \end{bmatrix}
   =
   \begin{bmatrix} c a_1 \\ c a_2 \end{bmatrix}
   $$
3. **내적(Dot Product)**:
   $$
   \mathbf{a} \cdot \mathbf{b} = \sum_{i=1}^n a_i b_i
   $$
   → 두 벡터의 유사도 계산, 코사인 유사도 등에 활용
4. **노름(Norm)**:
   - 벡터의 크기(길이)
   - L2 노름:
     $$
     \|\mathbf{a}\|_2 = \sqrt{\sum_{i=1}^n a_i^2}
     $$

---

## 2. 행렬(Matrix)

### (1) 정의
- 숫자를 **행(row)**과 **열(column)**로 배치한 2차원 배열
- 머신 러닝에서:
  - **행(Row)** → 샘플(데이터 인스턴스)
  - **열(Column)** → 특징(Feature)

**예시**:
$$
X =
\begin{bmatrix}
x_{11} & x_{12} & x_{13} \\
x_{21} & x_{22} & x_{23} \\
x_{31} & x_{32} & x_{33}
\end{bmatrix}
$$

---

### (2) 주요 행렬 연산
1. **덧셈/뺄셈**: 같은 크기에서만 가능, 원소별 연산
2. **스칼라 곱**: 모든 원소에 스칼라를 곱함
3. **전치(Transpose)**:
   $$
   (A^T)_{ij} = A_{ji}
   $$
   → 행과 열을 뒤집음
4. **행렬 곱(Matrix Multiplication)**:
   $$
   (AB)_{ij} = \sum_{k=1}^n a_{ik} b_{kj}
   $$
   - A: \(m \times n\)
   - B: \(n \times p\)
   - 결과: \(m \times p\)

---

### (3) 단위 행렬(Identity Matrix)
- 대각선 원소가 1, 나머지가 0인 정사각 행렬
- 곱셈에서 항등원 역할:
  $$
  AI = IA = A
  $$

---

### (4) 역행렬(Inverse Matrix)
- \(AA^{-1} = I\)를 만족하는 행렬
- 선형 방정식 풀이, 선형 회귀 해석적 해에서 사용
- 역행렬이 존재하려면 행렬이 **정방행렬**이고 **가역(invertible)**해야 함

---

## 3. 머신 러닝에서 벡터·행렬 활용

### (1) 데이터 표현
- 하나의 데이터 샘플:
  $$
  \mathbf{x} \in \mathbb{R}^n
  $$
- 전체 데이터셋:
  $$
  X \in \mathbb{R}^{m \times n}
  $$
  - m: 샘플 개수
  - n: 특징 개수

### (2) 선형 모델
- 선형 회귀(Linear Regression) 예:
  $$
  \mathbf{y} = X \mathbf{w} + \mathbf{b}
  $$
  - \(X\): 입력 데이터 행렬
  - \(\mathbf{w}\): 가중치 벡터
  - \(\mathbf{b}\): 편향(bias)

### (3) 신경망 연산
- 입력 벡터와 가중치 행렬의 곱:
  $$
  \mathbf{z} = W \mathbf{x} + \mathbf{b}
  $$
- 여러 샘플을 동시에 처리하는 **미니배치 연산**에서 행렬 곱은 필수

---

## 4. 파이썬 예제
```python
import numpy as np

# 벡터
a = np.array([1, 2, 3])
b = np.array([4, 5, 6])

dot_product = np.dot(a, b)       # 내적
norm_a = np.linalg.norm(a)       # 노름

# 행렬
A = np.array([[1, 2], [3, 4]])
B = np.array([[5, 6], [7, 8]])

matrix_sum = A + B               # 덧셈
matrix_product = np.dot(A, B)    # 행렬 곱
transpose_A = A.T                # 전치
inverse_A = np.linalg.inv(A)     # 역행렬

print("내적:", dot_product)
print("A의 노름:", norm_a)
print("행렬 곱:\n", matrix_product)
print("A의 역행렬:\n", inverse_A)
```

---

## 📌 정리
- **벡터**: 데이터 샘플, 방향과 크기
- **행렬**: 데이터셋, 선형 변환
- **주요 연산**: 덧셈, 스칼라 곱, 내적, 전치, 행렬 곱, 역행렬
- 머신 러닝에서는 모든 데이터를 벡터/행렬 형태로 표현하며, 연산을 통해 모델 학습과 예측이 이루어짐

선형대수를 이해하면 **모델이 데이터를 어떻게 변환하고 학습하는지**를 수학적으로 명확히 파악할 수 있습니다.