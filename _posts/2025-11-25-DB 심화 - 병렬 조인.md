---
layout: post
title: DB 심화 - 병렬 조인
date: 2025-11-25 14:25:23 +0900
category: DB 심화
---
# 완전 정복

**주제**
1) **Full Partition-Wise Join**: *둘 다 같은 기준으로 파티셔닝된 경우*
2) **Partial Partition-Wise Join**: *둘 중 하나만 파티셔닝된 경우*
3) **Dynamic Partitioning(동적 파티셔닝)**: *실행 시 조인 키 기준으로 런타임 재분배*
4) **Broadcast 방식**: *작은 집합 복제 후 큰 집합과 조인*

> 목표: 실행계획의 **IN-OUT**, **PX SEND/RECEIVE**, **TQ**를 통해 **데이터가 어디서 어떻게 이동하는지**를 끝까지 보여주고,
> **DDL/힌트/트레이스 쿼리**로 각 기법의 **성능/대기 이벤트** 특성을 체감하게 합니다.
> 기준 버전: Oracle 11g 이상(12c+ 일부 용어 포함).

---

## 공통 실습 스키마 & 환경 세팅

```sql
ALTER SESSION SET nls_date_format = 'YYYY-MM-DD';
ALTER SESSION SET statistics_level = ALL;  -- DBMS_XPLAN.DISPLAY_CURSOR 통계 풍부
-- (필요시) 병렬 정책
-- ALTER SYSTEM SET parallel_degree_policy = MANUAL;  -- 또는 AUTO
-- ALTER SYSTEM SET pga_aggregate_target  = 2G;       -- 랩 환경 가정
```

### 샘플 테이블(해시 파티셔닝: cust_id 기준, Full PWJ 데모용)

```sql
DROP TABLE fact_sales PURGE;
CREATE TABLE fact_sales (
  sales_id   NUMBER       NOT NULL,
  cust_id    NUMBER       NOT NULL,
  sales_dt   DATE         NOT NULL,
  region_cd  VARCHAR2(6)  NOT NULL,
  amount     NUMBER(12,2) NOT NULL,
  CONSTRAINT pk_fact_sales PRIMARY KEY (sales_id)
)
PARTITION BY HASH (cust_id)
PARTITIONS 8;

DROP TABLE fact_clicks PURGE;
CREATE TABLE fact_clicks (
  click_id   NUMBER       NOT NULL,
  cust_id    NUMBER       NOT NULL,
  click_dt   DATE         NOT NULL,
  source_cd  VARCHAR2(10) NOT NULL,
  cost       NUMBER(12,2) NOT NULL,
  CONSTRAINT pk_fact_clicks PRIMARY KEY (click_id)
)
PARTITION BY HASH (cust_id)
PARTITIONS 8;  -- fact_sales와 같은 파티션 개수/방식 → Full PWJ 전제 충족
```

### Partial/동적/브로드캐스트 데모용 추가 테이블

```sql
-- (Partial용) 비파티션 테이블
DROP TABLE orders_np PURGE;
CREATE TABLE orders_np (
  order_id   NUMBER       NOT NULL,
  cust_id    NUMBER       NOT NULL,
  order_dt   DATE         NOT NULL,
  amt        NUMBER(12,2) NOT NULL,
  CONSTRAINT pk_orders_np PRIMARY KEY (order_id)
);

-- (Range 파티셔닝 예시: partial/dynamic 비교)
DROP TABLE shipments_range PURGE;
CREATE TABLE shipments_range (
  ship_id   NUMBER NOT NULL,
  cust_id   NUMBER NOT NULL,
  ship_dt   DATE   NOT NULL,
  fee       NUMBER(12,2),
  CONSTRAINT pk_shipments_range PRIMARY KEY (ship_id)
)
PARTITION BY RANGE (ship_dt) (
  PARTITION p2025m01 VALUES LESS THAN (DATE '2025-02-01'),
  PARTITION p2025m02 VALUES LESS THAN (DATE '2025-03-01'),
  PARTITION p2025m03 VALUES LESS THAN (DATE '2025-04-01'),
  PARTITION pmax     VALUES LESS THAN (MAXVALUE)
);

-- (브로드캐스트용) 소형 차원
DROP TABLE dim_customer PURGE;
CREATE TABLE dim_customer (
  cust_id      NUMBER PRIMARY KEY,
  region_group VARCHAR2(10),
  grade        VARCHAR2(10),
  active_yn    CHAR(1)
);
```

### 샘플 데이터 & 통계

```sql
-- 데이터(축약): 실제 테스트는 수백만~수천만 로우로 APPEND + 병렬 적재 권장
INSERT INTO dim_customer VALUES (101,'APAC','GOLD','Y');
INSERT INTO dim_customer VALUES (202,'AMER','SILVER','Y');
INSERT INTO dim_customer VALUES (303,'EMEA','BRONZE','N');

INSERT INTO fact_sales   VALUES (1,101, DATE '2025-02-10','KR',100);
INSERT INTO fact_sales   VALUES (2,202, DATE '2025-02-11','US',170);
INSERT INTO fact_sales   VALUES (3,202, DATE '2025-03-01','US',250);

INSERT INTO fact_clicks  VALUES (1,101, DATE '2025-02-10','AD', 1.2);
INSERT INTO fact_clicks  VALUES (2,202, DATE '2025-02-11','SEO',0.7);
INSERT INTO fact_clicks  VALUES (3,202, DATE '2025-03-01','AD', 1.1);

INSERT INTO orders_np    VALUES (10,101, DATE '2025-02-10', 300);
INSERT INTO orders_np    VALUES (20,202, DATE '2025-02-11', 500);
INSERT INTO orders_np    VALUES (30,202, DATE '2025-03-01', 700);

INSERT INTO shipments_range VALUES (100,101,DATE '2025-02-10', 30);
INSERT INTO shipments_range VALUES (200,202,DATE '2025-02-11', 50);
INSERT INTO shipments_range VALUES (300,202,DATE '2025-03-01', 70);

COMMIT;

BEGIN
  DBMS_STATS.GATHER_TABLE_STATS(USER,'FACT_SALES');
  DBMS_STATS.GATHER_TABLE_STATS(USER,'FACT_CLICKS');
  DBMS_STATS.GATHER_TABLE_STATS(USER,'ORDERS_NP');
  DBMS_STATS.GATHER_TABLE_STATS(USER,'SHIPMENTS_RANGE');
  DBMS_STATS.GATHER_TABLE_STATS(USER,'DIM_CUSTOMER');
END;
/
```

---

# Full Partition-Wise Join (FPWJ) — **둘 다 같은 기준으로 파티셔닝**

## 개념 & 요건

- **정의**: 조인하는 양쪽 테이블이 **같은 파티셔닝 키**, **같은 방식**(예: HASH(cust_id)), **같은 파티션 개수/경계**를 가질 때,
  각 **동일 키 파티션끼리만** 조인하게 하여 **데이터 재분배(P->P) 없이** 또는 **극소화**하여 수행하는 조인.
- **요건**
  1) **조인 키 = 파티션 키**
  2) **파티셔닝 방식/경계/개수 동일**(HASH/HASH, RANGE 같은 경계 등)
  3) 가급적 **로컬 인덱스**(prefixed)로 파티션/서브파티션 단위 액세스
- **장점**
  - **PX SEND**(재분배) 최소 → **네트워크/큐잉 대기↓**
  - **RAC**에서 **GC 대기↓**(인스턴스/파티션 affinity 설계 시)
  - 매우 **예측 가능한 선형 확장성**

## 실습: FPWJ 강제 & 플랜 읽기

```sql
EXPLAIN PLAN FOR
SELECT /*+ leading(s) use_hash(c)
           parallel(s 16) parallel(c 16)
           pq_distribute(s PARTITION PARTITION)
           pq_distribute(c PARTITION PARTITION)
           monitor */
       s.cust_id, SUM(s.amount) amt, SUM(c.cost) ad_cost
FROM   fact_sales  s
JOIN   fact_clicks c
  ON   c.cust_id = s.cust_id
GROUP  BY s.cust_id;

SELECT *
FROM   TABLE(DBMS_XPLAN.DISPLAY(NULL,NULL,'BASIC +PARALLEL +ALIAS +NOTE +PARTITION'));
```

### 기대 플랜 특징 & 해석

- **Granule**: `PX PARTITION HASH`(또는 `PX PARTITION HASH ALL/ITERATOR`)
- **IN-OUT**: 하위 스캔/해시빌드는 보통 **PCWP/PCWC**(같은 PX 집합 결합)
- **재분배**: **없거나 아주 적음**. `PX SEND`가 **HASH/BROADCAST**로 크게 나타나지 않음
- **NOTE**: *partition-wise join* 관련 메시지가 보일 수 있음(버전/옵션에 따라 문구 차이)

### 모니터링: 재분배 스큐 확인

```sql
-- 실행 후
SELECT *
FROM   TABLE(DBMS_XPLAN.DISPLAY_CURSOR(NULL,NULL,'BASIC +PARALLEL +NOTE'));

-- TQ 분배(거의 없거나 균형)
SELECT dfo_number, tq_id, server_type, inst_id, process, num_rows, bytes
FROM   v$pq_tqstat
ORDER  BY dfo_number, tq_id, server_type, inst_id, process;
```

### FPWJ의 대기 이벤트 특성

- `PX Deq Credit: send blkd` **낮음**(재분배 억제)
- `gc cr/current request` **낮음**(RAC에서 파티션-인스턴스 affinity 시)
- 대량이면 **direct path read**는 증가할 수 있으나, 네트워크/큐잉 병목이 적어 **스루풋↑**

> **Tip**: DW/ETL 설계 단계에서 **조인 키 중심 동일 파티셔닝**을 맞추는 것만으로도 병렬 조인의 70%가 해결됩니다.

---

# Partial Partition-Wise Join (PPWJ) — **한쪽만 파티셔닝**

## 개념

- **정의**: 한쪽 테이블만 **조인 키로 파티셔닝**되고, 다른 한쪽은 **비파티션**(혹은 다른 키/방식)인 상태에서,
  **파티셔닝된 쪽은 파티션 단위로 병렬 처리**하고 **비파티션 쪽은 전체를 스캔**(또는 재사용)하며 조인하는 형태.
- **장점**
  - 파티션 키 기반 **프루닝/병렬 분할**로 파티셔닝된 쪽의 스캔 효율↑
  - 풀 P-WJ 보단 못하지만 **데이터 지역성** 효과 일부 확보
- **단점**
  - 비파티션 쪽은 **모든 파티션과 조인**될 수 있어 **I/O 부담**이 남음
  - 네트워크 재분배는 여전히 발생할 수 있음(방식에 따라 상쇄 가능)

## × 비파티션

```sql
EXPLAIN PLAN FOR
SELECT /*+ leading(s) use_hash(o)
           parallel(s 16) parallel(o 16)
           -- 조인키는 cust_id, s는 HASH(cust_id) 파티션. o는 비파티션.
           -- PQ_DISTRIBUTE 생략 시 옵티마이저가 HASH/HASH 분배를 선택할 수 있음
           monitor */
       s.cust_id, SUM(s.amount) amt, SUM(o.amt) orders
FROM   fact_sales s
JOIN   orders_np o
  ON   o.cust_id = s.cust_id
GROUP  BY s.cust_id;

SELECT *
FROM   TABLE(DBMS_XPLAN.DISPLAY(NULL,NULL,'BASIC +PARALLEL +ALIAS +NOTE'));
```

### 해석 포인트

- **스캔**: `PX PARTITION HASH`(s 쪽), o는 `PX BLOCK ITERATOR`(BRG)
- **재분배**: 보통 `PX SEND HASH` 1회(그룹 또는 조인 키 기준)
- **효과**: s는 **파티션 단위**로 효율적이지만, o 전체가 **반복 조인**될 여지 → I/O가 커질 수 있음

### 언제 유리한가?

- **파티셔닝된 쪽이 압도적으로 크고**, **조인/필터가 파티션 프루닝**을 잘 유도할 때
- 비파티션 쪽이 상대적으로 작거나, **브로드캐스트**로 보완 가능한 상황(다음 장)

---

# Dynamic Partitioning(동적 파티셔닝) — **런타임 재분배로 가상 파티션 정렬**

## 개념

- **정의**: 물리적으로 파티셔닝되어 있지 않거나 **파티션 키가 다른** 테이블을, **조인 키 해시**로 **런타임 재분배(PX SEND HASH)** 하여
  **각 PX가 동일 키 범위를 독점 처리**하도록 만드는 기법.
- **의도**: **가상적으로** 파티션 정렬을 만들어 **교차 통신 최소화/균형 분산**을 달성.

> 쉽게 말해, “**둘 다 파티션이 안 맞아도** 실행 시 **같은 키로 나눠** 각 PX가 **자기 몫만** 처리하게 하자” 입니다.

## 실습: 파티션×비파티션을 **동적 재분배**로 정렬

```sql
EXPLAIN PLAN FOR
SELECT /*+ leading(s) use_hash(o)
           parallel(s 16) parallel(o 16)
           pq_distribute(s HASH HASH)      -- s도 해시 재분배
           pq_distribute(o HASH HASH)      -- o도 해시 재분배
           monitor */
       s.cust_id, SUM(s.amount) amt, SUM(o.amt) orders
FROM   fact_sales s
JOIN   orders_np o
  ON   o.cust_id = s.cust_id
GROUP  BY s.cust_id;

SELECT *
FROM   TABLE(DBMS_XPLAN.DISPLAY(NULL,NULL,'BASIC +PARALLEL +NOTE +ALIAS'));
```

### 기대 플랜/효과

- 중간에 **`PX SEND HASH` → `PX RECEIVE`**가 **양쪽 모두** 보임(각각 해시 재분배)
- 이후 단계에서 **같은 해시 구간**이 **같은 PX**에 모여 **지역 조인** → **P->P 교차 비용↓**
- **단점**: 재분배 자체의 **네트워크/버퍼링** 비용은 존재(스큐 시 `PX Deq Credit: send blkd`↑)

### 변형: 한쪽만 동적 재분배하여 PPWJ 보완

```sql
EXPLAIN PLAN FOR
SELECT /*+ leading(s) use_hash(o)
           parallel(s 16) parallel(o 16)
           pq_distribute(o HASH HASH)      -- o만 재분배(비파티션 → 조인키 해시)
           monitor */
       s.cust_id, SUM(s.amount) amt, SUM(o.amt) orders
FROM   fact_sales s
JOIN   orders_np o
  ON   o.cust_id = s.cust_id
GROUP  BY s.cust_id;
```
- **의도**: s의 물리 파티션과 **가까운 해시 구간**으로 o를 맞춰 **교차 통신 최소화**
- **RAC**: 서비스/인스턴스별로 **파티션 affinity**를 주면 **GC 대기↓**

### 대응(필수)

- 조인 키에 **편중**이 있으면 일부 PX로 **몰림** → `PX Deq Credit: send blkd` 급증
- **대응**: **SALT 컬럼**(예: `MOD(ORA_HASH(cust_id), 8)`), **복합 키** 해시, **브로드캐스트**로 전환(작은 쪽일 때)

---

# Broadcast 방식 — **작은 집합 복제 후 큰 집합과 조인**

## 개념 & 특징

- **정의**: 작은 테이블(차원)을 **모든 PX 서버**로 **복제(`PX SEND BROADCAST`)** → 큰 테이블(사실)을 **재분배 없이** 조인
- **장점**
  - **재분배 비용 최소**(큰 테이블은 로컬 처리)
  - **스타 스키마**에서 특히 강력
- **전제**
  - 브로드캐스트 대상이 **충분히 작아야** 한다(일반적으로 수십~수백 MB 이내, 환경에 따라 다름)

## 실습: 소형 차원 브로드캐스트

```sql
EXPLAIN PLAN FOR
SELECT /*+ leading(d) use_hash(s)
           parallel(s 16) parallel(d 16)
           pq_distribute(d BROADCAST NONE)    -- d를 모든 PX에 복제
           monitor */
       s.cust_id, SUM(s.amount) amt
FROM   dim_customer d
JOIN   fact_sales   s
  ON   s.cust_id = d.cust_id
WHERE  d.grade IN ('GOLD','SILVER')
GROUP  BY s.cust_id
ORDER  BY amt DESC;

SELECT *
FROM   TABLE(DBMS_XPLAN.DISPLAY_CURSOR(NULL,NULL,'BASIC +PARALLEL +NOTE +ALIAS'));
```

### 기대 플랜/대기 이벤트

- **`PX SEND BROADCAST`** 표기
- 큰 테이블 쪽은 **재분배 없이** 스캔/해시 → **네트워크/Deq 대기↓**
- 대용량 ORDER BY 동반 시 `direct path write/read temp`는 별개로 관리(PGA/Top-N)

---

# RANGE 파티션 vs HASH 파티션 혼합 사례

## 파티션 × Hash(cust) 파티션

- 사실: `shipments_range (PARTITION BY RANGE ship_dt)`
- 사실: `fact_sales (PARTITION BY HASH cust_id)`
- 조인: `cust_id`가 조인 키 → **파티션 방식/키가 다름** → **Full PWJ 불가**

### 동적 파티셔닝으로 절충

```sql
EXPLAIN PLAN FOR
SELECT /*+ leading(s) use_hash(sh)
           parallel(s 16) parallel(sh 16)
           pq_distribute(s HASH HASH)     -- cust 해시 재분배
           pq_distribute(sh HASH HASH)    -- ship_dt 파티션 테이블도 cust 해시로 재분배
           monitor */
       s.cust_id, SUM(s.amount) amt, SUM(sh.fee) fee
FROM   fact_sales s
JOIN   shipments_range sh
  ON   sh.cust_id = s.cust_id
WHERE  sh.ship_dt BETWEEN DATE '2025-02-01' AND DATE '2025-03-01'
GROUP  BY s.cust_id;

SELECT *
FROM   TABLE(DBMS_XPLAN.DISPLAY_CURSOR(NULL,NULL,'BASIC +PARALLEL +NOTE +PARTITION'));
```
- **RANGE 프루닝**(p2025m02만) + **cust 해시 재분배**로 **지역 조인화**
- FPWJ만큼 이상적이진 않지만, **혼합 파티션 기준**에서도 좋은 절충

---

# IN-OUT, PX SEND/RECEIVE, TQ로 **데이터 흐름 읽는 법**

```sql
-- 실제 실행 후 (가장 최근 커서)
SELECT *
FROM   TABLE(DBMS_XPLAN.DISPLAY_CURSOR(NULL,NULL,'BASIC +PARALLEL +ALIAS +PREDICATE +NOTE'));

-- TQ별 송수신 로우/바이트 및 스큐
SELECT dfo_number, tq_id, server_type, inst_id, process,
       num_rows, bytes
FROM   v$pq_tqstat
ORDER  BY dfo_number, tq_id, server_type, inst_id, process;
```

- **`IN-OUT`**:
  - `S->P`(Serial→Parallel), `P->S`(Parallel→Serial), `P->P`(Parallel↔Parallel 재분배)
  - `PCWP/PCWC`(부모/자식 결합): **TQ 생략**으로 메시징 오버헤드↓
- **`PX SEND` 종류**:
  - **BROADCAST, HASH, RANGE, ROUND-ROBIN, PARTITION**
  - **Full PWJ**는 **PARTITION** 또는 **SEND 최소**
  - **Dynamic**은 **HASH** 중심
- **스큐**: `v$pq_tqstat`에서 **num_rows의 최댓값-최솟값** 차이가 크면 **키 편중**

---

# 대기 이벤트 & 튜닝 포인트(패턴별)

| 패턴 | 주 대기 이벤트 | 원인 | 해법 |
|---|---|---|---|
| **Full PWJ** | (상대적) 적음, I/O 중심 | 재분배 없음 → 네트워크/큐잉↓ | **동일 파티션 설계** 지속, 파티션-인스턴스 affinity |
| **Partial PWJ** | `direct path read`, 일부 `PX Deq...` | 비파티션 쪽 반복 조인, 때때로 재분배 | 비파티션 축소(선행 필터/인덱스), 브로드캐스트/동적 재분배 혼용 |
| **Dynamic** | `PX Deq Credit: send blkd`, `direct path write/read temp` | 재분배/해시빌드, 키 스큐, 워크에어리어 부족 | **SALT/복합키**, PGA 상향, 브로드캐스트 전환(작은 쪽) |
| **Broadcast** | (적음) 작은 쪽 복제 비용 | 브로드캐스트 대상이 생각보다 큼 | 대상 축소/필터, 통계 정확화, 필요시 HASH로 전환 |

---

# 의사결정 매트릭스(실전 요약)

| 상황 | 추천 |
|---|---|
| **양쪽 모두 조인키로 파티셔닝 가능** | **Full PWJ**(최우선) |
| **한쪽만 파티셔닝, 다른쪽 비파티션** | **Partial PWJ** + (필요시) **동적 재분배** |
| **둘 다 파티션 미스매치/없음** | **Dynamic(해시 재분배)** |
| **소형 차원 vs 대형 사실** | **Broadcast** |
| **RAC에서 GC 대기 심함** | **Full/Partial PWJ** + **서비스/파티션 affinity** |
| **스큐 의심** | **SALT/복합키** or **Broadcast** |

---

# 실습 시나리오 모음(바로 실행/비교)

## Full PWJ vs Dynamic 비교

```sql
-- A) Full PWJ (HASH cust_id, partitions 동일)
SELECT /*+ leading(s) use_hash(c)
           parallel(s 16) parallel(c 16)
           pq_distribute(s PARTITION PARTITION)
           pq_distribute(c PARTITION PARTITION) monitor */
       s.cust_id, SUM(s.amount) amt, SUM(c.cost) ad_cost
FROM fact_sales s JOIN fact_clicks c ON c.cust_id = s.cust_id
GROUP BY s.cust_id;

-- B) Dynamic (의도적으로 PARTITION 힌트 제거/해시 재분배 강제)
SELECT /*+ leading(s) use_hash(c)
           parallel(s 16) parallel(c 16)
           pq_distribute(s HASH HASH) pq_distribute(c HASH HASH) monitor */
       s.cust_id, SUM(s.amount), SUM(c.cost)
FROM fact_sales s JOIN fact_clicks c ON c.cust_id = s.cust_id
GROUP BY s.cust_id;
```
> `DBMS_XPLAN.DISPLAY_CURSOR`와 `V$PQ_TQSTAT`로 **PX SEND 유무**, **num_rows 분포**, **NOTE**를 비교하세요.
> FPWJ가 네트워크/큐잉 부하에서 유리함을 쉽게 볼 수 있습니다.

## Partial → 동적 보완 → Broadcast 전환

```sql
-- A) Partial (s 파티션, o 비파티션)
SELECT /*+ leading(s) use_hash(o) parallel(s 16) parallel(o 16) monitor */
       s.cust_id, SUM(s.amount), SUM(o.amt)
FROM fact_sales s JOIN orders_np o ON o.cust_id = s.cust_id
GROUP BY s.cust_id;

-- B) 동적 보완(비파티션 → 해시 재분배)
SELECT /*+ leading(s) use_hash(o)
           parallel(s 16) parallel(o 16)
           pq_distribute(o HASH HASH) monitor */
       s.cust_id, SUM(s.amount), SUM(o.amt)
FROM fact_sales s JOIN orders_np o ON o.cust_id = s.cust_id
GROUP BY s.cust_id;

-- C) (작을 때) Broadcast로 근본적 해결
SELECT /*+ leading(d) use_hash(s)
           parallel(s 16) parallel(d 16)
           pq_distribute(d BROADCAST NONE) monitor */
       s.cust_id, SUM(s.amount)
FROM dim_customer d JOIN fact_sales s ON s.cust_id = d.cust_id
GROUP BY s.cust_id;
```

---

# 체크리스트 & 베스트 프랙티스

- **설계 단계**
  - **Full PWJ가 가능**하도록 **조인 키 동일 파티셔닝**(방식/경계/개수) 맞추기
  - **로컬 인덱스**(prefixed)로 파티션별 액세스 최적화
  - **RAC**: 파티션-서비스 **affinity**(인스턴스 고정)로 **GC 대기↓**
- **실행/튜닝 단계**
  - **PQ_DISTRIBUTE**로 **분배 방식 고정**: `PARTITION`, `HASH`, `BROADCAST`
  - **스큐** 감지: `V$PQ_TQSTAT`로 **num_rows** 편차 체크 → **SALT/복합키**
  - **메모리/Temp**: `WORKAREA_SIZE_POLICY=AUTO` + 적절한 **PGA_AGGREGATE_TARGET**
  - **DOP**: 너무 크면 Temp/큐잉 경합 ↑. 스토리지/네트워크/CPU에 맞춘 **균형 값**
  - **플랜 해석**: `IN-OUT`, `PX SEND/RECEIVE`, `TQ####`, `NOTE` 섹션을 습관적으로 확인

---

## 한 줄 정리

- **Full PWJ**가 **정답에 가장 가깝다**. (조인 키 동일 파티셔닝 설계)
- **Partial**은 **파티션 쪽 이득**을 취하되, **비파티션 쪽 보완**(동적 재분배/브로드캐스트)을 병행하라.
- **Dynamic**은 **현실적인 절충**이지만 **스큐/네트워크 비용**을 주시하라.
- **Broadcast**는 **작을 때 미덕**이다. (작지 않다면 오히려 독)

> 실행계획의 **PX SEND 종류**와 **TQ 스큐**만 정확히 읽어도, 병렬 조인의 8할은 진단과 처방이 끝납니다.
