---
layout: post
title: 선형대수 - SVD의 응용
date: 2025-06-22 22:20:23 +0900
category: 선형대수
---
# SVD의 실제 응용 : 이미지 압축 · 추천 시스템

> **한 줄 요약**
> **이미지 압축**: $$A\approx U_k\Sigma_kV_k^{\mathsf T}$$ 로 저랭크 근사 → 저장·전송량↓, 품질 유지
> **추천 시스템**: 사용자–아이템 평점행렬을 저랭크로 근사하여 **잠재요인(latent factors)** 추출 → 미평가 예측

---

## 준비 개념 — 저랭크 근사의 핵심

- 임의의 $$m\times n$$ 행렬 $$A$$ 에 대해 SVD:
  $$
  \boxed{A=U\Sigma V^{\mathsf T}},\quad
  \Sigma=\operatorname{diag}(\sigma_1\ge\cdots\ge\sigma_r>0),\ r=\operatorname{rank}(A).
  $$
- **랭크-$$k$$ 최적 근사(Eckart–Young–Mirsky)**:
  $$
  \boxed{A_k=U_k\Sigma_kV_k^{\mathsf T}}
  $$
  는 임의의 랭크-$$k$$ 행렬 중 $$\|A-A_k\|_F,\ \|A-A_k\|_2$$ 를 **최소**로 한다.
  오차: $$\|A-A_k\|_F=\sqrt{\sum_{i>k}\sigma_i^2},\quad \|A-A_k\|_2=\sigma_{k+1}$$
- **누적 설명률(에너지)**:
  $$
  \text{ExplainedRatio}(k)=\dfrac{\sum_{i=1}^k\sigma_i^2}{\sum_{j=1}^{\min(m,n)}\sigma_j^2}.
  $$

---

## 🖼️ 이미지 압축(Image Compression) — SVD로 간단하고 강력하게

### 원리

- 흑백 이미지를 $$A\in\mathbb{R}^{m\times n}$$ (픽셀 그레이스케일)로 본다.
- SVD 후 상위 $$k$$ 개만 유지:
  $$
  \boxed{A_k=U_k\Sigma_kV_k^{\mathsf T}},\quad k\ll\min(m,n).
  $$
- 저장량 비교(스칼라 개수):
  - 원본: $$mn$$
  - 근사: $$k(m+n+1)$$ ( \(U_k: mk\), \(\Sigma_k: k\), \(V_k: nk\) )
  - **압축률**:
    $$
    \text{CR}=\frac{mn}{k(m+n+1)}\quad(\text{클수록 좋음})
    $$

> 대부분의 자연영상은 **저랭크 구조**가 강하다 → 큰 특이값에 정보가 집중.

### 품질·성능 지표

- **PSNR** (Peak Signal-to-Noise Ratio):
  $$
  \text{PSNR}=10\log_{10}\frac{(\text{MAX})^2}{\text{MSE}},\quad
  \text{MSE}=\frac{1}{mn}\sum_{ij}(A_{ij}-A_{k,ij})^2.
  $$
- **SSIM**: 구조적 유사도(명암·대비·구조 반영) — skimage 등으로 측정 가능.
- **누적 설명률**로 \(k\) 결정: 예) 0.95 이상 유지.

### 컬러(3채널) 처리

- **채널 분리형**: 각 채널(R,G,B)을 독립 SVD → 결합.
- **색공간 변환**: RGB→YCbCr 변환 후 **Y**(밝기)에 더 많은 \(k\) 배분, **Cb/Cr** 에 작은 \(k\) 배분 (시각 특성 반영).

### PyTorch 실전 코드 (흑백/컬러 지원, 품질 지표 포함)

```python
# PyTorch 기반 SVD 이미지 압축: 흑백/컬러 지원 + 누적설명률로 k 선택 + PSNR

from PIL import Image
import torch
import numpy as np

def to_tensor_gray(img_pil):
    # (H,W) float64 [0,255]
    A = np.array(img_pil.convert("L"), dtype=np.float64)
    return torch.from_numpy(A)

def to_tensor_rgb(img_pil):
    arr = np.array(img_pil.convert("RGB"), dtype=np.float64)  # (H,W,3)
    return torch.from_numpy(arr)  # torch.float64

def svd_compress_channel(A, k=None, keep_ratio=None):
    """
    A: (H,W) torch.float64
    k: 정수, 유지 특이값 개수
    keep_ratio: 누적 설명률(0~1). k가 None이면 이 기준으로 자동 결정.
    """
    U, S, Vh = torch.linalg.svd(A, full_matrices=False)  # thin SVD
    if k is None:
        if keep_ratio is None:
            raise ValueError("k 또는 keep_ratio 중 하나는 지정해야 합니다.")
        energy = (S**2).cumsum(0) / (S**2).sum()
        k = int(torch.searchsorted(energy, torch.tensor(keep_ratio), right=False)) + 1
    Ak = (U[:, :k] * S[:k]) @ Vh[:k, :]
    return Ak, S, k

def psnr(orig, recon, maxval=255.0):
    mse = torch.mean((orig - recon)**2)
    if mse == 0: return float('inf')
    return 10.0 * torch.log10(maxval**2 / mse).item()

# ---- Demo ----
# img = Image.open("image.jpg")  # 사용 이미지 경로
# Grayscale

def compress_gray(img, keep_ratio=0.95):
    A = to_tensor_gray(img)
    Ak, S, k = svd_compress_channel(A, keep_ratio=keep_ratio)
    score = psnr(A, Ak)
    cr = (A.shape[0]*A.shape[1]) / (k*(A.shape[0]+A.shape[1]+1))
    return Ak.clamp(0,255), k, score, cr

# Color (RGB, 채널별 다른 keep_ratio 허용)

def compress_rgb(img, keep_ratio_y=0.98, keep_ratio_cb=0.90, keep_ratio_cr=0.90):
    # 간단히 RGB 채널 독립 SVD (YCbCr 변환은 생략 가능)
    A = to_tensor_rgb(img)  # (H,W,3)
    outs, ks, psnrs = [], [], []
    for c, keep in enumerate([keep_ratio_y, keep_ratio_cb, keep_ratio_cr]):
        Ak, S, k = svd_compress_channel(A[..., c], keep_ratio=keep)
        outs.append(Ak.unsqueeze(-1))
        ks.append(k)
        psnrs.append(psnr(A[..., c], Ak))
    recon = torch.cat(outs, dim=-1).clamp(0,255)
    # 대략적 압축률(채널합산)
    H, W, _ = A.shape
    comp_params = sum(ks) * (H + W + 1)  # 채널별 합(정확히는 채널마다 합산)
    cr = (3*H*W) / comp_params
    return recon, ks, psnrs, cr

# 사용 예:
# gray_recon, k_used, gray_psnr, gray_cr = compress_gray(img, keep_ratio=0.95)
# color_recon, ks, psnrs, color_cr = compress_rgb(img, 0.98, 0.92, 0.92)

```

> **팁**: 실무에서는 \(k\)를 고정하기보다 **누적설명률**로 자동 결정 → 해상도·콘텐츠가 달라도 일정한 품질 달성.

---

## 🎯 추천 시스템(Recommender Systems) — 잠재요인으로 예측하기

### 데이터 모델

- **사용자–아이템 평점행렬** $$R\in\mathbb{R}^{m\times n}$$ (미평가=결측).
- 목표: 미평가 항목의 **예측 평점** $$\hat r_{ij}$$ 또는 **Top-K 추천**.

### SVD 접근의 두 갈래

1) **선형대수적 SVD(정확 SVD)**: 결측을 처리하려면 **보간/중심화**가 필요.
2) **행렬분해(MF, “Funk-SVD”)**: 이름은 SVD지만 실제로는
   $$
   \min_{P,Q,b_u,b_i}\sum_{(i,j)\in\Omega}\big(r_{ij}-(\mu+b_{u_i}+b_{i_j}+P_i^{\mathsf T}Q_j)\big)^2+\lambda(\|P\|^2+\|Q\|^2+\cdots)
   $$
   를 **최적화**로 푸는 방법(ALS/SGD). *정확 SVD와는 다르다*는 점이 중요.

> 교육·프로토타입은 **중심화+SVD** 로 빠르게 가능.
> 대용량·실무는 **정규화된 MF(ALS/SGD)** 가 일반적.

### 사용자 기준 중심화 + Truncated SVD (프로토타입)

- 사용자 평균으로 결측을 0-중심화(편향 제거):
  $$
  R'_{ij}=
  \begin{cases}
  r_{ij}-\bar r_i, & (i,j)\in\Omega\\
  0, & \text{else(임시 대체)}
  \end{cases}
  $$
- $$R'\approx U_k\Sigma_kV_k^{\mathsf T}$$ ⇒
  $$
  \hat R = U_k\Sigma_kV_k^{\mathsf T} + \bar r\,\mathbf{1}^{\mathsf T}\ (\text{또는 사용자별 평균 복원})
  $$

#### PyTorch 구현(간단 중심화 + SVD → 예측)

```python
import torch
import math

def user_centering(R, mask_zero=True):
    """
    R: (m,n) float64, 0=미평가
    반환: R_centered, user_means, mask
    """
    R = torch.as_tensor(R, dtype=torch.float64)
    mask = (R != 0)
    # 사용자 평균(미평가 제외)
    counts = mask.sum(dim=1).clamp(min=1)
    sums = (R * mask).sum(dim=1)
    user_means = sums / counts
    # 중심화
    R_centered = R - user_means.unsqueeze(1)
    if mask_zero:
        R_centered = R_centered * mask  # 미평가 위치를 0으로 유지
    return R_centered, user_means, mask

def svd_recommend(R, k=20, clip=(1.0, 5.0)):
    """
    간단 중심화 + thin SVD + 복원.
    R: (m,n) with zeros as missing.
    """
    R_c, mu, mask = user_centering(R)
    # thin SVD
    U, S, Vh = torch.linalg.svd(R_c, full_matrices=False)
    U, S, Vh = U[:, :k], S[:k], Vh[:k, :]
    R_hat_c = (U * S) @ Vh
    R_hat = R_hat_c + mu.unsqueeze(1)
    if clip is not None:
        lo, hi = clip
        R_hat = torch.clamp(R_hat, lo, hi)
    return R_hat, (U, S, Vh), mu

# Demo

R_demo = torch.tensor([
    [5., 4., 0., 1.],
    [3., 0., 0., 5.],
    [4., 2., 3., 0.],
    [0., 0., 5., 4.]
], dtype=torch.float64)

R_pred, svd_objs, mu = svd_recommend(R_demo, k=2, clip=(1., 5.))
print("예측 평점:\n", torch.round(R_pred*100)/100)
```

> **주의**: 위 방식은 결측을 0으로 두고 SVD를 하므로 **편향 가능**.
> 실무는 반복적 보간(SoftImpute), MF 최적화, 정규화·베이스라인(사용자·아이템 바이어스) 포함을 권장.

### Funk-SVD(행렬분해, SGD) — 소형 예제

- 모델:
  $$
  \hat r_{ij}=\mu+b_{u_i}+b_{i_j}+P_i^{\mathsf T}Q_j,\quad
  \min\sum_{(i,j)\in\Omega}(r_{ij}-\hat r_{ij})^2+\lambda(\|P\|^2+\|Q\|^2+b_u^2+b_i^2).
  $$
- **장점**: 결측 직접 처리, 희소 대규모 데이터에 적합, 정규화로 과적합 제어.

```python
import torch

def funk_svd(R, k=10, lr=0.01, reg=0.02, epochs=200, seed=0, clip=(1.,5.)):
    """
    매우 단순한 SGD 버전(학습률·에폭은 예시). R: zeros=missing.
    """
    torch.manual_seed(seed)
    R = torch.as_tensor(R, dtype=torch.float64)
    m, n = R.shape
    mask = (R != 0)

    mu = R[mask].mean() if mask.any() else torch.tensor(0., dtype=torch.float64)
    bu = torch.zeros(m, dtype=torch.float64)
    bi = torch.zeros(n, dtype=torch.float64)
    P = 0.1*torch.randn(m, k, dtype=torch.float64)
    Q = 0.1*torch.randn(n, k, dtype=torch.float64)

    ui, ij = mask.nonzero(as_tuple=True)

    for epoch in range(epochs):
        # 샘플 순서 섞기
        idx = torch.randperm(ui.numel())
        ui_ep, ij_ep = ui[idx], ij[idx]
        for u, i in zip(ui_ep.tolist(), ij_ep.tolist()):
            r = R[u, i]
            pred = mu + bu[u] + bi[i] + (P[u] @ Q[i])
            e = r - pred
            # 업데이트
            bu[u] += lr * (e - reg * bu[u])
            bi[i] += lr * (e - reg * bi[i])
            Pu = P[u].clone()
            Qi = Q[i].clone()
            P[u] += lr * (e * Qi - reg * Pu)
            Q[i] += lr * (e * Pu - reg * Qi)

    # 예측 행렬
    R_hat = mu + bu.unsqueeze(1) + bi.unsqueeze(0) + P @ Q.T
    if clip is not None:
        lo, hi = clip
        R_hat = torch.clamp(R_hat, lo, hi)
    return R_hat, (mu, bu, bi, P, Q)

# Demo on the same R_demo

R_hat_funk, params = funk_svd(R_demo, k=2, lr=0.05, reg=0.02, epochs=300, seed=42)
print("Funk-SVD 예측:\n", torch.round(R_hat_funk*100)/100)
```

> 실무에서는 **ALS(교대 최소자승)**, **샘플 가중(암묵피드백)**, **정교한 초기화** 등을 함께 쓴다.
> Python 생태계: `implicit`(ALS), `surprise`(SVD++, KNNBaseline), `lightfm`(hybrid) 등.

### 평가 지표

- **회귀형**(평점 예측): RMSE, MAE.
  $$
  \text{RMSE}=\sqrt{\frac{1}{|\Omega_{\text{test}}|}\sum_{(i,j)\in\Omega_{\text{test}}}(r_{ij}-\hat r_{ij})^2}.
  $$
- **랭킹형**(Top-K 추천): Precision@K, Recall@K, NDCG@K, MAP@K.

### 암묵적 피드백(Implicit) — 클릭/뷰/구매 로그

- 관측행렬 $$C$$ (신뢰도)와 선호행렬 $$P$$ 사용(예: $$P=1[C>0]$$, $$C=1+\alpha\cdot\text{count}$$).
- 목적:
  $$
  \min_{P,Q}\sum_{i,j} C_{ij}\,\big(P_{ij}-P_i^{\mathsf T}Q_j\big)^2+\lambda(\|P\|^2+\|Q\|^2),
  $$
  → **ALS** 로 대규모 처리.

### 실무 팁

- **중심화/바이어스(베이스라인)**: \(\mu, b_u, b_i\) 만으로도 RMSE를 크게 줄인다.
- **정규화**: 데이터 희소할수록 중요(과적합 방지).
- **콜드스타트**: 콘텐츠 피처(텍스트/이미지 임베딩)와 결합한 **하이브리드** 추천 필요.
- **스케일링**: Truncated/Randomized SVD, ALS는 수억 엔트리까지 확장 가능.

---

## ✍️ 미니 시나리오와 선택 가이드

### 이미지 압축 시나리오

- 목표: **파일 5× 압축**, PSNR ≥ 32 dB
- 절차:
  1. 누적설명률 0.97 목표로 k 자동 선택.
  2. YCbCr 변환 → Y에 0.98, Cb/Cr에 0.90 적용(가시성 최적).
  3. PSNR/SSIM 측정, 목표 미달이면 k 소폭 증가.

### 추천 시스템 시나리오

- 데이터: 100k 유저 × 30k 아이템, 관측 0.3%
- 절차:
  1. 베이스라인( \(\mu,b_u,b_i\) )로 시작.
  2. MF(Funk-SVD) \(k=64\), L2 정규화, 조기종료.
  3. 암묵 신호 존재 시 **ALS(implicit)** 로 전환.
  4. 주기적 재학습 + 신선도 가중치.

### 무엇을 선택할까?

- **작고 밀집**: 중심화 + Truncated SVD로 빠른 프로토타입.
- **크고 희소**: MF(ALS/SGD) + 정규화 + 베이스라인.
- **설명가능성**: SVD의 직교 축(요인 해석) vs MF의 유연한 편향·제약.

---

## 부록 — NumPy 버전의 간단 예시(참고)

### 이미지(흑백) SVD 압축

```python
import numpy as np
from PIL import Image

img = Image.open("image.jpg").convert("L")
A = np.array(img, dtype=float)
U, S, VT = np.linalg.svd(A, full_matrices=False)

# 누적설명률로 k 결정

energy = np.cumsum(S**2) / np.sum(S**2)
k = np.searchsorted(energy, 0.95) + 1

A_k = (U[:, :k] * S[:k]) @ VT[:k, :]
A_k = np.clip(A_k, 0, 255).astype(np.uint8)
Image.fromarray(A_k).save("compressed.jpg")
```

### 추천(중심화 + SVD)

```python
import numpy as np

R = np.array([
    [5, 4, 0, 1],
    [3, 0, 0, 5],
    [4, 2, 3, 0],
    [0, 0, 5, 4]
], dtype=float)

mask = (R != 0)
user_means = np.divide(R.sum(1), mask.sum(1), where=mask.sum(1)!=0)
R_c = R - user_means[:, None]
R_c[~mask] = 0

U, S, VT = np.linalg.svd(R_c, full_matrices=False)
k = 2
R_hat = (U[:, :k] * S[:k]) @ VT[:k, :] + user_means[:, None]
R_hat = np.clip(R_hat, 1, 5)
print(np.round(R_hat, 2))
```

---

## 핵심 요약표

| 주제 | 핵심식/포인트 | 장점 | 유의점 |
|---|---|---|---|
| 이미지 압축 | $$A_k=U_k\Sigma_kV_k^{\mathsf T}$$ | 단순·효율, 저랭크 구조 활용 | 색공간 처리, \(k\) 선택(설명률/PSNR) |
| 압축률 | $$\text{CR}=\frac{mn}{k(m+n+1)}$$ | 수치로 효과 즉시 산출 | 너무 큰 \(k\)는 이득↓ |
| 추천(프로토) | 중심화 + SVD | 구현 쉬움, 빠른 베이스라인 | 결측 취급 한계(편향) |
| 추천(실무) | MF(Funk-SVD/ALS) | 희소·대규모에 강함, 정규화 용이 | 정확 SVD 아님, 튜닝 필요 |
| 평가지표 | RMSE/MAE, NDCG@K | 품질 모니터링 | 데이터 편향·콜드스타트 |

---

### Checklist (현업용)

- 이미지: **누적설명률 목표** → k 자동, YCbCr 가중 분배, PSNR/SSIM 확인
- 추천: **베이스라인 편향** 포함, 정규화·조기종료, 암묵피드백이면 ALS, **랭킹 지표**로 최적화
- 스케일: Truncated/Randomized SVD 또는 분산 ALS 선택
- 재현성: 시드·전처리(중심화/스케일링) 명확화
