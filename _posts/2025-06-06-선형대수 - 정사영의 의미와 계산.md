---
layout: post
title: 선형대수 - 정사영의 의미와 계산
date: 2025-06-06 19:20:23 +0900
category: 선형대수
---
# 완전 정복 — 정의 → 유도 → QR/SVD → PyTorch 실습

정사영은 **벡터를 직선/평면/부분공간에 수직으로 내린 그림자**다.
이 한 줄이 **최소제곱(Least Squares)**, **직교 분해**, **거리 계산**, **PCA/회귀**까지 관통한다.
아래에서는 직관 → 수식 → 구현(안정성 고려)까지 한 번에 정리한다.

---

## 표기와 전제

- 벡터는 굵게: **v**, **u** (열벡터로 생각).
- 내적과 노름:
  $$
  \mathbf{a}\cdot\mathbf{b}=\mathbf{a}^\top \mathbf{b},\qquad
  \|\mathbf{a}\|=\sqrt{\mathbf{a}^\top\mathbf{a}}
  $$
- 부분공간 \(W=\mathrm{Col}(A)\): 행렬 \(A\)의 **열공간**.

---

## 벡터 위 정사영 (1차원 서브스페이스)

### 정의(방향 **u**로의 정사영)

$$
\boxed{\;\mathrm{proj}_{\mathbf{u}}\mathbf{v}
= \frac{\mathbf{v}\cdot\mathbf{u}}{\mathbf{u}\cdot\mathbf{u}}\;\mathbf{u}\;}
$$

- **스칼라 성분(component)**:
  $$
  \mathrm{comp}_{\mathbf{u}}(\mathbf{v})=\frac{\mathbf{v}\cdot\mathbf{u}}{\|\mathbf{u}\|}
  $$
- **정사영 벡터**(단위방향 \(\hat{\mathbf{u}}=\mathbf{u}/\|\mathbf{u}\|\)):
  $$
  \mathrm{proj}_{\mathbf{u}}\mathbf{v}=(\mathbf{v}\cdot\hat{\mathbf{u}})\,\hat{\mathbf{u}}
  $$

### 최적화 관점(유도)

$$
\min_{\alpha\in\mathbb{R}}\|\mathbf{v}-\alpha \mathbf{u}\|^2
\;\Rightarrow\;
\alpha^\star=\frac{\mathbf{v}\cdot\mathbf{u}}{\mathbf{u}\cdot\mathbf{u}}
\quad\Rightarrow\quad
\mathrm{proj}_{\mathbf{u}}\mathbf{v}=\alpha^\star \mathbf{u}.
$$

### 잔차의 직교성

$$
\mathbf{r}=\mathbf{v}-\mathrm{proj}_{\mathbf{u}}\mathbf{v}\quad\Rightarrow\quad
\mathbf{r}\cdot \mathbf{u}=0.
$$

---

## 위 정사영

### 문제 설정

- \(W=\mathrm{Col}(A)\subset\mathbb{R}^m\) (열벡터가 기저 후보), \(\mathbf{v}\in\mathbb{R}^m\).
- 목표: \(\mathbf{p}\in W\) 중 \(\|\mathbf{v}-\mathbf{p}\|\) 최소.

### 유도

$$
\mathbf{p}=A\mathbf{c},\quad
\min_{\mathbf{c}}\|\,\mathbf{v}-A\mathbf{c}\|^2
\;\Rightarrow\;
A^\top A\,\mathbf{c}=A^\top \mathbf{v}.
$$
(열독립 시)
$$
\mathbf{c}=(A^\top A)^{-1}A^\top\mathbf{v},\qquad
\boxed{\;\mathrm{proj}_{W}\mathbf{v}=A(A^\top A)^{-1}A^\top\mathbf{v}\;}
$$

### 정사영 행렬 \(P\)

$$
\boxed{\,P=A(A^\top A)^{-1}A^\top\,},\qquad
\mathrm{proj}_{W}\mathbf{v}=P\mathbf{v}.
$$
성질: 대칭 \(P^\top=P\), 멱등 \(P^2=P\), \(\mathrm{rank}(P)=\dim W\), 고유값은 0/1.

### QR/SVD 관점(수치 안정)

- \(A=QR\) (경제형 QR, \(Q\in\mathbb{R}^{m\times r}\), \(r=\mathrm{rank}(A)\))이면
  $$
  \boxed{\,P=QQ^\top\,},\qquad \mathrm{proj}_{W}\mathbf{v}=Q(Q^\top \mathbf{v}).
  $$
- SVD \(A=U\Sigma V^\top\), 유효 랭크 \(r\):
  $$
  P=U_{[:,1:r]}U_{[:,1:r]}^\top.
  $$

### 랭크 결핍 시(의사역행렬)

$$
\boxed{\,P=AA^+\,}\quad(\text{무어–펜로즈 }A^+),\qquad \mathrm{proj}_{W}\mathbf{v}=AA^+\mathbf{v}.
$$

---

## 원점을 지나지 않는 Affine 직선/평면 위 정사영

### 직선 \(\ell=\{\mathbf{p}_0+\alpha \mathbf{u}\}\)

$$
\boxed{\;\mathrm{proj}_{\ell}\mathbf{v}
=\mathbf{p}_0+\frac{(\mathbf{v}-\mathbf{p}_0)\cdot\mathbf{u}}{\mathbf{u}\cdot\mathbf{u}}\;\mathbf{u}\;}
$$

### (법선 \(\mathbf{n}\), 점 \(\mathbf{p}_0\)) 또는 평면식 \(\mathbf{n}\cdot\mathbf{x}=d\)

$$
\mathrm{proj}_{\Pi}\mathbf{v}
=\mathbf{v}-\frac{(\mathbf{v}-\mathbf{p}_0)\cdot\mathbf{n}}{\|\mathbf{n}\|^2}\mathbf{n}
\quad\text{or}\quad
\mathbf{v}-\frac{\mathbf{n}\cdot\mathbf{v}-d}{\|\mathbf{n}\|^2}\mathbf{n}.
$$

---

## 각도·거리·코사인 유사도

- 각도:
  $$
  \cos\theta=\frac{\mathbf{v}\cdot\mathbf{u}}{\|\mathbf{v}\|\,\|\mathbf{u}\|}.
  $$
- 정사영 길이: \(\|\mathrm{proj}_{\mathbf{u}}\mathbf{v}\|=\|\mathbf{v}\|\,|\cos\theta|\)
- 직선/평면까지의 거리: \(\|\mathbf{v}-\mathrm{proj}\_\cdot \mathbf{v}\|\)
- 피타고라스(직교 분해):
  $$
  \|\mathbf{v}\|^2=\|\mathrm{proj}_W\mathbf{v}\|^2+\|\mathbf{v}-\mathrm{proj}_W\mathbf{v}\|^2.
  $$

---

## 계산 레시피(안정성 우선)

- \((A^\top A)^{-1}\) **직접 계산 금지**(조건수 악화).
- 권장: **QR**로 \(Q\)만 구해 \(Q(Q^\top v)\) 또는 **lstsq/SVD**.
- 대형 문제에선 **P를 만들지 말고** 바로 \(Q(Q^\top v)\).

---

## PyTorch 실전 코드(검산 포함)

```python
import torch

def proj_on_vector(v, u, eps=1e-12):
    """
    v, u: (..., d) 배치 가능. u=0 처리에 대비해 eps로 분모 하한.
    """
    v = torch.as_tensor(v, dtype=torch.float64)
    u = torch.as_tensor(u, dtype=torch.float64)
    denom = (u * u).sum(dim=-1, keepdim=True).clamp_min(eps)
    alpha = (v * u).sum(dim=-1, keepdim=True) / denom
    return alpha * u

def proj_on_affine_line(v, p0, u, eps=1e-12):
    """
    점 p0를 지나고 방향 u인 직선에 v를 정사영.
    """
    v = torch.as_tensor(v, dtype=torch.float64)
    p0 = torch.as_tensor(p0, dtype=torch.float64)
    u  = torch.as_tensor(u, dtype=torch.float64)
    denom = (u*u).sum().clamp_min(eps)
    alpha = ((v - p0) * u).sum() / denom
    return p0 + alpha * u

def proj_on_plane_by_normal(v, n, d=None, p0=None, eps=1e-12):
    """
    법선 n, 평면식 n·x=d 또는 평면 위 점 p0 제공.
    """
    v = torch.as_tensor(v, dtype=torch.float64)
    n = torch.as_tensor(n, dtype=torch.float64)
    nn = (n*n).sum().clamp_min(eps)
    if d is not None:
        return v - ((v @ n - d)/nn) * n
    elif p0 is not None:
        return v - (((v - p0) @ n)/nn) * n
    else:
        raise ValueError("d 또는 p0 중 하나를 제공하세요.")

def proj_on_subspace_QR(v, A):
    """
    W=Col(A) 정사영. A: (m, r), v: (m,) or (m, k)
    QR로 Q를 얻어 proj = Q(Q^T v).
    """
    A = torch.as_tensor(A, dtype=torch.float64)
    v = torch.as_tensor(v, dtype=torch.float64)
    Q, R = torch.linalg.qr(A, mode='reduced')  # Q: (m,r)
    return Q @ (Q.T @ v)

def projection_matrix_QR(A):
    """
    교육/검산용: P = Q Q^T (대형 문제에서는 P를 만들지 말 것)
    """
    A = torch.as_tensor(A, dtype=torch.float64)
    Q, R = torch.linalg.qr(A, mode='reduced')
    return Q @ Q.T

# ====== 간단 검산 =======

v = torch.tensor([2., 3.])
u = torch.tensor([1., 0.])
p = proj_on_vector(v, u)
print("proj_u(v) =", p.tolist())            # [2., 0.]

p0 = torch.tensor([1., 1.])
u  = torch.tensor([2., 1.])
v  = torch.tensor([3., 4.])
p_line = proj_on_affine_line(v, p0, u)
print("proj_line(v) =", p_line.tolist())

n = torch.tensor([0., 0., 1.])
v3 = torch.tensor([2., 3., 4.])
p_plane = proj_on_plane_by_normal(v3, n, d=0.)  # z=0 평면
print("proj_plane(v3) =", p_plane.tolist())     # [2., 3., 0.]

A = torch.tensor([[1.,0.],
                  [1.,1.],
                  [0.,1.]])  # R^3의 2D 평면
v = torch.tensor([1.,2.,3.])
pW = proj_on_subspace_QR(v, A)
print("proj_W(v) =", pW.tolist())

P = projection_matrix_QR(A)
sym_err = torch.norm(P - P.T).item()
idem_err = torch.norm(P @ P - P).item()
print("symmetry error:", sym_err, " idempotency error:", idem_err)
```

---

## 손으로 푸는 예제

### 2D 단일 벡터

$$
\mathbf{v}=\begin{bmatrix}3\\4\end{bmatrix},\quad
\mathbf{u}=\begin{bmatrix}1\\1\end{bmatrix}.
$$
$$
\mathrm{proj}_{\mathbf{u}}\mathbf{v}
=\frac{3\cdot1+4\cdot1}{1^2+1^2}\begin{bmatrix}1\\1\end{bmatrix}
=\frac{7}{2}\begin{bmatrix}1\\1\end{bmatrix}
=\begin{bmatrix}3.5\\3.5\end{bmatrix}.
$$
거리 \(=\|\,[3,4]-[3.5,3.5]\,\|=\sqrt{0.5^2+0.5^2}=\sqrt{0.5}\).

### 3D 평면(법선식)

평면 \(x+2y+2z=6\) (법선 \(\mathbf{n}=[1,2,2]\), \(d=6\)), 점 \(\mathbf{v}=[2,3,4]\):
$$
\mathrm{proj}_\Pi\mathbf{v}
=\mathbf{v}-\frac{\mathbf{n}\cdot\mathbf{v}-d}{\|\mathbf{n}\|^2}\mathbf{n}
=[2,3,4]-\frac{(2+6+8)-6}{1+4+4}[1,2,2]
=[2,3,4]-\frac{10}{9}[1,2,2]
=\left[\frac{8}{9},\frac{7}{9},\frac{8}{9}\right].
$$
평면까지 거리 \(=\dfrac{|\mathbf{n}\cdot\mathbf{v}-d|}{\|\mathbf{n}\|}=\dfrac{10}{3}\).

### — 기저가 비직교일 때

$$
A=\begin{bmatrix}
1&0\\
1&1\\
0&1
\end{bmatrix},\quad
\mathbf{v}=\begin{bmatrix}1\\2\\3\end{bmatrix}.
$$
정규방정식 \(A^\top A\,\mathbf{c}=A^\top \mathbf{v}\):
$$
A^\top A=\begin{bmatrix}2&1\\1&2\end{bmatrix},\quad
A^\top \mathbf{v}=\begin{bmatrix}3\\5\end{bmatrix}
\Rightarrow
\mathbf{c}=\begin{bmatrix}\frac{1}{3}\\ \frac{7}{3}\end{bmatrix},
\quad
\mathbf{p}=A\mathbf{c}
=\begin{bmatrix}\frac{1}{3}\\ \frac{8}{3}\\ \frac{7}{3}\end{bmatrix}.
$$

---

## 응용 요약

- **최소제곱 회귀**: \( \hat{\beta}=(X^\top X)^{-1}X^\top y \)는 \(y\)를 \(\mathrm{Col}(X)\)로 정사영한 계수.
- **PCA**: 데이터 중심화 후 주성분 \(U_r\)에 정사영 \( \hat{x}=U_rU_r^\top x \).
- **그래픽스/기하**: 점-직선/평면 최단 거리, 그림자/조명.
- **신호처리**: 서브스페이스 투영(잡음 제거), 빔포밍.

---

## 자주 하는 실수 & 베스트 프랙티스

1) 기저가 **정규직교가 아닌데** 축별 단순 투영 합산 → ❌ → 정규방정식/QR 사용.
2) \((A^\top A)^{-1}\) **직접** 계산 → ❌ → `QR`, `lstsq`, SVD.
3) \(\mathbf{u}=\mathbf{0}\) 경계 처리 누락 → ❌ → `eps`로 하한/예외.
4) **정사영 행렬 P**를 대규모로 생성 → 메모리/시간 폭발 → \(Q(Q^\top v)\)로 직접 적용.
5) 랭크 결핍/자유변수 무시 → 결과 불안정 → `lstsq(rcond=…)`, SVD 기반 의사역행렬.

---

## 치트시트

- 벡터:
  $$
  \mathrm{proj}_{\mathbf{u}}\mathbf{v}
  =\frac{\mathbf{v}\cdot\mathbf{u}}{\mathbf{u}\cdot\mathbf{u}}\mathbf{u}
  $$
- 서브스페이스(열독립 가정):
  $$
  P=A(A^\top A)^{-1}A^\top,\qquad \mathrm{proj}_{W}\mathbf{v}=P\mathbf{v}
  $$
- QR:
  $$
  A=QR\Rightarrow P=QQ^\top,\quad \mathrm{proj}_{W}\mathbf{v}=Q(Q^\top v)
  $$
- 평면(법선 \(n\), 상수 \(d\)):
  $$
  \mathrm{proj}_\Pi v=v-\frac{n\cdot v-d}{\|n\|^2}n
  $$
- 직선(점 \(p_0\), 방향 \(u\)):
  $$
  \mathrm{proj}_\ell v=p_0+\frac{(v-p_0)\cdot u}{\|u\|^2}u
  $$
- 잔차 직교: \((v-\mathrm{proj}_W v)\perp W\)
- \(P\) 성질: 대칭, 멱등, 고유값 \(\{0,1\}\)
