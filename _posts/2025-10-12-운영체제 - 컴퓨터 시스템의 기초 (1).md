---
layout: post
title: 운영체제 - 컴퓨터 시스템의 기초 (1)
date: 2025-10-12 22:25:23 +0900
category: 운영체제
---
# Chapter 1 — 무엇을, 왜, 어떻게: 운영체제 큰 그림

운영체제(OS, Operating System)는 **하드웨어 자원(CPU·메모리·디스크·네트워크·I/O 장치)을 관리**하고, 사용자/프로그램에게 **안전하고 일관된 추상화**를 제공하는 **중개자(mediator)**다. 이 장에서는 사용자 관점과 시스템 관점, 용어 정리, 그리고 컴퓨터 시스템 구성(인터럽트, 저장장치 계층, I/O 구조)과 아키텍처(Single/Multi-Processor)를 **실행 가능한 예제 코드·명령과 함께** 상세히 설명한다.

---

## What Operating Systems Do

운영체제는 크게 두 가지 역할을 수행한다:

1) **자원 관리자(Resource Manager)**
- CPU 스케줄링, 메모리 할당/회수, 파일시스템·I/O 배치, 네트워크 스택 조정
- **목표:** 공정성(fairness), 효율성(throughput), 응답성(latency), 격리(isolation), 안전성(safety)

2) **추상화 제공자(Abstraction Provider)**
- 프로세스/스레드, 주소 공간(virtual memory), 파일/디렉터리, 소켓, 파이프, 신호/이벤트 등
- **목표:** 복잡한 하드웨어 세부를 숨기고, **일관된 모델**을 앱에게 제공

### 실습: OS가 제공하는 “동일한 파일 추상화”

아래는 서로 다른 장치(SSD, tmpfs, 네트워크 파일시스템)를 **“그냥 파일”**로 다루는 예다.

```bash
# SSD 상의 일반 파일

echo "hello-ssd" > /var/tmp/os_demo_ssd.txt
stat /var/tmp/os_demo_ssd.txt

# 메모리 기반 파일시스템(tmpfs)

echo "hello-tmpfs" > /dev/shm/os_demo_tmpfs.txt
stat /dev/shm/os_demo_tmpfs.txt

# 네트워크 파일시스템(NFS, 가정)
# mount -t nfs server:/export /mnt/nfs

echo "hello-nfs" > /mnt/nfs/os_demo_nfs.txt
stat /mnt/nfs/os_demo_nfs.txt

# 모두 동일한 open/write/close/rename 추상화 사용

```

---

## User View (사용자 관점)

사용자(또는 앱 개발자)는 OS를 **서비스 제공자**로 본다.

- **편의성**: 파일 저장·탐색, 프로세스 실행·중지, 패키지 설치
- **보안**: 접근 제어(권한·소유권), 격리(프로세스·컨테이너), 암호화(디스크·네트워크)
- **안정성**: 프로세스가 크래시해도 시스템 전체는 보호, 메모리 보호(다른 프로세스 메모리 접근 불가)

#### 예제: 사용자 관점에서의 “공정성 체감”

동시에 CPU를 많이 쓰는 작업 2개를 띄워도, 어느 한 쪽이 영원히 굶주리지(Starvation) 않도록 **스케줄러**가 시분할(time-sharing)한다.

```bash
# 터미널 1

yes > /dev/null

# 터미널 2

yes > /dev/null

# 또 다른 터미널

top -H -p $(pgrep -d',' yes)   # yes 쓰레드들의 CPU 사용률을 관찰
```

> 두 `yes`가 대체로 **비슷한 CPU 지분**을 얻는 것을 확인할 수 있다(정확한 비율은 우선순위/부하 등 환경에 따라 달라짐).

---

## System View (시스템 관점)

커널은 하드웨어와 앱 사이의 **제어 지점(control point)**이다.

- **자원 스케줄링/알로케이션**: CPU(스케줄러), 메모리(페이징·캐싱), 디스크(Block I/O 스케줄러), 네트워크(큐 관리)
- **상태 추적/정책 적용**: 프로세스 테이블, 페이지 테이블, inode 캐시, 라우팅 테이블
- **이벤트 처리**: 인터럽트(하드웨어), 트랩/시스템콜(소프트웨어), 예외 처리

#### 예제: 시스템콜 경로(사용자→커널→사용자)

간단한 C 프로그램으로 **`getpid()`**와 **`write()`**의 시스템콜을 호출해보자.

```c
// sys_demo.c : 시스템콜 호출 예시 (Linux/Unix-like)
#include <unistd.h>
#include <sys/syscall.h>
#include <stdio.h>

int main(void) {
    pid_t p1 = getpid();                    // glibc -> syscall wrapper -> 커널 트랩
    // syscall 직접 호출도 가능(플랫폼별 번호 상이)
    long p2 = syscall(SYS_getpid);

    dprintf(1, "getpid via libc: %d\n", p1);
    dprintf(1, "getpid via syscall: %ld\n", p2);

    // write 시스템콜 경로를 통해 표준출력으로 출력
    const char *msg = "hello via write syscall\n";
    syscall(SYS_write, 1, msg, 24);
    return 0;
}
```

```bash
gcc -O2 sys_demo.c -o sys_demo && ./sys_demo
strace -o trace.txt ./sys_demo   # 실제 시스템콜 트레이스 확인
sed -n '1,40p' trace.txt
```

---

## Defining Operating Systems (정의)

운영체제는 **부트로더 이후 하드웨어 제어권을 보유**하고, **사용자 프로그램 실행을 지원**하며, **자원 보호·격리**를 제공하는 **특권 소프트웨어**다. 좁은 의미(커널)와 넓은 의미(기본 유틸리티 포함한 시스템 소프트웨어 집합)로 나뉠 수 있다.

### 성능·안정성의 직관 — 간단 수식

- 시스템 이용률을 $$\rho$$(0~1), 평균 서비스 시간을 $$S$$, 평균 대기 시간을 $$W$$라 할 때, 단순 큐잉 직관에서:
$$
W \approx \frac{\rho}{1-\rho}\cdot S
$$
- **해석**: 자원 이용률이 1에 가까워질수록 대기시간이 **비선형적으로 폭증** → 커널은 **스케줄링·스로틀링**으로 과부하를 방지한다.

---

## Computer-System Organization (컴퓨터 시스템 구성)

부트 후, 커널은 다음을 초기화한다.

- **인터럽트 벡터/테이블**: 장치·예외·타이머 이벤트를 핸들러에 매핑
- **메모리 매니저**: 물리/가상 메모리, 페이지 프레임, 스와핑 정책
- **프로세스 서브시스템**: PID 할당, 스케줄러, 컨텍스트 스위치
- **파일/I/O 서브시스템**: VFS, 특정 FS 드라이버, 블록 I/O, 버퍼 캐시
- **네트워크 스택**: 드라이버, 프로토콜(TCP/IP), 소켓 레이어

---

## Interrupts (인터럽트)

**인터럽트**는 CPU가 실행 중인 흐름을 **즉시 중단**하고 **핸들러(커널 코드)**로 점프시키는 하드웨어 신호다.
종류:
- **하드웨어 인터럽트**: 장치 완료(디스크 I/O 끝), 네트워크 패킷 도착, 타이머 틱
- **소프트웨어 인터럽트/트랩**: 시스템콜, 예외(페이지 폴트·Divide-by-zero)

핵심 지표:
- **인터럽트 레이턴시**: 신호 발생→핸들러 진입까지 시간
- **ISR(Top half)**: 매우 짧게! 즉시 처리(원인 확인·작업 예약)
- **Bottom half**: 나머지 무거운 일은 소프트IRQ/Tasklet/Workqueue/Thread로 미룸

### 관찰

실제 HW 인터럽트는 커널 영역이지만, **시그널**로 유사 이벤트 흐름을 체험할 수 있다.

```c
// signal_tick.c : 타이머 시그널로 "인터럽트 같은" 비동기 이벤트 처리 맛보기
#define _GNU_SOURCE
#include <signal.h>
#include <time.h>
#include <stdio.h>
#include <unistd.h>

static volatile unsigned long ticks = 0;

void on_tick(int signo) {
    ticks++;
}

int main(void) {
    struct sigaction sa = {0};
    sa.sa_handler = on_tick;
    sigaction(SIGALRM, &sa, NULL);

    struct itimerval it = {0};
    it.it_interval.tv_sec = 0; it.it_interval.tv_usec = 50000; // 50ms 주기
    it.it_value = it.it_interval;
    setitimer(ITIMER_REAL, &it, NULL);

    for (int i = 0; i < 100; i++) {
        usleep(100000);
        printf("work... ticks=%lu\n", ticks);
    }
}
```

```bash
gcc -O2 signal_tick.c -o signal_tick && ./signal_tick
```

> 주기적 시그널이 발생할 때마다 `on_tick` 핸들러가 실행된다. 커널의 **타이머 인터럽트 → 스케줄러 틱**과 유사한 흐름을 체감할 수 있다.

---

## Storage Structure (저장장치 구조)

저장장치는 **속도·비용·휘발성**에 따라 계층화된다.

- **레지스터** > **L1/L2/L3 캐시** > **메인 메모리(DRAM)** > **비활성 메모리(SSD/HDD)** > **원격/오브젝트 스토리지**
- **참조 지역성(Locality)**: 시간/공간 지역성을 이용해 상위 계층 캐시 적중률을 높인다.

### 예제: 페이지 캐시 효과 관찰

같은 파일을 두 번 읽으면, 두 번째는 커널의 **페이지 캐시** 덕분에 훨씬 빠르다.

```bash
# 큰 파일 준비 (1~2GB 권장; 디스크 여건에 맞춰 조정)

dd if=/dev/urandom of=/var/tmp/big.bin bs=1M count=512 status=progress

# 1차 읽기(캐시 미적중 가능)

/usr/bin/time -f "elapsed=%E major=%F minor=%R" cat /var/tmp/big.bin > /dev/null

# 2차 읽기(페이지 캐시 적중 기대)

/usr/bin/time -f "elapsed=%E major=%F minor=%R" cat /var/tmp/big.bin > /dev/null
```

> **minor page fault 증가(페이지 캐시 적중)**, **elapsed 감소**를 관찰할 수 있다(환경에 따라 수치 다름).

---

## I/O Structure (I/O 구조)

I/O 경로는 다음 단계를 포함한다:

1) **장치 제어기(Device Controller)**: 레지스터/버퍼 보유, DMA 지원
2) **드라이버(커널 모듈)**: 제어기와 상호작용, 큐 관리, 인터럽트 처리
3) **커널 I/O 서브시스템**: VFS/Block Layer/네트워크 스택, 스케줄러
4) **사용자 API**: open/read/write/ioctl, send/recv, mmap 등

### DMA vs Programmed I/O

- **PIO**: CPU가 직접 장치 레지스터를 폴링·전송
- **DMA**: 제어기가 메모리와 직접 데이터 교환, CPU 개입 최소화 → 적은 CPU 사용량·높은 처리량

### 예제: 메모리 매핑 I/O(mmap)로 파일 읽기

`read()` 대신 `mmap()`을 사용하면 페이지 캐시와 가상메모리를 활용해 파일을 **주소 공간에 직접 매핑**할 수 있다.

```c
// mmap_read.c
#define _GNU_SOURCE
#include <sys/mman.h>
#include <sys/stat.h>
#include <fcntl.h>
#include <unistd.h>
#include <stdio.h>

int main(int argc, char **argv) {
    if (argc < 2) { fprintf(stderr, "usage: %s file\n", argv[0]); return 1; }
    int fd = open(argv[1], O_RDONLY);
    if (fd < 0) { perror("open"); return 1; }
    struct stat st; fstat(fd, &st);
    size_t sz = st.st_size;
    char *p = mmap(NULL, sz, PROT_READ, MAP_PRIVATE, fd, 0);
    if (p == MAP_FAILED) { perror("mmap"); return 1; }
    // 첫 64바이트 훑기
    for (size_t i = 0; i < 64 && i < sz; i++) putchar(p[i]);
    munmap(p, sz);
    close(fd);
    return 0;
}
```

```bash
gcc -O2 mmap_read.c -o mmap_read
./mmap_read /var/tmp/big.bin | hexdump -C | head
```

---

## Computer-System Architecture (컴퓨터 시스템 아키텍처)

**ISA(Instruction Set Architecture)**, **메모리 모델**, **인터럽트/예외**, **동시성 지원**(원자적 연산, 캐시 일관성) 등이 OS 설계에 직접적인 제약을 준다.

- **특권 모드(커널 모드) / 사용자 모드**: 시스템콜·I/O·페이지 테이블 갱신은 특권 명령
- **TLB/페이지 테이블**: 가상화된 주소 공간 → 보호·격리
- **캐시 일관성(Coherence)**: 다중 코어에서 동일한 메모리 사본을 일관되게 관리

---

## Single-Processor Systems (단일 프로세서)

**단일 CPU(또는 단일 하드웨어 스레드)** 환경에서 OS는 **시분할**로 다수 작업을 공정하게 실행한다.

### 컨텍스트 스위치(Context Switch)

- ** PCB(Process Control Block)**: 레지스터, 프로그램 카운터, 스택 포인터, 페이지 테이블 베이스, 스케줄링 정보
- 스위치 시 오버헤드는 있지만, 인터랙티브 응답성을 위해 필요

### 예제: 단일 코어에서의 CPU 바운드 vs I/O 바운드

두 작업을 실행해, 스케줄러의 상이한 처리 체감:

```bash
# CPU 바운드: 큰 소수 찾기(단순 루프)

python3 - <<'PY'
import math
def isprime(n):
    if n<2: return False
    r=int(math.isqrt(n))
    for i in range(2,r+1):
        if n%i==0: return False
    return True
cnt=0
n=2
while cnt<5000:
    if isprime(n): cnt+=1
    n+=1
print("done")
PY
```

```bash
# I/O 바운드: 네트워크에서 파일 여러 개 받기(예: wget 병렬)
# 실제 URL은 환경에 맞게 조정
# xargs -P 병렬성으로 I/O 대기 많은 작업을 섞어 CPU 점유율 패턴을 비교

printf "https://example.com/file1\nhttps://example.com/file2\n" | \
xargs -n1 -P4 wget -q
```

> `top`/`vmstat 1`로 관찰해보면 CPU 바운드는 **RUN 큐**가 늘고, I/O 바운드는 **iowait**이 늘기 쉽다.

---

## Multiprocessor Systems (다중 프로세서)

다중 코어/소켓 시스템에서는 OS가 **부하 분산(load balancing)**, **캐시 친화성(cache locality)**, **동기화(synchronization)**를 관리한다.

- **SMP(Symmetric Multiprocessing)**: 모든 CPU가 대등, 하나의 커널 이미지 공유
- **NUMA(Non-Uniform Memory Access)**: CPU 노드별 로컬 메모리 → **메모리 접근 지연**이 노드 간 다름
- **스레드 배치(외부·내부)**: CPU 친화도(affinity)·스케줄러 도메인

### 동시성 기본 원리 — 메모리 모델 & 원자 연산

- 다중 코어에서 올바른 공유 데이터 접근을 위해 **원자 연산, 메모리 장벽** 필요
- 단일·다중 프로듀서/컨슈머, 락/락프리 구조 설계

#### 예제: 락 기반 공유 카운터(C11 원자)

```c
// mp_atomic.c : POSIX 쓰레드 + C11 atomics
#define _GNU_SOURCE
#include <stdatomic.h>
#include <pthread.h>
#include <stdio.h>
#include <stdint.h>

static atomic_long counter = 0;

void* worker(void* arg){
    long iters = (long)arg;
    for (long i=0; i<iters; i++){
        atomic_fetch_add_explicit(&counter, 1, memory_order_relaxed);
    }
    return NULL;
}

int main(void){
    pthread_t t1, t2, t3, t4;
    long iters = 1000000;
    pthread_create(&t1, NULL, worker, (void*)iters);
    pthread_create(&t2, NULL, worker, (void*)iters);
    pthread_create(&t3, NULL, worker, (void*)iters);
    pthread_create(&t4, NULL, worker, (void*)iters);
    pthread_join(t1,NULL); pthread_join(t2,NULL);
    pthread_join(t3,NULL); pthread_join(t4,NULL);
    printf("counter=%ld\n", atomic_load(&counter));
}
```

```bash
gcc -O2 -pthread mp_atomic.c -o mp_atomic && ./mp_atomic
```

> 원자적 증가로 **레이스 없이 일관된 결과**를 얻는다.

#### 예제: NUMA에서의 메모리 바인딩(리눅스)

NUMA 시스템에서 노드에 바인딩하면 **메모리 접근 지연**을 줄일 수 있다.

```bash
# numactl 사용 예 (시스템에 NUMA가 있어야 함)

numactl --cpunodebind=0 --membind=0 ./mp_atomic
```

---

# 1.2/1.3 종합 실전: 경량 웹서버의 I/O·스케줄링 관찰

**시나리오:** Python의 간단한 HTTP 서버를 돌리고, 동시 접속 부하를 줘서 **I/O 구조(소켓), 인터럽트(네트워킹), 스케줄링(멀티코어)**의 상호작용을 관찰한다.

```bash
# 경량 서버 실행

python3 - <<'PY'
from http.server import SimpleHTTPRequestHandler, ThreadingHTTPServer
import threading, os

class H(SimpleHTTPRequestHandler):
    def do_GET(self):
        if self.path == "/cpu":
            # CPU 바운드 응답(예: 소수 계산)
            import math
            n=18000013
            prime=True
            for i in range(2, int(math.isqrt(n))+1):
                if n%i==0: prime=False; break
            self.send_response(200); self.end_headers()
            self.wfile.write(f"prime? {prime}\n".encode())
        else:
            # I/O 바운드 응답(파일 읽기)
            try:
                with open("/var/tmp/big.bin","rb") as f: f.read(1024*1024)
            except Exception as e:
                pass
            self.send_response(200); self.end_headers()
            self.wfile.write(b"ok\n")

srv = ThreadingHTTPServer(("0.0.0.0", 8080), H)
print(f"PID={os.getpid()} on port 8080, threads={threading.active_count()}")
srv.serve_forever()
PY
```

```bash
# 부하 발생: 혼합 트래픽
# (ab, wrk 등 사용 가능. 여기서는 간단히 xargs 병렬 curl)

printf "/\n/cpu\n/\n/cpu\n" | xargs -n1 -P16 -I{} curl -s http://127.0.0.1:8080{} > /dev/null

# 관찰

pid=$(lsof -i:8080 -t | head -1)
top -H -p $pid              # 쓰레드별 CPU
sar -n DEV 1 5              # 네트워크 장치 rx/tx
vmstat 1 5                  # r/iowait/us/sy 관찰
```

**관찰 포인트**
- `/cpu` 요청이 많으면 **RUN 큐 증가**(r), **us% 상승**
- `/` 요청이 많으면 파일 I/O와 네트워크 I/O의 **캐시/소켓 버퍼** 영향
- **멀티코어**면 여러 커널 워커(softirq)와 서버 쓰레드가 **병렬**로 돌아가는 모습

---

# 부록 A — 체크리스트·요약 표

### 운영체제의 핵심 목표

- **안전성**: 메모리 보호, 접근 제어, 예외 격리
- **효율성**: 캐시/페이지 캐시, DMA, 배치 I/O
- **공정성**: 우선순위·타임 슬라이스, 기아 방지
- **확장성**: SMP/NUMA, 다단계 큐, I/O 멀티큐
- **관측성**: perf/ftrace/eBPF, procfs/sysfs

### 실습 명령 모음

```bash
# CPU/스케줄링

top -H -p <pid>
ps -eo pid,psr,pri,ni,rtprio,stat,comm | head
taskset -c 0 ./app      # CPU affinity

# 메모리/페이지 캐시

vmstat 1
free -h
sudo sh -c "echo 3 > /proc/sys/vm/drop_caches"   # 캐시 드롭(주의!)

# I/O

iostat -xz 1
sar -n DEV 1
strace -f -o trace.txt ./app
```

### 용어 정리

- **프로세스/스레드**: 실행 단위(주소 공간 공유 여부)
- **시스템콜**: 사용자→커널 진입 트랩 경로
- **인터럽트/예외/트랩**: 비동기/동기 이벤트의 분류
- **DMA**: CPU 개입 없이 메모리↔장치 전송
- **SMP/NUMA**: 멀티프로세서 조직 모델

---

# 마무리

이 문서는 **1.1~1.3**의 하위 항목(사용자/시스템 관점, 정의, 인터럽트, 저장 구조, I/O 구조, 단일·다중 프로세서 아키텍처)을 **실행 예제와 함께** 정리했다.
핵심은 **“OS는 복잡한 하드웨어를 숨기고 예측 가능한 추상화를 제공하며, 동시에 공정하고 안전하게 자원을 나눠준다.”**는 점이다.
