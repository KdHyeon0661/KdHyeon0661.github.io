---
layout: post
title: 기계학습 - 고객 세분화
date: 2025-08-20 20:25:23 +0900
category: 기계학습
---
# 🧩 고객 세분화(Customer Segmentation) — 비지도 학습 실전 가이드

고객 세분화는 고객을 **유사한 행동·가치·니즈를 가진 그룹**으로 나누어
**차별화된 마케팅 / 제품 경험 / 가격 정책**을 실행하기 위한 분석 프레임입니다.
비지도 학습을 활용하면 레이블 없이 **데이터의 자연스러운 패턴**을 발견할 수 있습니다.

---

## 1) 세분화의 목적과 성공 기준

### 목적
- **타깃팅/개인화**: 캠페인, 추천, 온보딩 메시지 최적화  
- **가치 극대화**: LTV/ARPU 향상, 업셀/크로스셀, 이탈 감소  
- **전략 인사이트**: 어떤 고객군이 성장을 견인/저해하는지 파악

### 성공 기준(비즈니스)
- **행동·가치가 뚜렷이 구분**되고, **규모/수익 기여**가 의미 있음
- **실행 가능**(캠페인/상품/정책 연결), **안정성/재현성** 확보
- KPI(전환·리텐션·매출·NPS)에서 **유의미한 Lift** 발생

---

## 2) 데이터 설계와 피처 엔지니어링

### 2.1 소스와 기준
- **거래/과금**: 주문·환불·할인·마진  
- **사용/행동 로그**: 세션, 기능 사용, 체류 시간, 디바이스/채널  
- **CRM/마케팅**: 캠페인 노출·클릭·구매, 쿠폰 반응  
- **고객 지원/품질**: 티켓 수, CS 만족도, 반품  
- **메타**: 지역/플랫폼/가입 채널, 가입일/구독 상태

> **아이덴티티 통합**(ID resolution)로 중복 계정을 묶고, 분석 **관찰 창(window)** 을 정의하세요.  
> 예: “최근 180일 행동으로 세분화하고, 이후 30일을 성과 검증 기간으로”.

### 2.2 대표 피처 묶음
- **RFM**: Recency(최종활동-오늘), Frequency(활동/구매 횟수), Monetary(매출/마진)  
- **참여도**: DAU/WAU, 세션빈도, 평균 체류/스크린 수, 기능 다양성  
- **구매 행태**: 카테고리 분포(장바구니 TF–IDF), 가격 민감도(할인 탄력), 반품률  
- **고객가치**: LTV(또는 6/12개월 매출), 마진 기반 가치  
- **여정/상태**: 온보딩 완료, 구독 플랜, 잔존 기간, 이탈 신호  
- **품질/지원**: CS 건수·지연·불만율  
- **생애주기 보정**: **가입 후 경과일/활동기간으로 정규화**(tenure bias 제거)

### 2.3 전처리
- 결측: 비즈니스 의미로 대치(0, “미사용”), 그 외 `median/most_frequent`  
- 스케일: 거리 기반 알고리즘은 **표준화(StandardScaler)** 또는 **RobustScaler**  
- 분포: 왜도 큰 지표는 `log1p`/Yeo–Johnson  
- 범주형: One-Hot(고차원 시 빈도 상위 N+기타), **카테고리 임베딩**(고급)  
- 이상치: 윈저라이징/클리핑(상하위 1–2%)  
- 유출 방지: 모든 변환은 **학습 폴드에서 fit → 검증/적용은 transform**

---

## 3) 알고리즘 선택 가이드

| 알고리즘 | 거리/가정 | 강점 | 유의점/언제 쓰나 |
|---|---|---|---|
| **K-Means / MiniBatchKMeans** | 유클리드, 구형 클러스터 | 빠름·확장성, 해석 쉬움 | K 사전 지정, 스케일 민감, 이상치 민감 |
| **GMM (Gaussian Mixture)** | 가우시안 믹스, 타원형 허용 | **소프트 할당**(확률) | 공분산 폭발/초기화 민감, BIC로 K 결정 |
| **계층적(워드)** | 분산 최소 병합 | 덴드로그램·소규모 데이터 | O(n²) 비용, 커팅 높이 결정 필요 |
| **DBSCAN/HDBSCAN** | 밀도 | 임의 모양·노이즈 분리 | ε/MinPts 튜닝, 밀도 차이 크면 어려움 |
| **스펙트럴** | 그래프 라플라시안 | 비선형 구조 | 스케일·kNN 그래프 파라미터 민감 |
| **K-Prototypes / Gower** | 혼합형(수치+범주) | 실무형(혼합 데이터) | 추가 라이브러리(kmodes·gower) |
| **Autoencoder + KMeans** | 잠재공간 클러스터 | 복잡 패턴·고차원 | 학습·재현성 관리 필요 |

> **대규모/스트리밍**: MiniBatchKMeans, HDBSCAN, Spark MLlib KMeans.  
> **시계열 행동**: HMM/시퀀스 클러스터(고급).

---

## 4) K(군집 수)와 성능 평가

### 4.1 내부 지표(레이블 없음)
- **실루엣(Silhouette)**: \( [-1,1] \), 클수록 분리·응집 양호  
- **Davies–Bouldin (DB)**: 작을수록 좋음  
- **Calinski–Harabasz (CH)**: 클수록 좋음  
- **안정성**: 부트스트랩/재표본 후 군집 **자카드 유사도** 비교

### 4.2 방법
- **엘보(Elbow)**: SSE/관성 감소가 완만해지는 지점  
- **Gap Statistic**: 데이터 vs 무작위 레퍼런스 비교  
- **GMM의 BIC/AIC**: 통계 기준으로 K 선택  
- **비즈니스 제약**: 너무 작은/큰 세그 금지(예: 최소 3% 이상)

### 4.3 외부 검증(운영)
- 세그먼트별 **리텐션/전환/ARPU/NPS** 분포 차이  
- **A/B 테스트**로 타깃 전략의 lift 검증  
- **해석 가능성**: 각 세그의 **프로파일링**이 명확해야 함

---

## 5) 실전 파이프라인 (scikit-learn)

### 5.1 RFM 기반 K-Means (예시 코드)
```python
import pandas as pd, numpy as np
from datetime import datetime, timedelta

# (1) 거래 데이터: columns = [customer_id, order_id, order_date, amount]
tx = pd.read_csv("transactions.csv", parse_dates=["order_date"])
ref_date = tx["order_date"].max() + pd.Timedelta(days=1)  # 기준일(다음날)

# (2) RFM 피처
rfm = (tx.groupby("customer_id")
         .agg(
             last_purchase=("order_date", "max"),
             F=("order_id", "nunique"),
             M=("amount", "sum")
         )
         .assign(
             R=lambda d: (ref_date - d["last_purchase"]).dt.days
         )
         .drop(columns=["last_purchase"])
      )[["R","F","M"]].reset_index()

# (3) 전처리 + KMeans
from sklearn.preprocessing import StandardScaler, FunctionTransformer
from sklearn.pipeline import Pipeline
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score

pipe = Pipeline([
    ("log", FunctionTransformer(lambda X: np.log1p(X))),  # 왜도 완화
    ("scaler", StandardScaler()),
    ("km", KMeans(n_clusters=5, n_init="auto", random_state=42))
])

rfm_feats = rfm[["R","F","M"]].values
pipe.fit(rfm_feats)
labels = pipe.named_steps["km"].labels_
rfm["segment"] = labels

# (4) 프로파일링
summary = rfm.groupby("segment").agg(
    n=("customer_id","nunique"),
    R_median=("R","median"),
    F_median=("F","median"),
    M_median=("M","median"),
    M_sum=("M","sum")
).sort_values("M_sum", ascending=False)
print(summary)

# (5) K 선택 보조: silhouette
sils = {}
for k in range(2,10):
    km = Pipeline([
        ("log", FunctionTransformer(lambda X: np.log1p(X))),
        ("scaler", StandardScaler()),
        ("km", KMeans(n_clusters=k, n_init="auto", random_state=42))
    ]).fit(rfm_feats)
    sils[k] = silhouette_score(km.named_steps["scaler"].transform(np.log1p(rfm_feats)),
                               km.named_steps["km"].labels_)
print(sils)
```

### 5.2 혼합형 데이터: K-Prototypes / Gower
- 수치+범주가 섞였으면 `kmodes` 패키지의 **K-Prototypes** 또는 **Gower 거리** 사용.
```python
# !pip install kmodes
from kmodes.kprototypes import KPrototypes

X = df[["R","F","M","gender","region","device"]]
categorical_idx = [3,4,5]
model = KPrototypes(n_jobs=-1, n_clusters=6, random_state=42, init='Huang')
labels = model.fit_predict(X, categorical=categorical_idx)
df["segment"] = labels
```

> 대안: `gower`로 거리행렬 계산 후 **DBSCAN/계층적** 적용.

### 5.3 차원 축소·시각화
- **PCA → 2D 산점도**로 대략적 분리 확인  
- t-SNE/UMAP은 **시각화 전용**(클러스터링엔 직접 사용 X)

---

## 6) 세그먼트 해석과 액션 디자인

### 6.1 프로파일링 템플릿
- 규모/가치: 고객 수, 매출/마진, ARPU, LTV
- 행동: RFM 중앙값/분위수, 방문·세션, 기능 이용 다양성
- 마케팅 반응: 오픈/클릭/전환, 쿠폰 사용률
- 리스크: 이탈 확률, CS 이슈율, 반품률
- **라벨링**: `고가치 충성`, `할인 민감 탐색형`, `잠재 고가치 온보딩`, `휴면 복귀 후보` 등

### 6.2 실행 전략 예시
- **고가치 충성**: 멤버십/얼리액세스, 추천/리뷰 리워드  
- **할인 민감**: 번들·쿠폰·가격 앵커링 테스트  
- **잠재 고가치(초기 빈도↑)**: 온보딩 가이드·기능 추천  
- **휴면/이탈 위험**: 복귀 쿠폰 A/B, 리마인더, 장바구니 회수  
- **지원 이슈多**: 프로세스 개선·우선 고객센터 라우팅

> 각 세그에 대해 **가설 → 캠페인 → A/B → Lift 측정 → 축적**의 루프를 돌리세요.

---

## 7) 운영·거버넌스

- **재학습 주기**: 월/분기, **미니배치**로 추가 고객 스코어링  
- **드리프트 감지**: 피처 분포/실루엣/세그 비중 변화 감시  
- **전이 관리**: 고객의 세그 이동(마이그레이션 매트릭스) 추적  
- **공정성/프라이버시**: 민감 속성 직접 사용 지양, 최소 필요 원칙, 동의/삭제, 익명화  
- **문서화**: 피처 사전, 변환·스케일, 모델/파라미터, 재현성(코드/버전/시드)

---

## 8) 흔한 함정과 해결

| 함정 | 증상 | 대응 |
|---|---|---|
| 스케일 미적용 K-Means | 엉뚱한 축으로 분할 | **표준화/로그 변환** |
| K 과다/과소 | 미니 세그·혼합 세그 | 내부지표+비즈니스 제약 동시 고려 |
| 이상치 영향 | 세그 경계 왜곡 | 윈저라이징/로버스트 스케일/DBSCAN |
| 텐юр 바이어스 | 오래된 고객이 ‘우수’로만 분류 | 지표를 **기간 대비 정규화** |
| 해석 불가 | 실행 연결 실패 | 프로파일링·라벨링·액션 설계 병행 |
| 일회성 | 시간이 지나 무의미 | 정기 재학습·드리프트 모니터링 |

---

## 9) 체크리스트

- [ ] 분석 창(window)·검증 창 정의(데이터 누수 방지)  
- [ ] 전처리 파이프라인(결측/스케일/로그/인코딩)  
- [ ] 알고리즘 선택 + K 결정(내부지표+제약)  
- [ ] **세그 프로파일링 리포트**와 라벨링  
- [ ] 액션·캠페인·추천 전략 설계 + A/B  
- [ ] KPI 지표로 Lift 확인·지속 개선  
- [ ] 재현성/거버넌스 문서화·모니터링

---

### ✅ 한줄 요약
**탄탄한 피처(특히 RFM·행동·가치), 적절한 전처리/알고리즘, 실루엣·안정성 평가, 그리고 액션/검증 루프**가  
고객 세분화를 **인사이트에서 실질 성과**로 연결하는 핵심입니다.