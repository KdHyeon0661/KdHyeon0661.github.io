---
layout: post
title: 기계학습 - 다항 회귀
date: 2025-08-14 23:25:23 +0900
category: 기계학습
---
# 다항 회귀(Polynomial Regression)

**다항 회귀(Polynomial Regression)**는 선형 회귀(Linear Regression)를 확장하여  
입력 변수와 출력 변수 사이의 **비선형 관계**를 **다항식(Polynomial)** 형태로 모델링하는 방법입니다.

---

## 1. 개념

### (1) 정의
- 입력 변수 \(x\)와 출력 변수 \(y\)의 관계를 **다항식**으로 표현하는 회귀 기법
- 모델 식:
$$
\hat{y} = w_0 + w_1 x + w_2 x^2 + \dots + w_d x^d
$$
- 여기서:
  - \(d\): 다항식 차수(Degree)
  - \(w_i\): 가중치(Weight)
  - \(x^i\): 변수의 거듭제곱 항

---

### (2) 선형 회귀와의 관계
- **선형 회귀**는 변수 \(x\)에 대해 1차 항만 사용하는 모델
- **다항 회귀**는 \(x^2, x^3, \dots\) 고차항을 포함하여 **비선형 관계를 선형 회귀 알고리즘으로 학습**
- 주의: "선형 회귀"에서의 **선형**은 변수에 대한 선형이 아니라, **모델 파라미터에 대한 선형성**을 의미  
  → 다항 회귀도 여전히 선형 회귀의 한 종류

---

## 2. 수학적 표현

### (1) 다항식 변환
- 입력 벡터:
$$
x = \begin{bmatrix} x_1 \\ x_2 \\ \vdots \\ x_n \end{bmatrix}
$$
- 다항식 확장(차수 \(d=3\) 예):
$$
\phi(x) = \begin{bmatrix} 1, x, x^2, x^3 \end{bmatrix}
$$
- 확장된 데이터 \(\phi(x)\)를 선형 회귀 모델에 적용:
$$
\hat{y} = \mathbf{\phi}(x) \cdot \mathbf{w}
$$

---

### (2) MSE 손실 함수
다항 회귀도 MSE를 최소화하여 학습:
$$
MSE = \frac{1}{n} \sum_{i=1}^n (y_i - \hat{y}_i)^2
$$

---

## 3. 장점과 단점

### 장점
- 복잡한 비선형 패턴도 근사 가능
- 변수 변환(Feature Transformation)으로 모델 표현력 강화

### 단점
- 차수가 높아질수록 **과적합(Overfitting)** 가능성 증가
- 다중공선성(Multicollinearity) 문제 발생 가능
- 해석이 어려움

---

## 4. 과적합과 차수 선택

- **차수가 너무 낮으면** → **과소적합(Underfitting)**: 패턴을 충분히 학습하지 못함
- **차수가 너무 높으면** → **과적합(Overfitting)**: 학습 데이터에는 잘 맞지만, 새로운 데이터에서 성능 저하
- 해결책:
  - 교차 검증(Cross Validation)으로 적절한 차수 선택
  - 정규화 회귀(Ridge, Lasso) 적용

---

## 5. 파이썬 예제
```python
import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import PolynomialFeatures

# 데이터 생성 (비선형 관계)
X = np.linspace(0, 6, 30).reshape(-1, 1)
y = 0.5 * X**3 - 2*X**2 + X + np.random.randn(30, 1) * 3

# 다항 특성 변환 (3차)
poly = PolynomialFeatures(degree=3, include_bias=False)
X_poly = poly.fit_transform(X)

# 선형 회귀 모델 학습
model = LinearRegression()
model.fit(X_poly, y)
y_pred = model.predict(X_poly)

# 시각화
plt.scatter(X, y, color='blue', label='Actual')
plt.plot(X, y_pred, color='red', label='Polynomial Regression (degree=3)')
plt.legend()
plt.show()
```

---

## 6. 실제 활용 사례
- **경제학**: 수요·공급 곡선 근사
- **생물학**: 성장 곡선 모델링
- **엔지니어링**: 기계 부품의 마모 패턴 예측
- **물리학**: 비선형 물리 현상 근사

---

## 📌 정리
- 다항 회귀는 입력 변수를 고차항으로 확장해 **비선형 관계를 선형 회귀 알고리즘으로 학습**
- 차수 선택이 중요: 너무 낮으면 과소적합, 너무 높으면 과적합
- 교차 검증과 정규화를 통해 안정적인 모델 설계 가능
- 다양한 분야에서 **곡선 형태의 데이터 예측**에 활용
