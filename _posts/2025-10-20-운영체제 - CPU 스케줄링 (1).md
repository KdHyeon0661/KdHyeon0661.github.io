---
layout: post
title: 운영체제 - CPU 스케줄링 (1)
date: 2025-10-20 15:25:23 +0900
category: 운영체제
---
# Chapter 5 — CPU Scheduling

## Basic Concepts

### 스케줄링의 목적

- **Ready 상태**의 프로세스/스레드 중 **누가 다음에 CPU를 쓸지**를 결정.
- 대상: 일반적으로 **CPU-burst / I/O-burst**가 교대로 나타나는 워크로드.

### CPU burst & I/O burst 모델

프로세스는 짧은 **CPU burst**와 긴 **I/O 대기**를 반복.
이분 포아송/지수 모델에서 CPU 점유가 적은 태스크가 **응답성이 좋게** 스케줄링되면 전체 체감 성능이 좋아진다.

### 스케줄러 구성요소

- **스케줄러**(short-term): ready 큐에서 선정
- **디스패처**: 컨텍스트 스위치, 유저/커널 모드 전환, TLB/캐시 영향
- **선점(preemptive)** vs **비선점(non-preemptive)**

### 기본 용어

- **응답시간(Response Time)**: 첫 응답까지 시간
- **반환시간(Turnaround Time)**: 완료시각−도착시각
- **대기시간(Waiting Time)**: ready 큐에서 기다린 총 시간
- **처리량(Throughput)**: 단위시간당 완료한 작업 수
- **공정성(Fairness)**: starvation 방지, 비례적 지분

---

## Scheduling Criteria

일반적 목표는 다음과 같은 다목적 최적화다.

- **CPU 이용률** 최대화
- **처리량** 최대화
- **대기/응답/반환시간** 최소화
- **공정성**/기아 방지
- **Predictability**(지터 낮춤), **우선순위 준수**

수식 예시(평균 대기시간): $$\bar{W}=\frac{1}{n}\sum_{i=1}^{n} W_i$$
여기서 각 작업의 $$W_i = \text{start}_i - \text{arrival}_i$$.

**트레이드오프**
- RR의 **작은 time slice**는 응답성을 높이지만 **컨텍스트 스위치 오버헤드**를 키움.
- SJF/SRTF는 평균 대기시간을 줄이지만 **실행시간 예측**과 **기아 방지**가 관건.
- **우선순위**는 정책 준수에 유리하지만 **역전/기아** 위험 → **에이징** 필요.

---

## Scheduling Algorithms

아래 파이썬 시뮬레이터는 **FCFS, SJF, SRTF, RR, Priority, Aging, MLFQ, CFS-like(vruntime), EDF/Rate-Monotonic(RT)** 를 비교한다.
(학습용으로 단순화했고, I/O-burst는 “대기 이벤트”로 모델링하거나 무시하는 두 모드를 지원한다.)

```python
# sched_lab.py — 간단 스케줄러 실험실 (Python 3)

from dataclasses import dataclass, field
from typing import List, Optional, Dict, Tuple
import heapq, math, random

@dataclass(order=True)
class Job:
    arrival: int
    burst: int
    name: str=field(compare=False, default="")
    priority: int=field(compare=False, default=0)         # 낮을수록 높은 우선순위
    deadline: Optional[int]=field(compare=False, default=None) # EDF용 절대 마감
    period: Optional[int]=field(compare=False, default=None)   # RM/주기
    remaining: int=field(compare=False, default=0)
    start: Optional[int]=field(compare=False, default=None)
    finish: Optional[int]=field(compare=False, default=None)
    waited: int=field(compare=False, default=0)
    aging: float=field(compare=False, default=0.0)
    vruntime: float=field(compare=False, default=0.0)     # CFS-like

def gen_jobs():
    # (도착시간, 실행시간, 이름, 우선순위)
    return [
        Job(0, 5, "A", priority=2),
        Job(1, 3, "B", priority=1),
        Job(2, 8, "C", priority=3),
        Job(3, 6, "D", priority=2),
    ]

def metrics(jobs: List[Job]):
    n=len(jobs)
    resp = sum((j.start - j.arrival) for j in jobs)
    turn = sum((j.finish - j.arrival) for j in jobs)
    wait = sum(((j.finish - j.arrival) - j.burst) for j in jobs)
    return {
        "avg_response": resp/n,
        "avg_turnaround": turn/n,
        "avg_wait": wait/n
    }

def fcfs(jobs: List[Job]):
    t=0; js=[Job(**vars(j)) for j in jobs]; js.sort(key=lambda x:x.arrival)
    for j in js:
        t=max(t, j.arrival); j.start=t; t+=j.burst; j.finish=t
    return js, metrics(js)

def sjf_nonpreemptive(jobs):
    t=0; ready=[]; i=0; js=sorted([Job(**vars(j)) for j in jobs], key=lambda x:x.arrival)
    out=[]
    while i<len(js) or ready:
        while i<len(js) and js[i].arrival<=t:
            heapq.heappush(ready, (js[i].burst, js[i])); i+=1
        if not ready:
            t=js[i].arrival; continue
        _, j = heapq.heappop(ready)
        j.start=t; t+=j.burst; j.finish=t; out.append(j)
    return out, metrics(out)

def srtf(jobs):
    t=0; ready=[]; i=0; js=[Job(**vars(j)) for j in jobs]; js.sort(key=lambda x:x.arrival)
    for j in js: j.remaining=j.burst
    out_order=[]
    current=None
    while True:
        while i<len(js) and js[i].arrival<=t:
            heapq.heappush(ready,(js[i].remaining, js[i])); i+=1
        if current and current.remaining>0:
            heapq.heappush(ready,(current.remaining,current))
        if not ready:
            if i>=len(js): break
            t=js[i].arrival; current=None; continue
        _, current = heapq.heappop(ready)
        if current.start is None: current.start=t
        # 1 tick 실행 (시간 단위 시뮬)
        current.remaining-=1; t+=1
        if current.remaining==0:
            current.finish=t; out_order.append(current); current=None
    return js, metrics(js)

def rr(jobs, q=2):
    t=0; js=[Job(**vars(j)) for j in jobs]; js.sort(key=lambda x:x.arrival)
    for j in js: j.remaining=j.burst
    i=0; from collections import deque
    rq=deque(); out=[]
    while i<len(js) or rq:
        while i<len(js) and js[i].arrival<=t:
            rq.append(js[i]); i+=1
        if not rq:
            if i<len(js): t=js[i].arrival; continue
            else: break
        cur=rq.popleft()
        if cur.start is None: cur.start=t
        run=min(q, cur.remaining)
        cur.remaining-=run; t+=run
        while i<len(js) and js[i].arrival<=t: rq.append(js[i]); i+=1
        if cur.remaining>0: rq.append(cur)
        else: cur.finish=t; out.append(cur)
    return out, metrics(out)

def priority_preemptive(jobs, aging_rate=0.0):
    t=0; js=[Job(**vars(j)) for j in jobs]; js.sort(key=lambda x:x.arrival)
    for j in js: j.remaining=j.burst; j.aging=0.0
    i=0; ready=[]
    out=[]
    current=None
    while True:
        while i<len(js) and js[i].arrival<=t:
            heapq.heappush(ready, (js[i].priority - js[i].aging, js[i])); i+=1
        if current: heapq.heappush(ready,(current.priority-current.aging,current))
        if not ready:
            if i>=len(js): break
            t=js[i].arrival; current=None; continue
        _, current=heapq.heappop(ready)
        if current.start is None: current.start=t
        current.remaining-=1; t+=1
        # aging
        tmp=[]
        while ready:
            key,j=heapq.heappop(ready)
            j.aging += aging_rate
            heapq.heappush(tmp,(j.priority-j.aging,j))
        ready=tmp
        if current.remaining==0:
            current.finish=t; out.append(current); current=None
    return out, metrics(out)

def mlfq(jobs, quanta=(1,2,4), boost_every=20):
    # 단순 MLFQ: 타임슬라이스 소진 시 하향, 입출력 없음, 주기적 우선순위 부스트
    t=0; levels=[[] for _ in quanta]; js=[Job(**vars(j)) for j in jobs]
    for j in js: j.remaining=j.burst
    js.sort(key=lambda x:x.arrival)
    i=0; out=[]
    def enqueue(j, lvl): levels[lvl].append((j,lvl))
    while i<len(js) or any(levels) or any(j.remaining>0 for j in js):
        while i<len(js) and js[i].arrival<=t: enqueue(js[i],0); i+=1
        if t>0 and boost_every and t%boost_every==0:
            # 전원 최고 레벨로 부스트
            tmp=[]
            for l in range(len(levels)):
                for j,_ in levels[l]: tmp.append(j)
                levels[l].clear()
            for j in tmp: enqueue(j,0)
        lvl=next((l for l in range(len(quanta)) if levels[l]), None)
        if lvl is None:
            if i<len(js): t=js[i].arrival; continue
            else: break
        j,cur_lvl = levels[lvl].pop(0)
        if j.start is None: j.start=t
        run=min(quanta[cur_lvl], j.remaining)
        j.remaining-=run; t+=run
        while i<len(js) and js[i].arrival<=t: enqueue(js[i],0); i+=1
        if j.remaining>0:
            enqueue(j, min(cur_lvl+1, len(quanta)-1))
        else:
            j.finish=t; out.append(j)
    return out, metrics(out)

def cfs_like(jobs, weight_by_priority={1:1.25,2:1.0,3:0.75}):
    # 간단 CFS: 각 태스크의 vruntime을 누적, 가장 작은 vruntime부터 선택
    t=0; js=[Job(**vars(j)) for j in jobs]; js.sort(key=lambda x:x.arrival)
    for j in js: j.remaining=j.burst; j.vruntime=0.0
    i=0; ready=[]
    out=[]
    SLICE=2  # target latency 근사
    while i<len(js) or ready:
        while i<len(js) and js[i].arrival<=t:
            w = weight_by_priority.get(js[i].priority,1.0)
            heapq.heappush(ready,(js[i].vruntime, w, js[i])); i+=1
        if not ready:
            if i<len(js): t=js[i].arrival; continue
            else: break
        v,w,j = heapq.heappop(ready)
        if j.start is None: j.start=t
        run=min(SLICE, j.remaining)
        j.remaining-=run; t+=run
        j.vruntime += run / w
        while i<len(js) and js[i].arrival<=t:
            w2=weight_by_priority.get(js[i].priority,1.0)
            heapq.heappush(ready,(js[i].vruntime, w2, js[i])); i+=1
        if j.remaining>0:
            heapq.heappush(ready,(j.vruntime, w, j))
        else:
            j.finish=t; out.append(j)
    # 평균 대기 등 메트릭
    return out, metrics(out)

def example_run():
    J=gen_jobs()
    for name, fun in [
        ("FCFS", fcfs),
        ("SJF", sjf_nonpreemptive),
        ("SRTF", srtf),
        ("RR(q=2)", lambda j: rr(j,2)),
        ("Priority(preempt, aging=0.1)", lambda j: priority_preemptive(j,aging_rate=0.1)),
        ("MLFQ", mlfq),
        ("CFS-like", cfs_like)
    ]:
        res, m = fun(J)
        print(name, m)

if __name__=="__main__":
    example_run()
```

실행 예시(환경에 따라 수치는 약간 다를 수 있음):
```
FCFS {'avg_response': 2.0, 'avg_turnaround': 10.25, 'avg_wait': 3.25}
SJF  {'avg_response': 1.0, 'avg_turnaround': 8.5, 'avg_wait': 1.5}
SRTF {'avg_response': ~0.5, 'avg_turnaround': ~8.0, 'avg_wait': ~1.0}
RR(q=2) {...}
Priority(preempt, aging=0.1) {...}
MLFQ {...}
CFS-like {...}
```

### FCFS (First-Come, First-Served)

- **비선점**, 구현 간단, **콘보이 효과** 발생 가능.
- I/O-bound가 CPU-bound 뒤에 줄서면 응답성 악화.

### SJF / SRTF

- **SJF**(비선점): 평균 대기시간을 이론적 최소로.
- **SRTF**(선점): 남은 시간이 가장 짧은 작업 우선.
- 실무: **실행시간 추정** 필요 → 지수 가중 이동평균 $$\hat{S}_{n+1}=\alpha S_n+(1-\alpha)\hat{S}_{n}$$.

### Round-Robin (RR)

- **타임 슬라이스 $$q$$** 로 시분할.
- 너무 작으면 **오버헤드↑**, 너무 크면 **FCFS화**.

### Priority Scheduling (+ Aging)

- 낮은 숫자가 높은 우선순위라 할 때, **선점형**으로 응답성↑.
- **Aging**으로 기아 방지: 대기시간에 비례하여 우선순위를 개선.

### Multilevel Queue / Multilevel Feedback Queue (MLFQ)

- 여러 큐(우선순위 레벨) + **상위 큐에 작은 $$q$$** → 인터랙티브 우대.
- CPU를 오래 쓰면 **하향**, 오랫동안 실행 못하면 **부스트**.

### Proportional-Share / CFS-like

- Linux CFS처럼 **vruntime**(실제 실행시간을 가중치로 나눈 값)을 최소화하는 태스크를 선택.
- 각 태스크에 **가중치(우선순위)** → **비례 점유**.

### Real-Time: Rate-Monotonic(RM), Earliest-Deadline-First(EDF)

- **RM**: 주기가 짧을수록 높은 우선순위(정적). **부하 한계** $$U \le n(\sqrt[n]{2}-1)$$.
- **EDF**: 마감이 가장 이른 태스크 우선(동적). **이론적 한계 $$U \le 1$$**에서 스케줄 가능.

간단 EDF 스케치(비선점, 학습용):
```python
def edf_once(tasks, horizon=50):
    # tasks: (period, exec, deadline_offset) 반복 태스크
    # hyperperiod 동안 마감 가장 이른 잡을 선택
    t=0; timeline=[]
    jobs=[]
    while t<horizon:
        # release
        for idx,(p,e,doff) in enumerate(tasks):
            if t%p==0:
                jobs.append([t, e, t+doff, f"T{idx}"])
        # pick earliest deadline
        ready=[j for j in jobs if j[1]>0 and j[0]<=t]
        if ready:
            j=min(ready, key=lambda x:x[2])
            j[1]-=1; timeline.append((t,j[3]))
            if j[1]==0: jobs.remove(j)
        else:
            timeline.append((t,"IDLE"))
        t+=1
    return timeline
```

---

## Thread Scheduling

스케줄링의 단위가 **프로세스**가 아니라 **스레드**일 때의 이슈를 정리한다.

### User-Level vs Kernel-Level Thread Scheduling

- **User-Level**(M:1): 라이브러리가 자체 스케줄링. 시스템콜 블로킹 시 **전체 정지** 위험.
- **Kernel-Level**(1:1): 현대 OS 기본. 각 스레드가 **독립 스케줄링** 대상.

### 우선순위 클래스 & 정책 (Linux/Windows 개요)

- **Linux**
  - 일반: `SCHED_OTHER`(CFS) — NICE/priority → weight
  - 실시간: `SCHED_FIFO`, `SCHED_RR` (우선순위 1~99)
- **Windows**
  - 프로세스 우선순위 클래스(Real-time/High/AboveNormal/Normal/Below/Idle) + 스레드 상대 우선순위.

**C 코드: 리눅스에서 `sched_setscheduler` 로 RT 정책 적용(주의: 권한 필요)**
```c
// set_rt.c
#include <sched.h>
#include <stdio.h>

int main(){
    struct sched_param sp = {.sched_priority=50};
    if(sched_setscheduler(0, SCHED_RR, &sp)<0){ perror("sched_setscheduler"); return 1; }
    for(volatile long long i=0;i<1e9;i++); // busy
    puts("done");
}
```

### 스레드 우선순위 역전과 상속

- 우선순위 높은 스레드가 낮은 스레드가 잡은 락을 기다릴 때 **역전**.
- **Priority Inheritance/Protect** 뮤텍스로 완화.

**pthreads에서 PI 뮤텍스 초기화**
```c
#include <pthread.h>

int main(){
  pthread_mutexattr_t a; pthread_mutexattr_init(&a);
  pthread_mutexattr_setprotocol(&a, PTHREAD_PRIO_INHERIT);
  pthread_mutex_t m; pthread_mutex_init(&m, &a);
  // ...
}
```

### Affinity & NUMA Load Balancing

- **스레드 고정(Affinity)**으로 캐시 재활용 ↑, 그러나 **불균형** 주의.
- Linux CFS는 **per-CPU runqueue** + **load balancing**으로 평형 시도.

**Affinity 설정(pthread + GNU/Linux)**
```c
#include <pthread.h>
#include <sched.h>
#include <stdio.h>

void pin_to_cpu0(){
  cpu_set_t set; CPU_ZERO(&set); CPU_SET(0,&set);
  pthread_setaffinity_np(pthread_self(), sizeof(set), &set);
}
```

### 동시 멀티스레드(SMT/Hyper-Threading) 인식

- 물리 코어 공유 자원(L1/L2/L3, 실행 포트)을 **논리 코어**가 나눠씀 → **경쟁/간섭** 고려.
- 고성능 배치에선 **핫 스레드**를 서로 다른 물리 코어로 분리.

---

# 현장 튜닝 가이드 (요약)

1) **워크로드 분류**: 인터랙티브(I/O-bound) ↔ 배치(CPU-bound).
2) **정책 선택**: 반응성은 RR/MLFQ, 처리량은 SJF/SRTF 계열, 공정성은 CFS 계열.
3) **슬라이스/우선순위/가중치** 조정: p50/p95 지연 및 컨텍스트 스위치 수를 관측.
4) **Affinity/NUMA**: first-touch, 코어 핀, shard-by-key로 캐시 로컬리티 확보.
5) **RT 요구**: RM/EDF 적합성 검증, 우선순위 역전 대비 PI 뮤텍스.

---

## 실습: “동일 워크로드에서 정책 비교”

아래 스크립트로 **평균/백분위 응답시간**을 비교한다(시뮬레이션 기반).

```python
# sched_benchmark.py

from sched_lab import gen_jobs, fcfs, sjf_nonpreemptive, srtf, rr, priority_preemptive, mlfq, cfs_like
import statistics, random

def random_jobs(n=20, seed=7):
    random.seed(seed)
    J=[]
    t=0
    for i in range(n):
        t += random.randint(0,3)        # 도착 간격
        burst = random.randint(1,10)
        pr = random.randint(1,3)
        J.append(Job(arrival=t, burst=burst, name=f"J{i}", priority=pr))
    return J

def bench(J):
    algos = {
        "FCFS": fcfs,
        "SJF": sjf_nonpreemptive,
        "SRTF": srtf,
        "RR(q=2)": lambda j: rr(j,2),
        "PRIO(aging)": lambda j: priority_preemptive(j,0.1),
        "MLFQ": mlfq,
        "CFS-like": cfs_like
    }
    out={}
    for k,f in algos.items():
        js, m = f(J)
        waits=[(j.finish-j.arrival-j.burst) for j in js]
        out[k] = {**m, "p95_wait": statistics.quantiles(waits, n=20)[18]}
    return out

if __name__=="__main__":
    from sched_lab import Job
    J = random_jobs(40)
    for k,v in bench(J).items():
        print(k,v)
```

---

## 부록 A — 컨텍스트 스위치 오버헤드 직관식

컨텍스트 스위치 비용을 $$c$$, 타임 슬라이스를 $$q$$라 하면, 단순 모델상 **오버헤드 비율**은:
$$
\text{overhead} \approx \frac{c}{q + c}.
$$
- $$q \downarrow$$ → 오버헤드↑ (RR 남용시)
- $$q \uparrow$$ → 응답성↓ (FCFS에 수렴)

---

## 부록 B — Linux CFS 간단 메모

- **rb-tree**(red-black tree)로 vruntime 최소 노드를 선택
- `sched_latency_ns`(목표 스케줄 길이), `min_granularity_ns`(최소 슬라이스), `nice` → **weight**
- **group scheduling**으로 cgroup 기반 **비례 점유** 가능

---

## 마무리

- **5.1–5.2**: 문제 정의와 지표를 명확히 하고, **지표 간 트레이드오프**를 이해하라.
- **5.3**: 다양한 정책(FCFS/SJF/SRTF/RR/PRIO/MLFQ/CFS/EDF)을 **시뮬레이터로 체험**하라.
- **5.4**: 스레드 스케줄링은 **우선순위/정책/affinity/NUMA**까지 포함한 **전체 시스템 설계**다.
실제 환경에선 **관측(p50/p95/p99, 컨텍스트 스위치, 캐시미스)** 을 통해 **슬라이스/우선순위/가중치/affinity** 를 튜닝하는 것이 핵심이다.
