---
layout: post
title: 운영체제 - 파일 시스템 구현 (2)
date: 2025-10-29 17:25:23 +0900
category: 운영체제
---
# Chapter 14 — File-System Implementation (2)

## Allocation Methods

### 개요: “파일 오프셋 → 장치 블록(또는 LBA)”

파일 시스템은 **파일의 논리 오프셋**을 **장치의 물리(논리) 블록**으로 매핑하는 구조를 갖는다. 대표 방식:

1) **Contiguous allocation**: 큰 **연속 영역**으로 배정(최고의 순차 성능, 외부 조각화 위험).
2) **Linked allocation**: 각 블록이 다음 블록의 포인터를 포함(FAT 포함).
3) **Indexed allocation**: 별도의 인덱스 블록(또는 아이노드)이 **블록 배열**을 가짐(단/다중 수준).
4) **Extent-based**: `(시작, 길이)`의 범위로 연속 구간을 기술(현대 FS 표준).
5) **Log-Structured / COW 계열**: 쓰기는 **새 위치에 append**, 메타 트리 루트 스윙으로 커밋.

---

### Contiguous Allocation (연속 할당)

**장점**
- 순차 읽기/쓰기 최적: 한 번의 시킹 이후 큰 연속 I/O 가능.
- 단순한 **오프셋 변환**:
  $$ \text{LBA} = \text{base} + \left\lfloor \frac{\text{offset}}{B} \right\rfloor $$
  (여기서 \(B\)는 블록 크기)

**단점**
- **외부 조각화**: 다양한 크기의 파일 생성/삭제를 반복하면 충분한 **연속** 빈 공간을 찾기 어려움.
- 파일 **성장 예측** 필요 → 오버프로비저닝(예약) or 재배치 비용.

**연속 빈공간 찾기 정책**
- **First-fit / Next-fit / Best-fit / Worst-fit** (힙 할당과 동일한 고전 기법).
- **예약 창(reservation window)**: 파일을 생성할 때 **근처에 여유 extent**를 미리 확보.

```python
# contiguous_alloc.py — first-fit / best-fit로 연속 k블록 찾기(개념)

def find_run(bitmap, k, policy="first"):
    # bitmap: 0=free, 1=used
    runs=[]
    n=len(bitmap); i=0
    while i<n:
        if bitmap[i]==0:
            j=i
            while j<n and bitmap[j]==0: j+=1
            runlen=j-i
            if runlen>=k:
                if policy=="first": return i
                runs.append((runlen, i))
            i=j
        else:
            i+=1
    if policy=="best" and runs:
        _,pos=min(runs)   # 가장 짧은 적합 런(외부 파편 최소화 가설)
        return pos
    return None
```

**조각화 근사**
전체 블록 수 \(N\), 빈 비율 \(f\), 필요한 연속 길이 \(k\)일 때 단순 근사로
$$
E[\text{스캔}] \approx \frac{k}{f}\quad(\text{균일 분포 가정})
$$
\(f\)가 낮아질수록 연속 할당 탐색 비용 급증.

---

### Linked Allocation (연결 리스트, FAT 포함)

**아이디어**: 파일의 각 데이터 블록이 **다음 블록의 번호**를 보유. FAT는 이를 **테이블(배열)**에 모아 캐시.

**장점**
- 외부 조각화 없음(어떤 빈 블록이든 연결 가능).
- 디렉터리 엔트리에 **첫 블록 번호**만 저장해도 파일 추적 가능.

**단점**
- **랜덤 접근 O(n)**: n번째 블록에 도달하려면 앞에서부터 따라가야 함(FAT는 부분 완화).
- **신뢰성**: 포인터/테이블 손상 시 사슬이 끊김(저널, FAT 미러 등으로 완화).
- **메타데이터 오버헤드**: 블록당 포인터 or FAT의 메모리 상주 비용.

```python
# fat_follow.py — FAT를 사용한 n번째 블록 찾기

def fat_nth_block(fat, start, n):
    blk=start
    for _ in range(n):
        blk=fat[blk]   # 다음 블록 인덱스
        if blk==-1: return None
    return blk
```

---

### Indexed Allocation (인덱스 블록 / 아이노드 다중 간접)

**싱글 인덱스**: 별도 블록에 **데이터 블록 번호 배열**을 저장.
**다중 인덱스**: 유닉스 아이노드 스타일 **직접 12 + 단일/이중/삼중 간접**.

```c
// off2blk.c — 12 direct + 1 single + 1 double 간접 매핑(개념)
#include <stdint.h>
#define NDIRECT 12
#define NPOINTERS (4096/4)

typedef struct {
  uint32_t direct[NDIRECT];
  uint32_t indirect1; // single
  uint32_t indirect2; // double
} inode_t;

// 블록 번호 배열을 읽는 장치 의존 함수는 생략(캐시 가정)
uint32_t off_to_blk(inode_t* in, uint64_t offset, uint32_t blksz){
  uint64_t lbn = offset / blksz;          // logical block number
  if(lbn < NDIRECT) return in->direct[lbn];
  lbn -= NDIRECT;
  if(lbn < NPOINTERS){ /* single */ /*...*/ }
  lbn -= NPOINTERS;
  /* double */ /*...*/
  return 0;
}
```

**장점**: 랜덤 접근 \(O(1)\) 수준(간접 레벨 수 내).
**단점**: 큰 파일은 **간접 블록 다수** 필요(메타데이터 I/O).

---

### Extent-Based Allocation (현대 주류)

**extent**: `(start_lba, length)` 구간. 몇 개의 extent로 큰 파일 전체를 기술.

**장점**
- 큰 파일의 메타데이터 **작고 빠름**, 순차 접근 최적.
- **지연 할당**과 결합 시 조각화 대폭 감소.

**단점**
- 파편화 진행 시 extent 수 증가 → 메타데이터 트리(예: B+Tree) 깊이 증가.
- extent split/merge 비용, 잠금 경합.

**정책**
- **Best-fit on extents**: 필요한 길이에 가까운 자유 구간을 선택(외부 조각 억제).
- **Locality**: 같은 디렉터리/아이노드 그룹 근처 배치.
- **Preallocation / fallocate**: 예상 성장량만큼 미리 예약.

```python
# extent_alloc.py — 자유 공간을 (start,len)로 관리, best-fit 할당/병합

import bisect
class FreeExtents:
    def __init__(self): self.ext=[(0,10_000)]  # 예: 0..9999 free
    def alloc(self, need):
        best_i, best_gap = None, None
        for i,(s,l) in enumerate(self.ext):
            if l>=need:
                gap=l-need
                if best_gap is None or gap<best_gap:
                    best_i, best_gap = i, gap
        if best_i is None: return None
        s,l=self.ext[best_i]
        out=(s,need)
        if l==need: self.ext.pop(best_i)
        else: self.ext[best_i]=(s+need, l-need)
        return out
    def free(self, s,l):
        i=bisect.bisect_left(self.ext,(s,l)); self.ext.insert(i,(s,l))
        # 병합
        if i>0 and self.ext[i-1][0]+self.ext[i-1][1]==self.ext[i][0]:
            s0,l0=self.ext[i-1]; s1,l1=self.ext[i]; self.ext[i-1]=(s0,l0+l1); self.ext.pop(i); i-=1
        if i+1<len(self.ext) and self.ext[i][0]+self.ext[i][1]==self.ext[i+1][0]:
            s0,l0=self.ext[i]; s1,l1=self.ext[i+1]; self.ext[i]=(s0,l0+l1); self.ext.pop(i+1)
```

**조각화 지표(간단화)**
평균 extent 개수 \(m\), 고정 오버헤드 \(t_0\), 전송 시간 계수 \(t_b\), 파일 크기 \(S\):
$$
T \approx m \cdot t_0 + S \cdot t_b
$$
→ **m(조각 수)** 를 줄이는 정책(지연 할당, 예약 창, 근거리 우선)이 핵심.

---

### Tail Packing / Inline Data (소형 파일 최적화)

- 작은 파일(수백 바이트)을 **디렉터리 블록/아이노드**에 **인라인**으로 저장하면 랜덤 I/O 감소.
- ReiserFS, btrfs(extent 아이템 내 inline), ext4(inline data 기능) 등.

---

### Log-Structured & COW 스타일 (요약)

**Log-Structured (LFS)**: 모든 쓰기를 **세그먼트에 append**, 주기적 **cleaning**으로 살아있는 데이터만 집약.
**COW(Btrfs/ZFS)**: 변경 노드를 **새로 쓰고** 부모 포인터를 갱신(루트 스윙) → 스냅샷/체크섬 용이.

```python
# lfs_cleaner.py — 세그먼트 유효율 기반 청소 우선순위(개념)

segments=[{"id":i,"util":u} for i,u in enumerate([0.15,0.9,0.6,0.2,0.4])]
# util=살아있는 비율, 낮을수록 청소 효율↑

order=sorted(segments, key=lambda x: x["util"])
print([s["id"] for s in order])  # [0,3,4,2,1]
```

---

## Free-Space Management

### Bitmaps (가장 보편)

- **1비트=1블록** → 공간 효율 최고, **연속 k블록** 탐색에도 유리(워드 단위 스캔 + 비트연산).
- **가속**: 워드가 **전부 1**인지 빠르게 검사(popcount), **run 찾기**에 전용 알고리즘 사용.

```python
# bitmap_find_run.py — 64비트 워드 기반 k 연속 0 비트 찾기

def find_run_u64(words, k):
    B=64
    run=0; start=-1; pos=0
    for w in words:
        inv = ~w & ((1<<B)-1)   # 0=free -> 1
        for b in range(B):
            if (inv>>b)&1:
                if run==0: start=pos
                run+=1
                if run==k: return start
            else:
                run=0
            pos+=1
    return None
```

**장점**: 밀도/빠른 스캔/간단한 저널링(비트 세트/클리어).
**주의**: 매우 큰 볼륨에서 비트맵 자체 I/O → **그룹화/캐싱** 필요.

---

### Free List / Grouping

- **싱글 링크드 프리 리스트**: 간단하지만 **연속 할당**이 어려움(랜덤화).
- **Grouping**: 한 블록에 **다수 free 블록 번호**를 담고 **다음 그룹 포인터**를 둠(전통적 UNIX 기법).

```python
# freelist_group.py — 그룹 헤더 {count, next, entries[]}

class Group:
    def __init__(self,next_id=None,entries=None):
        self.next=next_id; self.entries=entries or []
class FreeList:
    def __init__(self): self.head=Group(None, list(range(100,200)))
    def alloc(self):
        if not self.head.entries: return None
        return self.head.entries.pop()
    def free(self, blk): self.head.entries.append(blk)
```

---

### Counting (범위로 free 공간 표현)

- **(start, length)** 로 free run을 저장 → **연속 할당**과 잘 맞음.
- 병합/분할이 빈번 → **정렬 리스트 or 트리**로 관리.

```python
# 세트 병합/분할

from bisect import bisect_left
class FreeCount:
    def __init__(self): self.extents=[(0,10000)]
    def alloc(self,need):  # first-fit
        for i,(s,l) in enumerate(self.extents):
            if l>=need:
                out=(s,need)
                if l==need: self.extents.pop(i)
                else: self.extents[i]=(s+need, l-need)
                return out
        return None
    def free(self,s,l):
        i=bisect_left(self.extents,(s,l)); self.extents.insert(i,(s,l))
        # 좌우 병합(생략 없이 구현은 14.4.5 참고)
```

---

### Buddy Allocator (2의 거듭제곱 단위)

- **크기 2^k** 블록을 관리, **buddy**와 합쳐 상위 오더로 병합 → 빠른 분할/병합.
- 파일시스템 **free-space** 에도 사용할 수 있으나, 임의 크기 연속 요청과는 맞지 않을 수 있음(내부 조각).

```python
# buddy.py — 매우 단순한 buddy(개념)

from collections import defaultdict
class Buddy:
    def __init__(self, order):  # 전체 크기 = 2^order
        self.freelists=defaultdict(list)
        self.freelists[order]=[0]
    def alloc(self, need_order):
        o=need_order
        while o<=max(self.freelists):
            if self.freelists[o]:
                blk=self.freelists[o].pop()
                while o>need_order:
                    o-=1
                    buddy=blk+(1<<o)
                    self.freelists[o].append(buddy)
                return blk
            o+=1
        return None
    def free(self, blk, order):
        while True:
            b=blk^(1<<order)
            if b in self.freelists[order]:
                self.freelists[order].remove(b)
                blk=min(blk,b); order+=1
            else:
                break
        self.freelists[order].append(blk)
```

---

### 트리 기반(범위 트리, B+Tree, RBTree)

- **XFS**: AG(Allocation Group)마다 **B+Tree**로 free space 관리.
- **ext4 mballoc**: **buddy + 예약 창** 혼합, 근접성/연속성 최적화.
- 장점: 대용량에서 확장성, 동시성(AG 단위 락/CPU 로컬 큐).

---

### SSD/NVMe 고려 사항

- **지우기(erase)** 단위(예: 2MiB)와 **쓰기(프로그램)** 단위(예: 16KiB)의 차이 → **정렬(1MiB)** & **대형 연속 쓰기**가 유리.
- **TRIM/Discard**: free 공간을 장치에 알려 **GC 효율** 개선.
- **쓰기 증폭(WA)** 줄이기: 지연 할당/그룹 커밋/대형 청크.

---

### 크래시 일관성 (free-space)

- 비트맵/트리 갱신은 **저널링 트랜잭션**으로 묶거나 COW에서 **새 루트 커밋**으로 원자화.
- “할당 → 데이터 쓰기 → 메타 갱신”에서 **순서**가 깨지면 **유령 할당/중복 할당** 발생 → 저널 순서/배리어 필수.

---

## Efficiency and Performance

### 성능 모델(간단 근사)

**HDD** 평균 접근시간:
$$
T_{\text{HDD}} \approx T_{\text{seek}} + T_{\text{rot}} + \frac{S}{R}
$$
**SSD** 랜덤 I/O:
- 처리량 \(\approx \min(Q \cdot \text{IOPS}_{\text{per\,queue}}, \text{장치 최대})\)
- p99 지연은 **큐 딥/GC/배리어** 영향.

**파일 접근시간**
조각 수 \(m\)과 파일 크기 \(S\)에서
$$
E[T] \approx m\cdot t_0 + \frac{S}{\text{BW}}
$$
→ **extent 수(m) 최소화**가 가장 중요.

---

### 고성능을 위한 설계 패턴

1) **Delayed Allocation(+Extent)**: 쓰기 패턴을 관찰 후 **큰 연속 범위** 할당 → 조각화↓, 쓰기 증폭↓.
2) **Preallocation / fallocate**: 예측 가능 성장 파일(DB/WAL/로그)에 **미리 큰 청크** 확보.
3) **Writeback Clustering**: 더러운 페이지를 **인접 순서**로 묶어 플러시.
4) **Block/Allocation Groups 근접성**: **디렉터리/아이노드/데이터**를 **같은 그룹/AG**에 → 검색/메타I/O 줄이기.
5) **Journal Mode & Commit Interval**: `ordered`/`writeback`/`data=journal`, `commit=5s` vs **SLO** 기반 조정.
6) **I/O 크기/정렬**: 128KiB~1MiB **정렬 쓰기**로 병합/장치 내부 병렬성 활용.
7) **Direct I/O**: DB 등에서 **페이지 캐시 우회**로 이중 캐싱 제거.
8) **파일 인라인/Small-file packing**: 메타 오버헤드/랜덤 I/O 감소.
9) **Readahead 힌트**: 순차 접근에 `posix_fadvise(SEQUENTIAL/WILLNEED)`.
10) **NUMA/멀틱**: per-CPU/AG 락과 IRQ/locality 정렬.

---

### 시뮬레이터: 정책별 조각화·I/O 시간 비교

```python
# vs extent-best-fit 비교(개념 시뮬)

import random
from extent_alloc import FreeExtents
BLKS=200000
files=[]

def simulate_contiguous():
    bm=[0]*BLKS
    from contiguous_alloc import find_run
    def alloc(k):
        pos=find_run(bm,k,"best")  # best-fit 연속
        if pos is None: return None
        for i in range(pos,pos+k): bm[i]=1
        return [(pos,k)]
    return alloc

def simulate_extent():
    fe=FreeExtents(); fe.ext=[(0,BLKS)]
    def alloc(k): return [fe.alloc(k)]  # 하나의 큰 extent 시도
    return alloc

def simulate_random():
    bm=[0]*BLKS
    def alloc(k):
        out=[]; need=k
        while need>0:
            pos=random.randrange(BLKS)
            if bm[pos]==0:
                bm[pos]=1; out.append((pos,1)); need-=1
        # 병합 생략(가장 조각화됨)
        return out
    return alloc

def iotime(extents, blk_time=50e-6, xfer_per_blk=5e-6):
    # 블록당 고정오버헤드 + 전송 시간 (단순 근사)
    m=sum(1 for e in extents if e)  # extent 수
    s=sum(l for _,l in extents if e) if (e:=True) else 0
    return m*blk_time + s*xfer_per_blk

for name, mk in [("contig",simulate_contiguous),("extent",simulate_extent),("random",simulate_random)]:
    alloc=mk(); total=0.0; msum=0
    for _ in range(1000):
        size=random.randint(32,4096)   # 블록 단위
        ex=alloc(size);
        if ex is None: break
        m=sum(1 for e in ex if e)
        msum+=m; total+=iotime(ex)
    print(name, "avg_extents=", msum/1000, "avg_time(us)=", total/1000*1e6)
```

**예상 경향**
- `contig/extent` 는 평균 extent 수가 **1에 근접**, `random` 은 **크게 증가** → I/O 오버헤드↑.

---

### 운영 실습: `fallocate`/`posix_fadvise`/`fio`

```c
// reserve.c — fallocate로 대형 연속 예약 + 순차 쓰기
#define _GNU_SOURCE
#include <fcntl.h>
#include <unistd.h>
#include <stdio.h>
#include <sys/stat.h>

int main(){
  int fd=open("big.dat",O_CREAT|O_RDWR|O_DIRECT,0644);
  off_t bytes=1LL<<30;                 // 1 GiB
  fallocate(fd, 0, 0, bytes);          // 미리 연속 공간 확보
  posix_fadvise(fd,0,bytes,POSIX_FADV_SEQUENTIAL);
  // 정렬 버퍼로 큰 블록 단위 쓰기(생략)
  close(fd); return 0;
}
```

```ini
# fio.job — 순차/랜덤, direct=1, 큐딥/블록 크기 비교

[global]
ioengine=libaio
iodepth=32
direct=1
runtime=30
time_based=1

[seqwrite]
rw=write
bs=1m
filename=./fio_seq.dat

[randread]
rw=randread
bs=4k
filename=./fio_rand.dat
```

---

### 흔한 함정 & 대응

- **작은 동기 쓰기 + 빈번한 fsync** → 저널 커밋 폭증, p99 급등 → **그룹 커밋/배치**·주기 조정.
- **사이즈 미지정 append 파일** → 지연 할당 불리 → **fallocate 사전예약**.
- **작은 파일 폭증 + 큰 디렉터리 선형 구조** → `readdir`/lookup 지연 → **dir 해시/B+트리** 필요.
- **SSD TRIM 미사용** → 내부 GC 비효율 → **주기적 fstrim**, mount 옵션 확인.
- **멀티스레드 rename 폭주** → 락 경합 → **부모 디렉터리 분산/샤딩**, per-AG 설계.
- **NUMA 원격 메타데이터 업데이트** → 지연 증가 → **코어/IRQ/스레드 바인딩**.

---

### 체크리스트(튜닝 요약)

1) **목표 정의**: 순차 BW? 랜덤 IOPS? p99? 내구 SLA?
2) **파일 배치**: AG/그룹/근접성/예약 창.
3) **I/O 크기**: 128KiB~1MiB 정렬 쓰기, 읽기는 패턴별 readahead 조정.
4) **할당 정책**: 지연 할당 + extent best-fit, 대형 파일 fallocate.
5) **저널/배리어**: 모드/주기 조정, 장치 FUA/flush 확인.
6) **캐시 정책**: `fadvise`, Direct I/O(필요 시), dirty ratio/백그라운드 쓰레드.
7) **장치 최적화**: TRIM, 큐딥, IRQ/moderation, NUMA.
8) **관측**: 조각 수, avg extent, flush 주기, `iostat/blktrace/perf` + p99 지표.

---

## 통합 시나리오: “대용량 로그 저장소(SSD)”

**요구**: 1일 3TB append, 장애 시 1초 내 데이터 손실 한계, p99<10ms(인제스트).
**설계**
- **파일당 1~4GiB로 롤오버**, 생성 시 **`fallocate`로 4GiB 예약**.
- **지연 할당 + extent best-fit** FS(ext4/XFS).
- 쓰기는 **1MiB 배치** + `O_DIRECT` (이중 캐싱 제거) or page cache + `msync(MS_ASYNC)` 10ms.
- **배리어 그룹 커밋**: 커밋 간격 100ms, WAL 별도 파일.
- **주기적 `fstrim`**, 장치 큐딥 32~64, NUMA 로컬 IRQ.
- **모니터링**: 평균 extent 수(≈1), dirty backlog, flush latency, 장치 GC 이벤트.

---

## 핵심 요약

- **14.4 Allocation**: 연속/연결/인덱스/extent/COW 각 방법의 **성능-조각화-복잡도** 트레이드오프를 이해하라. 현대 FS는 **extent + 지연 할당 + 예약**으로 **조각 수(m)** 를 최소화한다.
- **14.5 Free-Space**: **비트맵/카운팅/버디/트리**를 적절히 조합해 **빠른 연속 할당**과 **낮은 메타 오버헤드**를 달성한다. SSD에서는 **정렬/대형 청크/Discard**가 핵심.
- **14.6 효율/성능**: 성능 모델을 수치로 세우고(**p99**, extent 수, flush 주기), **사전예약/지연할당/클러스터링/배리어**로 병목을 제거하라. 설계-운영-관측이 함께 돌아가야 한다.
