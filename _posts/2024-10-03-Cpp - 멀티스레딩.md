---
layout: post
title: C++ - 멀티스레딩
date: 2024-10-03 19:20:23 +0900
category: Cpp
---
# C++ 멀티스레딩과 동기화: 안전한 동시성 프로그래밍 가이드

## 서론: 왜 멀티스레딩이 필요한가?

현대 컴퓨터는 멀티코어 프로세서가 표준입니다. 단일 스레드 프로그램은 이 강력한 하드웨어를 충분히 활용하지 못합니다. 멀티스레딩을 통해 우리는:

1. **성능 향상**: 계산 작업을 여러 코어에 분배
2. **반응성 향상**: UI 스레드를 차단하지 않고 백그라운드 작업 수행
3. **효율성**: I/O 대기 시간 동안 다른 작업 수행

하지만 이 힘에는 큰 책임이 따릅니다. 스레드 안전성, 교착 상태, 경쟁 조건 등의 복잡한 문제들을 이해하고 관리해야 합니다.

---

## 제1장: 스레드 기초 - `std::thread`

### 스레드 생성과 관리

```cpp
#include <iostream>
#include <thread>
#include <vector>

void print_hello(int id) {
    std::cout << "Hello from thread " << id << std::endl;
}

void basic_thread_example() {
    std::vector<std::thread> threads;
    
    // 5개의 스레드 생성
    for (int i = 0; i < 5; ++i) {
        threads.emplace_back(print_hello, i);
    }
    
    // 모든 스레드가 완료될 때까지 기다림
    for (auto& thread : threads) {
        thread.join();
    }
    
    std::cout << "모든 스레드가 종료되었습니다." << std::endl;
}
```

### `join()` vs `detach()`

```cpp
#include <thread>
#include <iostream>
#include <chrono>

void long_running_task() {
    std::this_thread::sleep_for(std::chrono::seconds(2));
    std::cout << "긴 작업 완료" << std::endl;
}

void join_detach_example() {
    // join 예제: 메인 스레드가 작업 완료를 기다림
    std::thread t1(long_running_task);
    if (t1.joinable()) {
        t1.join();  // t1이 완료될 때까지 블록
    }
    
    // detach 예제: 백그라운드에서 실행 (위험!)
    std::thread t2(long_running_task);
    t2.detach();  // t2를 백그라운드로 분리
    // t2는 계속 실행되지만, 메인 스레드와 연결 끊김
    
    std::cout << "메인 스레드 계속 실행" << std::endl;
    // 프로그램 종료 시 detach된 스레드가 여전히 실행 중이면 미정의 동작
}
```

**중요 원칙**: 가능하면 항상 `join()`을 사용하세요. `detach()`는 신중히 사용해야 합니다.

### 람다와 스레드

```cpp
#include <thread>
#include <iostream>
#include <vector>

void lambda_thread_example() {
    std::vector<int> data = {1, 2, 3, 4, 5};
    std::vector<std::thread> workers;
    std::vector<int> results(data.size());
    
    // 각 데이터 항목을 별도 스레드에서 처리
    for (size_t i = 0; i < data.size(); ++i) {
        workers.emplace_back([i, &data, &results]() {
            // 안전한 계산 (지금은 동기화 없음)
            results[i] = data[i] * data[i];
        });
    }
    
    // 모든 작업 완료 대기
    for (auto& worker : workers) {
        worker.join();
    }
    
    // 결과 출력
    for (int result : results) {
        std::cout << result << " ";
    }
    std::cout << std::endl;
}
```

---

## 제2장: 상호 배제 - `std::mutex`와 락

### 데이터 레이스의 위험

```cpp
#include <thread>
#include <iostream>
#include <vector>

int counter = 0;  // 공유 변수

void unsafe_increment() {
    for (int i = 0; i < 100000; ++i) {
        ++counter;  // 데이터 레이스 발생!
    }
}

void data_race_example() {
    std::thread t1(unsafe_increment);
    std::thread t2(unsafe_increment);
    
    t1.join();
    t2.join();
    
    // 결과가 200000이 아닐 수 있음!
    std::cout << "Counter: " << counter << std::endl;
}
```

### `std::mutex`로 안전하게 보호하기

```cpp
#include <mutex>
#include <thread>
#include <iostream>

std::mutex counter_mutex;
int safe_counter = 0;

void safe_increment() {
    for (int i = 0; i < 100000; ++i) {
        std::lock_guard<std::mutex> lock(counter_mutex);
        ++safe_counter;  // 안전하게 보호됨
    }
}

void mutex_example() {
    std::thread t1(safe_increment);
    std::thread t2(safe_increment);
    
    t1.join();
    t2.join();
    
    // 항상 200000 출력
    std::cout << "Safe Counter: " << safe_counter << std::endl;
}
```

### 다양한 락 종류

```cpp
#include <mutex>
#include <thread>
#include <iostream>

std::mutex mtx;

void lock_types_example() {
    // 1. lock_guard: 가장 간단한 RAII 락
    {
        std::lock_guard<std::mutex> lock(mtx);
        std::cout << "lock_guard로 보호된 영역" << std::endl;
    }
    
    // 2. unique_lock: 더 많은 유연성
    std::unique_lock<std::mutex> ulock(mtx, std::defer_lock);
    // ... 다른 작업 ...
    ulock.lock();  // 명시적으로 잠금
    std::cout << "unique_lock으로 보호된 영역" << std::endl;
    ulock.unlock();  // 명시적으로 해제
    
    // 3. scoped_lock: 여러 뮤텍스를 안전하게 잠금 (C++17)
    std::mutex mtx1, mtx2;
    {
        std::scoped_lock lock(mtx1, mtx2);  // 교착 상태 방지
        std::cout << "scoped_lock으로 보호된 영역" << std::endl;
    }
}
```

---

## 제3장: 조건 변수 - 스레드 간 신호 전달

### 생산자-소비자 패턴

```cpp
#include <queue>
#include <mutex>
#include <condition_variable>
#include <thread>
#include <iostream>
#include <chrono>

class ThreadSafeQueue {
private:
    std::queue<int> queue_;
    mutable std::mutex mutex_;
    std::condition_variable not_empty_;
    std::condition_variable not_full_;
    size_t capacity_;
    bool shutdown_ = false;
    
public:
    explicit ThreadSafeQueue(size_t capacity) : capacity_(capacity) {}
    
    void shutdown() {
        {
            std::lock_guard<std::mutex> lock(mutex_);
            shutdown_ = true;
        }
        not_empty_.notify_all();
        not_full_.notify_all();
    }
    
    bool push(int value, std::chrono::milliseconds timeout) {
        std::unique_lock<std::mutex> lock(mutex_);
        
        // 큐에 공간이 생길 때까지 대기 (타임아웃 포함)
        if (!not_full_.wait_for(lock, timeout, [this]() {
            return queue_.size() < capacity_ || shutdown_;
        })) {
            return false;  // 타임아웃
        }
        
        if (shutdown_) return false;
        
        queue_.push(value);
        not_empty_.notify_one();  // 소비자에게 알림
        return true;
    }
    
    bool pop(int& value, std::chrono::milliseconds timeout) {
        std::unique_lock<std::mutex> lock(mutex_);
        
        // 큐에 데이터가 있을 때까지 대기 (타임아웃 포함)
        if (!not_empty_.wait_for(lock, timeout, [this]() {
            return !queue_.empty() || shutdown_;
        })) {
            return false;  // 타임아웃
        }
        
        if (shutdown_ && queue_.empty()) return false;
        
        value = queue_.front();
        queue_.pop();
        not_full_.notify_one();  // 생산자에게 알림
        return true;
    }
};

void producer_consumer_example() {
    ThreadSafeQueue queue(10);
    
    std::thread producer([&queue]() {
        for (int i = 0; i < 20; ++i) {
            if (queue.push(i, std::chrono::seconds(1))) {
                std::cout << "생산: " << i << std::endl;
            } else {
                std::cout << "생산 타임아웃" << std::endl;
            }
            std::this_thread::sleep_for(std::chrono::milliseconds(100));
        }
        queue.shutdown();
    });
    
    std::thread consumer([&queue]() {
        int value;
        while (queue.pop(value, std::chrono::seconds(1))) {
            std::cout << "소비: " << value << std::endl;
            std::this_thread::sleep_for(std::chrono::milliseconds(150));
        }
        std::cout << "소비자 종료" << std::endl;
    });
    
    producer.join();
    consumer.join();
}
```

### 조건 변수의 올바른 사용 패턴

```cpp
#include <condition_variable>
#include <mutex>
#include <thread>
#include <iostream>

class Worker {
private:
    std::mutex mutex_;
    std::condition_variable cv_;
    bool ready_ = false;
    bool shutdown_ = false;
    
public:
    void wait_for_work() {
        std::unique_lock<std::mutex> lock(mutex_);
        
        // 올바른 패턴: while 루프로 조건 재확인
        cv_.wait(lock, [this]() {
            return ready_ || shutdown_;
        });
        
        if (ready_) {
            std::cout << "작업 시작" << std::endl;
            ready_ = false;
        }
    }
    
    void signal_work() {
        {
            std::lock_guard<std::mutex> lock(mutex_);
            ready_ = true;
        }
        cv_.notify_one();  // 하나의 대기 중인 스레드 깨움
    }
    
    void signal_all() {
        {
            std::lock_guard<std::mutex> lock(mutex_);
            ready_ = true;
        }
        cv_.notify_all();  // 모든 대기 중인 스레드 깨움
    }
    
    void shutdown() {
        {
            std::lock_guard<std::mutex> lock(mutex_);
            shutdown_ = true;
        }
        cv_.notify_all();
    }
};
```

---

## 제4장: 원자 연산과 메모리 모델

### `std::atomic` 기본 사용

```cpp
#include <atomic>
#include <thread>
#include <iostream>
#include <vector>

std::atomic<int> atomic_counter(0);

void atomic_increment() {
    for (int i = 0; i < 100000; ++i) {
        atomic_counter.fetch_add(1, std::memory_order_relaxed);
    }
}

void atomic_example() {
    std::vector<std::thread> threads;
    
    for (int i = 0; i < 10; ++i) {
        threads.emplace_back(atomic_increment);
    }
    
    for (auto& thread : threads) {
        thread.join();
    }
    
    std::cout << "원자 카운터: " << atomic_counter << std::endl;
}
```

### 메모리 순서 이해하기

```cpp
#include <atomic>
#include <thread>
#include <iostream>

std::atomic<int> x{0}, y{0};
int r1, r2;

void thread1() {
    x.store(1, std::memory_order_release);
    r1 = y.load(std::memory_order_acquire);
}

void thread2() {
    y.store(1, std::memory_order_release);
    r2 = x.load(std::memory_order_acquire);
}

void memory_order_example() {
    std::thread t1(thread1);
    std::thread t2(thread2);
    
    t1.join();
    t2.join();
    
    std::cout << "r1: " << r1 << ", r2: " << r2 << std::endl;
    // 강한 메모리 모델에서는 r1 == r2 == 1이 보장되지만,
    // 약한 모델에서는 r1 == 0 && r2 == 0도 가능
}
```

### Compare-And-Swap (CAS) 패턴

```cpp
#include <atomic>
#include <iostream>

class LockFreeStack {
private:
    struct Node {
        int value;
        Node* next;
    };
    
    std::atomic<Node*> head_{nullptr};
    
public:
    void push(int value) {
        Node* new_node = new Node{value, nullptr};
        new_node->next = head_.load(std::memory_order_relaxed);
        
        // CAS로 원자적으로 head 업데이트
        while (!head_.compare_exchange_weak(
            new_node->next, 
            new_node,
            std::memory_order_release,
            std::memory_order_relaxed)) {
            // 다른 스레드가 먼저 삽입했으면 재시도
        }
    }
    
    bool pop(int& value) {
        Node* old_head = head_.load(std::memory_order_relaxed);
        if (!old_head) return false;
        
        // CAS로 원자적으로 head 제거
        while (!head_.compare_exchange_weak(
            old_head,
            old_head->next,
            std::memory_order_release,
            std::memory_order_relaxed)) {
            if (!old_head) return false;
        }
        
        value = old_head->value;
        delete old_head;
        return true;
    }
};
```

---

## 제5장: 고급 패턴과 최적화

### 스레드 풀 구현

```cpp
#include <vector>
#include <queue>
#include <thread>
#include <functional>
#include <mutex>
#include <condition_variable>
#include <future>
#include <memory>
#include <iostream>

class ThreadPool {
private:
    std::vector<std::thread> workers_;
    std::queue<std::function<void()>> tasks_;
    std::mutex queue_mutex_;
    std::condition_variable condition_;
    bool stop_ = false;
    
public:
    explicit ThreadPool(size_t threads) {
        for (size_t i = 0; i < threads; ++i) {
            workers_.emplace_back([this] {
                while (true) {
                    std::function<void()> task;
                    {
                        std::unique_lock<std::mutex> lock(queue_mutex_);
                        condition_.wait(lock, [this] {
                            return stop_ || !tasks_.empty();
                        });
                        
                        if (stop_ && tasks_.empty()) return;
                        
                        task = std::move(tasks_.front());
                        tasks_.pop();
                    }
                    task();
                }
            });
        }
    }
    
    template<class F, class... Args>
    auto enqueue(F&& f, Args&&... args) 
        -> std::future<typename std::result_of<F(Args...)>::type> {
        
        using return_type = typename std::result_of<F(Args...)>::type;
        
        auto task = std::make_shared<std::packaged_task<return_type()>>(
            std::bind(std::forward<F>(f), std::forward<Args>(args)...)
        );
        
        std::future<return_type> result = task->get_future();
        {
            std::lock_guard<std::mutex> lock(queue_mutex_);
            if (stop_) {
                throw std::runtime_error("스레드 풀이 중지되었습니다");
            }
            tasks_.emplace([task]() { (*task)(); });
        }
        condition_.notify_one();
        return result;
    }
    
    ~ThreadPool() {
        {
            std::lock_guard<std::mutex> lock(queue_mutex_);
            stop_ = true;
        }
        condition_.notify_all();
        for (std::thread& worker : workers_) {
            worker.join();
        }
    }
};

void thread_pool_example() {
    ThreadPool pool(4);
    std::vector<std::future<int>> results;
    
    for (int i = 0; i < 8; ++i) {
        results.emplace_back(pool.enqueue([i] {
            std::cout << "작업 " << i << " 시작" << std::endl;
            std::this_thread::sleep_for(std::chrono::seconds(1));
            std::cout << "작업 " << i << " 완료" << std::endl;
            return i * i;
        }));
    }
    
    for (auto& result : results) {
        std::cout << "결과: " << result.get() << std::endl;
    }
}
```

### 읽기-쓰기 락

```cpp
#include <shared_mutex>
#include <map>
#include <string>
#include <thread>
#include <iostream>

class ThreadSafeDictionary {
private:
    std::map<std::string, std::string> data_;
    mutable std::shared_mutex mutex_;  // 읽기-쓰기 락
    
public:
    // 읽기 작업: 여러 스레드에서 동시 접근 가능
    std::string get(const std::string& key) const {
        std::shared_lock<std::shared_mutex> lock(mutex_);
        auto it = data_.find(key);
        return it != data_.end() ? it->second : "";
    }
    
    // 쓰기 작업: 배타적 접근 필요
    void set(const std::string& key, const std::string& value) {
        std::unique_lock<std::shared_mutex> lock(mutex_);
        data_[key] = value;
    }
    
    // 여러 항목 읽기
    std::map<std::string, std::string> snapshot() const {
        std::shared_lock<std::shared_mutex> lock(mutex_);
        return data_;  // 복사본 반환
    }
};
```

### C++20 `std::jthread`와 취소 기능

```cpp
#include <thread>
#include <stop_token>
#include <iostream>
#include <chrono>

void cancellable_worker(std::stop_token stoken) {
    while (!stoken.stop_requested()) {
        std::cout << "작업 중..." << std::endl;
        std::this_thread::sleep_for(std::chrono::seconds(1));
    }
    std::cout << "작업 취소됨" << std::endl;
}

void jthread_example() {
    std::jthread worker(cancellable_worker);
    
    // 3초 후 작업 취소
    std::this_thread::sleep_for(std::chrono::seconds(3));
    worker.request_stop();
    
    // 자동으로 join() 호출됨
}
```

---

## 제6장: 성능 최적화와 문제 진단

### False Sharing 방지

```cpp
#include <thread>
#include <vector>
#include <atomic>
#include <chrono>
#include <iostream>

// 문제: false sharing 발생
struct BadCounter {
    std::atomic<int> a;
    std::atomic<int> b;
};

// 해결: 캐시 라인 정렬
struct alignas(64) GoodCounter {
    std::atomic<int> a;
    char padding[64 - sizeof(std::atomic<int>)];
    std::atomic<int> b;
};

void false_sharing_example() {
    BadCounter bad;
    GoodCounter good;
    
    auto start = std::chrono::high_resolution_clock::now();
    
    std::thread t1([&bad]() {
        for (int i = 0; i < 10000000; ++i) {
            bad.a.fetch_add(1, std::memory_order_relaxed);
        }
    });
    
    std::thread t2([&bad]() {
        for (int i = 0; i < 10000000; ++i) {
            bad.b.fetch_add(1, std::memory_order_relaxed);
        }
    });
    
    t1.join();
    t2.join();
    
    auto mid = std::chrono::high_resolution_clock::now();
    
    std::thread t3([&good]() {
        for (int i = 0; i < 10000000; ++i) {
            good.a.fetch_add(1, std::memory_order_relaxed);
        }
    });
    
    std::thread t4([&good]() {
        for (int i = 0; i < 10000000; ++i) {
            good.b.fetch_add(1, std::memory_order_relaxed);
        }
    });
    
    t3.join();
    t4.join();
    
    auto end = std::chrono::high_resolution_clock::now();
    
    std::cout << "False sharing: " 
              << std::chrono::duration_cast<std::chrono::milliseconds>(mid - start).count() 
              << "ms" << std::endl;
    std::cout << "Aligned: " 
              << std::chrono::duration_cast<std::chrono::milliseconds>(end - mid).count() 
              << "ms" << std::endl;
}
```

### 병렬 알고리즘 성능 분석

```cpp
#include <algorithm>
#include <vector>
#include <thread>
#include <chrono>
#include <iostream>
#include <numeric>

void parallel_accumulate(const std::vector<int>& data, size_t num_threads) {
    auto start = std::chrono::high_resolution_clock::now();
    
    std::vector<std::thread> threads;
    std::vector<long long> partial_sums(num_threads, 0);
    size_t chunk_size = data.size() / num_threads;
    
    for (size_t i = 0; i < num_threads; ++i) {
        size_t begin = i * chunk_size;
        size_t end = (i == num_threads - 1) ? data.size() : begin + chunk_size;
        
        threads.emplace_back([&data, &partial_sums, i, begin, end]() {
            partial_sums[i] = std::accumulate(
                data.begin() + begin,
                data.begin() + end,
                0LL
            );
        });
    }
    
    for (auto& thread : threads) {
        thread.join();
    }
    
    long long total = std::accumulate(partial_sums.begin(), partial_sums.end(), 0LL);
    
    auto end = std::chrono::high_resolution_clock::now();
    auto duration = std::chrono::duration_cast<std::chrono::milliseconds>(end - start);
    
    std::cout << num_threads << " 스레드: " << duration.count() << "ms, 합계: " << total << std::endl;
}

void parallel_performance_example() {
    std::vector<int> data(10000000);
    std::iota(data.begin(), data.end(), 1);  // 1부터 10000000까지
    
    for (size_t threads : {1, 2, 4, 8, 16}) {
        parallel_accumulate(data, threads);
    }
}
```

---

## 결론: 안전한 멀티스레딩을 위한 원칙

### 1. **기본부터 탄탄하게**
   - 단일 스레드에서 정확히 작동하는 코드부터 시작하세요
   - 점진적으로 병렬화를 추가하세요
   - 프로파일링으로 실제 병목을 찾으세요

### 2. **RAII를 철저히 적용하세요**
   - `std::lock_guard`와 `std::unique_lock`로 락을 관리하세요
   - 자원 누수를 방지하세요
   - 예외 안전성을 보장하세요

### 3. **동기화 도구를 올바르게 선택하세요**
   - 간단한 카운터: `std::atomic`
   - 복잡한 데이터 구조: `std::mutex`
   - 생산자-소비자 패턴: `std::condition_variable`
   - 읽기 많은 데이터: `std::shared_mutex`

### 4. **교착 상태를 예방하세요**
   - 항상 동일한 순서로 락을 획득하세요
   - `std::scoped_lock`로 여러 뮤텍스를 안전하게 잠그세요
   - 락을 오래 보유하지 마세요

### 5. **성능을 측정하고 최적화하세요**
   - False sharing을 피하세요
   - 불필요한 동기화를 제거하세요
   - 작업 부하를 균등하게 분배하세요

### 6. **도구를 활용하세요**
   - ThreadSanitizer로 데이터 레이스를 찾으세요
   - 프로파일러로 성병 병목을 찾으세요
   - 디버거로 교착 상태를 분석하세요

### 7. **단순성을 유지하세요**
   - 가능하면 높은 수준의 추상화를 사용하세요
   - 너무 복잡한 락프리 알고리즘은 피하세요
   - 가독성을 희생하지 마세요

멀티스레딩은 강력한 도구이지만, 올바르게 사용해야 합니다. 처음에는 어려울 수 있지만, 원칙을 이해하고 체계적으로 접근하면 안전하고 효율적인 동시성 코드를 작성할 수 있습니다. 가장 중요한 것은 항상 테스트하고 측정하며, 작은 단계로 나아가는 것입니다.

기억하세요: 멀티스레딩에서 가장 어려운 부분은 버그를 재현하고 디버깅하는 것입니다. 예방이 최선의 치료법입니다.