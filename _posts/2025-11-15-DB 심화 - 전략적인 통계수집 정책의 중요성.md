---
layout: post
title: DB 심화 - 전략적인 통계수집 정책의 중요성
date: 2025-11-15 23:25:23 +0900
category: DB 심화
---
# 전략적인 통계수집 정책의 중요성 — Oracle `DBMS_STATS` 실전 가이드

> 실행 후에는 반드시 **실측 플랜**으로 효과를 검증하세요.
```sql
SELECT *
FROM   TABLE(DBMS_XPLAN.DISPLAY_CURSOR(
         NULL, NULL,
        'ALLSTATS LAST +PREDICATE +PEEKED_BINDS +IOSTATS +MEMSTATS'
));
```

---

## 0) 왜 “전략적인” 통계수집인가?

옵티마이저의 판단(카디널리티, 조인 순서/방법, 액세스 경로)은 **통계의 정확도/적시성**에 좌우됩니다.
무전략적 일괄 수집은 다음 문제를 일으킵니다.

- **스큐 미반영** → 상위값/희소값에 같은 플랜 (과소/과대 추정 → 랜덤 I/O 폭증)
- **지나치게 잦은 재수집** → 플랜 변동성 ↑, 하드파싱/라이브러리 캐시 압박
- **대형 파티션 테이블 전체 재수집** → 긴 배치 시간, 불필요한 I/O/CPU 소모
- **샘플링 과소/과대** → NDV/히스토그램 부정확, 비용 모델 왜곡

**핵심 원칙**
1) **변경량 기반**(Stale 기준)으로 **필요한 곳만** 수집
2) **스큐/업무 질의 기반**으로 **선택적 히스토그램**
3) 파티션 테이블은 **증분 통계**(+ Pending Stats로 안전 배포)
4) 샘플링은 **AUTO** 기본, 특정 컬럼/테이블만 **정밀/절약** 조합
5) 모든 변경은 **E-Rows vs A-Rows**·AWR/ASH로 **팩트 검증**

---

## 1) 실습 환경 만들기 (파티션 + 차원/사실 테이블)

```sql
ALTER SESSION SET nls_date_format = 'YYYY-MM-DD';
ALTER SESSION SET statistics_level = ALL;

-- 깨끗이
BEGIN
  FOR t IN (SELECT table_name FROM user_tables
            WHERE table_name IN ('D_CUSTOMER','D_PRODUCT','F_SALES')) LOOP
    EXECUTE IMMEDIATE 'DROP TABLE '||t.table_name||' PURGE';
  END LOOP;
EXCEPTION WHEN OTHERS THEN NULL; END;
/

-- 차원 테이블
CREATE TABLE D_CUSTOMER(
  CUST_ID NUMBER PRIMARY KEY,
  REGION  VARCHAR2(8),
  TIER    VARCHAR2(8)
);

CREATE TABLE D_PRODUCT(
  PROD_ID  NUMBER PRIMARY KEY,
  CATEGORY VARCHAR2(12),
  BRAND    VARCHAR2(12)
);

-- 월 파티션 사실 테이블(판매)
CREATE TABLE F_SALES(
  SALES_ID NUMBER PRIMARY KEY,
  CUST_ID  NUMBER NOT NULL,
  PROD_ID  NUMBER NOT NULL,
  SALES_DT DATE   NOT NULL,
  QTY      NUMBER NOT NULL,
  AMOUNT   NUMBER(12,2) NOT NULL
)
PARTITION BY RANGE (SALES_DT)(
  PARTITION P202401 VALUES LESS THAN (DATE '2024-02-01'),
  PARTITION P202402 VALUES LESS THAN (DATE '2024-03-01'),
  PARTITION P202403 VALUES LESS THAN (DATE '2024-04-01'),
  PARTITION PMAX    VALUES LESS THAN (MAXVALUE)
);

-- 인덱스(대표)
CREATE INDEX IX_CUST_REGION     ON D_CUSTOMER(REGION, CUST_ID);
CREATE INDEX IX_PROD_CAT_BRAND  ON D_PRODUCT(CATEGORY, BRAND, PROD_ID);
CREATE INDEX IX_FS_CUST_DT      ON F_SALES(CUST_ID, SALES_DT) LOCAL;
CREATE INDEX IX_FS_PROD_DT      ON F_SALES(PROD_ID, SALES_DT) LOCAL;

-- 샘플 데이터(스큐 포함)
BEGIN
  FOR c IN 1..50000 LOOP
    INSERT INTO D_CUSTOMER
    VALUES(
      c,
      CASE MOD(c,6) WHEN 0 THEN 'KOR' WHEN 1 THEN 'KOR'
                    WHEN 2 THEN 'APAC' WHEN 3 THEN 'EMEA'
                    WHEN 4 THEN 'AMER' ELSE 'JPN' END,
      CASE MOD(c,4) WHEN 0 THEN 'VIP' WHEN 1 THEN 'GOLD'
                    WHEN 2 THEN 'SILVER' ELSE 'GEN' END
    );
  END LOOP;

  FOR p IN 1..20000 LOOP
    INSERT INTO D_PRODUCT
    VALUES(
      p,
      CASE MOD(p,5) WHEN 0 THEN 'ELEC' WHEN 1 THEN 'FOOD'
                    WHEN 2 THEN 'TOY'  WHEN 3 THEN 'HOME' ELSE 'FASH' END,
      CASE WHEN p <= 6000 THEN 'B0' ELSE 'B'||LPAD(TO_CHAR(MOD(p,80)),2,'0') END
    );
  END LOOP;

  FOR m IN 1..3 LOOP  -- 1~3월 분산 삽입
    FOR r IN 1..150000 LOOP
      INSERT INTO F_SALES
      VALUES(
        (m-1)*150000 + r,
        MOD(r,50000)+1,
        MOD(r,20000)+1,
        ADD_MONTHS(DATE '2024-01-15', m-1) + MOD(r,28),
        1 + MOD(r,5),
        ROUND(DBMS_RANDOM.VALUE(10,800),2)
      );
    END LOOP;
  END LOOP;
  COMMIT;
END;
/

-- 최초 통계(히스토그램은 후에 선별 적용)
BEGIN
  DBMS_STATS.GATHER_TABLE_STATS(USER,'D_CUSTOMER', cascade=>TRUE, method_opt=>'FOR ALL COLUMNS SIZE 1');
  DBMS_STATS.GATHER_TABLE_STATS(USER,'D_PRODUCT' , cascade=>TRUE, method_opt=>'FOR ALL COLUMNS SIZE 1');
  DBMS_STATS.GATHER_TABLE_STATS(USER,'F_SALES'   , cascade=>TRUE, method_opt=>'FOR ALL COLUMNS SIZE 1', granularity=>'GLOBAL AND PARTITION');
END;
/
```

---

## 2) `DBMS_STATS` 핵심 API & 운영 스니펫

### 기본 수집

```sql
-- 스키마 단위 전체 수집(일회성): AUTO 샘플 + 히스토그램 판단도 AUTO
BEGIN
  DBMS_STATS.GATHER_SCHEMA_STATS(
    ownname          => USER,
    options          => 'GATHER',
    estimate_percent => DBMS_STATS.AUTO_SAMPLE_SIZE,
    method_opt       => 'FOR ALL COLUMNS SIZE AUTO',
    cascade          => TRUE,
    degree           => DBMS_STATS.AUTO_DEGREE  -- 병렬 자동
  );
END;
/
```

### 테이블 선호 설정(Preferences)

```sql
-- 변경량 기준/플랜 안정화/증분 통계 등 테이블별 선호 설정
BEGIN
  -- 변경량 임계치: 5%만 변해도 Stale 처리
  DBMS_STATS.SET_TABLE_PREFS(USER,'F_SALES','STALE_PERCENT','5');

  -- 플랜 무효화 지연(하드파싱 폭주 방지)
  DBMS_STATS.SET_TABLE_PREFS(USER,'F_SALES','NO_INVALIDATE','TRUE');

  -- Pending Stats: 수집은 하되 바로 게시하지 않음(검증 후 게시)
  DBMS_STATS.SET_TABLE_PREFS(USER,'F_SALES','PUBLISH','FALSE');

  -- 파티션 테이블: 증분 통계 활성화(신규 파티션만 수집)
  DBMS_STATS.SET_TABLE_PREFS(USER,'F_SALES','INCREMENTAL','TRUE');

  -- 증분 통계의 신선도(옵션): 파티션 교체 등 상황 고려
  -- DBMS_STATS.SET_TABLE_PREFS(USER,'F_SALES','INCREMENTAL_STALENESS','USE_STALE_STATS');

  -- 그라뉼러리티: AUTO 권장(글로벌/파티션 자동 판단)
  DBMS_STATS.SET_TABLE_PREFS(USER,'F_SALES','GRANULARITY','AUTO');
END;
/
```

### 수집/검증/게시(Pending Stats 활용)

```sql
-- 수집(게시 보류)
BEGIN
  DBMS_STATS.GATHER_TABLE_STATS(USER,'F_SALES', cascade=>TRUE);
END;
/

-- 테스트 세션에서 Pending Stats만 보이게
ALTER SESSION SET optimizer_use_pending_statistics = TRUE;

-- 핵심 리포트 쿼리 실행 → 플랜/카디널리티 검증
EXPLAIN PLAN FOR
SELECT /* rpt */ p.category, SUM(s.amount)
FROM   F_SALES s
JOIN   D_PRODUCT p ON p.prod_id = s.prod_id
WHERE  s.sales_dt BETWEEN DATE '2024-03-01' AND DATE '2024-03-31'
GROUP  BY p.category;

SELECT * FROM TABLE(DBMS_XPLAN.DISPLAY);

-- 문제 없으면 게시(PUBLISH)
BEGIN
  DBMS_STATS.PUBLISH_PENDING_STATS(USER,'F_SALES');
END;
/

-- 이력 비교(이전 vs 현재 통계 차이 확인)
SELECT DBMS_STATS.DIFF_TABLE_STATS_IN_HISTORY(USER,'F_SALES', SYSTIMESTAMP-1, SYSTIMESTAMP) AS diff
FROM   dual;
```

### 통계 백업/복원/잠금

```sql
-- 백업 테이블
EXEC DBMS_STATS.CREATE_STAT_TABLE(USER,'STAT_BKP');

-- Export/Import
EXEC DBMS_STATS.EXPORT_SCHEMA_STATS(USER,'STAT_BKP');
-- ... 필요 시
EXEC DBMS_STATS.IMPORT_SCHEMA_STATS(USER,'STAT_BKP');

-- 특정 테이블 복원(과거 시점)
EXEC DBMS_STATS.RESTORE_TABLE_STATS(USER,'F_SALES', SYSTIMESTAMP - INTERVAL '2' HOUR);

-- 자동 수집 방지(잠금) / 해제
EXEC DBMS_STATS.LOCK_TABLE_STATS(USER,'D_PRODUCT');
EXEC DBMS_STATS.UNLOCK_TABLE_STATS(USER,'D_PRODUCT');
```

### 변경량(모디피케이션) 확인 & Flush

```sql
-- 테이블 변경 모니터링 뷰(백그라운드 지연 → 수집 전 강제 Flush 권장)
EXEC DBMS_STATS.FLUSH_DATABASE_MONITORING_INFO;

SELECT table_name, inserts, updates, deletes, timestamp, truncated
FROM   user_tab_modifications
WHERE  table_name IN ('F_SALES','D_PRODUCT')
ORDER  BY timestamp DESC;
```

---

## 3) **칼럼 히스토그램** 수집 전략

### 원칙

- 스큐가 **큰 컬럼** & **where/join 조건**에 **자주 등장**하는 컬럼만
- 히스토그램 남발은 **플랜 변동성**↑ (바인드/ACS와 상호작용)
- 기본은 `SIZE AUTO` → 필요 컬럼만 **정밀 지정**

### 도수분포/Top-Frequency(카테고리형)

```sql
-- 스큐가 큰 BRAND는 정밀히, 나머지는 SIZE 1
BEGIN
  DBMS_STATS.GATHER_TABLE_STATS(
    ownname    => USER,
    tabname    => 'D_PRODUCT',
    method_opt => 'FOR COLUMNS SIZE 254 BRAND, FOR ALL COLUMNS SIZE 1',
    cascade    => TRUE
  );
END;
/

SELECT column_name, histogram, num_distinct, density, last_analyzed
FROM   user_tab_col_statistics
WHERE  table_name='D_PRODUCT' AND column_name='BRAND';
```
- **대량값(B0)**과 **희소값(B47)**의 E-Rows가 **명확히 차별**되어 인덱스/풀스캔 선택이 현실화됩니다.

### 높이균형/하이브리드(연속형/범위)

```sql
-- 연속형 분포 AMOUNT에 구간 분포 반영
BEGIN
  DBMS_STATS.GATHER_TABLE_STATS(
    ownname    => USER,
    tabname    => 'F_SALES',
    method_opt => 'FOR COLUMNS SIZE 254 AMOUNT',
    cascade    => TRUE
  );
END;
/
SELECT column_name, histogram
FROM   user_tab_col_statistics
WHERE  table_name='F_SALES' AND column_name='AMOUNT';
```
- 범위 조건(예: 10~100 vs 500~700)의 **카디널리티 차이**가 플랜에 제대로 반영됩니다.

### 업무 질의 기반 선별(컬럼 사용 리포트)

```sql
-- (권장) 업무 질의로 실제 사용된 컬럼 수집을 활성화/리포트
EXEC DBMS_STATS.SEED_COL_USAGE(NULL, NULL, 300); -- 초 단위(예: 5분간 활성화)

-- 이후 리포트: 어떤 컬럼이 프레디킷/그룹/조인에 쓰였는지
SELECT DBMS_STATS.REPORT_COL_USAGE(USER,'F_SALES') AS report FROM dual;
```
- 이 리포트를 참고하여 **히스토그램 대상 컬럼**을 좁힙니다.

---

## 4) **데이터 샘플링** 전략 (`estimate_percent`)

### AUTO vs 수동 퍼센트

- **기본 권장:** `estimate_percent => DBMS_STATS.AUTO_SAMPLE_SIZE`
  - 버전에 따라 개선된 알고리즘(근사 NDV/HyperLogLog 유사)을 사용해 **정확도/시간** 균형
- **수동 퍼센트**는 **특정 상황**에서만:
  - 초대형 테이블에서 **스캔 시간이 과도**할 때(예: `estimate_percent=>5`)
  - **NDV/스큐**가 중요한 컬럼 위주로는 **높은 샘플** 또는 **FULL**(드묾)

### 샘플링 실습 비교

```sql
-- 1) AUTO
BEGIN
  DBMS_STATS.GATHER_TABLE_STATS(USER,'D_PRODUCT',
    estimate_percent => DBMS_STATS.AUTO_SAMPLE_SIZE,
    method_opt       => 'FOR ALL COLUMNS SIZE AUTO');
END;
/

-- 2) 저퍼센트(빠름, 정밀도↓ 위험)
BEGIN
  DBMS_STATS.GATHER_TABLE_STATS(USER,'D_PRODUCT',
    estimate_percent => 5,
    method_opt       => 'FOR ALL COLUMNS SIZE AUTO');
END;
/

-- 3) FULL(정확, 비용↑)
BEGIN
  DBMS_STATS.GATHER_TABLE_STATS(USER,'D_PRODUCT',
    estimate_percent => 100,
    method_opt       => 'FOR ALL COLUMNS SIZE AUTO');
END;
/
```
- `user_tab_col_statistics`·`user_indexes`(NDV/CF/leaf_blocks) 변화를 비교해 **비용/정확도 트레이드오프**를 체감하세요.

### 샘플링 체크리스트

- [ ] 대형 Fact는 **AUTO**로 시작 → 병목이면 **5~15%**로 절충
- [ ] 스큐 컬럼은 **히스토그램**을 병행(샘플이 낮으면 히스토그램 품질 저하)
- [ ] **Pending Stats**로 신규 통계를 검증 후 게시

---

## 5) **파티션 테이블** 통계 — 증분(Incremental) 전략

### 문제 배경

- 월/일 단위 파티션 테이블은 **매일 신규 파티션만** 변경
- 매 수집마다 **글로벌 통계**까지 재계산하면 **비효율**

### 증분 통계(시놉시스 기반) 설정

```sql
BEGIN
  DBMS_STATS.SET_TABLE_PREFS(USER,'F_SALES','INCREMENTAL','TRUE');
  DBMS_STATS.SET_TABLE_PREFS(USER,'F_SALES','GRANULARITY','AUTO');
END;
/
```
- 이제 **변경 파티션의 통계만 수집**하면 Oracle이 내부 **시놉시스**로 글로벌 통계를 **합성**합니다.

### 월별 로드 시나리오 (Partition Exchange + Stats)

```sql
-- 1) 스테이징 테이블에 신월 데이터 로드 후 통계 수집
CREATE TABLE F_SALES_STG AS SELECT * FROM F_SALES WHERE 1=0;

-- 벌크 로드/ETL 이후
BEGIN
  DBMS_STATS.GATHER_TABLE_STATS(USER,'F_SALES_STG',
    estimate_percent => DBMS_STATS.AUTO_SAMPLE_SIZE,
    method_opt       => 'FOR ALL COLUMNS SIZE 1');
END;
/

-- 2) 파티션 교체(메타데이터 동작, 빠름)
ALTER TABLE F_SALES EXCHANGE PARTITION P202404 WITH TABLE F_SALES_STG WITHOUT VALIDATION;

-- 3) 변경 파티션만 수집(증분)
BEGIN
  DBMS_STATS.GATHER_PARTITION_STATS(USER,'F_SALES','P202404', cascade=>TRUE);
END;
/

-- 4) 글로벌 통계는 시놉시스로 자동 합성
SELECT table_name, partition_name, num_rows, last_analyzed
FROM   user_tab_statistics
WHERE  table_name='F_SALES'
ORDER  BY partition_position NULLS LAST;
```

### 파티션 Granularity 옵션

- `granularity => 'PARTITION'` : 파티션만
- `granularity => 'GLOBAL'` : 글로벌만
- `granularity => 'GLOBAL AND PARTITION'` : 둘 다
- `granularity => 'AUTO'` : Oracle 판단(증분 활성화 시 권장)

### 파티션 환경의 히스토그램

- 주로 **차원 키/카테고리형**만 도수분포(Top-Frequency)
- 사실 테이블 연속형(금액/시간)은 **HYBRID**로 구간 분포만 반영
- 파티션별 분포가 크게 다르면 **파티션 통계**도 함께 고려

---

## 6) 운영 시나리오: “밤마다 빠르고 안전하게”

### 야간/배치 스케줄 (예: 매일 02:00)

```sql
BEGIN
  DBMS_SCHEDULER.CREATE_JOB(
    job_name        => 'JOB_NIGHTLY_STATS',
    job_type        => 'PLSQL_BLOCK',
    job_action      => q'[
      BEGIN
        -- 변경량 Flush
        DBMS_STATS.FLUSH_DATABASE_MONITORING_INFO;

        -- 변경 많은 핵심 테이블만 선별 (예: F_SALES 최근 파티션)
        DBMS_STATS.GATHER_TABLE_STATS(USER,'F_SALES', options=>'GATHER STALE',
          estimate_percent => DBMS_STATS.AUTO_SAMPLE_SIZE,
          method_opt       => 'FOR ALL COLUMNS SIZE 1',  -- 기본은 SIZE 1
          cascade          => TRUE,
          granularity      => 'AUTO');

        -- 스큐 컬럼은 주간에만 정밀 (부하 분산) 또는 월초 1회
        -- DBMS_STATS.GATHER_TABLE_STATS(USER,'D_PRODUCT',
        --   method_opt => 'FOR COLUMNS SIZE 254 BRAND', cascade=>TRUE);

        -- Pending으로 수집 후, 핵심 리포트 쿼리 검증(사전 테스트 세션) → 다음 단계서 Publish
      END;
    ]',
    start_date      => SYSTIMESTAMP,
    repeat_interval => 'FREQ=DAILY;BYHOUR=2;BYMINUTE=0;BYSECOND=0',
    enabled         => TRUE
  );
END;
/
```

### 검증-게시 파이프라인

1) **Pending**으로 수집(`PUBLISH=FALSE`)
2) **검증 세션**에서 핵심 보고/대시보드 쿼리 실행 → 플랜/카디널리티 확인
3) 이상 없으면 `DBMS_STATS.PUBLISH_PENDING_STATS`로 게시
4) 필요 시 **Baseline/Profile**로 플랜 안정화

---

## 7) 트러블슈팅 & 베스트 프랙티스

### 플랜 변동성/성능 저하 발생 시

- **E-Rows vs A-Rows** 비교로 **추정 오류 지점** 찾기
- 스큐 컬럼 히스토그램 부재/오래됨 → **재수집**
- 복합 조건(상관관계) → **확장 통계**(컬럼 그룹) 도입
- 파티션 교체 후 글로벌 추정이 이상 → **증분 설정/시놉시스 재점검**

```sql
-- 확장 통계(결합 선택도 보정) 예
BEGIN
  DBMS_STATS.CREATE_EXTENDED_STATS(USER,'D_CUSTOMER','(REGION, TIER)');
  DBMS_STATS.GATHER_TABLE_STATS(USER,'D_CUSTOMER');
END;
/
```

### 히스토그램 남발 방지

- **업무 질의 기반**으로 **정말 필요한 컬럼만**
- 바인드 사용 + 스큐 컬럼은 **ACS**가 학습되도록 **반복 실행 환경**을 허용
- 보고서 값군이 극단적으로 다르면 **SQL 분리(리터럴)**도 고려

### 샘플링 실패 예방

- 초대형 테이블에서 **저퍼센트 + 스큐 컬럼 히스토그램**은 위험(분포 왜곡)
- 문제 시 해당 테이블/컬럼만 **높은 샘플** 또는 **FULL**
- 항상 **Pending → 검증 → 게시**

### 통계 작업 가시성

```sql
-- 최근 통계 작업 로그
SELECT *
FROM   dba_optstat_operations
ORDER  BY start_time DESC FETCH FIRST 20 ROWS ONLY;

-- 차이 리포트(히스토그램/NDV/블록/행수 변화 감지)
SELECT DBMS_STATS.DIFF_TABLE_STATS_IN_HISTORY(USER,'D_PRODUCT', SYSTIMESTAMP-1, SYSTIMESTAMP)
FROM   dual;
```

---

## 8) 효과 관찰: 통계 변경 → 실행계획 차이

### 히스토그램 유무 (BRAND)

```sql
-- (A) 히스토그램 제거
BEGIN
  DBMS_STATS.GATHER_TABLE_STATS(USER,'D_PRODUCT',
    method_opt => 'FOR COLUMNS SIZE 1 BRAND', cascade=>TRUE);
END;
/
EXPLAIN PLAN FOR SELECT COUNT(*) FROM D_PRODUCT WHERE BRAND='B0';
EXPLAIN PLAN FOR SELECT COUNT(*) FROM D_PRODUCT WHERE BRAND='B47';
SELECT * FROM TABLE(DBMS_XPLAN.DISPLAY);

-- (B) 히스토그램 생성
BEGIN
  DBMS_STATS.GATHER_TABLE_STATS(USER,'D_PRODUCT',
    method_opt => 'FOR COLUMNS SIZE 254 BRAND', cascade=>TRUE);
END;
/
EXPLAIN PLAN FOR SELECT COUNT(*) FROM D_PRODUCT WHERE BRAND='B0';
EXPLAIN PLAN FOR SELECT COUNT(*) FROM D_PRODUCT WHERE BRAND='B47';
SELECT * FROM TABLE(DBMS_XPLAN.DISPLAY);
```
- 동일 쿼리의 **E-Rows/스캔 경로**가 바뀌는 것을 확인합니다.

### 증분 통계(신규 파티션) 효과

```sql
-- 신월 파티션 P202404 데이터 교체/수집 후, 4월 집계 쿼리의 플랜/E-Rows 변화를 관찰
EXPLAIN PLAN FOR
SELECT p.category, SUM(s.amount)
FROM   F_SALES s JOIN D_PRODUCT p ON p.prod_id=s.prod_id
WHERE  s.sales_dt BETWEEN DATE '2024-04-01' AND DATE '2024-05-01'
GROUP  BY p.category;

SELECT * FROM TABLE(DBMS_XPLAN.DISPLAY);
```

---

## 9) 최종 체크리스트(현업용)

- **변경량 기반**: `STALE_PERCENT` 적절화(핵심 테이블 5~10%)
- **플랜 안정화**: `NO_INVALIDATE=TRUE`, `PUBLISH=FALSE` → **Pending 검증 후 게시**
- **파티션 테이블**: `INCREMENTAL=TRUE`, `GRANULARITY=AUTO`, **PELT + PARTITION_STATS**
- **히스토그램**: 스큐 큰 컬럼만, `SIZE 254` 등 **선별 적용**
- **샘플링**: 기본 **AUTO**, 필요 시 테이블/컬럼 별도 **정밀/저퍼센트** 혼용
- **가시성**: `user_tab_modifications` / `dba_optstat_operations` / `DIFF_TABLE_STATS_*`
- **검증**: 항상 **E-Rows vs A-Rows**, 필요 시 **Extended Stats**
- **백업/복구/잠금**: `CREATE_STAT_TABLE` / `EXPORT/IMPORT/RESTORE` / `LOCK/UNLOCK`
- **자동화**: `DBMS_SCHEDULER`에 **야간 작업**, 주간/월간 **정밀 히스토그램** 분리

---

## 부록 A. 자주 쓰는 `DBMS_STATS` 옵션/문구 모음

- `estimate_percent => DBMS_STATS.AUTO_SAMPLE_SIZE`
- `method_opt => 'FOR ALL COLUMNS SIZE AUTO'`
- `method_opt => 'FOR COLUMNS SIZE 254 col1, FOR ALL COLUMNS SIZE 1'`
- `granularity => 'AUTO' | 'GLOBAL' | 'PARTITION' | 'GLOBAL AND PARTITION'`
- `options => 'GATHER' | 'GATHER STALE' | 'GATHER EMPTY' | 'GATHER AUTO'`
- `degree => DBMS_STATS.AUTO_DEGREE`
- `cascade => TRUE` (인덱스 통계 동시 수집)
- `SET_TABLE_PREFS(…,'INCREMENTAL','TRUE')` (증분)
- `SET_TABLE_PREFS(…,'PUBLISH','FALSE')` (Pending)
- `SET_TABLE_PREFS(…,'NO_INVALIDATE','TRUE')` (플랜 무효화 지연)
- `SET_TABLE_PREFS(…,'STALE_PERCENT','5')` (변경량 임계치)

---

## 부록 B. 한 눈에 보는 “정책 템플릿”

```sql
-- ① 기본 정책(스키마 공통)
BEGIN
  DBMS_STATS.GATHER_SCHEMA_STATS(
    ownname          => USER,
    options          => 'GATHER STALE',
    estimate_percent => DBMS_STATS.AUTO_SAMPLE_SIZE,
    method_opt       => 'FOR ALL COLUMNS SIZE AUTO',
    cascade          => TRUE,
    degree           => DBMS_STATS.AUTO_DEGREE
  );
END;
/

-- ② 핵심 Fact 테이블(F_SALES): 선호 설정
BEGIN
  DBMS_STATS.SET_TABLE_PREFS(USER,'F_SALES','STALE_PERCENT','5');
  DBMS_STATS.SET_TABLE_PREFS(USER,'F_SALES','NO_INVALIDATE','TRUE');
  DBMS_STATS.SET_TABLE_PREFS(USER,'F_SALES','PUBLISH','FALSE');
  DBMS_STATS.SET_TABLE_PREFS(USER,'F_SALES','INCREMENTAL','TRUE');
  DBMS_STATS.SET_TABLE_PREFS(USER,'F_SALES','GRANULARITY','AUTO');
END;
/

-- ③ 스큐 컬럼(브랜드) 히스토그램: 주간/월간 분리
BEGIN
  DBMS_STATS.GATHER_TABLE_STATS(
    ownname    => USER,
    tabname    => 'D_PRODUCT',
    method_opt => 'FOR COLUMNS SIZE 254 BRAND, FOR ALL COLUMNS SIZE 1',
    cascade    => TRUE
  );
END;
/
```

---

### 결론

- **전략적 통계수집**은 “**정확함**×**적시성**×**안정성**”의 균형 예술입니다.
- **DBMS_STATS**의 **Preferences**(STALE_PERCENT/NO_INVALIDATE/PUBLISH/INCREMENTAL/GRANULARITY)와
  **히스토그램/샘플링/증분 통계**를 상황별로 조합하면 **성능은 빠르게**, **플랜은 안정적으로** 유지할 수 있습니다.
- 마지막 단계는 언제나 **사실검증**: **E-Rows vs A-Rows** / **AWR/ASH** / **핵심 리포트 체감 성능**입니다.
