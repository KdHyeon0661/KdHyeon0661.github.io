---
layout: post
title: AWS - Flink
date: 2025-07-28 21:20:23 +0900
category: AWS
---
# Apache Flink 애플리케이션 고급 처리 — AWS Kinesis Data Analytics for Apache Flink

## 0. 왜 Flink인가 — 핵심 가치 요약

- **Event Time 우선**: 지연/재전송/역순 이벤트에도 정확한 집계.
- **Exactly-once**: 소스→연산→싱크 전체 경로의 **단 한 번 처리** 보장.
- **상태 기반(Stateful)** 스트리밍: 세션·패턴·조인·머신러닝 전처리 등 복잡 로직.
- **탄력·복구(Checkpoint/Savepoint)**: 중단 후 **그 위치**에서 재개.

---

## 1. 시간(Time)과 워터마크(Watermark)

### 1.1 시간 특성
| 시간 개념 | 기준 | 장점 | 단점 |
|---|---|---|---|
| Processing Time | 작업자(머신) 시계 | 지연 최소 | 데이터 지연/역순에 취약 |
| Ingestion Time | 시스템 유입 시각 | 간편 | 정밀한 지연 제어 한계 |
| **Event Time** | **이벤트 자체 타임스탬프** | 지연·역순 견고 | 워터마크 설계 필요 |

```java
// Flink 1.12+ 기본 EventTime, WatermarkStrategy로 정의
DataStream<Event> stream = env
  .fromSource(source, WatermarkStrategy
      .<Event>forBoundedOutOfOrderness(Duration.ofSeconds(10))
      .withTimestampAssigner((e, ts) -> e.getEventTimeMillis()),
  "kinesis-source");
```

### 1.2 워터마크 설계 공식 감각
- 최대 무질서(Out-of-Orderness) 허용치를 $$\Delta$$ 라고 하면,
  $$
  W(t) = \max(\text{seen\_event\_time}) - \Delta
  $$
- $$\Delta$$ 를 줄이면 지연이 감소(빠른 결과)하나 **늦은 이벤트 손실↑**.
- 허용 지연과 정확도의 트레이드오프를 **서비스 SLO**에 맞춰 선택.

---

## 2. 윈도우(Window) — 고정/슬라이딩/세션/글로벌

### 2.1 기본 패턴
```java
stream
  .keyBy(e -> e.userId())
  .window(TumblingEventTimeWindows.of(Time.minutes(1)))
  .reduce(new SumReducer());
```

- **Tumbling**: 겹침 없음(예: 1분 고정)
- **Sliding**: 겹침(예: 5분 윈도우, 1분 슬라이드)
- **Session**: 유휴 간격 기반(예: inactivity 10분)

```java
// 세션 윈도우 + 동적 세션 갭(사용자별)
.keyBy(Event::userId)
.window(ProcessingTimeSessionWindows.withDynamicGap(e -> Time.seconds(e.gap())))
.aggregate(new AggFn(), new ProcessWindowFunction<...>(){...});
```

### 2.2 늦은 이벤트(Allowed Lateness)와 사이드아웃
```java
final OutputTag<Event> late = new OutputTag<Event>("late"){};

stream
  .keyBy(Event::userId)
  .window(TumblingEventTimeWindows.of(Time.minutes(1)))
  .allowedLateness(Time.seconds(30))
  .sideOutputLateData(late)
  .reduce(new SumReducer());

DataStream<Event> lateStream = result.getSideOutput(late);
```
- **allowedLateness**: 워터마크 이후에도 추가 집계 허용.
- 사이드아웃: 완전히 늦은 이벤트를 별도 경로로 저장/보정.

---

## 3. 상태(State) — RocksDB, Value/List/Map/Reducing/Aggregating

### 3.1 Keyed State 사용 예
```java
public class SumByUser extends RichFlatMapFunction<Event, UserSum> {
  private transient ValueState<Long> sum;

  @Override
  public void open(Configuration parameters) {
    ValueStateDescriptor<Long> desc =
      new ValueStateDescriptor<>("sum", Long.class);
    desc.enableTimeToLive(StateTtlConfig
         .newBuilder(Time.days(7))
         .cleanupFullSnapshot()
         .build());
    sum = getRuntimeContext().getState(desc);
  }

  @Override
  public void flatMap(Event e, Collector<UserSum> out) throws Exception {
    long s = Optional.ofNullable(sum.value()).orElse(0L) + e.value();
    sum.update(s);
    out.collect(new UserSum(e.userId(), s));
  }
}
```

- **TTL**: 오래된 상태 자동 정리 → 메모리/디스크 부담 완화.
- **RocksDB 상태 백엔드**: 대규모 상태(GB~TB) 안정적 관리.

```java
// (Flink 1.15+) RocksDB 설정 예
Configuration conf = new Configuration();
conf.setString("state.backend", "rocksdb");
conf.setString("state.checkpoints.dir", "s3://my-checkpoints/jobA/");
conf.setString("state.savepoints.dir", "s3://my-savepoints/jobA/");
```

### 3.2 타이머(TimerService) — per-key 스케줄링
```java
public class InactivityAlert
  extends KeyedProcessFunction<String, Event, Alert> {
  private transient ValueState<Long> timerTs;

  @Override
  public void processElement(Event e, Context ctx, Collector<Alert> out) throws Exception {
    Long old = timerTs.value();
    if (old != null) ctx.timerService().deleteProcessingTimeTimer(old);
    long ts = ctx.timerService().currentProcessingTime() + 5 * 60 * 1000;
    ctx.timerService().registerProcessingTimeTimer(ts);
    timerTs.update(ts);
  }

  @Override
  public void onTimer(long timestamp, OnTimerContext ctx, Collector<Alert> out) {
    out.collect(new Alert(ctx.getCurrentKey(), "inactive-5m"));
  }
}
```

---

## 4. Exactly-once 처리 — 체크포인트, 싱크 트랜잭션

### 4.1 체크포인트(Checkpoint) & 세이브포인트(Savepoint)
```java
env.enableCheckpointing(30_000); // 30s
CheckpointConfig cfg = env.getCheckpointConfig();
cfg.setCheckpointingMode(CheckpointingMode.EXACTLY_ONCE);
cfg.setMinPauseBetweenCheckpoints(10_000);
cfg.setExternalizedCheckpointCleanup(RETAIN_ON_CANCELLATION);
```
- **Externalized**: 작업 취소 후에도 체크포인트 보존 → 빠른 재시작.
- **Savepoint**: 계획된 배포/업그레이드용 스냅샷(경로 지정).

### 4.2 S3/Redshift/OpenSearch 등 싱크의 exactly-once
- 파일 기반: **FileSink/StreamingFileSink** 는 2-Phase commit(마지막 rename)로 정확성 보장.
```java
final FileSink<String> sink = FileSink
  .forRowFormat(new Path("s3://data-lake/refined/"), new SimpleStringEncoder<String>("UTF-8"))
  .withRollingPolicy(OnCheckpointRollingPolicy.build())
  .build();

stream.map(Serializer::toLine).sinkTo(sink);
```
- JDBC/외부 시스템: **2PC 지원 싱크** 사용 또는 **idempotent upsert** / **트랜잭션**으로 보장.

---

## 5. 스트림 결합(Join) — 윈도우 조인/인터벌 조인/유저정의

### 5.1 윈도우 조인
```java
DataStream<A> a = ...
DataStream<B> b = ...
a.join(b)
 .where(A::key).equalTo(B::key)
 .window(TumblingEventTimeWindows.of(Time.minutes(5)))
 .apply((ax, bx) -> new Joined(ax.id(), bx.id(), ax.ts()));
```

### 5.2 인터벌 조인(Interval Join) — 두 스트림의 시간 관계
```java
a.keyBy(A::key)
 .intervalJoin(b.keyBy(B::key))
 .between(Time.seconds(-10), Time.seconds(30))
 .process(new ProcessJoinFunction<A,B,Out>(){...});
```

- **사용처**: 클릭 후 30초 내 구매 연결, 센서값 융합 등.

---

## 6. CEP(Complex Event Processing) — 패턴 탐지

```java
Pattern<Event, ?> pattern = Pattern.<Event>begin("click")
  .where(e -> e.type().equals("click"))
  .next("purchase")
  .where(e -> e.type().equals("purchase"))
  .within(Time.minutes(10));

PatternStream<Event> ps = CEP.pattern(stream.keyBy(Event::userId), pattern);

DataStream<Fraud> alerts = ps.process(new PatternProcessFunction<Event, Fraud>(){
  @Override
  public void processMatch(Map<String, List<Event>> match, Context ctx, Collector<Fraud> out) {
    out.collect(new Fraud(match.get("click").get(0).userId(), "click->purchase"));
  }
});
```

- 누락/반복/선택/단계적 조건 등 **복합 시퀀스** 인식.

---

## 7. Flink SQL / Table API — 선언형 스트리밍

### 7.1 Kinesis + JSON 테이블 예(카탈로그·DDL)
```sql
CREATE TABLE clicks (
  user_id STRING,
  url STRING,
  ts TIMESTAMP(3),
  WATERMARK FOR ts AS ts - INTERVAL '10' SECOND
) WITH (
  'connector' = 'kinesis',
  'stream' = 'clicks',
  'aws.region' = 'ap-northeast-2',
  'format' = 'json',
  'json.fail-on-missing-field' = 'false'
);

-- 1분 Tumbling 집계
CREATE TABLE pageviews_1m (
  window_start TIMESTAMP(3),
  window_end TIMESTAMP(3),
  url STRING,
  pv BIGINT
) WITH ('connector'='blackhole');

INSERT INTO pageviews_1m
SELECT
  window_start, window_end, url, COUNT(*)
FROM TABLE(
  TUMBLE(TABLE clicks, DESCRIPTOR(ts), INTERVAL '1' MINUTE)
)
GROUP BY window_start, window_end, url;
```

- **WATERMARK** 구문으로 이벤트 지연 허용.
- KDA-Flink에서도 동일 컨셉(버전별 커넥터 옵션 확인).

---

## 8. 직렬화/스키마 — Avro/Protobuf/JSON 선택 기준

| 포맷 | 장점 | 단점 | 권장 |
|---|---|---|---|
| JSON | 가독성·유연 | 무겁고 스키마 약함 | 디버깅/초기 |
| **Avro** | 진화·호환·경량 | 스키마 관리 필요 | API·데이터 레이크 |
| Protobuf | 매우 경량·강타입 | 필드 관리·툴링 | 고성능·내부 RPC |

```java
// Avro SpecificRecord 직렬화 예 (Kafka/Kinesis Serde 유사)
Properties p = new Properties();
p.setProperty("format", "avro");
```

- **스키마 진화**: 필드 추가는 대체로 호환, 타입 변경/삭제는 주의 → **버전 관리** 필수.

---

## 9. AWS에서 Flink: Kinesis Data Analytics for Apache Flink

### 9.1 아키텍처(실전)
```
Kinesis Data Streams (ingest)
   → Kinesis Data Analytics for Apache Flink (compute, state, checkpoints on S3)
       → S3(FileSink Parquet) / OpenSearch / Redshift (JDBC/Firehose) / DynamoDB
       → CloudWatch Logs (logging & metrics)
```

### 9.2 IAM 역할
- **Kinesis Consume**, **S3 Checkpoint/Savepoint**, **S3 Sink**, **CloudWatch** 권한.
- SSE-KMS 사용 시 **KMS 키 정책에 역할 허용**.

### 9.3 JAR 배포
- Maven 빌드 → JAR → **S3 업로드** → KDA 콘솔에서 **Artifact 지정** → 병렬도 설정.

```xml
<!-- pom.xml 핵심 -->
<dependency>
  <groupId>org.apache.flink</groupId>
  <artifactId>flink-streaming-java</artifactId>
  <version>${flink.version}</version>
</dependency>
<dependency>
  <groupId>software.amazon.kinesis</groupId>
  <artifactId>amazon-kinesis-connector-flink</artifactId>
  <version>${kda.compat.version}</version>
</dependency>
```

### 9.4 체크포인트/세이브포인트(S3)
- KDA 설정에서 **Checkpoint 주기**, **외부 저장소(S3)** 지정.
- 애플리케이션 **Stop with savepoint** → 롤링 업그레이드/회귀.

### 9.5 모니터링/오토스케일(핵심)
- **CloudWatch 지표**: `ManagedKinesisShardMillisBehindLatest`, `numRecordsInPerSecond`, `backPressuredTimeMsPerSecond`, `busyTimeMsPerSecond`, `checkpointSize`.
- **병목 탐지**: BackPressure UI(운영 탭) 또는 지표 알람.
- **병렬도 조정**: 병목 오퍼레이터에 맞춰 **Rebalance** 또는 **Rescale**.

---

## 10. 엔드투엔드 예제(ETL + 이상 탐지 + S3 Parquet)

### 10.1 도메인 모델
```java
public record Click(String userId, String url, long ts, double spend) {}
public record Alert(String userId, String code, long ts) {}
```

### 10.2 소스(Kinesis) + 워터마크
```java
DataStream<Click> clicks = env.fromSource(
  KinesisSources.json("clicks", region, consumerProps, Click.class),
  WatermarkStrategy.<Click>forBoundedOutOfOrderness(Duration.ofSeconds(10))
    .withTimestampAssigner((e, ts) -> e.ts()),
  "kinesis-clicks");
```

### 10.3 상태 기반 이상 탐지(5분 내 누적 결제 > 임계)
```java
clicks
  .keyBy(Click::userId)
  .window(SlidingEventTimeWindows.of(Time.minutes(5), Time.minutes(1)))
  .aggregate(new AggregateFunction<Click, Double, Double>() {
      public Double createAccumulator(){ return 0.0; }
      public Double add(Click v, Double acc){ return acc + v.spend(); }
      public Double getResult(Double acc){ return acc; }
      public Double merge(Double a, Double b){ return a + b; }
    },
    new ProcessWindowFunction<Double, Alert, String, TimeWindow>(){
      public void process(String key, Context ctx, Iterable<Double> vals, Collector<Alert> out){
        double total = vals.iterator().next();
        if (total > 1000.0)
          out.collect(new Alert(key, "HIGH_SPEND_5M", ctx.window().getEnd()));
      }
    })
  .name("high-spend-detector");
```

### 10.4 S3 Parquet 싱크
```java
FileSink<String> sink = FileSink
  .forRowFormat(new Path("s3://data-lake/etl/refined/"), new SimpleStringEncoder<String>("UTF-8"))
  .withRollingPolicy(OnCheckpointRollingPolicy.build())
  .build();

clicks
  .map(c -> toParquetLine(c)) // 실제론 FileSink<RowData/ParquetWriter> 사용(커넥터/포맷)
  .sinkTo(sink)
  .name("s3-parquet-sink");
```

> 실제 Parquet는 **FileSink + ParquetWriterFactory**(Flink Formats) 사용을 권장.

---

## 11. 테스트 전략 — MiniCluster, Golden Test, Watermark 시뮬레이션

```java
@ExtendWith(MiniClusterExtension.class)
public class PipelineTest {
  @RegisterExtension
  static final MiniClusterExtension MINI_CLUSTER =
     new MiniClusterExtension(new MiniClusterResourceConfiguration.Builder()
         .setNumberTaskManagers(1).setNumberSlotsPerTaskManager(2).build());

  @Test
  void aggregate_shouldAlert() throws Exception {
    StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();
    // Test source with event times
    // Assert collected alerts with TestSink
  }
}
```

- **Deterministic Test**: 고정 입력/워터마크로 윈도우 결과 검증.
- **Stateful UDF**: JUnit + Embedded RocksDB 임시 디렉토리.

---

## 12. 운영 — 백프레셔, 재처리, 데이터 품질

- **Backpressure**: 느린 싱크/연산자 → **병렬도 상향** 또는 **버퍼 전략 조정**.
- **Reprocessing**: Kinesis 보존 기간 내 **타임라인 재소비** 또는 **세이브포인트 롤백**.
- **DQ(Data Quality)**: 스키마 검증, null/범위 체크, **사이드아웃**으로 격리 후 재처리.

---

## 13. 모니터링·알람 — CloudWatch + Flink Metrics

- **지표**: `numRecordsInOutPerSecond`, `busy/backpressured time`, `checkpointDuration`, `checkpointAlignment`, `checkpointFailed`.
- **알람 예시**: BackPressure 60%↑ 5분 지속, Checkpoint 실패 3회 연속, DataFreshness(소스 레이트 급감).
- **로그**: KDA 애플리케이션 로그 그룹/스트림 분리, **예외 스택 추적** 필수.

---

## 14. 성능·비용 최적화

- **RocksDB 옵션**: 블룸필터/압축/메모리 튜닝, Write Buffer/Compaction 조정.
- **윈도우 병렬도**: 키 스큐 해결(해시 프리픽스/2단계 집계).
- **S3 파일 크기**: **체크포인트 롤링** 정책으로 소파일 방지(128MB+ 권장).
- **Kinesis 샤드 수**: Ingestion 레이트와 병행 — **MillisBehindLatest 0 근접** 유지.
- **비용**: KDA 실행 시간 + Kinesis + S3 + CloudWatch → **유휴시 중지**, 데이터 형식 **Parquet**로 스캔량↓.

---

## 15. 배포 플레이북(KDA-Flink)

1) **Kinesis Stream**: `clicks`, 분당 레코드/샤드 산정
2) **IAM Role**: source(read), S3(checkpoint/sink), CW logs, KMS
3) **S3**: `s3://artifacts/my-job.jar`, `s3://checkpoints/my-job/`
4) **KDA App 생성**: jar path, main class, 병렬도, checkpoint interval
5) **Config**: env vars(스키마/KMS/key), Flink config override(rocksdb)
6) **실행/모니터링**: CloudWatch 대시보드/알람
7) **업그레이드**: **Stop with savepoint → 새 jar → From savepoint**
8) **장애**: Auto-restart, 최근 **Externalized checkpoint**로 재개

---

## 16. 자주 만나는 장애/해결

| 증상 | 원인 | 해결 |
|---|---|---|
| Checkpoint alignment 시간 급증 | 싱크 느림/네트워크 불균형 | 싱크 병렬도↑, 네트워크·스토리지 IO 확인 |
| MillisBehindLatest 증가 | Kinesis 샤드 부족/백프레셔 | 샤드 수↑, 연산자 튜닝 |
| 소파일 폭증 | 짧은 윈도우/롤링/체크포인트 | 롤링 기준 조정, 다운스트림 컴팩션 |
| 상태 폭증/GC | TTL 미설정/키스큐 | TTL, 사전 집계, 키 균등화 |
| 늦은 이벤트 유실 | 워터마크/허용지연 과소 | allowedLateness↑, 사이드아웃 처리 |

---

## 17. 보안 — VPC, KMS, 비밀관리

- **VPC 연결**: 프라이빗 엔드포인트로 싱크 접근(예: 내부 OpenSearch/Databases).
- **KMS**: S3 체크포인트/결과, Kinesis 데이터 스트림 암호화 키 별도 관리.
- **시크릿**: Secrets Manager/Parameter Store에서 크리덴셜 주입(환경변수·커넥터).

---

## 18. 수학적 감 — 워터마크 지연과 품질의 균형

- **지연 한계(레이트-지연 상관)**:
  $$
  \text{ResultLatency} \approx \Delta + \text{WindowSize} + \epsilon
  $$
  여기서 $$\Delta$$ 는 워터마크 무질서 허용, $$\epsilon$$ 은 시스템 오버헤드.
- **정확도**는 $$\Delta$$ 가 클수록 증가(늦은 이벤트 포함)하나 레이턴시↑.

---

## 19. 마무리 — 실전 요약 체크리스트

- [ ] **Event Time + Watermark**: 도메인 지연 특성 기반 $$\Delta$$ 설정
- [ ] **상태·RocksDB**: TTL/메모리/컴팩션 튜닝
- [ ] **Exactly-once**: 체크포인트/2PC 싱크/Externalized on
- [ ] **윈도우·조인·CEP**: 요구사항에 맞는 패턴 선택
- [ ] **Flink SQL**: 빠른 검증·운영 일원화
- [ ] **KDA-Flink 배포**: Savepoint 롤링, CloudWatch 모니터링
- [ ] **파일·포맷**: Parquet+롤링/컴팩션, 소파일 방지
- [ ] **보안**: VPC/KMS/Secrets, 최소권한 IAM
- [ ] **비용**: Kinesis 샤드·KDA 시간·S3/Athena 스캔 최적화

---

## 부록 A) 간단 Node/Kinesis 프로듀서(테스트용)
```js
// npm i @aws-sdk/client-kinesis
const { KinesisClient, PutRecordsCommand } = require("@aws-sdk/client-kinesis");
const client = new KinesisClient({ region: "ap-northeast-2" });

(async () => {
  const Records = Array.from({length: 10}).map((_,i) => ({
    Data: Buffer.from(JSON.stringify({
      userId:`u-${i%3}`, url:"/buy", ts:Date.now() - (i%5)*1000, spend: Math.random()*100
    })), PartitionKey: `p-${i%3}`
  }));
  await client.send(new PutRecordsCommand({ StreamName:"clicks", Records }));
  console.log("sent");
})();
```

## 부록 B) Maven 프로파일(로컬/운영 구분)
```xml
<profiles>
  <profile>
    <id>local</id>
    <properties>
      <flink.parallelism>2</flink.parallelism>
    </properties>
  </profile>
  <profile>
    <id>prod</id>
    <properties>
      <flink.parallelism>16</flink.parallelism>
    </properties>
  </profile>
</profiles>
```

## 부록 C) 운영용 Flink 설정 스니펫
```properties
# flink-conf.yaml (개요)
state.backend=rocksdb
state.checkpoints.dir=s3://checkpoints/jobA/
state.savepoints.dir=s3://savepoints/jobA/
execution.checkpointing.interval=30000
execution.checkpointing.mode=EXACTLY_ONCE
execution.checkpointing.unaligned=true
taskmanager.numberOfTaskSlots=4
```

---

### 결론
Flink는 **시간·상태·정확성**의 3박자를 갖춘 실시간 엔진이며, KDA-Flink로 **운영 복잡도 없이** AWS 상에서 대규모 스트리밍 파이프라인을 구축할 수 있다. 본 가이드의 **워터마크/상태/체크포인트/싱크/모니터링** 원리를 그대로 적용하면, **지연·역순·장애** 상황에서도 **정확하고 비용 효율적**인 실시간 분석·ETL을 실현할 수 있다.
